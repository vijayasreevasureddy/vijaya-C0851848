{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VIJAYA_C0851848_200_Neurons.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "cWACPRL869I4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "942041cb-91c2-4fbb-ef11-496e6dcf4d65"
      },
      "cell_type": "code",
      "source": [
        "!pip install gym >/dev/null\n",
        "!pip install JSAnimation >/dev/null\n",
        "%pip install -U gym>=0.21.0\n",
        "%pip install -U gym[atari,accept-rom-license]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.7/dist-packages (0.25.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (4.12.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (0.0.8)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.21.6)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.3.0)\n",
            "Requirement already satisfied: ale-py~=0.7.5 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (0.7.5)\n",
            "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (0.4.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py~=0.7.5->gym[accept-rom-license,atari]) (5.9.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (4.64.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.23.0)\n",
            "Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (0.4.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (3.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2022.6.15)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "wotUOa_e6edP"
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from JSAnimation.IPython_display import display_animation\n",
        "from matplotlib import animation\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML\n",
        "\n",
        "def display_frames_as_gif(frames):\n",
        "    \"\"\"\n",
        "    Displays a list of frames as a gif, with controls\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 144)\n",
        "    patch = plt.imshow(frames[0])\n",
        "    plt.axis('off')\n",
        "\n",
        "    def animate(i):\n",
        "        patch.set_data(frames[i])\n",
        "\n",
        "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
        "    HTML(anim.to_jshtml())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R66_INeZ9nYX"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 2: Playing Pong"
      ]
    },
    {
      "metadata": {
        "id": "MtT2GyK_6edc",
        "outputId": "04c6e72f-a341-4673-c9ef-279b17f0dbf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import gym\n",
        "env = gym.make('Pong-v0')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py:594: UserWarning: \u001b[33mWARN: The environment Pong-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  f\"The environment {id} is out of date. You should consider \"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:330: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "oRE6WmXQJ1Z0",
        "outputId": "7a9e9fb2-fa17-4d40-db61-10b8c16b9395",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "env.action_space"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discrete(6)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "yl_9d4HFJ31W",
        "outputId": "592969cc-603a-482e-dfcc-1821e7953b99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "env.observation_space"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Box(0, 255, (210, 160, 3), uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "trwRXI-h6eeI",
        "outputId": "f3ca9453-a418-4b8a-bb69-110a5e7ee127",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# Run a demo of the environment\n",
        "observation = env.reset()\n",
        "cumulated_reward = 0\n",
        "\n",
        "frames = []\n",
        "for t in range(1000):\n",
        "#     print(observation)\n",
        "    frames.append(env.render(mode = 'rgb_array'))\n",
        "    # very stupid agent, just makes a random action within the allowd action space\n",
        "    action = env.action_space.sample()\n",
        "#     print(\"Action: {}\".format(t+1))    \n",
        "    observation, reward, done, info = env.step(action)\n",
        "#     print(reward)\n",
        "    cumulated_reward += reward\n",
        "    if done:\n",
        "        print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n",
        "        break\n",
        "print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n",
        "\n",
        "env.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  \"The argument mode in render method is deprecated; \"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:298: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
            "  \"No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  \"Core environment is written in old step API which returns one bool instead of two. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode finished without success, accumulated reward = -16.0\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "3zZTecVWLLes"
      },
      "cell_type": "code",
      "source": [
        "def sigmoid(x): \n",
        "  return 1.0 / (1.0 + np.exp(-x)) # sigmoid \"squashing\" function to interval [0,1]\n",
        "\n",
        "def prepro(I):\n",
        "  \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n",
        "  I = I[35:195] # crop\n",
        "  I = I[::2,::2,0] # downsample by factor of 2\n",
        "  I[I == 144] = 0 # erase background (background type 1)\n",
        "  I[I == 109] = 0 # erase background (background type 2)\n",
        "  I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
        "  return I.astype(np.float).ravel()\n",
        "\n",
        "def policy_forward(x):\n",
        "  h = np.dot(model['W1'], x)\n",
        "  h[h<0] = 0 # ReLU nonlinearity\n",
        "  logp = np.dot(model['W2'], h)\n",
        "  p = sigmoid(logp)\n",
        "  return p, h # return probability of taking action 2, and hidden state\n",
        "\n",
        "def model_step(model, observation, prev_x):\n",
        "  # preprocess the observation, set input to network to be difference image\n",
        "  cur_x = prepro(observation)\n",
        "  x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
        "  prev_x = cur_x\n",
        "  \n",
        "  # forward the policy network and sample an action from the returned probability\n",
        "  aprob, _ = policy_forward(x)\n",
        "  action = 2 if aprob >= 0.5 else 3 # roll the dice!\n",
        "  \n",
        "  return action, prev_x\n",
        "\n",
        "def play_game(env, model):\n",
        "  observation = env.reset()\n",
        "\n",
        "  frames = []\n",
        "  cumulated_reward = 0\n",
        "\n",
        "  prev_x = None # used in computing the difference frame\n",
        "\n",
        "  for t in range(1000):\n",
        "      frames.append(env.render(mode = 'rgb_array'))\n",
        "      action, prev_x = model_step(model, observation, prev_x)\n",
        "      observation, reward, done, info = env.step(action)\n",
        "      cumulated_reward += reward\n",
        "      if done:\n",
        "          print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n",
        "          break\n",
        "  print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n",
        "  display_frames_as_gif(frames)\n",
        "  env.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6gWvZQ7AQLQt"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 3: Policy Gradient from Scratch"
      ]
    },
    {
      "metadata": {
        "id": "eqFm7hqcItWl"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# model initialization\n",
        "H = 200 # number of hidden layer neurons\n",
        "D = 80 * 80 # input dimensionality: 80x80 grid\n",
        "model = {}\n",
        "model['W1'] = np.random.randn(H,D) / np.sqrt(D) # \"Xavier\" initialization\n",
        "model['W2'] = np.random.randn(H) / np.sqrt(H)\n",
        "\n",
        "# import pickle\n",
        "# model = pickle.load(open('model.pkl', 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TwjiwKisQM19"
      },
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "batch_size = 10 # every how many episodes to do a param update?\n",
        "# learning_rate = 1e-8\n",
        "learning_rate = 1e-8\n",
        " \n",
        "gamma = 0.99 # discount factor for reward\n",
        "decay_rate = 0.99 # decay factor for RMSProp leaky sum of grad^2\n",
        "  \n",
        "grad_buffer = { k : np.zeros_like(v) for k,v in model.items() } # update buffers that add up gradients over a batch\n",
        "rmsprop_cache = { k : np.zeros_like(v) for k,v in model.items() } # rmsprop memory\n",
        "\n",
        "\n",
        "def policy_backward(epx, eph, epdlogp):\n",
        "  \"\"\" backward pass. (eph is array of intermediate hidden states) \"\"\"\n",
        "  dW2 = np.dot(eph.T, epdlogp).ravel()\n",
        "  dh = np.outer(epdlogp, model['W2'])\n",
        "  dh[eph <= 0] = 0 # backpro prelu\n",
        "  dW1 = np.dot(dh.T, epx)\n",
        "  return {'W1':dW1, 'W2':dW2}\n",
        "\n",
        "def discount_rewards(r):\n",
        "  \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
        "  discounted_r = np.zeros_like(r, dtype=np.float32)\n",
        "  running_add = 0\n",
        "  for t in reversed(range(0, r.size)):\n",
        "    if r[t] != 0: running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n",
        "    running_add = running_add * gamma + r[t]\n",
        "    discounted_r[t] = running_add\n",
        "  return discounted_r\n",
        "\n",
        "def train_model(env, model, total_episodes = 100):\n",
        "  hist = []\n",
        "  observation = env.reset()\n",
        "\n",
        "  prev_x = None # used in computing the difference frame\n",
        "  xs,hs,dlogps,drs = [],[],[],[]\n",
        "  running_reward = None\n",
        "  reward_sum = 0\n",
        "  episode_number = 0\n",
        "\n",
        "  while True:\n",
        "    # preprocess the observation, set input to network to be difference image\n",
        "    cur_x = prepro(observation)\n",
        "    x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
        "    prev_x = cur_x\n",
        "\n",
        "    # forward the policy network and sample an action from the returned probability\n",
        "    aprob, h = policy_forward(x)\n",
        "    action = 2 if np.random.uniform() < aprob else 3 # roll the dice!\n",
        "\n",
        "    # record various intermediates (needed later for backprop)\n",
        "    xs.append(x) # observation\n",
        "    hs.append(h) # hidden state\n",
        "    y = 1 if action == 2 else 0 # a \"fake label\"\n",
        "    dlogps.append(y - aprob) # grad that encourages the action that was taken to be taken (see http://cs231n.github.io/neural-networks-2/#losses if confused)\n",
        "\n",
        "    # step the environment and get new measurements\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    reward_sum += reward\n",
        "\n",
        "    drs.append(reward) # record reward (has to be done after we call step() to get reward for previous action)\n",
        "\n",
        "    if done: # an episode finished\n",
        "      episode_number += 1\n",
        "\n",
        "      # stack together all inputs, hidden states, action gradients, and rewards for this episode\n",
        "      epx = np.vstack(xs)\n",
        "      eph = np.vstack(hs)\n",
        "      epdlogp = np.vstack(dlogps)\n",
        "      epr = np.vstack(drs)\n",
        "      xs,hs,dlogps,drs = [],[],[],[] # reset array memory\n",
        "\n",
        "      # compute the discounted reward backwards through time\n",
        "      discounted_epr = discount_rewards(epr)\n",
        "      # standardize the rewards to be unit normal (helps control the gradient estimator variance)\n",
        "      discounted_epr -= np.mean(discounted_epr)\n",
        "      discounted_epr /= np.std(discounted_epr)\n",
        "\n",
        "      epdlogp *= discounted_epr # modulate the gradient with advantage (PG magic happens right here.)\n",
        "      grad = policy_backward(epx, eph, epdlogp)\n",
        "      for k in model: grad_buffer[k] += grad[k] # accumulate grad over batch\n",
        "\n",
        "      # perform rmsprop parameter update every batch_size episodes\n",
        "      if episode_number % batch_size == 0:\n",
        "        for k,v in model.items():\n",
        "          g = grad_buffer[k] # gradient\n",
        "          rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1 - decay_rate) * g**2\n",
        "          model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n",
        "          grad_buffer[k] = np.zeros_like(v) # reset batch gradient buffer\n",
        "\n",
        "      # boring book-keeping\n",
        "      running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
        "      hist.append((episode_number, reward_sum, running_reward))\n",
        "      print ('resetting env. episode %f, reward total was %f. running mean: %f' % (episode_number, reward_sum, running_reward))\n",
        "      reward_sum = 0\n",
        "      observation = env.reset() # reset env\n",
        "      prev_x = None\n",
        "      if episode_number == total_episodes: return hist\n",
        "\n",
        "      if reward != 0: # Pong has either +1 or -1 reward exactly when game ends.\n",
        "        print (('ep %d: game finished, reward: %f' % (episode_number, reward)) + ('' if reward == -1 else ' !!!!!!!!'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G6Ka_5Vl9Orm",
        "outputId": "ee0a38d6-9f59-4e4f-daac-099abd62b76c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "%time hist1 = train_model(env, model, total_episodes=4000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resetting env. episode 1.000000, reward total was -21.000000. running mean: -21.000000\n",
            "resetting env. episode 2.000000, reward total was -19.000000. running mean: -20.980000\n",
            "resetting env. episode 3.000000, reward total was -20.000000. running mean: -20.970200\n",
            "resetting env. episode 4.000000, reward total was -20.000000. running mean: -20.960498\n",
            "resetting env. episode 5.000000, reward total was -19.000000. running mean: -20.940893\n",
            "resetting env. episode 6.000000, reward total was -21.000000. running mean: -20.941484\n",
            "resetting env. episode 7.000000, reward total was -21.000000. running mean: -20.942069\n",
            "resetting env. episode 8.000000, reward total was -21.000000. running mean: -20.942649\n",
            "resetting env. episode 9.000000, reward total was -21.000000. running mean: -20.943222\n",
            "resetting env. episode 10.000000, reward total was -21.000000. running mean: -20.943790\n",
            "resetting env. episode 11.000000, reward total was -21.000000. running mean: -20.944352\n",
            "resetting env. episode 12.000000, reward total was -20.000000. running mean: -20.934908\n",
            "resetting env. episode 13.000000, reward total was -21.000000. running mean: -20.935559\n",
            "resetting env. episode 14.000000, reward total was -20.000000. running mean: -20.926204\n",
            "resetting env. episode 15.000000, reward total was -20.000000. running mean: -20.916942\n",
            "resetting env. episode 16.000000, reward total was -21.000000. running mean: -20.917772\n",
            "resetting env. episode 17.000000, reward total was -21.000000. running mean: -20.918595\n",
            "resetting env. episode 18.000000, reward total was -20.000000. running mean: -20.909409\n",
            "resetting env. episode 19.000000, reward total was -21.000000. running mean: -20.910315\n",
            "resetting env. episode 20.000000, reward total was -21.000000. running mean: -20.911211\n",
            "resetting env. episode 21.000000, reward total was -21.000000. running mean: -20.912099\n",
            "resetting env. episode 22.000000, reward total was -21.000000. running mean: -20.912978\n",
            "resetting env. episode 23.000000, reward total was -19.000000. running mean: -20.893849\n",
            "resetting env. episode 24.000000, reward total was -21.000000. running mean: -20.894910\n",
            "resetting env. episode 25.000000, reward total was -18.000000. running mean: -20.865961\n",
            "resetting env. episode 26.000000, reward total was -20.000000. running mean: -20.857301\n",
            "resetting env. episode 27.000000, reward total was -21.000000. running mean: -20.858728\n",
            "resetting env. episode 28.000000, reward total was -20.000000. running mean: -20.850141\n",
            "resetting env. episode 29.000000, reward total was -21.000000. running mean: -20.851640\n",
            "resetting env. episode 30.000000, reward total was -20.000000. running mean: -20.843123\n",
            "resetting env. episode 31.000000, reward total was -20.000000. running mean: -20.834692\n",
            "resetting env. episode 32.000000, reward total was -21.000000. running mean: -20.836345\n",
            "resetting env. episode 33.000000, reward total was -21.000000. running mean: -20.837982\n",
            "resetting env. episode 34.000000, reward total was -21.000000. running mean: -20.839602\n",
            "resetting env. episode 35.000000, reward total was -19.000000. running mean: -20.821206\n",
            "resetting env. episode 36.000000, reward total was -21.000000. running mean: -20.822994\n",
            "resetting env. episode 37.000000, reward total was -20.000000. running mean: -20.814764\n",
            "resetting env. episode 38.000000, reward total was -21.000000. running mean: -20.816616\n",
            "resetting env. episode 39.000000, reward total was -21.000000. running mean: -20.818450\n",
            "resetting env. episode 40.000000, reward total was -21.000000. running mean: -20.820265\n",
            "resetting env. episode 41.000000, reward total was -20.000000. running mean: -20.812063\n",
            "resetting env. episode 42.000000, reward total was -20.000000. running mean: -20.803942\n",
            "resetting env. episode 43.000000, reward total was -18.000000. running mean: -20.775903\n",
            "resetting env. episode 44.000000, reward total was -21.000000. running mean: -20.778144\n",
            "resetting env. episode 45.000000, reward total was -21.000000. running mean: -20.780362\n",
            "resetting env. episode 46.000000, reward total was -20.000000. running mean: -20.772559\n",
            "resetting env. episode 47.000000, reward total was -21.000000. running mean: -20.774833\n",
            "resetting env. episode 48.000000, reward total was -21.000000. running mean: -20.777085\n",
            "resetting env. episode 49.000000, reward total was -19.000000. running mean: -20.759314\n",
            "resetting env. episode 50.000000, reward total was -21.000000. running mean: -20.761721\n",
            "resetting env. episode 51.000000, reward total was -21.000000. running mean: -20.764104\n",
            "resetting env. episode 52.000000, reward total was -18.000000. running mean: -20.736463\n",
            "resetting env. episode 53.000000, reward total was -20.000000. running mean: -20.729098\n",
            "resetting env. episode 54.000000, reward total was -20.000000. running mean: -20.721807\n",
            "resetting env. episode 55.000000, reward total was -21.000000. running mean: -20.724589\n",
            "resetting env. episode 56.000000, reward total was -20.000000. running mean: -20.717343\n",
            "resetting env. episode 57.000000, reward total was -21.000000. running mean: -20.720170\n",
            "resetting env. episode 58.000000, reward total was -20.000000. running mean: -20.712968\n",
            "resetting env. episode 59.000000, reward total was -21.000000. running mean: -20.715838\n",
            "resetting env. episode 60.000000, reward total was -21.000000. running mean: -20.718680\n",
            "resetting env. episode 61.000000, reward total was -19.000000. running mean: -20.701493\n",
            "resetting env. episode 62.000000, reward total was -21.000000. running mean: -20.704478\n",
            "resetting env. episode 63.000000, reward total was -20.000000. running mean: -20.697433\n",
            "resetting env. episode 64.000000, reward total was -21.000000. running mean: -20.700459\n",
            "resetting env. episode 65.000000, reward total was -21.000000. running mean: -20.703454\n",
            "resetting env. episode 66.000000, reward total was -21.000000. running mean: -20.706420\n",
            "resetting env. episode 67.000000, reward total was -21.000000. running mean: -20.709356\n",
            "resetting env. episode 68.000000, reward total was -21.000000. running mean: -20.712262\n",
            "resetting env. episode 69.000000, reward total was -21.000000. running mean: -20.715139\n",
            "resetting env. episode 70.000000, reward total was -21.000000. running mean: -20.717988\n",
            "resetting env. episode 71.000000, reward total was -21.000000. running mean: -20.720808\n",
            "resetting env. episode 72.000000, reward total was -21.000000. running mean: -20.723600\n",
            "resetting env. episode 73.000000, reward total was -21.000000. running mean: -20.726364\n",
            "resetting env. episode 74.000000, reward total was -20.000000. running mean: -20.719100\n",
            "resetting env. episode 75.000000, reward total was -20.000000. running mean: -20.711909\n",
            "resetting env. episode 76.000000, reward total was -21.000000. running mean: -20.714790\n",
            "resetting env. episode 77.000000, reward total was -21.000000. running mean: -20.717642\n",
            "resetting env. episode 78.000000, reward total was -19.000000. running mean: -20.700466\n",
            "resetting env. episode 79.000000, reward total was -20.000000. running mean: -20.693461\n",
            "resetting env. episode 80.000000, reward total was -19.000000. running mean: -20.676527\n",
            "resetting env. episode 81.000000, reward total was -20.000000. running mean: -20.669761\n",
            "resetting env. episode 82.000000, reward total was -21.000000. running mean: -20.673064\n",
            "resetting env. episode 83.000000, reward total was -20.000000. running mean: -20.666333\n",
            "resetting env. episode 84.000000, reward total was -20.000000. running mean: -20.659670\n",
            "resetting env. episode 85.000000, reward total was -19.000000. running mean: -20.643073\n",
            "resetting env. episode 86.000000, reward total was -21.000000. running mean: -20.646642\n",
            "resetting env. episode 87.000000, reward total was -21.000000. running mean: -20.650176\n",
            "resetting env. episode 88.000000, reward total was -21.000000. running mean: -20.653674\n",
            "resetting env. episode 89.000000, reward total was -20.000000. running mean: -20.647138\n",
            "resetting env. episode 90.000000, reward total was -21.000000. running mean: -20.650666\n",
            "resetting env. episode 91.000000, reward total was -21.000000. running mean: -20.654159\n",
            "resetting env. episode 92.000000, reward total was -21.000000. running mean: -20.657618\n",
            "resetting env. episode 93.000000, reward total was -19.000000. running mean: -20.641042\n",
            "resetting env. episode 94.000000, reward total was -21.000000. running mean: -20.644631\n",
            "resetting env. episode 95.000000, reward total was -20.000000. running mean: -20.638185\n",
            "resetting env. episode 96.000000, reward total was -20.000000. running mean: -20.631803\n",
            "resetting env. episode 97.000000, reward total was -21.000000. running mean: -20.635485\n",
            "resetting env. episode 98.000000, reward total was -21.000000. running mean: -20.639130\n",
            "resetting env. episode 99.000000, reward total was -21.000000. running mean: -20.642739\n",
            "resetting env. episode 100.000000, reward total was -21.000000. running mean: -20.646312\n",
            "resetting env. episode 101.000000, reward total was -21.000000. running mean: -20.649848\n",
            "resetting env. episode 102.000000, reward total was -21.000000. running mean: -20.653350\n",
            "resetting env. episode 103.000000, reward total was -21.000000. running mean: -20.656816\n",
            "resetting env. episode 104.000000, reward total was -21.000000. running mean: -20.660248\n",
            "resetting env. episode 105.000000, reward total was -19.000000. running mean: -20.643646\n",
            "resetting env. episode 106.000000, reward total was -21.000000. running mean: -20.647209\n",
            "resetting env. episode 107.000000, reward total was -21.000000. running mean: -20.650737\n",
            "resetting env. episode 108.000000, reward total was -20.000000. running mean: -20.644230\n",
            "resetting env. episode 109.000000, reward total was -17.000000. running mean: -20.607788\n",
            "resetting env. episode 110.000000, reward total was -20.000000. running mean: -20.601710\n",
            "resetting env. episode 111.000000, reward total was -21.000000. running mean: -20.605693\n",
            "resetting env. episode 112.000000, reward total was -21.000000. running mean: -20.609636\n",
            "resetting env. episode 113.000000, reward total was -21.000000. running mean: -20.613539\n",
            "resetting env. episode 114.000000, reward total was -21.000000. running mean: -20.617404\n",
            "resetting env. episode 115.000000, reward total was -21.000000. running mean: -20.621230\n",
            "resetting env. episode 116.000000, reward total was -21.000000. running mean: -20.625018\n",
            "resetting env. episode 117.000000, reward total was -20.000000. running mean: -20.618767\n",
            "resetting env. episode 118.000000, reward total was -21.000000. running mean: -20.622580\n",
            "resetting env. episode 119.000000, reward total was -21.000000. running mean: -20.626354\n",
            "resetting env. episode 120.000000, reward total was -21.000000. running mean: -20.630090\n",
            "resetting env. episode 121.000000, reward total was -21.000000. running mean: -20.633790\n",
            "resetting env. episode 122.000000, reward total was -20.000000. running mean: -20.627452\n",
            "resetting env. episode 123.000000, reward total was -21.000000. running mean: -20.631177\n",
            "resetting env. episode 124.000000, reward total was -20.000000. running mean: -20.624865\n",
            "resetting env. episode 125.000000, reward total was -20.000000. running mean: -20.618617\n",
            "resetting env. episode 126.000000, reward total was -18.000000. running mean: -20.592431\n",
            "resetting env. episode 127.000000, reward total was -20.000000. running mean: -20.586506\n",
            "resetting env. episode 128.000000, reward total was -21.000000. running mean: -20.590641\n",
            "resetting env. episode 129.000000, reward total was -21.000000. running mean: -20.594735\n",
            "resetting env. episode 130.000000, reward total was -20.000000. running mean: -20.588787\n",
            "resetting env. episode 131.000000, reward total was -20.000000. running mean: -20.582900\n",
            "resetting env. episode 132.000000, reward total was -19.000000. running mean: -20.567071\n",
            "resetting env. episode 133.000000, reward total was -19.000000. running mean: -20.551400\n",
            "resetting env. episode 134.000000, reward total was -21.000000. running mean: -20.555886\n",
            "resetting env. episode 135.000000, reward total was -21.000000. running mean: -20.560327\n",
            "resetting env. episode 136.000000, reward total was -20.000000. running mean: -20.554724\n",
            "resetting env. episode 137.000000, reward total was -21.000000. running mean: -20.559176\n",
            "resetting env. episode 138.000000, reward total was -21.000000. running mean: -20.563585\n",
            "resetting env. episode 139.000000, reward total was -21.000000. running mean: -20.567949\n",
            "resetting env. episode 140.000000, reward total was -21.000000. running mean: -20.572269\n",
            "resetting env. episode 141.000000, reward total was -21.000000. running mean: -20.576547\n",
            "resetting env. episode 142.000000, reward total was -20.000000. running mean: -20.570781\n",
            "resetting env. episode 143.000000, reward total was -21.000000. running mean: -20.575073\n",
            "resetting env. episode 144.000000, reward total was -19.000000. running mean: -20.559323\n",
            "resetting env. episode 145.000000, reward total was -20.000000. running mean: -20.553729\n",
            "resetting env. episode 146.000000, reward total was -21.000000. running mean: -20.558192\n",
            "resetting env. episode 147.000000, reward total was -18.000000. running mean: -20.532610\n",
            "resetting env. episode 148.000000, reward total was -21.000000. running mean: -20.537284\n",
            "resetting env. episode 149.000000, reward total was -21.000000. running mean: -20.541911\n",
            "resetting env. episode 150.000000, reward total was -20.000000. running mean: -20.536492\n",
            "resetting env. episode 151.000000, reward total was -21.000000. running mean: -20.541127\n",
            "resetting env. episode 152.000000, reward total was -21.000000. running mean: -20.545716\n",
            "resetting env. episode 153.000000, reward total was -20.000000. running mean: -20.540259\n",
            "resetting env. episode 154.000000, reward total was -21.000000. running mean: -20.544856\n",
            "resetting env. episode 155.000000, reward total was -21.000000. running mean: -20.549408\n",
            "resetting env. episode 156.000000, reward total was -20.000000. running mean: -20.543914\n",
            "resetting env. episode 157.000000, reward total was -20.000000. running mean: -20.538474\n",
            "resetting env. episode 158.000000, reward total was -20.000000. running mean: -20.533090\n",
            "resetting env. episode 159.000000, reward total was -21.000000. running mean: -20.537759\n",
            "resetting env. episode 160.000000, reward total was -21.000000. running mean: -20.542381\n",
            "resetting env. episode 161.000000, reward total was -21.000000. running mean: -20.546957\n",
            "resetting env. episode 162.000000, reward total was -21.000000. running mean: -20.551488\n",
            "resetting env. episode 163.000000, reward total was -20.000000. running mean: -20.545973\n",
            "resetting env. episode 164.000000, reward total was -20.000000. running mean: -20.540513\n",
            "resetting env. episode 165.000000, reward total was -21.000000. running mean: -20.545108\n",
            "resetting env. episode 166.000000, reward total was -21.000000. running mean: -20.549657\n",
            "resetting env. episode 167.000000, reward total was -21.000000. running mean: -20.554160\n",
            "resetting env. episode 168.000000, reward total was -21.000000. running mean: -20.558619\n",
            "resetting env. episode 169.000000, reward total was -20.000000. running mean: -20.553033\n",
            "resetting env. episode 170.000000, reward total was -21.000000. running mean: -20.557502\n",
            "resetting env. episode 171.000000, reward total was -21.000000. running mean: -20.561927\n",
            "resetting env. episode 172.000000, reward total was -21.000000. running mean: -20.566308\n",
            "resetting env. episode 173.000000, reward total was -20.000000. running mean: -20.560645\n",
            "resetting env. episode 174.000000, reward total was -21.000000. running mean: -20.565038\n",
            "resetting env. episode 175.000000, reward total was -20.000000. running mean: -20.559388\n",
            "resetting env. episode 176.000000, reward total was -19.000000. running mean: -20.543794\n",
            "resetting env. episode 177.000000, reward total was -21.000000. running mean: -20.548356\n",
            "resetting env. episode 178.000000, reward total was -20.000000. running mean: -20.542873\n",
            "resetting env. episode 179.000000, reward total was -21.000000. running mean: -20.547444\n",
            "resetting env. episode 180.000000, reward total was -21.000000. running mean: -20.551970\n",
            "resetting env. episode 181.000000, reward total was -21.000000. running mean: -20.556450\n",
            "resetting env. episode 182.000000, reward total was -20.000000. running mean: -20.550885\n",
            "resetting env. episode 183.000000, reward total was -20.000000. running mean: -20.545376\n",
            "resetting env. episode 184.000000, reward total was -20.000000. running mean: -20.539923\n",
            "resetting env. episode 185.000000, reward total was -20.000000. running mean: -20.534524\n",
            "resetting env. episode 186.000000, reward total was -21.000000. running mean: -20.539178\n",
            "resetting env. episode 187.000000, reward total was -20.000000. running mean: -20.533786\n",
            "resetting env. episode 188.000000, reward total was -19.000000. running mean: -20.518449\n",
            "resetting env. episode 189.000000, reward total was -20.000000. running mean: -20.513264\n",
            "resetting env. episode 190.000000, reward total was -21.000000. running mean: -20.518131\n",
            "resetting env. episode 191.000000, reward total was -21.000000. running mean: -20.522950\n",
            "resetting env. episode 192.000000, reward total was -21.000000. running mean: -20.527721\n",
            "resetting env. episode 193.000000, reward total was -21.000000. running mean: -20.532443\n",
            "resetting env. episode 194.000000, reward total was -20.000000. running mean: -20.527119\n",
            "resetting env. episode 195.000000, reward total was -20.000000. running mean: -20.521848\n",
            "resetting env. episode 196.000000, reward total was -21.000000. running mean: -20.526629\n",
            "resetting env. episode 197.000000, reward total was -18.000000. running mean: -20.501363\n",
            "resetting env. episode 198.000000, reward total was -21.000000. running mean: -20.506349\n",
            "resetting env. episode 199.000000, reward total was -21.000000. running mean: -20.511286\n",
            "resetting env. episode 200.000000, reward total was -21.000000. running mean: -20.516173\n",
            "resetting env. episode 201.000000, reward total was -20.000000. running mean: -20.511011\n",
            "resetting env. episode 202.000000, reward total was -21.000000. running mean: -20.515901\n",
            "resetting env. episode 203.000000, reward total was -21.000000. running mean: -20.520742\n",
            "resetting env. episode 204.000000, reward total was -19.000000. running mean: -20.505535\n",
            "resetting env. episode 205.000000, reward total was -20.000000. running mean: -20.500479\n",
            "resetting env. episode 206.000000, reward total was -21.000000. running mean: -20.505475\n",
            "resetting env. episode 207.000000, reward total was -21.000000. running mean: -20.510420\n",
            "resetting env. episode 208.000000, reward total was -20.000000. running mean: -20.505316\n",
            "resetting env. episode 209.000000, reward total was -21.000000. running mean: -20.510263\n",
            "resetting env. episode 210.000000, reward total was -20.000000. running mean: -20.505160\n",
            "resetting env. episode 211.000000, reward total was -21.000000. running mean: -20.510108\n",
            "resetting env. episode 212.000000, reward total was -21.000000. running mean: -20.515007\n",
            "resetting env. episode 213.000000, reward total was -20.000000. running mean: -20.509857\n",
            "resetting env. episode 214.000000, reward total was -21.000000. running mean: -20.514759\n",
            "resetting env. episode 215.000000, reward total was -20.000000. running mean: -20.509611\n",
            "resetting env. episode 216.000000, reward total was -19.000000. running mean: -20.494515\n",
            "resetting env. episode 217.000000, reward total was -21.000000. running mean: -20.499570\n",
            "resetting env. episode 218.000000, reward total was -20.000000. running mean: -20.494574\n",
            "resetting env. episode 219.000000, reward total was -21.000000. running mean: -20.499628\n",
            "resetting env. episode 220.000000, reward total was -20.000000. running mean: -20.494632\n",
            "resetting env. episode 221.000000, reward total was -21.000000. running mean: -20.499686\n",
            "resetting env. episode 222.000000, reward total was -19.000000. running mean: -20.484689\n",
            "resetting env. episode 223.000000, reward total was -18.000000. running mean: -20.459842\n",
            "resetting env. episode 224.000000, reward total was -19.000000. running mean: -20.445244\n",
            "resetting env. episode 225.000000, reward total was -21.000000. running mean: -20.450791\n",
            "resetting env. episode 226.000000, reward total was -21.000000. running mean: -20.456283\n",
            "resetting env. episode 227.000000, reward total was -21.000000. running mean: -20.461720\n",
            "resetting env. episode 228.000000, reward total was -18.000000. running mean: -20.437103\n",
            "resetting env. episode 229.000000, reward total was -21.000000. running mean: -20.442732\n",
            "resetting env. episode 230.000000, reward total was -20.000000. running mean: -20.438305\n",
            "resetting env. episode 231.000000, reward total was -20.000000. running mean: -20.433922\n",
            "resetting env. episode 232.000000, reward total was -20.000000. running mean: -20.429583\n",
            "resetting env. episode 233.000000, reward total was -20.000000. running mean: -20.425287\n",
            "resetting env. episode 234.000000, reward total was -21.000000. running mean: -20.431034\n",
            "resetting env. episode 235.000000, reward total was -21.000000. running mean: -20.436724\n",
            "resetting env. episode 236.000000, reward total was -21.000000. running mean: -20.442356\n",
            "resetting env. episode 237.000000, reward total was -19.000000. running mean: -20.427933\n",
            "resetting env. episode 238.000000, reward total was -21.000000. running mean: -20.433653\n",
            "resetting env. episode 239.000000, reward total was -21.000000. running mean: -20.439317\n",
            "resetting env. episode 240.000000, reward total was -21.000000. running mean: -20.444924\n",
            "resetting env. episode 241.000000, reward total was -21.000000. running mean: -20.450474\n",
            "resetting env. episode 242.000000, reward total was -19.000000. running mean: -20.435970\n",
            "resetting env. episode 243.000000, reward total was -21.000000. running mean: -20.441610\n",
            "resetting env. episode 244.000000, reward total was -20.000000. running mean: -20.437194\n",
            "resetting env. episode 245.000000, reward total was -19.000000. running mean: -20.422822\n",
            "resetting env. episode 246.000000, reward total was -20.000000. running mean: -20.418594\n",
            "resetting env. episode 247.000000, reward total was -19.000000. running mean: -20.404408\n",
            "resetting env. episode 248.000000, reward total was -21.000000. running mean: -20.410364\n",
            "resetting env. episode 249.000000, reward total was -21.000000. running mean: -20.416260\n",
            "resetting env. episode 250.000000, reward total was -20.000000. running mean: -20.412098\n",
            "resetting env. episode 251.000000, reward total was -21.000000. running mean: -20.417977\n",
            "resetting env. episode 252.000000, reward total was -18.000000. running mean: -20.393797\n",
            "resetting env. episode 253.000000, reward total was -21.000000. running mean: -20.399859\n",
            "resetting env. episode 254.000000, reward total was -20.000000. running mean: -20.395860\n",
            "resetting env. episode 255.000000, reward total was -21.000000. running mean: -20.401902\n",
            "resetting env. episode 256.000000, reward total was -20.000000. running mean: -20.397883\n",
            "resetting env. episode 257.000000, reward total was -20.000000. running mean: -20.393904\n",
            "resetting env. episode 258.000000, reward total was -21.000000. running mean: -20.399965\n",
            "resetting env. episode 259.000000, reward total was -20.000000. running mean: -20.395965\n",
            "resetting env. episode 260.000000, reward total was -18.000000. running mean: -20.372005\n",
            "resetting env. episode 261.000000, reward total was -21.000000. running mean: -20.378285\n",
            "resetting env. episode 262.000000, reward total was -21.000000. running mean: -20.384503\n",
            "resetting env. episode 263.000000, reward total was -21.000000. running mean: -20.390657\n",
            "resetting env. episode 264.000000, reward total was -20.000000. running mean: -20.386751\n",
            "resetting env. episode 265.000000, reward total was -21.000000. running mean: -20.392883\n",
            "resetting env. episode 266.000000, reward total was -20.000000. running mean: -20.388955\n",
            "resetting env. episode 267.000000, reward total was -18.000000. running mean: -20.365065\n",
            "resetting env. episode 268.000000, reward total was -21.000000. running mean: -20.371414\n",
            "resetting env. episode 269.000000, reward total was -20.000000. running mean: -20.367700\n",
            "resetting env. episode 270.000000, reward total was -18.000000. running mean: -20.344023\n",
            "resetting env. episode 271.000000, reward total was -21.000000. running mean: -20.350583\n",
            "resetting env. episode 272.000000, reward total was -20.000000. running mean: -20.347077\n",
            "resetting env. episode 273.000000, reward total was -21.000000. running mean: -20.353606\n",
            "resetting env. episode 274.000000, reward total was -21.000000. running mean: -20.360070\n",
            "resetting env. episode 275.000000, reward total was -20.000000. running mean: -20.356470\n",
            "resetting env. episode 276.000000, reward total was -21.000000. running mean: -20.362905\n",
            "resetting env. episode 277.000000, reward total was -20.000000. running mean: -20.359276\n",
            "resetting env. episode 278.000000, reward total was -21.000000. running mean: -20.365683\n",
            "resetting env. episode 279.000000, reward total was -20.000000. running mean: -20.362026\n",
            "resetting env. episode 280.000000, reward total was -21.000000. running mean: -20.368406\n",
            "resetting env. episode 281.000000, reward total was -21.000000. running mean: -20.374722\n",
            "resetting env. episode 282.000000, reward total was -19.000000. running mean: -20.360975\n",
            "resetting env. episode 283.000000, reward total was -19.000000. running mean: -20.347365\n",
            "resetting env. episode 284.000000, reward total was -20.000000. running mean: -20.343891\n",
            "resetting env. episode 285.000000, reward total was -20.000000. running mean: -20.340452\n",
            "resetting env. episode 286.000000, reward total was -21.000000. running mean: -20.347048\n",
            "resetting env. episode 287.000000, reward total was -21.000000. running mean: -20.353577\n",
            "resetting env. episode 288.000000, reward total was -21.000000. running mean: -20.360042\n",
            "resetting env. episode 289.000000, reward total was -21.000000. running mean: -20.366441\n",
            "resetting env. episode 290.000000, reward total was -19.000000. running mean: -20.352777\n",
            "resetting env. episode 291.000000, reward total was -21.000000. running mean: -20.359249\n",
            "resetting env. episode 292.000000, reward total was -21.000000. running mean: -20.365657\n",
            "resetting env. episode 293.000000, reward total was -21.000000. running mean: -20.372000\n",
            "resetting env. episode 294.000000, reward total was -20.000000. running mean: -20.368280\n",
            "resetting env. episode 295.000000, reward total was -21.000000. running mean: -20.374597\n",
            "resetting env. episode 296.000000, reward total was -21.000000. running mean: -20.380851\n",
            "resetting env. episode 297.000000, reward total was -20.000000. running mean: -20.377043\n",
            "resetting env. episode 298.000000, reward total was -21.000000. running mean: -20.383272\n",
            "resetting env. episode 299.000000, reward total was -21.000000. running mean: -20.389440\n",
            "resetting env. episode 300.000000, reward total was -18.000000. running mean: -20.365545\n",
            "resetting env. episode 301.000000, reward total was -20.000000. running mean: -20.361890\n",
            "resetting env. episode 302.000000, reward total was -21.000000. running mean: -20.368271\n",
            "resetting env. episode 303.000000, reward total was -17.000000. running mean: -20.334588\n",
            "resetting env. episode 304.000000, reward total was -21.000000. running mean: -20.341242\n",
            "resetting env. episode 305.000000, reward total was -18.000000. running mean: -20.317830\n",
            "resetting env. episode 306.000000, reward total was -20.000000. running mean: -20.314652\n",
            "resetting env. episode 307.000000, reward total was -20.000000. running mean: -20.311505\n",
            "resetting env. episode 308.000000, reward total was -21.000000. running mean: -20.318390\n",
            "resetting env. episode 309.000000, reward total was -21.000000. running mean: -20.325206\n",
            "resetting env. episode 310.000000, reward total was -20.000000. running mean: -20.321954\n",
            "resetting env. episode 311.000000, reward total was -21.000000. running mean: -20.328734\n",
            "resetting env. episode 312.000000, reward total was -21.000000. running mean: -20.335447\n",
            "resetting env. episode 313.000000, reward total was -20.000000. running mean: -20.332093\n",
            "resetting env. episode 314.000000, reward total was -19.000000. running mean: -20.318772\n",
            "resetting env. episode 315.000000, reward total was -21.000000. running mean: -20.325584\n",
            "resetting env. episode 316.000000, reward total was -21.000000. running mean: -20.332328\n",
            "resetting env. episode 317.000000, reward total was -21.000000. running mean: -20.339005\n",
            "resetting env. episode 318.000000, reward total was -21.000000. running mean: -20.345615\n",
            "resetting env. episode 319.000000, reward total was -21.000000. running mean: -20.352159\n",
            "resetting env. episode 320.000000, reward total was -21.000000. running mean: -20.358637\n",
            "resetting env. episode 321.000000, reward total was -21.000000. running mean: -20.365051\n",
            "resetting env. episode 322.000000, reward total was -21.000000. running mean: -20.371400\n",
            "resetting env. episode 323.000000, reward total was -20.000000. running mean: -20.367686\n",
            "resetting env. episode 324.000000, reward total was -21.000000. running mean: -20.374009\n",
            "resetting env. episode 325.000000, reward total was -20.000000. running mean: -20.370269\n",
            "resetting env. episode 326.000000, reward total was -21.000000. running mean: -20.376567\n",
            "resetting env. episode 327.000000, reward total was -18.000000. running mean: -20.352801\n",
            "resetting env. episode 328.000000, reward total was -21.000000. running mean: -20.359273\n",
            "resetting env. episode 329.000000, reward total was -21.000000. running mean: -20.365680\n",
            "resetting env. episode 330.000000, reward total was -21.000000. running mean: -20.372023\n",
            "resetting env. episode 331.000000, reward total was -21.000000. running mean: -20.378303\n",
            "resetting env. episode 332.000000, reward total was -20.000000. running mean: -20.374520\n",
            "resetting env. episode 333.000000, reward total was -21.000000. running mean: -20.380775\n",
            "resetting env. episode 334.000000, reward total was -21.000000. running mean: -20.386967\n",
            "resetting env. episode 335.000000, reward total was -21.000000. running mean: -20.393097\n",
            "resetting env. episode 336.000000, reward total was -21.000000. running mean: -20.399166\n",
            "resetting env. episode 337.000000, reward total was -21.000000. running mean: -20.405175\n",
            "resetting env. episode 338.000000, reward total was -21.000000. running mean: -20.411123\n",
            "resetting env. episode 339.000000, reward total was -21.000000. running mean: -20.417012\n",
            "resetting env. episode 340.000000, reward total was -20.000000. running mean: -20.412842\n",
            "resetting env. episode 341.000000, reward total was -21.000000. running mean: -20.418713\n",
            "resetting env. episode 342.000000, reward total was -21.000000. running mean: -20.424526\n",
            "resetting env. episode 343.000000, reward total was -20.000000. running mean: -20.420281\n",
            "resetting env. episode 344.000000, reward total was -21.000000. running mean: -20.426078\n",
            "resetting env. episode 345.000000, reward total was -21.000000. running mean: -20.431817\n",
            "resetting env. episode 346.000000, reward total was -21.000000. running mean: -20.437499\n",
            "resetting env. episode 347.000000, reward total was -20.000000. running mean: -20.433124\n",
            "resetting env. episode 348.000000, reward total was -21.000000. running mean: -20.438793\n",
            "resetting env. episode 349.000000, reward total was -21.000000. running mean: -20.444405\n",
            "resetting env. episode 350.000000, reward total was -21.000000. running mean: -20.449961\n",
            "resetting env. episode 351.000000, reward total was -20.000000. running mean: -20.445461\n",
            "resetting env. episode 352.000000, reward total was -20.000000. running mean: -20.441007\n",
            "resetting env. episode 353.000000, reward total was -19.000000. running mean: -20.426597\n",
            "resetting env. episode 354.000000, reward total was -21.000000. running mean: -20.432331\n",
            "resetting env. episode 355.000000, reward total was -19.000000. running mean: -20.418007\n",
            "resetting env. episode 356.000000, reward total was -20.000000. running mean: -20.413827\n",
            "resetting env. episode 357.000000, reward total was -21.000000. running mean: -20.419689\n",
            "resetting env. episode 358.000000, reward total was -21.000000. running mean: -20.425492\n",
            "resetting env. episode 359.000000, reward total was -21.000000. running mean: -20.431237\n",
            "resetting env. episode 360.000000, reward total was -20.000000. running mean: -20.426925\n",
            "resetting env. episode 361.000000, reward total was -19.000000. running mean: -20.412656\n",
            "resetting env. episode 362.000000, reward total was -20.000000. running mean: -20.408529\n",
            "resetting env. episode 363.000000, reward total was -20.000000. running mean: -20.404444\n",
            "resetting env. episode 364.000000, reward total was -19.000000. running mean: -20.390399\n",
            "resetting env. episode 365.000000, reward total was -21.000000. running mean: -20.396495\n",
            "resetting env. episode 366.000000, reward total was -21.000000. running mean: -20.402530\n",
            "resetting env. episode 367.000000, reward total was -21.000000. running mean: -20.408505\n",
            "resetting env. episode 368.000000, reward total was -21.000000. running mean: -20.414420\n",
            "resetting env. episode 369.000000, reward total was -21.000000. running mean: -20.420276\n",
            "resetting env. episode 370.000000, reward total was -20.000000. running mean: -20.416073\n",
            "resetting env. episode 371.000000, reward total was -21.000000. running mean: -20.421912\n",
            "resetting env. episode 372.000000, reward total was -20.000000. running mean: -20.417693\n",
            "resetting env. episode 373.000000, reward total was -20.000000. running mean: -20.413516\n",
            "resetting env. episode 374.000000, reward total was -21.000000. running mean: -20.419381\n",
            "resetting env. episode 375.000000, reward total was -21.000000. running mean: -20.425187\n",
            "resetting env. episode 376.000000, reward total was -21.000000. running mean: -20.430935\n",
            "resetting env. episode 377.000000, reward total was -21.000000. running mean: -20.436626\n",
            "resetting env. episode 378.000000, reward total was -21.000000. running mean: -20.442260\n",
            "resetting env. episode 379.000000, reward total was -20.000000. running mean: -20.437837\n",
            "resetting env. episode 380.000000, reward total was -21.000000. running mean: -20.443459\n",
            "resetting env. episode 381.000000, reward total was -21.000000. running mean: -20.449024\n",
            "resetting env. episode 382.000000, reward total was -21.000000. running mean: -20.454534\n",
            "resetting env. episode 383.000000, reward total was -19.000000. running mean: -20.439989\n",
            "resetting env. episode 384.000000, reward total was -21.000000. running mean: -20.445589\n",
            "resetting env. episode 385.000000, reward total was -21.000000. running mean: -20.451133\n",
            "resetting env. episode 386.000000, reward total was -21.000000. running mean: -20.456622\n",
            "resetting env. episode 387.000000, reward total was -20.000000. running mean: -20.452055\n",
            "resetting env. episode 388.000000, reward total was -21.000000. running mean: -20.457535\n",
            "resetting env. episode 389.000000, reward total was -21.000000. running mean: -20.462959\n",
            "resetting env. episode 390.000000, reward total was -21.000000. running mean: -20.468330\n",
            "resetting env. episode 391.000000, reward total was -20.000000. running mean: -20.463647\n",
            "resetting env. episode 392.000000, reward total was -19.000000. running mean: -20.449010\n",
            "resetting env. episode 393.000000, reward total was -21.000000. running mean: -20.454520\n",
            "resetting env. episode 394.000000, reward total was -20.000000. running mean: -20.449975\n",
            "resetting env. episode 395.000000, reward total was -21.000000. running mean: -20.455475\n",
            "resetting env. episode 396.000000, reward total was -21.000000. running mean: -20.460920\n",
            "resetting env. episode 397.000000, reward total was -21.000000. running mean: -20.466311\n",
            "resetting env. episode 398.000000, reward total was -21.000000. running mean: -20.471648\n",
            "resetting env. episode 399.000000, reward total was -21.000000. running mean: -20.476931\n",
            "resetting env. episode 400.000000, reward total was -21.000000. running mean: -20.482162\n",
            "resetting env. episode 401.000000, reward total was -18.000000. running mean: -20.457341\n",
            "resetting env. episode 402.000000, reward total was -21.000000. running mean: -20.462767\n",
            "resetting env. episode 403.000000, reward total was -21.000000. running mean: -20.468139\n",
            "resetting env. episode 404.000000, reward total was -19.000000. running mean: -20.453458\n",
            "resetting env. episode 405.000000, reward total was -21.000000. running mean: -20.458924\n",
            "resetting env. episode 406.000000, reward total was -21.000000. running mean: -20.464334\n",
            "resetting env. episode 407.000000, reward total was -19.000000. running mean: -20.449691\n",
            "resetting env. episode 408.000000, reward total was -21.000000. running mean: -20.455194\n",
            "resetting env. episode 409.000000, reward total was -21.000000. running mean: -20.460642\n",
            "resetting env. episode 410.000000, reward total was -21.000000. running mean: -20.466036\n",
            "resetting env. episode 411.000000, reward total was -21.000000. running mean: -20.471375\n",
            "resetting env. episode 412.000000, reward total was -20.000000. running mean: -20.466662\n",
            "resetting env. episode 413.000000, reward total was -21.000000. running mean: -20.471995\n",
            "resetting env. episode 414.000000, reward total was -19.000000. running mean: -20.457275\n",
            "resetting env. episode 415.000000, reward total was -21.000000. running mean: -20.462702\n",
            "resetting env. episode 416.000000, reward total was -21.000000. running mean: -20.468075\n",
            "resetting env. episode 417.000000, reward total was -19.000000. running mean: -20.453394\n",
            "resetting env. episode 418.000000, reward total was -20.000000. running mean: -20.448861\n",
            "resetting env. episode 419.000000, reward total was -21.000000. running mean: -20.454372\n",
            "resetting env. episode 420.000000, reward total was -21.000000. running mean: -20.459828\n",
            "resetting env. episode 421.000000, reward total was -21.000000. running mean: -20.465230\n",
            "resetting env. episode 422.000000, reward total was -20.000000. running mean: -20.460578\n",
            "resetting env. episode 423.000000, reward total was -21.000000. running mean: -20.465972\n",
            "resetting env. episode 424.000000, reward total was -20.000000. running mean: -20.461312\n",
            "resetting env. episode 425.000000, reward total was -21.000000. running mean: -20.466699\n",
            "resetting env. episode 426.000000, reward total was -20.000000. running mean: -20.462032\n",
            "resetting env. episode 427.000000, reward total was -21.000000. running mean: -20.467412\n",
            "resetting env. episode 428.000000, reward total was -21.000000. running mean: -20.472738\n",
            "resetting env. episode 429.000000, reward total was -18.000000. running mean: -20.448010\n",
            "resetting env. episode 430.000000, reward total was -20.000000. running mean: -20.443530\n",
            "resetting env. episode 431.000000, reward total was -20.000000. running mean: -20.439095\n",
            "resetting env. episode 432.000000, reward total was -20.000000. running mean: -20.434704\n",
            "resetting env. episode 433.000000, reward total was -21.000000. running mean: -20.440357\n",
            "resetting env. episode 434.000000, reward total was -21.000000. running mean: -20.445953\n",
            "resetting env. episode 435.000000, reward total was -21.000000. running mean: -20.451494\n",
            "resetting env. episode 436.000000, reward total was -21.000000. running mean: -20.456979\n",
            "resetting env. episode 437.000000, reward total was -21.000000. running mean: -20.462409\n",
            "resetting env. episode 438.000000, reward total was -20.000000. running mean: -20.457785\n",
            "resetting env. episode 439.000000, reward total was -20.000000. running mean: -20.453207\n",
            "resetting env. episode 440.000000, reward total was -20.000000. running mean: -20.448675\n",
            "resetting env. episode 441.000000, reward total was -20.000000. running mean: -20.444188\n",
            "resetting env. episode 442.000000, reward total was -20.000000. running mean: -20.439746\n",
            "resetting env. episode 443.000000, reward total was -21.000000. running mean: -20.445349\n",
            "resetting env. episode 444.000000, reward total was -21.000000. running mean: -20.450895\n",
            "resetting env. episode 445.000000, reward total was -21.000000. running mean: -20.456386\n",
            "resetting env. episode 446.000000, reward total was -20.000000. running mean: -20.451823\n",
            "resetting env. episode 447.000000, reward total was -20.000000. running mean: -20.447304\n",
            "resetting env. episode 448.000000, reward total was -21.000000. running mean: -20.452831\n",
            "resetting env. episode 449.000000, reward total was -21.000000. running mean: -20.458303\n",
            "resetting env. episode 450.000000, reward total was -20.000000. running mean: -20.453720\n",
            "resetting env. episode 451.000000, reward total was -20.000000. running mean: -20.449183\n",
            "resetting env. episode 452.000000, reward total was -21.000000. running mean: -20.454691\n",
            "resetting env. episode 453.000000, reward total was -19.000000. running mean: -20.440144\n",
            "resetting env. episode 454.000000, reward total was -21.000000. running mean: -20.445743\n",
            "resetting env. episode 455.000000, reward total was -19.000000. running mean: -20.431285\n",
            "resetting env. episode 456.000000, reward total was -21.000000. running mean: -20.436972\n",
            "resetting env. episode 457.000000, reward total was -17.000000. running mean: -20.402603\n",
            "resetting env. episode 458.000000, reward total was -21.000000. running mean: -20.408577\n",
            "resetting env. episode 459.000000, reward total was -19.000000. running mean: -20.394491\n",
            "resetting env. episode 460.000000, reward total was -21.000000. running mean: -20.400546\n",
            "resetting env. episode 461.000000, reward total was -20.000000. running mean: -20.396540\n",
            "resetting env. episode 462.000000, reward total was -20.000000. running mean: -20.392575\n",
            "resetting env. episode 463.000000, reward total was -21.000000. running mean: -20.398649\n",
            "resetting env. episode 464.000000, reward total was -21.000000. running mean: -20.404663\n",
            "resetting env. episode 465.000000, reward total was -21.000000. running mean: -20.410616\n",
            "resetting env. episode 466.000000, reward total was -21.000000. running mean: -20.416510\n",
            "resetting env. episode 467.000000, reward total was -21.000000. running mean: -20.422345\n",
            "resetting env. episode 468.000000, reward total was -19.000000. running mean: -20.408121\n",
            "resetting env. episode 469.000000, reward total was -21.000000. running mean: -20.414040\n",
            "resetting env. episode 470.000000, reward total was -21.000000. running mean: -20.419900\n",
            "resetting env. episode 471.000000, reward total was -20.000000. running mean: -20.415701\n",
            "resetting env. episode 472.000000, reward total was -21.000000. running mean: -20.421544\n",
            "resetting env. episode 473.000000, reward total was -21.000000. running mean: -20.427328\n",
            "resetting env. episode 474.000000, reward total was -21.000000. running mean: -20.433055\n",
            "resetting env. episode 475.000000, reward total was -21.000000. running mean: -20.438725\n",
            "resetting env. episode 476.000000, reward total was -21.000000. running mean: -20.444337\n",
            "resetting env. episode 477.000000, reward total was -21.000000. running mean: -20.449894\n",
            "resetting env. episode 478.000000, reward total was -20.000000. running mean: -20.445395\n",
            "resetting env. episode 479.000000, reward total was -21.000000. running mean: -20.450941\n",
            "resetting env. episode 480.000000, reward total was -21.000000. running mean: -20.456432\n",
            "resetting env. episode 481.000000, reward total was -21.000000. running mean: -20.461867\n",
            "resetting env. episode 482.000000, reward total was -21.000000. running mean: -20.467249\n",
            "resetting env. episode 483.000000, reward total was -21.000000. running mean: -20.472576\n",
            "resetting env. episode 484.000000, reward total was -19.000000. running mean: -20.457850\n",
            "resetting env. episode 485.000000, reward total was -21.000000. running mean: -20.463272\n",
            "resetting env. episode 486.000000, reward total was -21.000000. running mean: -20.468639\n",
            "resetting env. episode 487.000000, reward total was -21.000000. running mean: -20.473953\n",
            "resetting env. episode 488.000000, reward total was -21.000000. running mean: -20.479213\n",
            "resetting env. episode 489.000000, reward total was -20.000000. running mean: -20.474421\n",
            "resetting env. episode 490.000000, reward total was -21.000000. running mean: -20.479677\n",
            "resetting env. episode 491.000000, reward total was -16.000000. running mean: -20.434880\n",
            "resetting env. episode 492.000000, reward total was -20.000000. running mean: -20.430531\n",
            "resetting env. episode 493.000000, reward total was -20.000000. running mean: -20.426226\n",
            "resetting env. episode 494.000000, reward total was -19.000000. running mean: -20.411964\n",
            "resetting env. episode 495.000000, reward total was -21.000000. running mean: -20.417844\n",
            "resetting env. episode 496.000000, reward total was -20.000000. running mean: -20.413666\n",
            "resetting env. episode 497.000000, reward total was -21.000000. running mean: -20.419529\n",
            "resetting env. episode 498.000000, reward total was -21.000000. running mean: -20.425334\n",
            "resetting env. episode 499.000000, reward total was -20.000000. running mean: -20.421080\n",
            "resetting env. episode 500.000000, reward total was -21.000000. running mean: -20.426870\n",
            "resetting env. episode 501.000000, reward total was -19.000000. running mean: -20.412601\n",
            "resetting env. episode 502.000000, reward total was -21.000000. running mean: -20.418475\n",
            "resetting env. episode 503.000000, reward total was -21.000000. running mean: -20.424290\n",
            "resetting env. episode 504.000000, reward total was -21.000000. running mean: -20.430047\n",
            "resetting env. episode 505.000000, reward total was -19.000000. running mean: -20.415747\n",
            "resetting env. episode 506.000000, reward total was -21.000000. running mean: -20.421589\n",
            "resetting env. episode 507.000000, reward total was -18.000000. running mean: -20.397373\n",
            "resetting env. episode 508.000000, reward total was -20.000000. running mean: -20.393400\n",
            "resetting env. episode 509.000000, reward total was -20.000000. running mean: -20.389466\n",
            "resetting env. episode 510.000000, reward total was -20.000000. running mean: -20.385571\n",
            "resetting env. episode 511.000000, reward total was -21.000000. running mean: -20.391715\n",
            "resetting env. episode 512.000000, reward total was -21.000000. running mean: -20.397798\n",
            "resetting env. episode 513.000000, reward total was -20.000000. running mean: -20.393820\n",
            "resetting env. episode 514.000000, reward total was -21.000000. running mean: -20.399882\n",
            "resetting env. episode 515.000000, reward total was -21.000000. running mean: -20.405883\n",
            "resetting env. episode 516.000000, reward total was -20.000000. running mean: -20.401824\n",
            "resetting env. episode 517.000000, reward total was -19.000000. running mean: -20.387806\n",
            "resetting env. episode 518.000000, reward total was -21.000000. running mean: -20.393928\n",
            "resetting env. episode 519.000000, reward total was -20.000000. running mean: -20.389989\n",
            "resetting env. episode 520.000000, reward total was -19.000000. running mean: -20.376089\n",
            "resetting env. episode 521.000000, reward total was -20.000000. running mean: -20.372328\n",
            "resetting env. episode 522.000000, reward total was -21.000000. running mean: -20.378605\n",
            "resetting env. episode 523.000000, reward total was -21.000000. running mean: -20.384819\n",
            "resetting env. episode 524.000000, reward total was -21.000000. running mean: -20.390970\n",
            "resetting env. episode 525.000000, reward total was -21.000000. running mean: -20.397061\n",
            "resetting env. episode 526.000000, reward total was -21.000000. running mean: -20.403090\n",
            "resetting env. episode 527.000000, reward total was -21.000000. running mean: -20.409059\n",
            "resetting env. episode 528.000000, reward total was -20.000000. running mean: -20.404969\n",
            "resetting env. episode 529.000000, reward total was -20.000000. running mean: -20.400919\n",
            "resetting env. episode 530.000000, reward total was -21.000000. running mean: -20.406910\n",
            "resetting env. episode 531.000000, reward total was -20.000000. running mean: -20.402841\n",
            "resetting env. episode 532.000000, reward total was -19.000000. running mean: -20.388812\n",
            "resetting env. episode 533.000000, reward total was -21.000000. running mean: -20.394924\n",
            "resetting env. episode 534.000000, reward total was -20.000000. running mean: -20.390975\n",
            "resetting env. episode 535.000000, reward total was -20.000000. running mean: -20.387065\n",
            "resetting env. episode 536.000000, reward total was -21.000000. running mean: -20.393194\n",
            "resetting env. episode 537.000000, reward total was -20.000000. running mean: -20.389263\n",
            "resetting env. episode 538.000000, reward total was -20.000000. running mean: -20.385370\n",
            "resetting env. episode 539.000000, reward total was -21.000000. running mean: -20.391516\n",
            "resetting env. episode 540.000000, reward total was -20.000000. running mean: -20.387601\n",
            "resetting env. episode 541.000000, reward total was -21.000000. running mean: -20.393725\n",
            "resetting env. episode 542.000000, reward total was -20.000000. running mean: -20.389788\n",
            "resetting env. episode 543.000000, reward total was -20.000000. running mean: -20.385890\n",
            "resetting env. episode 544.000000, reward total was -21.000000. running mean: -20.392031\n",
            "resetting env. episode 545.000000, reward total was -21.000000. running mean: -20.398111\n",
            "resetting env. episode 546.000000, reward total was -21.000000. running mean: -20.404130\n",
            "resetting env. episode 547.000000, reward total was -18.000000. running mean: -20.380088\n",
            "resetting env. episode 548.000000, reward total was -21.000000. running mean: -20.386287\n",
            "resetting env. episode 549.000000, reward total was -21.000000. running mean: -20.392425\n",
            "resetting env. episode 550.000000, reward total was -20.000000. running mean: -20.388500\n",
            "resetting env. episode 551.000000, reward total was -21.000000. running mean: -20.394615\n",
            "resetting env. episode 552.000000, reward total was -20.000000. running mean: -20.390669\n",
            "resetting env. episode 553.000000, reward total was -21.000000. running mean: -20.396762\n",
            "resetting env. episode 554.000000, reward total was -19.000000. running mean: -20.382795\n",
            "resetting env. episode 555.000000, reward total was -21.000000. running mean: -20.388967\n",
            "resetting env. episode 556.000000, reward total was -20.000000. running mean: -20.385077\n",
            "resetting env. episode 557.000000, reward total was -21.000000. running mean: -20.391226\n",
            "resetting env. episode 558.000000, reward total was -21.000000. running mean: -20.397314\n",
            "resetting env. episode 559.000000, reward total was -21.000000. running mean: -20.403341\n",
            "resetting env. episode 560.000000, reward total was -20.000000. running mean: -20.399308\n",
            "resetting env. episode 561.000000, reward total was -20.000000. running mean: -20.395315\n",
            "resetting env. episode 562.000000, reward total was -19.000000. running mean: -20.381361\n",
            "resetting env. episode 563.000000, reward total was -21.000000. running mean: -20.387548\n",
            "resetting env. episode 564.000000, reward total was -21.000000. running mean: -20.393672\n",
            "resetting env. episode 565.000000, reward total was -20.000000. running mean: -20.389736\n",
            "resetting env. episode 566.000000, reward total was -20.000000. running mean: -20.385838\n",
            "resetting env. episode 567.000000, reward total was -21.000000. running mean: -20.391980\n",
            "resetting env. episode 568.000000, reward total was -19.000000. running mean: -20.378060\n",
            "resetting env. episode 569.000000, reward total was -20.000000. running mean: -20.374279\n",
            "resetting env. episode 570.000000, reward total was -20.000000. running mean: -20.370537\n",
            "resetting env. episode 571.000000, reward total was -21.000000. running mean: -20.376831\n",
            "resetting env. episode 572.000000, reward total was -21.000000. running mean: -20.383063\n",
            "resetting env. episode 573.000000, reward total was -20.000000. running mean: -20.379232\n",
            "resetting env. episode 574.000000, reward total was -21.000000. running mean: -20.385440\n",
            "resetting env. episode 575.000000, reward total was -21.000000. running mean: -20.391586\n",
            "resetting env. episode 576.000000, reward total was -21.000000. running mean: -20.397670\n",
            "resetting env. episode 577.000000, reward total was -20.000000. running mean: -20.393693\n",
            "resetting env. episode 578.000000, reward total was -20.000000. running mean: -20.389756\n",
            "resetting env. episode 579.000000, reward total was -20.000000. running mean: -20.385859\n",
            "resetting env. episode 580.000000, reward total was -21.000000. running mean: -20.392000\n",
            "resetting env. episode 581.000000, reward total was -21.000000. running mean: -20.398080\n",
            "resetting env. episode 582.000000, reward total was -21.000000. running mean: -20.404099\n",
            "resetting env. episode 583.000000, reward total was -21.000000. running mean: -20.410058\n",
            "resetting env. episode 584.000000, reward total was -19.000000. running mean: -20.395958\n",
            "resetting env. episode 585.000000, reward total was -19.000000. running mean: -20.381998\n",
            "resetting env. episode 586.000000, reward total was -21.000000. running mean: -20.388178\n",
            "resetting env. episode 587.000000, reward total was -20.000000. running mean: -20.384296\n",
            "resetting env. episode 588.000000, reward total was -20.000000. running mean: -20.380453\n",
            "resetting env. episode 589.000000, reward total was -21.000000. running mean: -20.386649\n",
            "resetting env. episode 590.000000, reward total was -20.000000. running mean: -20.382782\n",
            "resetting env. episode 591.000000, reward total was -21.000000. running mean: -20.388954\n",
            "resetting env. episode 592.000000, reward total was -21.000000. running mean: -20.395065\n",
            "resetting env. episode 593.000000, reward total was -21.000000. running mean: -20.401114\n",
            "resetting env. episode 594.000000, reward total was -21.000000. running mean: -20.407103\n",
            "resetting env. episode 595.000000, reward total was -19.000000. running mean: -20.393032\n",
            "resetting env. episode 596.000000, reward total was -20.000000. running mean: -20.389102\n",
            "resetting env. episode 597.000000, reward total was -19.000000. running mean: -20.375211\n",
            "resetting env. episode 598.000000, reward total was -20.000000. running mean: -20.371459\n",
            "resetting env. episode 599.000000, reward total was -20.000000. running mean: -20.367744\n",
            "resetting env. episode 600.000000, reward total was -21.000000. running mean: -20.374067\n",
            "resetting env. episode 601.000000, reward total was -21.000000. running mean: -20.380326\n",
            "resetting env. episode 602.000000, reward total was -21.000000. running mean: -20.386523\n",
            "resetting env. episode 603.000000, reward total was -21.000000. running mean: -20.392657\n",
            "resetting env. episode 604.000000, reward total was -21.000000. running mean: -20.398731\n",
            "resetting env. episode 605.000000, reward total was -18.000000. running mean: -20.374744\n",
            "resetting env. episode 606.000000, reward total was -20.000000. running mean: -20.370996\n",
            "resetting env. episode 607.000000, reward total was -21.000000. running mean: -20.377286\n",
            "resetting env. episode 608.000000, reward total was -20.000000. running mean: -20.373513\n",
            "resetting env. episode 609.000000, reward total was -20.000000. running mean: -20.369778\n",
            "resetting env. episode 610.000000, reward total was -21.000000. running mean: -20.376080\n",
            "resetting env. episode 611.000000, reward total was -21.000000. running mean: -20.382320\n",
            "resetting env. episode 612.000000, reward total was -21.000000. running mean: -20.388496\n",
            "resetting env. episode 613.000000, reward total was -21.000000. running mean: -20.394611\n",
            "resetting env. episode 614.000000, reward total was -20.000000. running mean: -20.390665\n",
            "resetting env. episode 615.000000, reward total was -21.000000. running mean: -20.396759\n",
            "resetting env. episode 616.000000, reward total was -21.000000. running mean: -20.402791\n",
            "resetting env. episode 617.000000, reward total was -21.000000. running mean: -20.408763\n",
            "resetting env. episode 618.000000, reward total was -21.000000. running mean: -20.414676\n",
            "resetting env. episode 619.000000, reward total was -21.000000. running mean: -20.420529\n",
            "resetting env. episode 620.000000, reward total was -21.000000. running mean: -20.426324\n",
            "resetting env. episode 621.000000, reward total was -21.000000. running mean: -20.432060\n",
            "resetting env. episode 622.000000, reward total was -21.000000. running mean: -20.437740\n",
            "resetting env. episode 623.000000, reward total was -20.000000. running mean: -20.433362\n",
            "resetting env. episode 624.000000, reward total was -21.000000. running mean: -20.439029\n",
            "resetting env. episode 625.000000, reward total was -20.000000. running mean: -20.434638\n",
            "resetting env. episode 626.000000, reward total was -21.000000. running mean: -20.440292\n",
            "resetting env. episode 627.000000, reward total was -21.000000. running mean: -20.445889\n",
            "resetting env. episode 628.000000, reward total was -21.000000. running mean: -20.451430\n",
            "resetting env. episode 629.000000, reward total was -20.000000. running mean: -20.446916\n",
            "resetting env. episode 630.000000, reward total was -21.000000. running mean: -20.452447\n",
            "resetting env. episode 631.000000, reward total was -19.000000. running mean: -20.437922\n",
            "resetting env. episode 632.000000, reward total was -19.000000. running mean: -20.423543\n",
            "resetting env. episode 633.000000, reward total was -21.000000. running mean: -20.429308\n",
            "resetting env. episode 634.000000, reward total was -21.000000. running mean: -20.435015\n",
            "resetting env. episode 635.000000, reward total was -21.000000. running mean: -20.440664\n",
            "resetting env. episode 636.000000, reward total was -21.000000. running mean: -20.446258\n",
            "resetting env. episode 637.000000, reward total was -21.000000. running mean: -20.451795\n",
            "resetting env. episode 638.000000, reward total was -21.000000. running mean: -20.457277\n",
            "resetting env. episode 639.000000, reward total was -21.000000. running mean: -20.462704\n",
            "resetting env. episode 640.000000, reward total was -20.000000. running mean: -20.458077\n",
            "resetting env. episode 641.000000, reward total was -21.000000. running mean: -20.463497\n",
            "resetting env. episode 642.000000, reward total was -21.000000. running mean: -20.468862\n",
            "resetting env. episode 643.000000, reward total was -19.000000. running mean: -20.454173\n",
            "resetting env. episode 644.000000, reward total was -20.000000. running mean: -20.449631\n",
            "resetting env. episode 645.000000, reward total was -21.000000. running mean: -20.455135\n",
            "resetting env. episode 646.000000, reward total was -21.000000. running mean: -20.460584\n",
            "resetting env. episode 647.000000, reward total was -21.000000. running mean: -20.465978\n",
            "resetting env. episode 648.000000, reward total was -21.000000. running mean: -20.471318\n",
            "resetting env. episode 649.000000, reward total was -21.000000. running mean: -20.476605\n",
            "resetting env. episode 650.000000, reward total was -21.000000. running mean: -20.481839\n",
            "resetting env. episode 651.000000, reward total was -20.000000. running mean: -20.477020\n",
            "resetting env. episode 652.000000, reward total was -17.000000. running mean: -20.442250\n",
            "resetting env. episode 653.000000, reward total was -21.000000. running mean: -20.447828\n",
            "resetting env. episode 654.000000, reward total was -19.000000. running mean: -20.433349\n",
            "resetting env. episode 655.000000, reward total was -21.000000. running mean: -20.439016\n",
            "resetting env. episode 656.000000, reward total was -21.000000. running mean: -20.444626\n",
            "resetting env. episode 657.000000, reward total was -21.000000. running mean: -20.450180\n",
            "resetting env. episode 658.000000, reward total was -21.000000. running mean: -20.455678\n",
            "resetting env. episode 659.000000, reward total was -21.000000. running mean: -20.461121\n",
            "resetting env. episode 660.000000, reward total was -21.000000. running mean: -20.466510\n",
            "resetting env. episode 661.000000, reward total was -21.000000. running mean: -20.471845\n",
            "resetting env. episode 662.000000, reward total was -19.000000. running mean: -20.457126\n",
            "resetting env. episode 663.000000, reward total was -21.000000. running mean: -20.462555\n",
            "resetting env. episode 664.000000, reward total was -21.000000. running mean: -20.467929\n",
            "resetting env. episode 665.000000, reward total was -21.000000. running mean: -20.473250\n",
            "resetting env. episode 666.000000, reward total was -21.000000. running mean: -20.478518\n",
            "resetting env. episode 667.000000, reward total was -21.000000. running mean: -20.483732\n",
            "resetting env. episode 668.000000, reward total was -20.000000. running mean: -20.478895\n",
            "resetting env. episode 669.000000, reward total was -20.000000. running mean: -20.474106\n",
            "resetting env. episode 670.000000, reward total was -21.000000. running mean: -20.479365\n",
            "resetting env. episode 671.000000, reward total was -21.000000. running mean: -20.484571\n",
            "resetting env. episode 672.000000, reward total was -21.000000. running mean: -20.489726\n",
            "resetting env. episode 673.000000, reward total was -20.000000. running mean: -20.484828\n",
            "resetting env. episode 674.000000, reward total was -21.000000. running mean: -20.489980\n",
            "resetting env. episode 675.000000, reward total was -20.000000. running mean: -20.485080\n",
            "resetting env. episode 676.000000, reward total was -21.000000. running mean: -20.490230\n",
            "resetting env. episode 677.000000, reward total was -20.000000. running mean: -20.485327\n",
            "resetting env. episode 678.000000, reward total was -21.000000. running mean: -20.490474\n",
            "resetting env. episode 679.000000, reward total was -21.000000. running mean: -20.495569\n",
            "resetting env. episode 680.000000, reward total was -20.000000. running mean: -20.490614\n",
            "resetting env. episode 681.000000, reward total was -21.000000. running mean: -20.495707\n",
            "resetting env. episode 682.000000, reward total was -21.000000. running mean: -20.500750\n",
            "resetting env. episode 683.000000, reward total was -20.000000. running mean: -20.495743\n",
            "resetting env. episode 684.000000, reward total was -20.000000. running mean: -20.490785\n",
            "resetting env. episode 685.000000, reward total was -21.000000. running mean: -20.495878\n",
            "resetting env. episode 686.000000, reward total was -21.000000. running mean: -20.500919\n",
            "resetting env. episode 687.000000, reward total was -21.000000. running mean: -20.505910\n",
            "resetting env. episode 688.000000, reward total was -21.000000. running mean: -20.510851\n",
            "resetting env. episode 689.000000, reward total was -20.000000. running mean: -20.505742\n",
            "resetting env. episode 690.000000, reward total was -21.000000. running mean: -20.510685\n",
            "resetting env. episode 691.000000, reward total was -21.000000. running mean: -20.515578\n",
            "resetting env. episode 692.000000, reward total was -21.000000. running mean: -20.520422\n",
            "resetting env. episode 693.000000, reward total was -21.000000. running mean: -20.525218\n",
            "resetting env. episode 694.000000, reward total was -20.000000. running mean: -20.519966\n",
            "resetting env. episode 695.000000, reward total was -21.000000. running mean: -20.524766\n",
            "resetting env. episode 696.000000, reward total was -20.000000. running mean: -20.519518\n",
            "resetting env. episode 697.000000, reward total was -20.000000. running mean: -20.514323\n",
            "resetting env. episode 698.000000, reward total was -21.000000. running mean: -20.519180\n",
            "resetting env. episode 699.000000, reward total was -21.000000. running mean: -20.523988\n",
            "resetting env. episode 700.000000, reward total was -18.000000. running mean: -20.498748\n",
            "resetting env. episode 701.000000, reward total was -21.000000. running mean: -20.503761\n",
            "resetting env. episode 702.000000, reward total was -21.000000. running mean: -20.508723\n",
            "resetting env. episode 703.000000, reward total was -21.000000. running mean: -20.513636\n",
            "resetting env. episode 704.000000, reward total was -21.000000. running mean: -20.518499\n",
            "resetting env. episode 705.000000, reward total was -20.000000. running mean: -20.513314\n",
            "resetting env. episode 706.000000, reward total was -21.000000. running mean: -20.518181\n",
            "resetting env. episode 707.000000, reward total was -19.000000. running mean: -20.503000\n",
            "resetting env. episode 708.000000, reward total was -21.000000. running mean: -20.507970\n",
            "resetting env. episode 709.000000, reward total was -21.000000. running mean: -20.512890\n",
            "resetting env. episode 710.000000, reward total was -21.000000. running mean: -20.517761\n",
            "resetting env. episode 711.000000, reward total was -20.000000. running mean: -20.512583\n",
            "resetting env. episode 712.000000, reward total was -21.000000. running mean: -20.517457\n",
            "resetting env. episode 713.000000, reward total was -21.000000. running mean: -20.522283\n",
            "resetting env. episode 714.000000, reward total was -21.000000. running mean: -20.527060\n",
            "resetting env. episode 715.000000, reward total was -21.000000. running mean: -20.531789\n",
            "resetting env. episode 716.000000, reward total was -21.000000. running mean: -20.536472\n",
            "resetting env. episode 717.000000, reward total was -21.000000. running mean: -20.541107\n",
            "resetting env. episode 718.000000, reward total was -21.000000. running mean: -20.545696\n",
            "resetting env. episode 719.000000, reward total was -21.000000. running mean: -20.550239\n",
            "resetting env. episode 720.000000, reward total was -20.000000. running mean: -20.544736\n",
            "resetting env. episode 721.000000, reward total was -21.000000. running mean: -20.549289\n",
            "resetting env. episode 722.000000, reward total was -20.000000. running mean: -20.543796\n",
            "resetting env. episode 723.000000, reward total was -21.000000. running mean: -20.548358\n",
            "resetting env. episode 724.000000, reward total was -21.000000. running mean: -20.552875\n",
            "resetting env. episode 725.000000, reward total was -21.000000. running mean: -20.557346\n",
            "resetting env. episode 726.000000, reward total was -21.000000. running mean: -20.561772\n",
            "resetting env. episode 727.000000, reward total was -20.000000. running mean: -20.556155\n",
            "resetting env. episode 728.000000, reward total was -21.000000. running mean: -20.560593\n",
            "resetting env. episode 729.000000, reward total was -21.000000. running mean: -20.564987\n",
            "resetting env. episode 730.000000, reward total was -21.000000. running mean: -20.569337\n",
            "resetting env. episode 731.000000, reward total was -21.000000. running mean: -20.573644\n",
            "resetting env. episode 732.000000, reward total was -21.000000. running mean: -20.577908\n",
            "resetting env. episode 733.000000, reward total was -21.000000. running mean: -20.582128\n",
            "resetting env. episode 734.000000, reward total was -20.000000. running mean: -20.576307\n",
            "resetting env. episode 735.000000, reward total was -21.000000. running mean: -20.580544\n",
            "resetting env. episode 736.000000, reward total was -20.000000. running mean: -20.574739\n",
            "resetting env. episode 737.000000, reward total was -21.000000. running mean: -20.578991\n",
            "resetting env. episode 738.000000, reward total was -20.000000. running mean: -20.573201\n",
            "resetting env. episode 739.000000, reward total was -21.000000. running mean: -20.577469\n",
            "resetting env. episode 740.000000, reward total was -19.000000. running mean: -20.561695\n",
            "resetting env. episode 741.000000, reward total was -21.000000. running mean: -20.566078\n",
            "resetting env. episode 742.000000, reward total was -21.000000. running mean: -20.570417\n",
            "resetting env. episode 743.000000, reward total was -21.000000. running mean: -20.574713\n",
            "resetting env. episode 744.000000, reward total was -21.000000. running mean: -20.578966\n",
            "resetting env. episode 745.000000, reward total was -21.000000. running mean: -20.583176\n",
            "resetting env. episode 746.000000, reward total was -20.000000. running mean: -20.577344\n",
            "resetting env. episode 747.000000, reward total was -21.000000. running mean: -20.581571\n",
            "resetting env. episode 748.000000, reward total was -21.000000. running mean: -20.585755\n",
            "resetting env. episode 749.000000, reward total was -21.000000. running mean: -20.589898\n",
            "resetting env. episode 750.000000, reward total was -21.000000. running mean: -20.593999\n",
            "resetting env. episode 751.000000, reward total was -21.000000. running mean: -20.598059\n",
            "resetting env. episode 752.000000, reward total was -20.000000. running mean: -20.592078\n",
            "resetting env. episode 753.000000, reward total was -20.000000. running mean: -20.586157\n",
            "resetting env. episode 754.000000, reward total was -20.000000. running mean: -20.580296\n",
            "resetting env. episode 755.000000, reward total was -21.000000. running mean: -20.584493\n",
            "resetting env. episode 756.000000, reward total was -20.000000. running mean: -20.578648\n",
            "resetting env. episode 757.000000, reward total was -21.000000. running mean: -20.582861\n",
            "resetting env. episode 758.000000, reward total was -21.000000. running mean: -20.587033\n",
            "resetting env. episode 759.000000, reward total was -21.000000. running mean: -20.591162\n",
            "resetting env. episode 760.000000, reward total was -19.000000. running mean: -20.575251\n",
            "resetting env. episode 761.000000, reward total was -21.000000. running mean: -20.579498\n",
            "resetting env. episode 762.000000, reward total was -21.000000. running mean: -20.583703\n",
            "resetting env. episode 763.000000, reward total was -21.000000. running mean: -20.587866\n",
            "resetting env. episode 764.000000, reward total was -21.000000. running mean: -20.591988\n",
            "resetting env. episode 765.000000, reward total was -21.000000. running mean: -20.596068\n",
            "resetting env. episode 766.000000, reward total was -21.000000. running mean: -20.600107\n",
            "resetting env. episode 767.000000, reward total was -21.000000. running mean: -20.604106\n",
            "resetting env. episode 768.000000, reward total was -21.000000. running mean: -20.608065\n",
            "resetting env. episode 769.000000, reward total was -19.000000. running mean: -20.591984\n",
            "resetting env. episode 770.000000, reward total was -21.000000. running mean: -20.596064\n",
            "resetting env. episode 771.000000, reward total was -21.000000. running mean: -20.600104\n",
            "resetting env. episode 772.000000, reward total was -19.000000. running mean: -20.584103\n",
            "resetting env. episode 773.000000, reward total was -21.000000. running mean: -20.588262\n",
            "resetting env. episode 774.000000, reward total was -21.000000. running mean: -20.592379\n",
            "resetting env. episode 775.000000, reward total was -21.000000. running mean: -20.596455\n",
            "resetting env. episode 776.000000, reward total was -21.000000. running mean: -20.600491\n",
            "resetting env. episode 777.000000, reward total was -21.000000. running mean: -20.604486\n",
            "resetting env. episode 778.000000, reward total was -21.000000. running mean: -20.608441\n",
            "resetting env. episode 779.000000, reward total was -20.000000. running mean: -20.602357\n",
            "resetting env. episode 780.000000, reward total was -21.000000. running mean: -20.606333\n",
            "resetting env. episode 781.000000, reward total was -19.000000. running mean: -20.590270\n",
            "resetting env. episode 782.000000, reward total was -19.000000. running mean: -20.574367\n",
            "resetting env. episode 783.000000, reward total was -21.000000. running mean: -20.578623\n",
            "resetting env. episode 784.000000, reward total was -20.000000. running mean: -20.572837\n",
            "resetting env. episode 785.000000, reward total was -19.000000. running mean: -20.557109\n",
            "resetting env. episode 786.000000, reward total was -21.000000. running mean: -20.561538\n",
            "resetting env. episode 787.000000, reward total was -21.000000. running mean: -20.565922\n",
            "resetting env. episode 788.000000, reward total was -18.000000. running mean: -20.540263\n",
            "resetting env. episode 789.000000, reward total was -19.000000. running mean: -20.524860\n",
            "resetting env. episode 790.000000, reward total was -21.000000. running mean: -20.529612\n",
            "resetting env. episode 791.000000, reward total was -20.000000. running mean: -20.524316\n",
            "resetting env. episode 792.000000, reward total was -21.000000. running mean: -20.529072\n",
            "resetting env. episode 793.000000, reward total was -21.000000. running mean: -20.533782\n",
            "resetting env. episode 794.000000, reward total was -19.000000. running mean: -20.518444\n",
            "resetting env. episode 795.000000, reward total was -21.000000. running mean: -20.523259\n",
            "resetting env. episode 796.000000, reward total was -21.000000. running mean: -20.528027\n",
            "resetting env. episode 797.000000, reward total was -20.000000. running mean: -20.522747\n",
            "resetting env. episode 798.000000, reward total was -21.000000. running mean: -20.527519\n",
            "resetting env. episode 799.000000, reward total was -19.000000. running mean: -20.512244\n",
            "resetting env. episode 800.000000, reward total was -19.000000. running mean: -20.497122\n",
            "resetting env. episode 801.000000, reward total was -19.000000. running mean: -20.482150\n",
            "resetting env. episode 802.000000, reward total was -20.000000. running mean: -20.477329\n",
            "resetting env. episode 803.000000, reward total was -21.000000. running mean: -20.482556\n",
            "resetting env. episode 804.000000, reward total was -21.000000. running mean: -20.487730\n",
            "resetting env. episode 805.000000, reward total was -20.000000. running mean: -20.482853\n",
            "resetting env. episode 806.000000, reward total was -19.000000. running mean: -20.468024\n",
            "resetting env. episode 807.000000, reward total was -21.000000. running mean: -20.473344\n",
            "resetting env. episode 808.000000, reward total was -20.000000. running mean: -20.468610\n",
            "resetting env. episode 809.000000, reward total was -21.000000. running mean: -20.473924\n",
            "resetting env. episode 810.000000, reward total was -21.000000. running mean: -20.479185\n",
            "resetting env. episode 811.000000, reward total was -21.000000. running mean: -20.484393\n",
            "resetting env. episode 812.000000, reward total was -21.000000. running mean: -20.489549\n",
            "resetting env. episode 813.000000, reward total was -21.000000. running mean: -20.494654\n",
            "resetting env. episode 814.000000, reward total was -20.000000. running mean: -20.489707\n",
            "resetting env. episode 815.000000, reward total was -18.000000. running mean: -20.464810\n",
            "resetting env. episode 816.000000, reward total was -21.000000. running mean: -20.470162\n",
            "resetting env. episode 817.000000, reward total was -21.000000. running mean: -20.475460\n",
            "resetting env. episode 818.000000, reward total was -20.000000. running mean: -20.470706\n",
            "resetting env. episode 819.000000, reward total was -20.000000. running mean: -20.465999\n",
            "resetting env. episode 820.000000, reward total was -21.000000. running mean: -20.471339\n",
            "resetting env. episode 821.000000, reward total was -21.000000. running mean: -20.476625\n",
            "resetting env. episode 822.000000, reward total was -20.000000. running mean: -20.471859\n",
            "resetting env. episode 823.000000, reward total was -21.000000. running mean: -20.477141\n",
            "resetting env. episode 824.000000, reward total was -21.000000. running mean: -20.482369\n",
            "resetting env. episode 825.000000, reward total was -21.000000. running mean: -20.487546\n",
            "resetting env. episode 826.000000, reward total was -21.000000. running mean: -20.492670\n",
            "resetting env. episode 827.000000, reward total was -19.000000. running mean: -20.477743\n",
            "resetting env. episode 828.000000, reward total was -21.000000. running mean: -20.482966\n",
            "resetting env. episode 829.000000, reward total was -21.000000. running mean: -20.488136\n",
            "resetting env. episode 830.000000, reward total was -21.000000. running mean: -20.493255\n",
            "resetting env. episode 831.000000, reward total was -21.000000. running mean: -20.498322\n",
            "resetting env. episode 832.000000, reward total was -21.000000. running mean: -20.503339\n",
            "resetting env. episode 833.000000, reward total was -21.000000. running mean: -20.508306\n",
            "resetting env. episode 834.000000, reward total was -21.000000. running mean: -20.513223\n",
            "resetting env. episode 835.000000, reward total was -20.000000. running mean: -20.508090\n",
            "resetting env. episode 836.000000, reward total was -21.000000. running mean: -20.513010\n",
            "resetting env. episode 837.000000, reward total was -20.000000. running mean: -20.507879\n",
            "resetting env. episode 838.000000, reward total was -21.000000. running mean: -20.512801\n",
            "resetting env. episode 839.000000, reward total was -21.000000. running mean: -20.517673\n",
            "resetting env. episode 840.000000, reward total was -21.000000. running mean: -20.522496\n",
            "resetting env. episode 841.000000, reward total was -20.000000. running mean: -20.517271\n",
            "resetting env. episode 842.000000, reward total was -20.000000. running mean: -20.512098\n",
            "resetting env. episode 843.000000, reward total was -19.000000. running mean: -20.496977\n",
            "resetting env. episode 844.000000, reward total was -21.000000. running mean: -20.502008\n",
            "resetting env. episode 845.000000, reward total was -21.000000. running mean: -20.506987\n",
            "resetting env. episode 846.000000, reward total was -20.000000. running mean: -20.501918\n",
            "resetting env. episode 847.000000, reward total was -21.000000. running mean: -20.506898\n",
            "resetting env. episode 848.000000, reward total was -21.000000. running mean: -20.511829\n",
            "resetting env. episode 849.000000, reward total was -21.000000. running mean: -20.516711\n",
            "resetting env. episode 850.000000, reward total was -20.000000. running mean: -20.511544\n",
            "resetting env. episode 851.000000, reward total was -19.000000. running mean: -20.496429\n",
            "resetting env. episode 852.000000, reward total was -20.000000. running mean: -20.491464\n",
            "resetting env. episode 853.000000, reward total was -21.000000. running mean: -20.496550\n",
            "resetting env. episode 854.000000, reward total was -21.000000. running mean: -20.501584\n",
            "resetting env. episode 855.000000, reward total was -21.000000. running mean: -20.506568\n",
            "resetting env. episode 856.000000, reward total was -21.000000. running mean: -20.511503\n",
            "resetting env. episode 857.000000, reward total was -20.000000. running mean: -20.506388\n",
            "resetting env. episode 858.000000, reward total was -20.000000. running mean: -20.501324\n",
            "resetting env. episode 859.000000, reward total was -21.000000. running mean: -20.506310\n",
            "resetting env. episode 860.000000, reward total was -21.000000. running mean: -20.511247\n",
            "resetting env. episode 861.000000, reward total was -18.000000. running mean: -20.486135\n",
            "resetting env. episode 862.000000, reward total was -21.000000. running mean: -20.491274\n",
            "resetting env. episode 863.000000, reward total was -20.000000. running mean: -20.486361\n",
            "resetting env. episode 864.000000, reward total was -21.000000. running mean: -20.491497\n",
            "resetting env. episode 865.000000, reward total was -21.000000. running mean: -20.496582\n",
            "resetting env. episode 866.000000, reward total was -21.000000. running mean: -20.501616\n",
            "resetting env. episode 867.000000, reward total was -21.000000. running mean: -20.506600\n",
            "resetting env. episode 868.000000, reward total was -17.000000. running mean: -20.471534\n",
            "resetting env. episode 869.000000, reward total was -21.000000. running mean: -20.476819\n",
            "resetting env. episode 870.000000, reward total was -20.000000. running mean: -20.472051\n",
            "resetting env. episode 871.000000, reward total was -20.000000. running mean: -20.467330\n",
            "resetting env. episode 872.000000, reward total was -20.000000. running mean: -20.462657\n",
            "resetting env. episode 873.000000, reward total was -21.000000. running mean: -20.468030\n",
            "resetting env. episode 874.000000, reward total was -19.000000. running mean: -20.453350\n",
            "resetting env. episode 875.000000, reward total was -21.000000. running mean: -20.458817\n",
            "resetting env. episode 876.000000, reward total was -21.000000. running mean: -20.464228\n",
            "resetting env. episode 877.000000, reward total was -20.000000. running mean: -20.459586\n",
            "resetting env. episode 878.000000, reward total was -20.000000. running mean: -20.454990\n",
            "resetting env. episode 879.000000, reward total was -21.000000. running mean: -20.460440\n",
            "resetting env. episode 880.000000, reward total was -20.000000. running mean: -20.455836\n",
            "resetting env. episode 881.000000, reward total was -21.000000. running mean: -20.461278\n",
            "resetting env. episode 882.000000, reward total was -21.000000. running mean: -20.466665\n",
            "resetting env. episode 883.000000, reward total was -21.000000. running mean: -20.471998\n",
            "resetting env. episode 884.000000, reward total was -21.000000. running mean: -20.477278\n",
            "resetting env. episode 885.000000, reward total was -20.000000. running mean: -20.472505\n",
            "resetting env. episode 886.000000, reward total was -21.000000. running mean: -20.477780\n",
            "resetting env. episode 887.000000, reward total was -21.000000. running mean: -20.483003\n",
            "resetting env. episode 888.000000, reward total was -18.000000. running mean: -20.458172\n",
            "resetting env. episode 889.000000, reward total was -20.000000. running mean: -20.453591\n",
            "resetting env. episode 890.000000, reward total was -21.000000. running mean: -20.459055\n",
            "resetting env. episode 891.000000, reward total was -21.000000. running mean: -20.464464\n",
            "resetting env. episode 892.000000, reward total was -21.000000. running mean: -20.469820\n",
            "resetting env. episode 893.000000, reward total was -19.000000. running mean: -20.455121\n",
            "resetting env. episode 894.000000, reward total was -21.000000. running mean: -20.460570\n",
            "resetting env. episode 895.000000, reward total was -21.000000. running mean: -20.465965\n",
            "resetting env. episode 896.000000, reward total was -21.000000. running mean: -20.471305\n",
            "resetting env. episode 897.000000, reward total was -20.000000. running mean: -20.466592\n",
            "resetting env. episode 898.000000, reward total was -20.000000. running mean: -20.461926\n",
            "resetting env. episode 899.000000, reward total was -20.000000. running mean: -20.457307\n",
            "resetting env. episode 900.000000, reward total was -20.000000. running mean: -20.452734\n",
            "resetting env. episode 901.000000, reward total was -21.000000. running mean: -20.458206\n",
            "resetting env. episode 902.000000, reward total was -20.000000. running mean: -20.453624\n",
            "resetting env. episode 903.000000, reward total was -21.000000. running mean: -20.459088\n",
            "resetting env. episode 904.000000, reward total was -20.000000. running mean: -20.454497\n",
            "resetting env. episode 905.000000, reward total was -20.000000. running mean: -20.449952\n",
            "resetting env. episode 906.000000, reward total was -20.000000. running mean: -20.445453\n",
            "resetting env. episode 907.000000, reward total was -20.000000. running mean: -20.440998\n",
            "resetting env. episode 908.000000, reward total was -18.000000. running mean: -20.416588\n",
            "resetting env. episode 909.000000, reward total was -19.000000. running mean: -20.402422\n",
            "resetting env. episode 910.000000, reward total was -21.000000. running mean: -20.408398\n",
            "resetting env. episode 911.000000, reward total was -19.000000. running mean: -20.394314\n",
            "resetting env. episode 912.000000, reward total was -21.000000. running mean: -20.400371\n",
            "resetting env. episode 913.000000, reward total was -20.000000. running mean: -20.396367\n",
            "resetting env. episode 914.000000, reward total was -20.000000. running mean: -20.392403\n",
            "resetting env. episode 915.000000, reward total was -21.000000. running mean: -20.398479\n",
            "resetting env. episode 916.000000, reward total was -21.000000. running mean: -20.404495\n",
            "resetting env. episode 917.000000, reward total was -21.000000. running mean: -20.410450\n",
            "resetting env. episode 918.000000, reward total was -21.000000. running mean: -20.416345\n",
            "resetting env. episode 919.000000, reward total was -21.000000. running mean: -20.422182\n",
            "resetting env. episode 920.000000, reward total was -20.000000. running mean: -20.417960\n",
            "resetting env. episode 921.000000, reward total was -21.000000. running mean: -20.423780\n",
            "resetting env. episode 922.000000, reward total was -20.000000. running mean: -20.419543\n",
            "resetting env. episode 923.000000, reward total was -21.000000. running mean: -20.425347\n",
            "resetting env. episode 924.000000, reward total was -20.000000. running mean: -20.421094\n",
            "resetting env. episode 925.000000, reward total was -21.000000. running mean: -20.426883\n",
            "resetting env. episode 926.000000, reward total was -19.000000. running mean: -20.412614\n",
            "resetting env. episode 927.000000, reward total was -21.000000. running mean: -20.418488\n",
            "resetting env. episode 928.000000, reward total was -21.000000. running mean: -20.424303\n",
            "resetting env. episode 929.000000, reward total was -21.000000. running mean: -20.430060\n",
            "resetting env. episode 930.000000, reward total was -20.000000. running mean: -20.425759\n",
            "resetting env. episode 931.000000, reward total was -21.000000. running mean: -20.431502\n",
            "resetting env. episode 932.000000, reward total was -21.000000. running mean: -20.437187\n",
            "resetting env. episode 933.000000, reward total was -20.000000. running mean: -20.432815\n",
            "resetting env. episode 934.000000, reward total was -19.000000. running mean: -20.418487\n",
            "resetting env. episode 935.000000, reward total was -21.000000. running mean: -20.424302\n",
            "resetting env. episode 936.000000, reward total was -21.000000. running mean: -20.430059\n",
            "resetting env. episode 937.000000, reward total was -20.000000. running mean: -20.425758\n",
            "resetting env. episode 938.000000, reward total was -21.000000. running mean: -20.431501\n",
            "resetting env. episode 939.000000, reward total was -20.000000. running mean: -20.427186\n",
            "resetting env. episode 940.000000, reward total was -21.000000. running mean: -20.432914\n",
            "resetting env. episode 941.000000, reward total was -20.000000. running mean: -20.428585\n",
            "resetting env. episode 942.000000, reward total was -21.000000. running mean: -20.434299\n",
            "resetting env. episode 943.000000, reward total was -19.000000. running mean: -20.419956\n",
            "resetting env. episode 944.000000, reward total was -21.000000. running mean: -20.425756\n",
            "resetting env. episode 945.000000, reward total was -20.000000. running mean: -20.421499\n",
            "resetting env. episode 946.000000, reward total was -21.000000. running mean: -20.427284\n",
            "resetting env. episode 947.000000, reward total was -21.000000. running mean: -20.433011\n",
            "resetting env. episode 948.000000, reward total was -21.000000. running mean: -20.438681\n",
            "resetting env. episode 949.000000, reward total was -20.000000. running mean: -20.434294\n",
            "resetting env. episode 950.000000, reward total was -20.000000. running mean: -20.429951\n",
            "resetting env. episode 951.000000, reward total was -20.000000. running mean: -20.425651\n",
            "resetting env. episode 952.000000, reward total was -21.000000. running mean: -20.431395\n",
            "resetting env. episode 953.000000, reward total was -20.000000. running mean: -20.427081\n",
            "resetting env. episode 954.000000, reward total was -19.000000. running mean: -20.412810\n",
            "resetting env. episode 955.000000, reward total was -20.000000. running mean: -20.408682\n",
            "resetting env. episode 956.000000, reward total was -21.000000. running mean: -20.414595\n",
            "resetting env. episode 957.000000, reward total was -21.000000. running mean: -20.420449\n",
            "resetting env. episode 958.000000, reward total was -21.000000. running mean: -20.426245\n",
            "resetting env. episode 959.000000, reward total was -21.000000. running mean: -20.431982\n",
            "resetting env. episode 960.000000, reward total was -20.000000. running mean: -20.427663\n",
            "resetting env. episode 961.000000, reward total was -21.000000. running mean: -20.433386\n",
            "resetting env. episode 962.000000, reward total was -20.000000. running mean: -20.429052\n",
            "resetting env. episode 963.000000, reward total was -21.000000. running mean: -20.434762\n",
            "resetting env. episode 964.000000, reward total was -21.000000. running mean: -20.440414\n",
            "resetting env. episode 965.000000, reward total was -20.000000. running mean: -20.436010\n",
            "resetting env. episode 966.000000, reward total was -19.000000. running mean: -20.421650\n",
            "resetting env. episode 967.000000, reward total was -20.000000. running mean: -20.417433\n",
            "resetting env. episode 968.000000, reward total was -21.000000. running mean: -20.423259\n",
            "resetting env. episode 969.000000, reward total was -20.000000. running mean: -20.419026\n",
            "resetting env. episode 970.000000, reward total was -20.000000. running mean: -20.414836\n",
            "resetting env. episode 971.000000, reward total was -20.000000. running mean: -20.410688\n",
            "resetting env. episode 972.000000, reward total was -21.000000. running mean: -20.416581\n",
            "resetting env. episode 973.000000, reward total was -19.000000. running mean: -20.402415\n",
            "resetting env. episode 974.000000, reward total was -20.000000. running mean: -20.398391\n",
            "resetting env. episode 975.000000, reward total was -21.000000. running mean: -20.404407\n",
            "resetting env. episode 976.000000, reward total was -19.000000. running mean: -20.390363\n",
            "resetting env. episode 977.000000, reward total was -20.000000. running mean: -20.386459\n",
            "resetting env. episode 978.000000, reward total was -18.000000. running mean: -20.362595\n",
            "resetting env. episode 979.000000, reward total was -18.000000. running mean: -20.338969\n",
            "resetting env. episode 980.000000, reward total was -19.000000. running mean: -20.325579\n",
            "resetting env. episode 981.000000, reward total was -21.000000. running mean: -20.332323\n",
            "resetting env. episode 982.000000, reward total was -21.000000. running mean: -20.339000\n",
            "resetting env. episode 983.000000, reward total was -21.000000. running mean: -20.345610\n",
            "resetting env. episode 984.000000, reward total was -20.000000. running mean: -20.342154\n",
            "resetting env. episode 985.000000, reward total was -21.000000. running mean: -20.348732\n",
            "resetting env. episode 986.000000, reward total was -21.000000. running mean: -20.355245\n",
            "resetting env. episode 987.000000, reward total was -21.000000. running mean: -20.361693\n",
            "resetting env. episode 988.000000, reward total was -21.000000. running mean: -20.368076\n",
            "resetting env. episode 989.000000, reward total was -21.000000. running mean: -20.374395\n",
            "resetting env. episode 990.000000, reward total was -21.000000. running mean: -20.380651\n",
            "resetting env. episode 991.000000, reward total was -20.000000. running mean: -20.376844\n",
            "resetting env. episode 992.000000, reward total was -21.000000. running mean: -20.383076\n",
            "resetting env. episode 993.000000, reward total was -20.000000. running mean: -20.379245\n",
            "resetting env. episode 994.000000, reward total was -21.000000. running mean: -20.385453\n",
            "resetting env. episode 995.000000, reward total was -20.000000. running mean: -20.381598\n",
            "resetting env. episode 996.000000, reward total was -21.000000. running mean: -20.387782\n",
            "resetting env. episode 997.000000, reward total was -21.000000. running mean: -20.393904\n",
            "resetting env. episode 998.000000, reward total was -21.000000. running mean: -20.399965\n",
            "resetting env. episode 999.000000, reward total was -21.000000. running mean: -20.405966\n",
            "resetting env. episode 1000.000000, reward total was -21.000000. running mean: -20.411906\n",
            "resetting env. episode 1001.000000, reward total was -21.000000. running mean: -20.417787\n",
            "resetting env. episode 1002.000000, reward total was -21.000000. running mean: -20.423609\n",
            "resetting env. episode 1003.000000, reward total was -19.000000. running mean: -20.409373\n",
            "resetting env. episode 1004.000000, reward total was -18.000000. running mean: -20.385279\n",
            "resetting env. episode 1005.000000, reward total was -20.000000. running mean: -20.381426\n",
            "resetting env. episode 1006.000000, reward total was -21.000000. running mean: -20.387612\n",
            "resetting env. episode 1007.000000, reward total was -21.000000. running mean: -20.393736\n",
            "resetting env. episode 1008.000000, reward total was -21.000000. running mean: -20.399799\n",
            "resetting env. episode 1009.000000, reward total was -20.000000. running mean: -20.395801\n",
            "resetting env. episode 1010.000000, reward total was -21.000000. running mean: -20.401843\n",
            "resetting env. episode 1011.000000, reward total was -21.000000. running mean: -20.407824\n",
            "resetting env. episode 1012.000000, reward total was -21.000000. running mean: -20.413746\n",
            "resetting env. episode 1013.000000, reward total was -18.000000. running mean: -20.389609\n",
            "resetting env. episode 1014.000000, reward total was -21.000000. running mean: -20.395713\n",
            "resetting env. episode 1015.000000, reward total was -21.000000. running mean: -20.401755\n",
            "resetting env. episode 1016.000000, reward total was -21.000000. running mean: -20.407738\n",
            "resetting env. episode 1017.000000, reward total was -21.000000. running mean: -20.413660\n",
            "resetting env. episode 1018.000000, reward total was -19.000000. running mean: -20.399524\n",
            "resetting env. episode 1019.000000, reward total was -21.000000. running mean: -20.405529\n",
            "resetting env. episode 1020.000000, reward total was -21.000000. running mean: -20.411473\n",
            "resetting env. episode 1021.000000, reward total was -20.000000. running mean: -20.407359\n",
            "resetting env. episode 1022.000000, reward total was -21.000000. running mean: -20.413285\n",
            "resetting env. episode 1023.000000, reward total was -21.000000. running mean: -20.419152\n",
            "resetting env. episode 1024.000000, reward total was -20.000000. running mean: -20.414961\n",
            "resetting env. episode 1025.000000, reward total was -21.000000. running mean: -20.420811\n",
            "resetting env. episode 1026.000000, reward total was -21.000000. running mean: -20.426603\n",
            "resetting env. episode 1027.000000, reward total was -18.000000. running mean: -20.402337\n",
            "resetting env. episode 1028.000000, reward total was -21.000000. running mean: -20.408314\n",
            "resetting env. episode 1029.000000, reward total was -20.000000. running mean: -20.404230\n",
            "resetting env. episode 1030.000000, reward total was -21.000000. running mean: -20.410188\n",
            "resetting env. episode 1031.000000, reward total was -20.000000. running mean: -20.406086\n",
            "resetting env. episode 1032.000000, reward total was -19.000000. running mean: -20.392025\n",
            "resetting env. episode 1033.000000, reward total was -21.000000. running mean: -20.398105\n",
            "resetting env. episode 1034.000000, reward total was -21.000000. running mean: -20.404124\n",
            "resetting env. episode 1035.000000, reward total was -21.000000. running mean: -20.410083\n",
            "resetting env. episode 1036.000000, reward total was -20.000000. running mean: -20.405982\n",
            "resetting env. episode 1037.000000, reward total was -21.000000. running mean: -20.411922\n",
            "resetting env. episode 1038.000000, reward total was -21.000000. running mean: -20.417803\n",
            "resetting env. episode 1039.000000, reward total was -21.000000. running mean: -20.423625\n",
            "resetting env. episode 1040.000000, reward total was -21.000000. running mean: -20.429389\n",
            "resetting env. episode 1041.000000, reward total was -20.000000. running mean: -20.425095\n",
            "resetting env. episode 1042.000000, reward total was -19.000000. running mean: -20.410844\n",
            "resetting env. episode 1043.000000, reward total was -19.000000. running mean: -20.396735\n",
            "resetting env. episode 1044.000000, reward total was -19.000000. running mean: -20.382768\n",
            "resetting env. episode 1045.000000, reward total was -21.000000. running mean: -20.388940\n",
            "resetting env. episode 1046.000000, reward total was -21.000000. running mean: -20.395051\n",
            "resetting env. episode 1047.000000, reward total was -21.000000. running mean: -20.401100\n",
            "resetting env. episode 1048.000000, reward total was -20.000000. running mean: -20.397089\n",
            "resetting env. episode 1049.000000, reward total was -21.000000. running mean: -20.403119\n",
            "resetting env. episode 1050.000000, reward total was -21.000000. running mean: -20.409087\n",
            "resetting env. episode 1051.000000, reward total was -20.000000. running mean: -20.404996\n",
            "resetting env. episode 1052.000000, reward total was -20.000000. running mean: -20.400947\n",
            "resetting env. episode 1053.000000, reward total was -19.000000. running mean: -20.386937\n",
            "resetting env. episode 1054.000000, reward total was -20.000000. running mean: -20.383068\n",
            "resetting env. episode 1055.000000, reward total was -21.000000. running mean: -20.389237\n",
            "resetting env. episode 1056.000000, reward total was -21.000000. running mean: -20.395345\n",
            "resetting env. episode 1057.000000, reward total was -21.000000. running mean: -20.401391\n",
            "resetting env. episode 1058.000000, reward total was -20.000000. running mean: -20.397377\n",
            "resetting env. episode 1059.000000, reward total was -20.000000. running mean: -20.393404\n",
            "resetting env. episode 1060.000000, reward total was -21.000000. running mean: -20.399469\n",
            "resetting env. episode 1061.000000, reward total was -21.000000. running mean: -20.405475\n",
            "resetting env. episode 1062.000000, reward total was -19.000000. running mean: -20.391420\n",
            "resetting env. episode 1063.000000, reward total was -21.000000. running mean: -20.397506\n",
            "resetting env. episode 1064.000000, reward total was -21.000000. running mean: -20.403531\n",
            "resetting env. episode 1065.000000, reward total was -19.000000. running mean: -20.389495\n",
            "resetting env. episode 1066.000000, reward total was -20.000000. running mean: -20.385601\n",
            "resetting env. episode 1067.000000, reward total was -21.000000. running mean: -20.391745\n",
            "resetting env. episode 1068.000000, reward total was -20.000000. running mean: -20.387827\n",
            "resetting env. episode 1069.000000, reward total was -20.000000. running mean: -20.383949\n",
            "resetting env. episode 1070.000000, reward total was -21.000000. running mean: -20.390109\n",
            "resetting env. episode 1071.000000, reward total was -18.000000. running mean: -20.366208\n",
            "resetting env. episode 1072.000000, reward total was -18.000000. running mean: -20.342546\n",
            "resetting env. episode 1073.000000, reward total was -21.000000. running mean: -20.349121\n",
            "resetting env. episode 1074.000000, reward total was -21.000000. running mean: -20.355629\n",
            "resetting env. episode 1075.000000, reward total was -21.000000. running mean: -20.362073\n",
            "resetting env. episode 1076.000000, reward total was -21.000000. running mean: -20.368452\n",
            "resetting env. episode 1077.000000, reward total was -18.000000. running mean: -20.344768\n",
            "resetting env. episode 1078.000000, reward total was -18.000000. running mean: -20.321320\n",
            "resetting env. episode 1079.000000, reward total was -21.000000. running mean: -20.328107\n",
            "resetting env. episode 1080.000000, reward total was -20.000000. running mean: -20.324826\n",
            "resetting env. episode 1081.000000, reward total was -21.000000. running mean: -20.331578\n",
            "resetting env. episode 1082.000000, reward total was -21.000000. running mean: -20.338262\n",
            "resetting env. episode 1083.000000, reward total was -19.000000. running mean: -20.324879\n",
            "resetting env. episode 1084.000000, reward total was -21.000000. running mean: -20.331631\n",
            "resetting env. episode 1085.000000, reward total was -19.000000. running mean: -20.318314\n",
            "resetting env. episode 1086.000000, reward total was -20.000000. running mean: -20.315131\n",
            "resetting env. episode 1087.000000, reward total was -21.000000. running mean: -20.321980\n",
            "resetting env. episode 1088.000000, reward total was -21.000000. running mean: -20.328760\n",
            "resetting env. episode 1089.000000, reward total was -19.000000. running mean: -20.315472\n",
            "resetting env. episode 1090.000000, reward total was -20.000000. running mean: -20.312318\n",
            "resetting env. episode 1091.000000, reward total was -20.000000. running mean: -20.309194\n",
            "resetting env. episode 1092.000000, reward total was -21.000000. running mean: -20.316103\n",
            "resetting env. episode 1093.000000, reward total was -21.000000. running mean: -20.322941\n",
            "resetting env. episode 1094.000000, reward total was -21.000000. running mean: -20.329712\n",
            "resetting env. episode 1095.000000, reward total was -21.000000. running mean: -20.336415\n",
            "resetting env. episode 1096.000000, reward total was -20.000000. running mean: -20.333051\n",
            "resetting env. episode 1097.000000, reward total was -20.000000. running mean: -20.329720\n",
            "resetting env. episode 1098.000000, reward total was -20.000000. running mean: -20.326423\n",
            "resetting env. episode 1099.000000, reward total was -17.000000. running mean: -20.293159\n",
            "resetting env. episode 1100.000000, reward total was -21.000000. running mean: -20.300227\n",
            "resetting env. episode 1101.000000, reward total was -21.000000. running mean: -20.307225\n",
            "resetting env. episode 1102.000000, reward total was -21.000000. running mean: -20.314153\n",
            "resetting env. episode 1103.000000, reward total was -21.000000. running mean: -20.321011\n",
            "resetting env. episode 1104.000000, reward total was -21.000000. running mean: -20.327801\n",
            "resetting env. episode 1105.000000, reward total was -21.000000. running mean: -20.334523\n",
            "resetting env. episode 1106.000000, reward total was -21.000000. running mean: -20.341178\n",
            "resetting env. episode 1107.000000, reward total was -21.000000. running mean: -20.347766\n",
            "resetting env. episode 1108.000000, reward total was -21.000000. running mean: -20.354288\n",
            "resetting env. episode 1109.000000, reward total was -21.000000. running mean: -20.360746\n",
            "resetting env. episode 1110.000000, reward total was -20.000000. running mean: -20.357138\n",
            "resetting env. episode 1111.000000, reward total was -21.000000. running mean: -20.363567\n",
            "resetting env. episode 1112.000000, reward total was -19.000000. running mean: -20.349931\n",
            "resetting env. episode 1113.000000, reward total was -21.000000. running mean: -20.356432\n",
            "resetting env. episode 1114.000000, reward total was -19.000000. running mean: -20.342867\n",
            "resetting env. episode 1115.000000, reward total was -21.000000. running mean: -20.349439\n",
            "resetting env. episode 1116.000000, reward total was -21.000000. running mean: -20.355944\n",
            "resetting env. episode 1117.000000, reward total was -21.000000. running mean: -20.362385\n",
            "resetting env. episode 1118.000000, reward total was -18.000000. running mean: -20.338761\n",
            "resetting env. episode 1119.000000, reward total was -21.000000. running mean: -20.345373\n",
            "resetting env. episode 1120.000000, reward total was -21.000000. running mean: -20.351920\n",
            "resetting env. episode 1121.000000, reward total was -20.000000. running mean: -20.348401\n",
            "resetting env. episode 1122.000000, reward total was -21.000000. running mean: -20.354917\n",
            "resetting env. episode 1123.000000, reward total was -21.000000. running mean: -20.361367\n",
            "resetting env. episode 1124.000000, reward total was -21.000000. running mean: -20.367754\n",
            "resetting env. episode 1125.000000, reward total was -21.000000. running mean: -20.374076\n",
            "resetting env. episode 1126.000000, reward total was -21.000000. running mean: -20.380335\n",
            "resetting env. episode 1127.000000, reward total was -19.000000. running mean: -20.366532\n",
            "resetting env. episode 1128.000000, reward total was -21.000000. running mean: -20.372867\n",
            "resetting env. episode 1129.000000, reward total was -20.000000. running mean: -20.369138\n",
            "resetting env. episode 1130.000000, reward total was -21.000000. running mean: -20.375447\n",
            "resetting env. episode 1131.000000, reward total was -19.000000. running mean: -20.361692\n",
            "resetting env. episode 1132.000000, reward total was -20.000000. running mean: -20.358075\n",
            "resetting env. episode 1133.000000, reward total was -20.000000. running mean: -20.354495\n",
            "resetting env. episode 1134.000000, reward total was -20.000000. running mean: -20.350950\n",
            "resetting env. episode 1135.000000, reward total was -20.000000. running mean: -20.347440\n",
            "resetting env. episode 1136.000000, reward total was -21.000000. running mean: -20.353966\n",
            "resetting env. episode 1137.000000, reward total was -19.000000. running mean: -20.340426\n",
            "resetting env. episode 1138.000000, reward total was -21.000000. running mean: -20.347022\n",
            "resetting env. episode 1139.000000, reward total was -21.000000. running mean: -20.353552\n",
            "resetting env. episode 1140.000000, reward total was -21.000000. running mean: -20.360016\n",
            "resetting env. episode 1141.000000, reward total was -21.000000. running mean: -20.366416\n",
            "resetting env. episode 1142.000000, reward total was -21.000000. running mean: -20.372752\n",
            "resetting env. episode 1143.000000, reward total was -21.000000. running mean: -20.379024\n",
            "resetting env. episode 1144.000000, reward total was -20.000000. running mean: -20.375234\n",
            "resetting env. episode 1145.000000, reward total was -21.000000. running mean: -20.381482\n",
            "resetting env. episode 1146.000000, reward total was -20.000000. running mean: -20.377667\n",
            "resetting env. episode 1147.000000, reward total was -21.000000. running mean: -20.383890\n",
            "resetting env. episode 1148.000000, reward total was -20.000000. running mean: -20.380051\n",
            "resetting env. episode 1149.000000, reward total was -21.000000. running mean: -20.386251\n",
            "resetting env. episode 1150.000000, reward total was -21.000000. running mean: -20.392388\n",
            "resetting env. episode 1151.000000, reward total was -20.000000. running mean: -20.388464\n",
            "resetting env. episode 1152.000000, reward total was -20.000000. running mean: -20.384580\n",
            "resetting env. episode 1153.000000, reward total was -20.000000. running mean: -20.380734\n",
            "resetting env. episode 1154.000000, reward total was -21.000000. running mean: -20.386927\n",
            "resetting env. episode 1155.000000, reward total was -21.000000. running mean: -20.393057\n",
            "resetting env. episode 1156.000000, reward total was -20.000000. running mean: -20.389127\n",
            "resetting env. episode 1157.000000, reward total was -19.000000. running mean: -20.375235\n",
            "resetting env. episode 1158.000000, reward total was -21.000000. running mean: -20.381483\n",
            "resetting env. episode 1159.000000, reward total was -21.000000. running mean: -20.387668\n",
            "resetting env. episode 1160.000000, reward total was -20.000000. running mean: -20.383792\n",
            "resetting env. episode 1161.000000, reward total was -21.000000. running mean: -20.389954\n",
            "resetting env. episode 1162.000000, reward total was -20.000000. running mean: -20.386054\n",
            "resetting env. episode 1163.000000, reward total was -21.000000. running mean: -20.392194\n",
            "resetting env. episode 1164.000000, reward total was -20.000000. running mean: -20.388272\n",
            "resetting env. episode 1165.000000, reward total was -21.000000. running mean: -20.394389\n",
            "resetting env. episode 1166.000000, reward total was -21.000000. running mean: -20.400445\n",
            "resetting env. episode 1167.000000, reward total was -20.000000. running mean: -20.396441\n",
            "resetting env. episode 1168.000000, reward total was -21.000000. running mean: -20.402476\n",
            "resetting env. episode 1169.000000, reward total was -19.000000. running mean: -20.388451\n",
            "resetting env. episode 1170.000000, reward total was -20.000000. running mean: -20.384567\n",
            "resetting env. episode 1171.000000, reward total was -21.000000. running mean: -20.390721\n",
            "resetting env. episode 1172.000000, reward total was -20.000000. running mean: -20.386814\n",
            "resetting env. episode 1173.000000, reward total was -21.000000. running mean: -20.392946\n",
            "resetting env. episode 1174.000000, reward total was -21.000000. running mean: -20.399016\n",
            "resetting env. episode 1175.000000, reward total was -17.000000. running mean: -20.365026\n",
            "resetting env. episode 1176.000000, reward total was -18.000000. running mean: -20.341376\n",
            "resetting env. episode 1177.000000, reward total was -21.000000. running mean: -20.347962\n",
            "resetting env. episode 1178.000000, reward total was -20.000000. running mean: -20.344483\n",
            "resetting env. episode 1179.000000, reward total was -20.000000. running mean: -20.341038\n",
            "resetting env. episode 1180.000000, reward total was -21.000000. running mean: -20.347627\n",
            "resetting env. episode 1181.000000, reward total was -20.000000. running mean: -20.344151\n",
            "resetting env. episode 1182.000000, reward total was -20.000000. running mean: -20.340710\n",
            "resetting env. episode 1183.000000, reward total was -20.000000. running mean: -20.337303\n",
            "resetting env. episode 1184.000000, reward total was -20.000000. running mean: -20.333929\n",
            "resetting env. episode 1185.000000, reward total was -21.000000. running mean: -20.340590\n",
            "resetting env. episode 1186.000000, reward total was -20.000000. running mean: -20.337184\n",
            "resetting env. episode 1187.000000, reward total was -19.000000. running mean: -20.323812\n",
            "resetting env. episode 1188.000000, reward total was -20.000000. running mean: -20.320574\n",
            "resetting env. episode 1189.000000, reward total was -21.000000. running mean: -20.327369\n",
            "resetting env. episode 1190.000000, reward total was -21.000000. running mean: -20.334095\n",
            "resetting env. episode 1191.000000, reward total was -19.000000. running mean: -20.320754\n",
            "resetting env. episode 1192.000000, reward total was -21.000000. running mean: -20.327546\n",
            "resetting env. episode 1193.000000, reward total was -19.000000. running mean: -20.314271\n",
            "resetting env. episode 1194.000000, reward total was -21.000000. running mean: -20.321128\n",
            "resetting env. episode 1195.000000, reward total was -18.000000. running mean: -20.297917\n",
            "resetting env. episode 1196.000000, reward total was -21.000000. running mean: -20.304938\n",
            "resetting env. episode 1197.000000, reward total was -20.000000. running mean: -20.301888\n",
            "resetting env. episode 1198.000000, reward total was -21.000000. running mean: -20.308870\n",
            "resetting env. episode 1199.000000, reward total was -21.000000. running mean: -20.315781\n",
            "resetting env. episode 1200.000000, reward total was -21.000000. running mean: -20.322623\n",
            "resetting env. episode 1201.000000, reward total was -20.000000. running mean: -20.319397\n",
            "resetting env. episode 1202.000000, reward total was -21.000000. running mean: -20.326203\n",
            "resetting env. episode 1203.000000, reward total was -21.000000. running mean: -20.332941\n",
            "resetting env. episode 1204.000000, reward total was -17.000000. running mean: -20.299611\n",
            "resetting env. episode 1205.000000, reward total was -21.000000. running mean: -20.306615\n",
            "resetting env. episode 1206.000000, reward total was -21.000000. running mean: -20.313549\n",
            "resetting env. episode 1207.000000, reward total was -21.000000. running mean: -20.320414\n",
            "resetting env. episode 1208.000000, reward total was -21.000000. running mean: -20.327209\n",
            "resetting env. episode 1209.000000, reward total was -21.000000. running mean: -20.333937\n",
            "resetting env. episode 1210.000000, reward total was -21.000000. running mean: -20.340598\n",
            "resetting env. episode 1211.000000, reward total was -20.000000. running mean: -20.337192\n",
            "resetting env. episode 1212.000000, reward total was -21.000000. running mean: -20.343820\n",
            "resetting env. episode 1213.000000, reward total was -21.000000. running mean: -20.350382\n",
            "resetting env. episode 1214.000000, reward total was -17.000000. running mean: -20.316878\n",
            "resetting env. episode 1215.000000, reward total was -21.000000. running mean: -20.323709\n",
            "resetting env. episode 1216.000000, reward total was -21.000000. running mean: -20.330472\n",
            "resetting env. episode 1217.000000, reward total was -21.000000. running mean: -20.337168\n",
            "resetting env. episode 1218.000000, reward total was -18.000000. running mean: -20.313796\n",
            "resetting env. episode 1219.000000, reward total was -21.000000. running mean: -20.320658\n",
            "resetting env. episode 1220.000000, reward total was -20.000000. running mean: -20.317451\n",
            "resetting env. episode 1221.000000, reward total was -21.000000. running mean: -20.324277\n",
            "resetting env. episode 1222.000000, reward total was -21.000000. running mean: -20.331034\n",
            "resetting env. episode 1223.000000, reward total was -20.000000. running mean: -20.327724\n",
            "resetting env. episode 1224.000000, reward total was -21.000000. running mean: -20.334446\n",
            "resetting env. episode 1225.000000, reward total was -21.000000. running mean: -20.341102\n",
            "resetting env. episode 1226.000000, reward total was -21.000000. running mean: -20.347691\n",
            "resetting env. episode 1227.000000, reward total was -21.000000. running mean: -20.354214\n",
            "resetting env. episode 1228.000000, reward total was -20.000000. running mean: -20.350672\n",
            "resetting env. episode 1229.000000, reward total was -16.000000. running mean: -20.307165\n",
            "resetting env. episode 1230.000000, reward total was -20.000000. running mean: -20.304094\n",
            "resetting env. episode 1231.000000, reward total was -21.000000. running mean: -20.311053\n",
            "resetting env. episode 1232.000000, reward total was -20.000000. running mean: -20.307942\n",
            "resetting env. episode 1233.000000, reward total was -21.000000. running mean: -20.314863\n",
            "resetting env. episode 1234.000000, reward total was -21.000000. running mean: -20.321714\n",
            "resetting env. episode 1235.000000, reward total was -21.000000. running mean: -20.328497\n",
            "resetting env. episode 1236.000000, reward total was -21.000000. running mean: -20.335212\n",
            "resetting env. episode 1237.000000, reward total was -20.000000. running mean: -20.331860\n",
            "resetting env. episode 1238.000000, reward total was -20.000000. running mean: -20.328541\n",
            "resetting env. episode 1239.000000, reward total was -21.000000. running mean: -20.335256\n",
            "resetting env. episode 1240.000000, reward total was -20.000000. running mean: -20.331903\n",
            "resetting env. episode 1241.000000, reward total was -19.000000. running mean: -20.318584\n",
            "resetting env. episode 1242.000000, reward total was -18.000000. running mean: -20.295398\n",
            "resetting env. episode 1243.000000, reward total was -17.000000. running mean: -20.262444\n",
            "resetting env. episode 1244.000000, reward total was -20.000000. running mean: -20.259820\n",
            "resetting env. episode 1245.000000, reward total was -21.000000. running mean: -20.267222\n",
            "resetting env. episode 1246.000000, reward total was -21.000000. running mean: -20.274550\n",
            "resetting env. episode 1247.000000, reward total was -20.000000. running mean: -20.271804\n",
            "resetting env. episode 1248.000000, reward total was -21.000000. running mean: -20.279086\n",
            "resetting env. episode 1249.000000, reward total was -20.000000. running mean: -20.276295\n",
            "resetting env. episode 1250.000000, reward total was -21.000000. running mean: -20.283532\n",
            "resetting env. episode 1251.000000, reward total was -21.000000. running mean: -20.290697\n",
            "resetting env. episode 1252.000000, reward total was -21.000000. running mean: -20.297790\n",
            "resetting env. episode 1253.000000, reward total was -21.000000. running mean: -20.304812\n",
            "resetting env. episode 1254.000000, reward total was -21.000000. running mean: -20.311764\n",
            "resetting env. episode 1255.000000, reward total was -21.000000. running mean: -20.318646\n",
            "resetting env. episode 1256.000000, reward total was -20.000000. running mean: -20.315460\n",
            "resetting env. episode 1257.000000, reward total was -21.000000. running mean: -20.322305\n",
            "resetting env. episode 1258.000000, reward total was -18.000000. running mean: -20.299082\n",
            "resetting env. episode 1259.000000, reward total was -19.000000. running mean: -20.286091\n",
            "resetting env. episode 1260.000000, reward total was -20.000000. running mean: -20.283230\n",
            "resetting env. episode 1261.000000, reward total was -21.000000. running mean: -20.290398\n",
            "resetting env. episode 1262.000000, reward total was -20.000000. running mean: -20.287494\n",
            "resetting env. episode 1263.000000, reward total was -21.000000. running mean: -20.294619\n",
            "resetting env. episode 1264.000000, reward total was -20.000000. running mean: -20.291673\n",
            "resetting env. episode 1265.000000, reward total was -20.000000. running mean: -20.288756\n",
            "resetting env. episode 1266.000000, reward total was -21.000000. running mean: -20.295869\n",
            "resetting env. episode 1267.000000, reward total was -21.000000. running mean: -20.302910\n",
            "resetting env. episode 1268.000000, reward total was -21.000000. running mean: -20.309881\n",
            "resetting env. episode 1269.000000, reward total was -20.000000. running mean: -20.306782\n",
            "resetting env. episode 1270.000000, reward total was -21.000000. running mean: -20.313714\n",
            "resetting env. episode 1271.000000, reward total was -20.000000. running mean: -20.310577\n",
            "resetting env. episode 1272.000000, reward total was -20.000000. running mean: -20.307471\n",
            "resetting env. episode 1273.000000, reward total was -21.000000. running mean: -20.314397\n",
            "resetting env. episode 1274.000000, reward total was -21.000000. running mean: -20.321253\n",
            "resetting env. episode 1275.000000, reward total was -20.000000. running mean: -20.318040\n",
            "resetting env. episode 1276.000000, reward total was -21.000000. running mean: -20.324860\n",
            "resetting env. episode 1277.000000, reward total was -20.000000. running mean: -20.321611\n",
            "resetting env. episode 1278.000000, reward total was -19.000000. running mean: -20.308395\n",
            "resetting env. episode 1279.000000, reward total was -21.000000. running mean: -20.315311\n",
            "resetting env. episode 1280.000000, reward total was -19.000000. running mean: -20.302158\n",
            "resetting env. episode 1281.000000, reward total was -21.000000. running mean: -20.309136\n",
            "resetting env. episode 1282.000000, reward total was -21.000000. running mean: -20.316045\n",
            "resetting env. episode 1283.000000, reward total was -20.000000. running mean: -20.312885\n",
            "resetting env. episode 1284.000000, reward total was -21.000000. running mean: -20.319756\n",
            "resetting env. episode 1285.000000, reward total was -21.000000. running mean: -20.326558\n",
            "resetting env. episode 1286.000000, reward total was -21.000000. running mean: -20.333293\n",
            "resetting env. episode 1287.000000, reward total was -20.000000. running mean: -20.329960\n",
            "resetting env. episode 1288.000000, reward total was -21.000000. running mean: -20.336660\n",
            "resetting env. episode 1289.000000, reward total was -21.000000. running mean: -20.343293\n",
            "resetting env. episode 1290.000000, reward total was -20.000000. running mean: -20.339861\n",
            "resetting env. episode 1291.000000, reward total was -21.000000. running mean: -20.346462\n",
            "resetting env. episode 1292.000000, reward total was -19.000000. running mean: -20.332997\n",
            "resetting env. episode 1293.000000, reward total was -21.000000. running mean: -20.339667\n",
            "resetting env. episode 1294.000000, reward total was -20.000000. running mean: -20.336271\n",
            "resetting env. episode 1295.000000, reward total was -21.000000. running mean: -20.342908\n",
            "resetting env. episode 1296.000000, reward total was -21.000000. running mean: -20.349479\n",
            "resetting env. episode 1297.000000, reward total was -21.000000. running mean: -20.355984\n",
            "resetting env. episode 1298.000000, reward total was -21.000000. running mean: -20.362424\n",
            "resetting env. episode 1299.000000, reward total was -21.000000. running mean: -20.368800\n",
            "resetting env. episode 1300.000000, reward total was -21.000000. running mean: -20.375112\n",
            "resetting env. episode 1301.000000, reward total was -20.000000. running mean: -20.371361\n",
            "resetting env. episode 1302.000000, reward total was -21.000000. running mean: -20.377647\n",
            "resetting env. episode 1303.000000, reward total was -21.000000. running mean: -20.383871\n",
            "resetting env. episode 1304.000000, reward total was -20.000000. running mean: -20.380032\n",
            "resetting env. episode 1305.000000, reward total was -21.000000. running mean: -20.386232\n",
            "resetting env. episode 1306.000000, reward total was -21.000000. running mean: -20.392369\n",
            "resetting env. episode 1307.000000, reward total was -19.000000. running mean: -20.378446\n",
            "resetting env. episode 1308.000000, reward total was -21.000000. running mean: -20.384661\n",
            "resetting env. episode 1309.000000, reward total was -21.000000. running mean: -20.390815\n",
            "resetting env. episode 1310.000000, reward total was -20.000000. running mean: -20.386907\n",
            "resetting env. episode 1311.000000, reward total was -20.000000. running mean: -20.383037\n",
            "resetting env. episode 1312.000000, reward total was -21.000000. running mean: -20.389207\n",
            "resetting env. episode 1313.000000, reward total was -21.000000. running mean: -20.395315\n",
            "resetting env. episode 1314.000000, reward total was -20.000000. running mean: -20.391362\n",
            "resetting env. episode 1315.000000, reward total was -20.000000. running mean: -20.387448\n",
            "resetting env. episode 1316.000000, reward total was -21.000000. running mean: -20.393574\n",
            "resetting env. episode 1317.000000, reward total was -20.000000. running mean: -20.389638\n",
            "resetting env. episode 1318.000000, reward total was -21.000000. running mean: -20.395742\n",
            "resetting env. episode 1319.000000, reward total was -20.000000. running mean: -20.391784\n",
            "resetting env. episode 1320.000000, reward total was -19.000000. running mean: -20.377866\n",
            "resetting env. episode 1321.000000, reward total was -21.000000. running mean: -20.384088\n",
            "resetting env. episode 1322.000000, reward total was -21.000000. running mean: -20.390247\n",
            "resetting env. episode 1323.000000, reward total was -21.000000. running mean: -20.396344\n",
            "resetting env. episode 1324.000000, reward total was -21.000000. running mean: -20.402381\n",
            "resetting env. episode 1325.000000, reward total was -21.000000. running mean: -20.408357\n",
            "resetting env. episode 1326.000000, reward total was -20.000000. running mean: -20.404274\n",
            "resetting env. episode 1327.000000, reward total was -19.000000. running mean: -20.390231\n",
            "resetting env. episode 1328.000000, reward total was -21.000000. running mean: -20.396329\n",
            "resetting env. episode 1329.000000, reward total was -21.000000. running mean: -20.402365\n",
            "resetting env. episode 1330.000000, reward total was -20.000000. running mean: -20.398342\n",
            "resetting env. episode 1331.000000, reward total was -21.000000. running mean: -20.404358\n",
            "resetting env. episode 1332.000000, reward total was -20.000000. running mean: -20.400315\n",
            "resetting env. episode 1333.000000, reward total was -20.000000. running mean: -20.396311\n",
            "resetting env. episode 1334.000000, reward total was -21.000000. running mean: -20.402348\n",
            "resetting env. episode 1335.000000, reward total was -21.000000. running mean: -20.408325\n",
            "resetting env. episode 1336.000000, reward total was -20.000000. running mean: -20.404242\n",
            "resetting env. episode 1337.000000, reward total was -20.000000. running mean: -20.400199\n",
            "resetting env. episode 1338.000000, reward total was -21.000000. running mean: -20.406197\n",
            "resetting env. episode 1339.000000, reward total was -21.000000. running mean: -20.412135\n",
            "resetting env. episode 1340.000000, reward total was -20.000000. running mean: -20.408014\n",
            "resetting env. episode 1341.000000, reward total was -21.000000. running mean: -20.413934\n",
            "resetting env. episode 1342.000000, reward total was -20.000000. running mean: -20.409794\n",
            "resetting env. episode 1343.000000, reward total was -21.000000. running mean: -20.415696\n",
            "resetting env. episode 1344.000000, reward total was -21.000000. running mean: -20.421539\n",
            "resetting env. episode 1345.000000, reward total was -21.000000. running mean: -20.427324\n",
            "resetting env. episode 1346.000000, reward total was -21.000000. running mean: -20.433051\n",
            "resetting env. episode 1347.000000, reward total was -21.000000. running mean: -20.438720\n",
            "resetting env. episode 1348.000000, reward total was -21.000000. running mean: -20.444333\n",
            "resetting env. episode 1349.000000, reward total was -20.000000. running mean: -20.439890\n",
            "resetting env. episode 1350.000000, reward total was -21.000000. running mean: -20.445491\n",
            "resetting env. episode 1351.000000, reward total was -21.000000. running mean: -20.451036\n",
            "resetting env. episode 1352.000000, reward total was -21.000000. running mean: -20.456526\n",
            "resetting env. episode 1353.000000, reward total was -21.000000. running mean: -20.461960\n",
            "resetting env. episode 1354.000000, reward total was -20.000000. running mean: -20.457341\n",
            "resetting env. episode 1355.000000, reward total was -20.000000. running mean: -20.452767\n",
            "resetting env. episode 1356.000000, reward total was -21.000000. running mean: -20.458240\n",
            "resetting env. episode 1357.000000, reward total was -18.000000. running mean: -20.433657\n",
            "resetting env. episode 1358.000000, reward total was -19.000000. running mean: -20.419321\n",
            "resetting env. episode 1359.000000, reward total was -20.000000. running mean: -20.415128\n",
            "resetting env. episode 1360.000000, reward total was -21.000000. running mean: -20.420976\n",
            "resetting env. episode 1361.000000, reward total was -19.000000. running mean: -20.406766\n",
            "resetting env. episode 1362.000000, reward total was -21.000000. running mean: -20.412699\n",
            "resetting env. episode 1363.000000, reward total was -21.000000. running mean: -20.418572\n",
            "resetting env. episode 1364.000000, reward total was -20.000000. running mean: -20.414386\n",
            "resetting env. episode 1365.000000, reward total was -21.000000. running mean: -20.420242\n",
            "resetting env. episode 1366.000000, reward total was -21.000000. running mean: -20.426040\n",
            "resetting env. episode 1367.000000, reward total was -19.000000. running mean: -20.411779\n",
            "resetting env. episode 1368.000000, reward total was -21.000000. running mean: -20.417662\n",
            "resetting env. episode 1369.000000, reward total was -21.000000. running mean: -20.423485\n",
            "resetting env. episode 1370.000000, reward total was -19.000000. running mean: -20.409250\n",
            "resetting env. episode 1371.000000, reward total was -20.000000. running mean: -20.405158\n",
            "resetting env. episode 1372.000000, reward total was -20.000000. running mean: -20.401106\n",
            "resetting env. episode 1373.000000, reward total was -20.000000. running mean: -20.397095\n",
            "resetting env. episode 1374.000000, reward total was -21.000000. running mean: -20.403124\n",
            "resetting env. episode 1375.000000, reward total was -21.000000. running mean: -20.409093\n",
            "resetting env. episode 1376.000000, reward total was -21.000000. running mean: -20.415002\n",
            "resetting env. episode 1377.000000, reward total was -21.000000. running mean: -20.420852\n",
            "resetting env. episode 1378.000000, reward total was -21.000000. running mean: -20.426643\n",
            "resetting env. episode 1379.000000, reward total was -19.000000. running mean: -20.412377\n",
            "resetting env. episode 1380.000000, reward total was -21.000000. running mean: -20.418253\n",
            "resetting env. episode 1381.000000, reward total was -20.000000. running mean: -20.414071\n",
            "resetting env. episode 1382.000000, reward total was -21.000000. running mean: -20.419930\n",
            "resetting env. episode 1383.000000, reward total was -21.000000. running mean: -20.425731\n",
            "resetting env. episode 1384.000000, reward total was -20.000000. running mean: -20.421473\n",
            "resetting env. episode 1385.000000, reward total was -21.000000. running mean: -20.427259\n",
            "resetting env. episode 1386.000000, reward total was -21.000000. running mean: -20.432986\n",
            "resetting env. episode 1387.000000, reward total was -20.000000. running mean: -20.428656\n",
            "resetting env. episode 1388.000000, reward total was -21.000000. running mean: -20.434370\n",
            "resetting env. episode 1389.000000, reward total was -21.000000. running mean: -20.440026\n",
            "resetting env. episode 1390.000000, reward total was -21.000000. running mean: -20.445626\n",
            "resetting env. episode 1391.000000, reward total was -20.000000. running mean: -20.441169\n",
            "resetting env. episode 1392.000000, reward total was -21.000000. running mean: -20.446758\n",
            "resetting env. episode 1393.000000, reward total was -21.000000. running mean: -20.452290\n",
            "resetting env. episode 1394.000000, reward total was -20.000000. running mean: -20.447767\n",
            "resetting env. episode 1395.000000, reward total was -18.000000. running mean: -20.423290\n",
            "resetting env. episode 1396.000000, reward total was -19.000000. running mean: -20.409057\n",
            "resetting env. episode 1397.000000, reward total was -21.000000. running mean: -20.414966\n",
            "resetting env. episode 1398.000000, reward total was -21.000000. running mean: -20.420816\n",
            "resetting env. episode 1399.000000, reward total was -21.000000. running mean: -20.426608\n",
            "resetting env. episode 1400.000000, reward total was -21.000000. running mean: -20.432342\n",
            "resetting env. episode 1401.000000, reward total was -20.000000. running mean: -20.428019\n",
            "resetting env. episode 1402.000000, reward total was -20.000000. running mean: -20.423739\n",
            "resetting env. episode 1403.000000, reward total was -21.000000. running mean: -20.429501\n",
            "resetting env. episode 1404.000000, reward total was -19.000000. running mean: -20.415206\n",
            "resetting env. episode 1405.000000, reward total was -21.000000. running mean: -20.421054\n",
            "resetting env. episode 1406.000000, reward total was -20.000000. running mean: -20.416844\n",
            "resetting env. episode 1407.000000, reward total was -21.000000. running mean: -20.422675\n",
            "resetting env. episode 1408.000000, reward total was -21.000000. running mean: -20.428448\n",
            "resetting env. episode 1409.000000, reward total was -20.000000. running mean: -20.424164\n",
            "resetting env. episode 1410.000000, reward total was -21.000000. running mean: -20.429922\n",
            "resetting env. episode 1411.000000, reward total was -21.000000. running mean: -20.435623\n",
            "resetting env. episode 1412.000000, reward total was -20.000000. running mean: -20.431267\n",
            "resetting env. episode 1413.000000, reward total was -20.000000. running mean: -20.426954\n",
            "resetting env. episode 1414.000000, reward total was -21.000000. running mean: -20.432685\n",
            "resetting env. episode 1415.000000, reward total was -21.000000. running mean: -20.438358\n",
            "resetting env. episode 1416.000000, reward total was -21.000000. running mean: -20.443974\n",
            "resetting env. episode 1417.000000, reward total was -21.000000. running mean: -20.449534\n",
            "resetting env. episode 1418.000000, reward total was -21.000000. running mean: -20.455039\n",
            "resetting env. episode 1419.000000, reward total was -20.000000. running mean: -20.450489\n",
            "resetting env. episode 1420.000000, reward total was -20.000000. running mean: -20.445984\n",
            "resetting env. episode 1421.000000, reward total was -20.000000. running mean: -20.441524\n",
            "resetting env. episode 1422.000000, reward total was -21.000000. running mean: -20.447109\n",
            "resetting env. episode 1423.000000, reward total was -21.000000. running mean: -20.452638\n",
            "resetting env. episode 1424.000000, reward total was -20.000000. running mean: -20.448111\n",
            "resetting env. episode 1425.000000, reward total was -21.000000. running mean: -20.453630\n",
            "resetting env. episode 1426.000000, reward total was -21.000000. running mean: -20.459094\n",
            "resetting env. episode 1427.000000, reward total was -19.000000. running mean: -20.444503\n",
            "resetting env. episode 1428.000000, reward total was -21.000000. running mean: -20.450058\n",
            "resetting env. episode 1429.000000, reward total was -20.000000. running mean: -20.445557\n",
            "resetting env. episode 1430.000000, reward total was -21.000000. running mean: -20.451102\n",
            "resetting env. episode 1431.000000, reward total was -21.000000. running mean: -20.456591\n",
            "resetting env. episode 1432.000000, reward total was -21.000000. running mean: -20.462025\n",
            "resetting env. episode 1433.000000, reward total was -19.000000. running mean: -20.447405\n",
            "resetting env. episode 1434.000000, reward total was -21.000000. running mean: -20.452930\n",
            "resetting env. episode 1435.000000, reward total was -21.000000. running mean: -20.458401\n",
            "resetting env. episode 1436.000000, reward total was -20.000000. running mean: -20.453817\n",
            "resetting env. episode 1437.000000, reward total was -21.000000. running mean: -20.459279\n",
            "resetting env. episode 1438.000000, reward total was -21.000000. running mean: -20.464686\n",
            "resetting env. episode 1439.000000, reward total was -19.000000. running mean: -20.450039\n",
            "resetting env. episode 1440.000000, reward total was -20.000000. running mean: -20.445539\n",
            "resetting env. episode 1441.000000, reward total was -20.000000. running mean: -20.441084\n",
            "resetting env. episode 1442.000000, reward total was -20.000000. running mean: -20.436673\n",
            "resetting env. episode 1443.000000, reward total was -20.000000. running mean: -20.432306\n",
            "resetting env. episode 1444.000000, reward total was -21.000000. running mean: -20.437983\n",
            "resetting env. episode 1445.000000, reward total was -21.000000. running mean: -20.443603\n",
            "resetting env. episode 1446.000000, reward total was -21.000000. running mean: -20.449167\n",
            "resetting env. episode 1447.000000, reward total was -21.000000. running mean: -20.454675\n",
            "resetting env. episode 1448.000000, reward total was -21.000000. running mean: -20.460129\n",
            "resetting env. episode 1449.000000, reward total was -21.000000. running mean: -20.465527\n",
            "resetting env. episode 1450.000000, reward total was -21.000000. running mean: -20.470872\n",
            "resetting env. episode 1451.000000, reward total was -20.000000. running mean: -20.466163\n",
            "resetting env. episode 1452.000000, reward total was -21.000000. running mean: -20.471502\n",
            "resetting env. episode 1453.000000, reward total was -21.000000. running mean: -20.476787\n",
            "resetting env. episode 1454.000000, reward total was -20.000000. running mean: -20.472019\n",
            "resetting env. episode 1455.000000, reward total was -19.000000. running mean: -20.457299\n",
            "resetting env. episode 1456.000000, reward total was -20.000000. running mean: -20.452726\n",
            "resetting env. episode 1457.000000, reward total was -21.000000. running mean: -20.458198\n",
            "resetting env. episode 1458.000000, reward total was -21.000000. running mean: -20.463616\n",
            "resetting env. episode 1459.000000, reward total was -21.000000. running mean: -20.468980\n",
            "resetting env. episode 1460.000000, reward total was -21.000000. running mean: -20.474290\n",
            "resetting env. episode 1461.000000, reward total was -21.000000. running mean: -20.479548\n",
            "resetting env. episode 1462.000000, reward total was -20.000000. running mean: -20.474752\n",
            "resetting env. episode 1463.000000, reward total was -21.000000. running mean: -20.480005\n",
            "resetting env. episode 1464.000000, reward total was -21.000000. running mean: -20.485205\n",
            "resetting env. episode 1465.000000, reward total was -20.000000. running mean: -20.480352\n",
            "resetting env. episode 1466.000000, reward total was -20.000000. running mean: -20.475549\n",
            "resetting env. episode 1467.000000, reward total was -20.000000. running mean: -20.470793\n",
            "resetting env. episode 1468.000000, reward total was -20.000000. running mean: -20.466086\n",
            "resetting env. episode 1469.000000, reward total was -21.000000. running mean: -20.471425\n",
            "resetting env. episode 1470.000000, reward total was -21.000000. running mean: -20.476710\n",
            "resetting env. episode 1471.000000, reward total was -20.000000. running mean: -20.471943\n",
            "resetting env. episode 1472.000000, reward total was -21.000000. running mean: -20.477224\n",
            "resetting env. episode 1473.000000, reward total was -21.000000. running mean: -20.482452\n",
            "resetting env. episode 1474.000000, reward total was -18.000000. running mean: -20.457627\n",
            "resetting env. episode 1475.000000, reward total was -21.000000. running mean: -20.463051\n",
            "resetting env. episode 1476.000000, reward total was -21.000000. running mean: -20.468420\n",
            "resetting env. episode 1477.000000, reward total was -21.000000. running mean: -20.473736\n",
            "resetting env. episode 1478.000000, reward total was -20.000000. running mean: -20.468999\n",
            "resetting env. episode 1479.000000, reward total was -21.000000. running mean: -20.474309\n",
            "resetting env. episode 1480.000000, reward total was -19.000000. running mean: -20.459566\n",
            "resetting env. episode 1481.000000, reward total was -21.000000. running mean: -20.464970\n",
            "resetting env. episode 1482.000000, reward total was -21.000000. running mean: -20.470320\n",
            "resetting env. episode 1483.000000, reward total was -21.000000. running mean: -20.475617\n",
            "resetting env. episode 1484.000000, reward total was -20.000000. running mean: -20.470861\n",
            "resetting env. episode 1485.000000, reward total was -21.000000. running mean: -20.476152\n",
            "resetting env. episode 1486.000000, reward total was -19.000000. running mean: -20.461391\n",
            "resetting env. episode 1487.000000, reward total was -21.000000. running mean: -20.466777\n",
            "resetting env. episode 1488.000000, reward total was -21.000000. running mean: -20.472109\n",
            "resetting env. episode 1489.000000, reward total was -21.000000. running mean: -20.477388\n",
            "resetting env. episode 1490.000000, reward total was -20.000000. running mean: -20.472614\n",
            "resetting env. episode 1491.000000, reward total was -21.000000. running mean: -20.477888\n",
            "resetting env. episode 1492.000000, reward total was -21.000000. running mean: -20.483109\n",
            "resetting env. episode 1493.000000, reward total was -20.000000. running mean: -20.478278\n",
            "resetting env. episode 1494.000000, reward total was -20.000000. running mean: -20.473495\n",
            "resetting env. episode 1495.000000, reward total was -20.000000. running mean: -20.468760\n",
            "resetting env. episode 1496.000000, reward total was -20.000000. running mean: -20.464073\n",
            "resetting env. episode 1497.000000, reward total was -19.000000. running mean: -20.449432\n",
            "resetting env. episode 1498.000000, reward total was -19.000000. running mean: -20.434938\n",
            "resetting env. episode 1499.000000, reward total was -20.000000. running mean: -20.430588\n",
            "resetting env. episode 1500.000000, reward total was -21.000000. running mean: -20.436282\n",
            "resetting env. episode 1501.000000, reward total was -21.000000. running mean: -20.441920\n",
            "resetting env. episode 1502.000000, reward total was -21.000000. running mean: -20.447500\n",
            "resetting env. episode 1503.000000, reward total was -20.000000. running mean: -20.443025\n",
            "resetting env. episode 1504.000000, reward total was -21.000000. running mean: -20.448595\n",
            "resetting env. episode 1505.000000, reward total was -20.000000. running mean: -20.444109\n",
            "resetting env. episode 1506.000000, reward total was -21.000000. running mean: -20.449668\n",
            "resetting env. episode 1507.000000, reward total was -21.000000. running mean: -20.455171\n",
            "resetting env. episode 1508.000000, reward total was -21.000000. running mean: -20.460620\n",
            "resetting env. episode 1509.000000, reward total was -21.000000. running mean: -20.466014\n",
            "resetting env. episode 1510.000000, reward total was -21.000000. running mean: -20.471353\n",
            "resetting env. episode 1511.000000, reward total was -21.000000. running mean: -20.476640\n",
            "resetting env. episode 1512.000000, reward total was -21.000000. running mean: -20.481873\n",
            "resetting env. episode 1513.000000, reward total was -21.000000. running mean: -20.487055\n",
            "resetting env. episode 1514.000000, reward total was -20.000000. running mean: -20.482184\n",
            "resetting env. episode 1515.000000, reward total was -19.000000. running mean: -20.467362\n",
            "resetting env. episode 1516.000000, reward total was -21.000000. running mean: -20.472689\n",
            "resetting env. episode 1517.000000, reward total was -20.000000. running mean: -20.467962\n",
            "resetting env. episode 1518.000000, reward total was -20.000000. running mean: -20.463282\n",
            "resetting env. episode 1519.000000, reward total was -21.000000. running mean: -20.468649\n",
            "resetting env. episode 1520.000000, reward total was -20.000000. running mean: -20.463963\n",
            "resetting env. episode 1521.000000, reward total was -21.000000. running mean: -20.469323\n",
            "resetting env. episode 1522.000000, reward total was -21.000000. running mean: -20.474630\n",
            "resetting env. episode 1523.000000, reward total was -21.000000. running mean: -20.479884\n",
            "resetting env. episode 1524.000000, reward total was -21.000000. running mean: -20.485085\n",
            "resetting env. episode 1525.000000, reward total was -21.000000. running mean: -20.490234\n",
            "resetting env. episode 1526.000000, reward total was -21.000000. running mean: -20.495332\n",
            "resetting env. episode 1527.000000, reward total was -18.000000. running mean: -20.470378\n",
            "resetting env. episode 1528.000000, reward total was -21.000000. running mean: -20.475675\n",
            "resetting env. episode 1529.000000, reward total was -21.000000. running mean: -20.480918\n",
            "resetting env. episode 1530.000000, reward total was -20.000000. running mean: -20.476109\n",
            "resetting env. episode 1531.000000, reward total was -21.000000. running mean: -20.481348\n",
            "resetting env. episode 1532.000000, reward total was -19.000000. running mean: -20.466534\n",
            "resetting env. episode 1533.000000, reward total was -20.000000. running mean: -20.461869\n",
            "resetting env. episode 1534.000000, reward total was -20.000000. running mean: -20.457250\n",
            "resetting env. episode 1535.000000, reward total was -21.000000. running mean: -20.462678\n",
            "resetting env. episode 1536.000000, reward total was -21.000000. running mean: -20.468051\n",
            "resetting env. episode 1537.000000, reward total was -20.000000. running mean: -20.463370\n",
            "resetting env. episode 1538.000000, reward total was -21.000000. running mean: -20.468737\n",
            "resetting env. episode 1539.000000, reward total was -21.000000. running mean: -20.474049\n",
            "resetting env. episode 1540.000000, reward total was -21.000000. running mean: -20.479309\n",
            "resetting env. episode 1541.000000, reward total was -21.000000. running mean: -20.484516\n",
            "resetting env. episode 1542.000000, reward total was -21.000000. running mean: -20.489670\n",
            "resetting env. episode 1543.000000, reward total was -21.000000. running mean: -20.494774\n",
            "resetting env. episode 1544.000000, reward total was -21.000000. running mean: -20.499826\n",
            "resetting env. episode 1545.000000, reward total was -21.000000. running mean: -20.504828\n",
            "resetting env. episode 1546.000000, reward total was -20.000000. running mean: -20.499780\n",
            "resetting env. episode 1547.000000, reward total was -21.000000. running mean: -20.504782\n",
            "resetting env. episode 1548.000000, reward total was -21.000000. running mean: -20.509734\n",
            "resetting env. episode 1549.000000, reward total was -21.000000. running mean: -20.514637\n",
            "resetting env. episode 1550.000000, reward total was -21.000000. running mean: -20.519490\n",
            "resetting env. episode 1551.000000, reward total was -21.000000. running mean: -20.524295\n",
            "resetting env. episode 1552.000000, reward total was -21.000000. running mean: -20.529052\n",
            "resetting env. episode 1553.000000, reward total was -20.000000. running mean: -20.523762\n",
            "resetting env. episode 1554.000000, reward total was -20.000000. running mean: -20.518524\n",
            "resetting env. episode 1555.000000, reward total was -19.000000. running mean: -20.503339\n",
            "resetting env. episode 1556.000000, reward total was -20.000000. running mean: -20.498306\n",
            "resetting env. episode 1557.000000, reward total was -21.000000. running mean: -20.503323\n",
            "resetting env. episode 1558.000000, reward total was -21.000000. running mean: -20.508289\n",
            "resetting env. episode 1559.000000, reward total was -21.000000. running mean: -20.513206\n",
            "resetting env. episode 1560.000000, reward total was -21.000000. running mean: -20.518074\n",
            "resetting env. episode 1561.000000, reward total was -21.000000. running mean: -20.522894\n",
            "resetting env. episode 1562.000000, reward total was -21.000000. running mean: -20.527665\n",
            "resetting env. episode 1563.000000, reward total was -20.000000. running mean: -20.522388\n",
            "resetting env. episode 1564.000000, reward total was -21.000000. running mean: -20.527164\n",
            "resetting env. episode 1565.000000, reward total was -21.000000. running mean: -20.531892\n",
            "resetting env. episode 1566.000000, reward total was -21.000000. running mean: -20.536574\n",
            "resetting env. episode 1567.000000, reward total was -21.000000. running mean: -20.541208\n",
            "resetting env. episode 1568.000000, reward total was -20.000000. running mean: -20.535796\n",
            "resetting env. episode 1569.000000, reward total was -20.000000. running mean: -20.530438\n",
            "resetting env. episode 1570.000000, reward total was -21.000000. running mean: -20.535133\n",
            "resetting env. episode 1571.000000, reward total was -21.000000. running mean: -20.539782\n",
            "resetting env. episode 1572.000000, reward total was -19.000000. running mean: -20.524384\n",
            "resetting env. episode 1573.000000, reward total was -19.000000. running mean: -20.509140\n",
            "resetting env. episode 1574.000000, reward total was -19.000000. running mean: -20.494049\n",
            "resetting env. episode 1575.000000, reward total was -21.000000. running mean: -20.499109\n",
            "resetting env. episode 1576.000000, reward total was -19.000000. running mean: -20.484117\n",
            "resetting env. episode 1577.000000, reward total was -20.000000. running mean: -20.479276\n",
            "resetting env. episode 1578.000000, reward total was -21.000000. running mean: -20.484483\n",
            "resetting env. episode 1579.000000, reward total was -20.000000. running mean: -20.479639\n",
            "resetting env. episode 1580.000000, reward total was -21.000000. running mean: -20.484842\n",
            "resetting env. episode 1581.000000, reward total was -20.000000. running mean: -20.479994\n",
            "resetting env. episode 1582.000000, reward total was -20.000000. running mean: -20.475194\n",
            "resetting env. episode 1583.000000, reward total was -20.000000. running mean: -20.470442\n",
            "resetting env. episode 1584.000000, reward total was -20.000000. running mean: -20.465738\n",
            "resetting env. episode 1585.000000, reward total was -21.000000. running mean: -20.471080\n",
            "resetting env. episode 1586.000000, reward total was -21.000000. running mean: -20.476369\n",
            "resetting env. episode 1587.000000, reward total was -19.000000. running mean: -20.461606\n",
            "resetting env. episode 1588.000000, reward total was -21.000000. running mean: -20.466990\n",
            "resetting env. episode 1589.000000, reward total was -19.000000. running mean: -20.452320\n",
            "resetting env. episode 1590.000000, reward total was -21.000000. running mean: -20.457797\n",
            "resetting env. episode 1591.000000, reward total was -21.000000. running mean: -20.463219\n",
            "resetting env. episode 1592.000000, reward total was -20.000000. running mean: -20.458586\n",
            "resetting env. episode 1593.000000, reward total was -21.000000. running mean: -20.464001\n",
            "resetting env. episode 1594.000000, reward total was -21.000000. running mean: -20.469361\n",
            "resetting env. episode 1595.000000, reward total was -20.000000. running mean: -20.464667\n",
            "resetting env. episode 1596.000000, reward total was -19.000000. running mean: -20.450020\n",
            "resetting env. episode 1597.000000, reward total was -19.000000. running mean: -20.435520\n",
            "resetting env. episode 1598.000000, reward total was -19.000000. running mean: -20.421165\n",
            "resetting env. episode 1599.000000, reward total was -21.000000. running mean: -20.426953\n",
            "resetting env. episode 1600.000000, reward total was -21.000000. running mean: -20.432684\n",
            "resetting env. episode 1601.000000, reward total was -21.000000. running mean: -20.438357\n",
            "resetting env. episode 1602.000000, reward total was -21.000000. running mean: -20.443973\n",
            "resetting env. episode 1603.000000, reward total was -20.000000. running mean: -20.439534\n",
            "resetting env. episode 1604.000000, reward total was -21.000000. running mean: -20.445138\n",
            "resetting env. episode 1605.000000, reward total was -19.000000. running mean: -20.430687\n",
            "resetting env. episode 1606.000000, reward total was -21.000000. running mean: -20.436380\n",
            "resetting env. episode 1607.000000, reward total was -21.000000. running mean: -20.442016\n",
            "resetting env. episode 1608.000000, reward total was -21.000000. running mean: -20.447596\n",
            "resetting env. episode 1609.000000, reward total was -21.000000. running mean: -20.453120\n",
            "resetting env. episode 1610.000000, reward total was -21.000000. running mean: -20.458589\n",
            "resetting env. episode 1611.000000, reward total was -20.000000. running mean: -20.454003\n",
            "resetting env. episode 1612.000000, reward total was -20.000000. running mean: -20.449463\n",
            "resetting env. episode 1613.000000, reward total was -21.000000. running mean: -20.454968\n",
            "resetting env. episode 1614.000000, reward total was -21.000000. running mean: -20.460419\n",
            "resetting env. episode 1615.000000, reward total was -21.000000. running mean: -20.465814\n",
            "resetting env. episode 1616.000000, reward total was -20.000000. running mean: -20.461156\n",
            "resetting env. episode 1617.000000, reward total was -21.000000. running mean: -20.466545\n",
            "resetting env. episode 1618.000000, reward total was -21.000000. running mean: -20.471879\n",
            "resetting env. episode 1619.000000, reward total was -21.000000. running mean: -20.477160\n",
            "resetting env. episode 1620.000000, reward total was -20.000000. running mean: -20.472389\n",
            "resetting env. episode 1621.000000, reward total was -21.000000. running mean: -20.477665\n",
            "resetting env. episode 1622.000000, reward total was -20.000000. running mean: -20.472888\n",
            "resetting env. episode 1623.000000, reward total was -21.000000. running mean: -20.478159\n",
            "resetting env. episode 1624.000000, reward total was -21.000000. running mean: -20.483378\n",
            "resetting env. episode 1625.000000, reward total was -21.000000. running mean: -20.488544\n",
            "resetting env. episode 1626.000000, reward total was -21.000000. running mean: -20.493659\n",
            "resetting env. episode 1627.000000, reward total was -21.000000. running mean: -20.498722\n",
            "resetting env. episode 1628.000000, reward total was -20.000000. running mean: -20.493735\n",
            "resetting env. episode 1629.000000, reward total was -21.000000. running mean: -20.498797\n",
            "resetting env. episode 1630.000000, reward total was -21.000000. running mean: -20.503809\n",
            "resetting env. episode 1631.000000, reward total was -21.000000. running mean: -20.508771\n",
            "resetting env. episode 1632.000000, reward total was -21.000000. running mean: -20.513684\n",
            "resetting env. episode 1633.000000, reward total was -19.000000. running mean: -20.498547\n",
            "resetting env. episode 1634.000000, reward total was -20.000000. running mean: -20.493561\n",
            "resetting env. episode 1635.000000, reward total was -21.000000. running mean: -20.498626\n",
            "resetting env. episode 1636.000000, reward total was -21.000000. running mean: -20.503639\n",
            "resetting env. episode 1637.000000, reward total was -21.000000. running mean: -20.508603\n",
            "resetting env. episode 1638.000000, reward total was -19.000000. running mean: -20.493517\n",
            "resetting env. episode 1639.000000, reward total was -20.000000. running mean: -20.488582\n",
            "resetting env. episode 1640.000000, reward total was -19.000000. running mean: -20.473696\n",
            "resetting env. episode 1641.000000, reward total was -21.000000. running mean: -20.478959\n",
            "resetting env. episode 1642.000000, reward total was -21.000000. running mean: -20.484170\n",
            "resetting env. episode 1643.000000, reward total was -20.000000. running mean: -20.479328\n",
            "resetting env. episode 1644.000000, reward total was -20.000000. running mean: -20.474535\n",
            "resetting env. episode 1645.000000, reward total was -21.000000. running mean: -20.479789\n",
            "resetting env. episode 1646.000000, reward total was -20.000000. running mean: -20.474991\n",
            "resetting env. episode 1647.000000, reward total was -21.000000. running mean: -20.480241\n",
            "resetting env. episode 1648.000000, reward total was -21.000000. running mean: -20.485439\n",
            "resetting env. episode 1649.000000, reward total was -21.000000. running mean: -20.490585\n",
            "resetting env. episode 1650.000000, reward total was -21.000000. running mean: -20.495679\n",
            "resetting env. episode 1651.000000, reward total was -20.000000. running mean: -20.490722\n",
            "resetting env. episode 1652.000000, reward total was -21.000000. running mean: -20.495815\n",
            "resetting env. episode 1653.000000, reward total was -18.000000. running mean: -20.470857\n",
            "resetting env. episode 1654.000000, reward total was -21.000000. running mean: -20.476148\n",
            "resetting env. episode 1655.000000, reward total was -19.000000. running mean: -20.461387\n",
            "resetting env. episode 1656.000000, reward total was -19.000000. running mean: -20.446773\n",
            "resetting env. episode 1657.000000, reward total was -21.000000. running mean: -20.452305\n",
            "resetting env. episode 1658.000000, reward total was -20.000000. running mean: -20.447782\n",
            "resetting env. episode 1659.000000, reward total was -19.000000. running mean: -20.433304\n",
            "resetting env. episode 1660.000000, reward total was -21.000000. running mean: -20.438971\n",
            "resetting env. episode 1661.000000, reward total was -21.000000. running mean: -20.444581\n",
            "resetting env. episode 1662.000000, reward total was -21.000000. running mean: -20.450136\n",
            "resetting env. episode 1663.000000, reward total was -21.000000. running mean: -20.455634\n",
            "resetting env. episode 1664.000000, reward total was -21.000000. running mean: -20.461078\n",
            "resetting env. episode 1665.000000, reward total was -21.000000. running mean: -20.466467\n",
            "resetting env. episode 1666.000000, reward total was -21.000000. running mean: -20.471802\n",
            "resetting env. episode 1667.000000, reward total was -21.000000. running mean: -20.477084\n",
            "resetting env. episode 1668.000000, reward total was -21.000000. running mean: -20.482314\n",
            "resetting env. episode 1669.000000, reward total was -21.000000. running mean: -20.487490\n",
            "resetting env. episode 1670.000000, reward total was -21.000000. running mean: -20.492615\n",
            "resetting env. episode 1671.000000, reward total was -19.000000. running mean: -20.477689\n",
            "resetting env. episode 1672.000000, reward total was -20.000000. running mean: -20.472912\n",
            "resetting env. episode 1673.000000, reward total was -21.000000. running mean: -20.478183\n",
            "resetting env. episode 1674.000000, reward total was -20.000000. running mean: -20.473401\n",
            "resetting env. episode 1675.000000, reward total was -20.000000. running mean: -20.468667\n",
            "resetting env. episode 1676.000000, reward total was -20.000000. running mean: -20.463981\n",
            "resetting env. episode 1677.000000, reward total was -20.000000. running mean: -20.459341\n",
            "resetting env. episode 1678.000000, reward total was -21.000000. running mean: -20.464748\n",
            "resetting env. episode 1679.000000, reward total was -20.000000. running mean: -20.460100\n",
            "resetting env. episode 1680.000000, reward total was -20.000000. running mean: -20.455499\n",
            "resetting env. episode 1681.000000, reward total was -21.000000. running mean: -20.460944\n",
            "resetting env. episode 1682.000000, reward total was -21.000000. running mean: -20.466335\n",
            "resetting env. episode 1683.000000, reward total was -20.000000. running mean: -20.461671\n",
            "resetting env. episode 1684.000000, reward total was -21.000000. running mean: -20.467055\n",
            "resetting env. episode 1685.000000, reward total was -20.000000. running mean: -20.462384\n",
            "resetting env. episode 1686.000000, reward total was -19.000000. running mean: -20.447760\n",
            "resetting env. episode 1687.000000, reward total was -20.000000. running mean: -20.443283\n",
            "resetting env. episode 1688.000000, reward total was -21.000000. running mean: -20.448850\n",
            "resetting env. episode 1689.000000, reward total was -19.000000. running mean: -20.434361\n",
            "resetting env. episode 1690.000000, reward total was -20.000000. running mean: -20.430018\n",
            "resetting env. episode 1691.000000, reward total was -21.000000. running mean: -20.435717\n",
            "resetting env. episode 1692.000000, reward total was -21.000000. running mean: -20.441360\n",
            "resetting env. episode 1693.000000, reward total was -21.000000. running mean: -20.446947\n",
            "resetting env. episode 1694.000000, reward total was -21.000000. running mean: -20.452477\n",
            "resetting env. episode 1695.000000, reward total was -21.000000. running mean: -20.457952\n",
            "resetting env. episode 1696.000000, reward total was -21.000000. running mean: -20.463373\n",
            "resetting env. episode 1697.000000, reward total was -21.000000. running mean: -20.468739\n",
            "resetting env. episode 1698.000000, reward total was -21.000000. running mean: -20.474052\n",
            "resetting env. episode 1699.000000, reward total was -21.000000. running mean: -20.479311\n",
            "resetting env. episode 1700.000000, reward total was -21.000000. running mean: -20.484518\n",
            "resetting env. episode 1701.000000, reward total was -21.000000. running mean: -20.489673\n",
            "resetting env. episode 1702.000000, reward total was -21.000000. running mean: -20.494776\n",
            "resetting env. episode 1703.000000, reward total was -18.000000. running mean: -20.469829\n",
            "resetting env. episode 1704.000000, reward total was -21.000000. running mean: -20.475130\n",
            "resetting env. episode 1705.000000, reward total was -21.000000. running mean: -20.480379\n",
            "resetting env. episode 1706.000000, reward total was -20.000000. running mean: -20.475575\n",
            "resetting env. episode 1707.000000, reward total was -21.000000. running mean: -20.480819\n",
            "resetting env. episode 1708.000000, reward total was -21.000000. running mean: -20.486011\n",
            "resetting env. episode 1709.000000, reward total was -20.000000. running mean: -20.481151\n",
            "resetting env. episode 1710.000000, reward total was -20.000000. running mean: -20.476340\n",
            "resetting env. episode 1711.000000, reward total was -20.000000. running mean: -20.471576\n",
            "resetting env. episode 1712.000000, reward total was -20.000000. running mean: -20.466860\n",
            "resetting env. episode 1713.000000, reward total was -19.000000. running mean: -20.452192\n",
            "resetting env. episode 1714.000000, reward total was -21.000000. running mean: -20.457670\n",
            "resetting env. episode 1715.000000, reward total was -21.000000. running mean: -20.463093\n",
            "resetting env. episode 1716.000000, reward total was -19.000000. running mean: -20.448462\n",
            "resetting env. episode 1717.000000, reward total was -21.000000. running mean: -20.453978\n",
            "resetting env. episode 1718.000000, reward total was -21.000000. running mean: -20.459438\n",
            "resetting env. episode 1719.000000, reward total was -18.000000. running mean: -20.434843\n",
            "resetting env. episode 1720.000000, reward total was -20.000000. running mean: -20.430495\n",
            "resetting env. episode 1721.000000, reward total was -20.000000. running mean: -20.426190\n",
            "resetting env. episode 1722.000000, reward total was -21.000000. running mean: -20.431928\n",
            "resetting env. episode 1723.000000, reward total was -21.000000. running mean: -20.437609\n",
            "resetting env. episode 1724.000000, reward total was -20.000000. running mean: -20.433233\n",
            "resetting env. episode 1725.000000, reward total was -21.000000. running mean: -20.438901\n",
            "resetting env. episode 1726.000000, reward total was -21.000000. running mean: -20.444511\n",
            "resetting env. episode 1727.000000, reward total was -21.000000. running mean: -20.450066\n",
            "resetting env. episode 1728.000000, reward total was -21.000000. running mean: -20.455566\n",
            "resetting env. episode 1729.000000, reward total was -21.000000. running mean: -20.461010\n",
            "resetting env. episode 1730.000000, reward total was -21.000000. running mean: -20.466400\n",
            "resetting env. episode 1731.000000, reward total was -19.000000. running mean: -20.451736\n",
            "resetting env. episode 1732.000000, reward total was -21.000000. running mean: -20.457219\n",
            "resetting env. episode 1733.000000, reward total was -20.000000. running mean: -20.452646\n",
            "resetting env. episode 1734.000000, reward total was -20.000000. running mean: -20.448120\n",
            "resetting env. episode 1735.000000, reward total was -20.000000. running mean: -20.443639\n",
            "resetting env. episode 1736.000000, reward total was -21.000000. running mean: -20.449202\n",
            "resetting env. episode 1737.000000, reward total was -21.000000. running mean: -20.454710\n",
            "resetting env. episode 1738.000000, reward total was -20.000000. running mean: -20.450163\n",
            "resetting env. episode 1739.000000, reward total was -21.000000. running mean: -20.455662\n",
            "resetting env. episode 1740.000000, reward total was -19.000000. running mean: -20.441105\n",
            "resetting env. episode 1741.000000, reward total was -20.000000. running mean: -20.436694\n",
            "resetting env. episode 1742.000000, reward total was -21.000000. running mean: -20.442327\n",
            "resetting env. episode 1743.000000, reward total was -21.000000. running mean: -20.447904\n",
            "resetting env. episode 1744.000000, reward total was -20.000000. running mean: -20.443425\n",
            "resetting env. episode 1745.000000, reward total was -21.000000. running mean: -20.448990\n",
            "resetting env. episode 1746.000000, reward total was -21.000000. running mean: -20.454501\n",
            "resetting env. episode 1747.000000, reward total was -21.000000. running mean: -20.459956\n",
            "resetting env. episode 1748.000000, reward total was -20.000000. running mean: -20.455356\n",
            "resetting env. episode 1749.000000, reward total was -21.000000. running mean: -20.460802\n",
            "resetting env. episode 1750.000000, reward total was -19.000000. running mean: -20.446194\n",
            "resetting env. episode 1751.000000, reward total was -21.000000. running mean: -20.451732\n",
            "resetting env. episode 1752.000000, reward total was -20.000000. running mean: -20.447215\n",
            "resetting env. episode 1753.000000, reward total was -21.000000. running mean: -20.452743\n",
            "resetting env. episode 1754.000000, reward total was -21.000000. running mean: -20.458216\n",
            "resetting env. episode 1755.000000, reward total was -21.000000. running mean: -20.463633\n",
            "resetting env. episode 1756.000000, reward total was -21.000000. running mean: -20.468997\n",
            "resetting env. episode 1757.000000, reward total was -21.000000. running mean: -20.474307\n",
            "resetting env. episode 1758.000000, reward total was -21.000000. running mean: -20.479564\n",
            "resetting env. episode 1759.000000, reward total was -20.000000. running mean: -20.474768\n",
            "resetting env. episode 1760.000000, reward total was -18.000000. running mean: -20.450021\n",
            "resetting env. episode 1761.000000, reward total was -21.000000. running mean: -20.455520\n",
            "resetting env. episode 1762.000000, reward total was -20.000000. running mean: -20.450965\n",
            "resetting env. episode 1763.000000, reward total was -20.000000. running mean: -20.446456\n",
            "resetting env. episode 1764.000000, reward total was -21.000000. running mean: -20.451991\n",
            "resetting env. episode 1765.000000, reward total was -21.000000. running mean: -20.457471\n",
            "resetting env. episode 1766.000000, reward total was -20.000000. running mean: -20.452896\n",
            "resetting env. episode 1767.000000, reward total was -20.000000. running mean: -20.448367\n",
            "resetting env. episode 1768.000000, reward total was -19.000000. running mean: -20.433884\n",
            "resetting env. episode 1769.000000, reward total was -21.000000. running mean: -20.439545\n",
            "resetting env. episode 1770.000000, reward total was -20.000000. running mean: -20.435150\n",
            "resetting env. episode 1771.000000, reward total was -21.000000. running mean: -20.440798\n",
            "resetting env. episode 1772.000000, reward total was -21.000000. running mean: -20.446390\n",
            "resetting env. episode 1773.000000, reward total was -21.000000. running mean: -20.451926\n",
            "resetting env. episode 1774.000000, reward total was -21.000000. running mean: -20.457407\n",
            "resetting env. episode 1775.000000, reward total was -21.000000. running mean: -20.462833\n",
            "resetting env. episode 1776.000000, reward total was -20.000000. running mean: -20.458204\n",
            "resetting env. episode 1777.000000, reward total was -21.000000. running mean: -20.463622\n",
            "resetting env. episode 1778.000000, reward total was -21.000000. running mean: -20.468986\n",
            "resetting env. episode 1779.000000, reward total was -21.000000. running mean: -20.474296\n",
            "resetting env. episode 1780.000000, reward total was -21.000000. running mean: -20.479553\n",
            "resetting env. episode 1781.000000, reward total was -21.000000. running mean: -20.484758\n",
            "resetting env. episode 1782.000000, reward total was -18.000000. running mean: -20.459910\n",
            "resetting env. episode 1783.000000, reward total was -20.000000. running mean: -20.455311\n",
            "resetting env. episode 1784.000000, reward total was -21.000000. running mean: -20.460758\n",
            "resetting env. episode 1785.000000, reward total was -21.000000. running mean: -20.466150\n",
            "resetting env. episode 1786.000000, reward total was -21.000000. running mean: -20.471489\n",
            "resetting env. episode 1787.000000, reward total was -21.000000. running mean: -20.476774\n",
            "resetting env. episode 1788.000000, reward total was -21.000000. running mean: -20.482006\n",
            "resetting env. episode 1789.000000, reward total was -20.000000. running mean: -20.477186\n",
            "resetting env. episode 1790.000000, reward total was -21.000000. running mean: -20.482414\n",
            "resetting env. episode 1791.000000, reward total was -20.000000. running mean: -20.477590\n",
            "resetting env. episode 1792.000000, reward total was -21.000000. running mean: -20.482814\n",
            "resetting env. episode 1793.000000, reward total was -21.000000. running mean: -20.487986\n",
            "resetting env. episode 1794.000000, reward total was -21.000000. running mean: -20.493106\n",
            "resetting env. episode 1795.000000, reward total was -21.000000. running mean: -20.498175\n",
            "resetting env. episode 1796.000000, reward total was -21.000000. running mean: -20.503194\n",
            "resetting env. episode 1797.000000, reward total was -21.000000. running mean: -20.508162\n",
            "resetting env. episode 1798.000000, reward total was -19.000000. running mean: -20.493080\n",
            "resetting env. episode 1799.000000, reward total was -21.000000. running mean: -20.498149\n",
            "resetting env. episode 1800.000000, reward total was -21.000000. running mean: -20.503168\n",
            "resetting env. episode 1801.000000, reward total was -21.000000. running mean: -20.508136\n",
            "resetting env. episode 1802.000000, reward total was -20.000000. running mean: -20.503055\n",
            "resetting env. episode 1803.000000, reward total was -21.000000. running mean: -20.508024\n",
            "resetting env. episode 1804.000000, reward total was -19.000000. running mean: -20.492944\n",
            "resetting env. episode 1805.000000, reward total was -21.000000. running mean: -20.498014\n",
            "resetting env. episode 1806.000000, reward total was -20.000000. running mean: -20.493034\n",
            "resetting env. episode 1807.000000, reward total was -21.000000. running mean: -20.498104\n",
            "resetting env. episode 1808.000000, reward total was -20.000000. running mean: -20.493123\n",
            "resetting env. episode 1809.000000, reward total was -20.000000. running mean: -20.488192\n",
            "resetting env. episode 1810.000000, reward total was -21.000000. running mean: -20.493310\n",
            "resetting env. episode 1811.000000, reward total was -21.000000. running mean: -20.498377\n",
            "resetting env. episode 1812.000000, reward total was -21.000000. running mean: -20.503393\n",
            "resetting env. episode 1813.000000, reward total was -21.000000. running mean: -20.508359\n",
            "resetting env. episode 1814.000000, reward total was -21.000000. running mean: -20.513275\n",
            "resetting env. episode 1815.000000, reward total was -20.000000. running mean: -20.508143\n",
            "resetting env. episode 1816.000000, reward total was -20.000000. running mean: -20.503061\n",
            "resetting env. episode 1817.000000, reward total was -21.000000. running mean: -20.508031\n",
            "resetting env. episode 1818.000000, reward total was -21.000000. running mean: -20.512950\n",
            "resetting env. episode 1819.000000, reward total was -21.000000. running mean: -20.517821\n",
            "resetting env. episode 1820.000000, reward total was -20.000000. running mean: -20.512643\n",
            "resetting env. episode 1821.000000, reward total was -20.000000. running mean: -20.507516\n",
            "resetting env. episode 1822.000000, reward total was -21.000000. running mean: -20.512441\n",
            "resetting env. episode 1823.000000, reward total was -20.000000. running mean: -20.507317\n",
            "resetting env. episode 1824.000000, reward total was -21.000000. running mean: -20.512243\n",
            "resetting env. episode 1825.000000, reward total was -19.000000. running mean: -20.497121\n",
            "resetting env. episode 1826.000000, reward total was -21.000000. running mean: -20.502150\n",
            "resetting env. episode 1827.000000, reward total was -21.000000. running mean: -20.507128\n",
            "resetting env. episode 1828.000000, reward total was -21.000000. running mean: -20.512057\n",
            "resetting env. episode 1829.000000, reward total was -21.000000. running mean: -20.516936\n",
            "resetting env. episode 1830.000000, reward total was -21.000000. running mean: -20.521767\n",
            "resetting env. episode 1831.000000, reward total was -21.000000. running mean: -20.526549\n",
            "resetting env. episode 1832.000000, reward total was -21.000000. running mean: -20.531284\n",
            "resetting env. episode 1833.000000, reward total was -19.000000. running mean: -20.515971\n",
            "resetting env. episode 1834.000000, reward total was -21.000000. running mean: -20.520811\n",
            "resetting env. episode 1835.000000, reward total was -20.000000. running mean: -20.515603\n",
            "resetting env. episode 1836.000000, reward total was -19.000000. running mean: -20.500447\n",
            "resetting env. episode 1837.000000, reward total was -18.000000. running mean: -20.475443\n",
            "resetting env. episode 1838.000000, reward total was -21.000000. running mean: -20.480688\n",
            "resetting env. episode 1839.000000, reward total was -21.000000. running mean: -20.485881\n",
            "resetting env. episode 1840.000000, reward total was -21.000000. running mean: -20.491023\n",
            "resetting env. episode 1841.000000, reward total was -20.000000. running mean: -20.486112\n",
            "resetting env. episode 1842.000000, reward total was -21.000000. running mean: -20.491251\n",
            "resetting env. episode 1843.000000, reward total was -19.000000. running mean: -20.476339\n",
            "resetting env. episode 1844.000000, reward total was -18.000000. running mean: -20.451575\n",
            "resetting env. episode 1845.000000, reward total was -21.000000. running mean: -20.457060\n",
            "resetting env. episode 1846.000000, reward total was -21.000000. running mean: -20.462489\n",
            "resetting env. episode 1847.000000, reward total was -21.000000. running mean: -20.467864\n",
            "resetting env. episode 1848.000000, reward total was -20.000000. running mean: -20.463185\n",
            "resetting env. episode 1849.000000, reward total was -19.000000. running mean: -20.448554\n",
            "resetting env. episode 1850.000000, reward total was -21.000000. running mean: -20.454068\n",
            "resetting env. episode 1851.000000, reward total was -21.000000. running mean: -20.459527\n",
            "resetting env. episode 1852.000000, reward total was -21.000000. running mean: -20.464932\n",
            "resetting env. episode 1853.000000, reward total was -19.000000. running mean: -20.450283\n",
            "resetting env. episode 1854.000000, reward total was -18.000000. running mean: -20.425780\n",
            "resetting env. episode 1855.000000, reward total was -21.000000. running mean: -20.431522\n",
            "resetting env. episode 1856.000000, reward total was -21.000000. running mean: -20.437207\n",
            "resetting env. episode 1857.000000, reward total was -21.000000. running mean: -20.442835\n",
            "resetting env. episode 1858.000000, reward total was -21.000000. running mean: -20.448407\n",
            "resetting env. episode 1859.000000, reward total was -21.000000. running mean: -20.453922\n",
            "resetting env. episode 1860.000000, reward total was -21.000000. running mean: -20.459383\n",
            "resetting env. episode 1861.000000, reward total was -21.000000. running mean: -20.464789\n",
            "resetting env. episode 1862.000000, reward total was -20.000000. running mean: -20.460142\n",
            "resetting env. episode 1863.000000, reward total was -21.000000. running mean: -20.465540\n",
            "resetting env. episode 1864.000000, reward total was -21.000000. running mean: -20.470885\n",
            "resetting env. episode 1865.000000, reward total was -21.000000. running mean: -20.476176\n",
            "resetting env. episode 1866.000000, reward total was -21.000000. running mean: -20.481414\n",
            "resetting env. episode 1867.000000, reward total was -21.000000. running mean: -20.486600\n",
            "resetting env. episode 1868.000000, reward total was -21.000000. running mean: -20.491734\n",
            "resetting env. episode 1869.000000, reward total was -21.000000. running mean: -20.496817\n",
            "resetting env. episode 1870.000000, reward total was -21.000000. running mean: -20.501848\n",
            "resetting env. episode 1871.000000, reward total was -21.000000. running mean: -20.506830\n",
            "resetting env. episode 1872.000000, reward total was -21.000000. running mean: -20.511762\n",
            "resetting env. episode 1873.000000, reward total was -21.000000. running mean: -20.516644\n",
            "resetting env. episode 1874.000000, reward total was -21.000000. running mean: -20.521478\n",
            "resetting env. episode 1875.000000, reward total was -21.000000. running mean: -20.526263\n",
            "resetting env. episode 1876.000000, reward total was -19.000000. running mean: -20.511000\n",
            "resetting env. episode 1877.000000, reward total was -20.000000. running mean: -20.505890\n",
            "resetting env. episode 1878.000000, reward total was -20.000000. running mean: -20.500831\n",
            "resetting env. episode 1879.000000, reward total was -21.000000. running mean: -20.505823\n",
            "resetting env. episode 1880.000000, reward total was -21.000000. running mean: -20.510765\n",
            "resetting env. episode 1881.000000, reward total was -21.000000. running mean: -20.515657\n",
            "resetting env. episode 1882.000000, reward total was -20.000000. running mean: -20.510501\n",
            "resetting env. episode 1883.000000, reward total was -21.000000. running mean: -20.515396\n",
            "resetting env. episode 1884.000000, reward total was -20.000000. running mean: -20.510242\n",
            "resetting env. episode 1885.000000, reward total was -21.000000. running mean: -20.515139\n",
            "resetting env. episode 1886.000000, reward total was -21.000000. running mean: -20.519988\n",
            "resetting env. episode 1887.000000, reward total was -21.000000. running mean: -20.524788\n",
            "resetting env. episode 1888.000000, reward total was -18.000000. running mean: -20.499540\n",
            "resetting env. episode 1889.000000, reward total was -19.000000. running mean: -20.484545\n",
            "resetting env. episode 1890.000000, reward total was -21.000000. running mean: -20.489699\n",
            "resetting env. episode 1891.000000, reward total was -21.000000. running mean: -20.494802\n",
            "resetting env. episode 1892.000000, reward total was -21.000000. running mean: -20.499854\n",
            "resetting env. episode 1893.000000, reward total was -19.000000. running mean: -20.484856\n",
            "resetting env. episode 1894.000000, reward total was -19.000000. running mean: -20.470007\n",
            "resetting env. episode 1895.000000, reward total was -21.000000. running mean: -20.475307\n",
            "resetting env. episode 1896.000000, reward total was -20.000000. running mean: -20.470554\n",
            "resetting env. episode 1897.000000, reward total was -20.000000. running mean: -20.465848\n",
            "resetting env. episode 1898.000000, reward total was -21.000000. running mean: -20.471190\n",
            "resetting env. episode 1899.000000, reward total was -21.000000. running mean: -20.476478\n",
            "resetting env. episode 1900.000000, reward total was -21.000000. running mean: -20.481713\n",
            "resetting env. episode 1901.000000, reward total was -21.000000. running mean: -20.486896\n",
            "resetting env. episode 1902.000000, reward total was -21.000000. running mean: -20.492027\n",
            "resetting env. episode 1903.000000, reward total was -21.000000. running mean: -20.497107\n",
            "resetting env. episode 1904.000000, reward total was -21.000000. running mean: -20.502136\n",
            "resetting env. episode 1905.000000, reward total was -21.000000. running mean: -20.507114\n",
            "resetting env. episode 1906.000000, reward total was -20.000000. running mean: -20.502043\n",
            "resetting env. episode 1907.000000, reward total was -19.000000. running mean: -20.487023\n",
            "resetting env. episode 1908.000000, reward total was -21.000000. running mean: -20.492153\n",
            "resetting env. episode 1909.000000, reward total was -20.000000. running mean: -20.487231\n",
            "resetting env. episode 1910.000000, reward total was -21.000000. running mean: -20.492359\n",
            "resetting env. episode 1911.000000, reward total was -21.000000. running mean: -20.497435\n",
            "resetting env. episode 1912.000000, reward total was -20.000000. running mean: -20.492461\n",
            "resetting env. episode 1913.000000, reward total was -19.000000. running mean: -20.477536\n",
            "resetting env. episode 1914.000000, reward total was -21.000000. running mean: -20.482761\n",
            "resetting env. episode 1915.000000, reward total was -20.000000. running mean: -20.477933\n",
            "resetting env. episode 1916.000000, reward total was -21.000000. running mean: -20.483154\n",
            "resetting env. episode 1917.000000, reward total was -21.000000. running mean: -20.488322\n",
            "resetting env. episode 1918.000000, reward total was -21.000000. running mean: -20.493439\n",
            "resetting env. episode 1919.000000, reward total was -20.000000. running mean: -20.488505\n",
            "resetting env. episode 1920.000000, reward total was -21.000000. running mean: -20.493620\n",
            "resetting env. episode 1921.000000, reward total was -21.000000. running mean: -20.498684\n",
            "resetting env. episode 1922.000000, reward total was -21.000000. running mean: -20.503697\n",
            "resetting env. episode 1923.000000, reward total was -20.000000. running mean: -20.498660\n",
            "resetting env. episode 1924.000000, reward total was -21.000000. running mean: -20.503673\n",
            "resetting env. episode 1925.000000, reward total was -21.000000. running mean: -20.508636\n",
            "resetting env. episode 1926.000000, reward total was -21.000000. running mean: -20.513550\n",
            "resetting env. episode 1927.000000, reward total was -20.000000. running mean: -20.508415\n",
            "resetting env. episode 1928.000000, reward total was -21.000000. running mean: -20.513330\n",
            "resetting env. episode 1929.000000, reward total was -21.000000. running mean: -20.518197\n",
            "resetting env. episode 1930.000000, reward total was -21.000000. running mean: -20.523015\n",
            "resetting env. episode 1931.000000, reward total was -21.000000. running mean: -20.527785\n",
            "resetting env. episode 1932.000000, reward total was -20.000000. running mean: -20.522507\n",
            "resetting env. episode 1933.000000, reward total was -20.000000. running mean: -20.517282\n",
            "resetting env. episode 1934.000000, reward total was -21.000000. running mean: -20.522109\n",
            "resetting env. episode 1935.000000, reward total was -21.000000. running mean: -20.526888\n",
            "resetting env. episode 1936.000000, reward total was -21.000000. running mean: -20.531619\n",
            "resetting env. episode 1937.000000, reward total was -20.000000. running mean: -20.526303\n",
            "resetting env. episode 1938.000000, reward total was -21.000000. running mean: -20.531040\n",
            "resetting env. episode 1939.000000, reward total was -21.000000. running mean: -20.535730\n",
            "resetting env. episode 1940.000000, reward total was -20.000000. running mean: -20.530372\n",
            "resetting env. episode 1941.000000, reward total was -21.000000. running mean: -20.535069\n",
            "resetting env. episode 1942.000000, reward total was -21.000000. running mean: -20.539718\n",
            "resetting env. episode 1943.000000, reward total was -20.000000. running mean: -20.534321\n",
            "resetting env. episode 1944.000000, reward total was -21.000000. running mean: -20.538978\n",
            "resetting env. episode 1945.000000, reward total was -20.000000. running mean: -20.533588\n",
            "resetting env. episode 1946.000000, reward total was -21.000000. running mean: -20.538252\n",
            "resetting env. episode 1947.000000, reward total was -19.000000. running mean: -20.522869\n",
            "resetting env. episode 1948.000000, reward total was -21.000000. running mean: -20.527641\n",
            "resetting env. episode 1949.000000, reward total was -19.000000. running mean: -20.512364\n",
            "resetting env. episode 1950.000000, reward total was -21.000000. running mean: -20.517241\n",
            "resetting env. episode 1951.000000, reward total was -20.000000. running mean: -20.512068\n",
            "resetting env. episode 1952.000000, reward total was -21.000000. running mean: -20.516948\n",
            "resetting env. episode 1953.000000, reward total was -21.000000. running mean: -20.521778\n",
            "resetting env. episode 1954.000000, reward total was -20.000000. running mean: -20.516560\n",
            "resetting env. episode 1955.000000, reward total was -21.000000. running mean: -20.521395\n",
            "resetting env. episode 1956.000000, reward total was -21.000000. running mean: -20.526181\n",
            "resetting env. episode 1957.000000, reward total was -20.000000. running mean: -20.520919\n",
            "resetting env. episode 1958.000000, reward total was -21.000000. running mean: -20.525710\n",
            "resetting env. episode 1959.000000, reward total was -19.000000. running mean: -20.510453\n",
            "resetting env. episode 1960.000000, reward total was -21.000000. running mean: -20.515348\n",
            "resetting env. episode 1961.000000, reward total was -21.000000. running mean: -20.520195\n",
            "resetting env. episode 1962.000000, reward total was -20.000000. running mean: -20.514993\n",
            "resetting env. episode 1963.000000, reward total was -20.000000. running mean: -20.509843\n",
            "resetting env. episode 1964.000000, reward total was -21.000000. running mean: -20.514744\n",
            "resetting env. episode 1965.000000, reward total was -20.000000. running mean: -20.509597\n",
            "resetting env. episode 1966.000000, reward total was -20.000000. running mean: -20.504501\n",
            "resetting env. episode 1967.000000, reward total was -21.000000. running mean: -20.509456\n",
            "resetting env. episode 1968.000000, reward total was -20.000000. running mean: -20.504361\n",
            "resetting env. episode 1969.000000, reward total was -21.000000. running mean: -20.509318\n",
            "resetting env. episode 1970.000000, reward total was -21.000000. running mean: -20.514225\n",
            "resetting env. episode 1971.000000, reward total was -20.000000. running mean: -20.509082\n",
            "resetting env. episode 1972.000000, reward total was -21.000000. running mean: -20.513991\n",
            "resetting env. episode 1973.000000, reward total was -21.000000. running mean: -20.518852\n",
            "resetting env. episode 1974.000000, reward total was -19.000000. running mean: -20.503663\n",
            "resetting env. episode 1975.000000, reward total was -21.000000. running mean: -20.508626\n",
            "resetting env. episode 1976.000000, reward total was -20.000000. running mean: -20.503540\n",
            "resetting env. episode 1977.000000, reward total was -21.000000. running mean: -20.508505\n",
            "resetting env. episode 1978.000000, reward total was -20.000000. running mean: -20.503420\n",
            "resetting env. episode 1979.000000, reward total was -21.000000. running mean: -20.508386\n",
            "resetting env. episode 1980.000000, reward total was -21.000000. running mean: -20.513302\n",
            "resetting env. episode 1981.000000, reward total was -21.000000. running mean: -20.518169\n",
            "resetting env. episode 1982.000000, reward total was -21.000000. running mean: -20.522987\n",
            "resetting env. episode 1983.000000, reward total was -20.000000. running mean: -20.517757\n",
            "resetting env. episode 1984.000000, reward total was -21.000000. running mean: -20.522580\n",
            "resetting env. episode 1985.000000, reward total was -21.000000. running mean: -20.527354\n",
            "resetting env. episode 1986.000000, reward total was -20.000000. running mean: -20.522080\n",
            "resetting env. episode 1987.000000, reward total was -18.000000. running mean: -20.496859\n",
            "resetting env. episode 1988.000000, reward total was -21.000000. running mean: -20.501891\n",
            "resetting env. episode 1989.000000, reward total was -21.000000. running mean: -20.506872\n",
            "resetting env. episode 1990.000000, reward total was -21.000000. running mean: -20.511803\n",
            "resetting env. episode 1991.000000, reward total was -21.000000. running mean: -20.516685\n",
            "resetting env. episode 1992.000000, reward total was -19.000000. running mean: -20.501518\n",
            "resetting env. episode 1993.000000, reward total was -21.000000. running mean: -20.506503\n",
            "resetting env. episode 1994.000000, reward total was -18.000000. running mean: -20.481438\n",
            "resetting env. episode 1995.000000, reward total was -21.000000. running mean: -20.486624\n",
            "resetting env. episode 1996.000000, reward total was -21.000000. running mean: -20.491757\n",
            "resetting env. episode 1997.000000, reward total was -21.000000. running mean: -20.496840\n",
            "resetting env. episode 1998.000000, reward total was -20.000000. running mean: -20.491871\n",
            "resetting env. episode 1999.000000, reward total was -20.000000. running mean: -20.486953\n",
            "resetting env. episode 2000.000000, reward total was -21.000000. running mean: -20.492083\n",
            "resetting env. episode 2001.000000, reward total was -21.000000. running mean: -20.497162\n",
            "resetting env. episode 2002.000000, reward total was -19.000000. running mean: -20.482191\n",
            "resetting env. episode 2003.000000, reward total was -21.000000. running mean: -20.487369\n",
            "resetting env. episode 2004.000000, reward total was -20.000000. running mean: -20.482495\n",
            "resetting env. episode 2005.000000, reward total was -21.000000. running mean: -20.487670\n",
            "resetting env. episode 2006.000000, reward total was -21.000000. running mean: -20.492794\n",
            "resetting env. episode 2007.000000, reward total was -21.000000. running mean: -20.497866\n",
            "resetting env. episode 2008.000000, reward total was -18.000000. running mean: -20.472887\n",
            "resetting env. episode 2009.000000, reward total was -21.000000. running mean: -20.478158\n",
            "resetting env. episode 2010.000000, reward total was -21.000000. running mean: -20.483376\n",
            "resetting env. episode 2011.000000, reward total was -21.000000. running mean: -20.488543\n",
            "resetting env. episode 2012.000000, reward total was -21.000000. running mean: -20.493657\n",
            "resetting env. episode 2013.000000, reward total was -20.000000. running mean: -20.488721\n",
            "resetting env. episode 2014.000000, reward total was -20.000000. running mean: -20.483834\n",
            "resetting env. episode 2015.000000, reward total was -20.000000. running mean: -20.478995\n",
            "resetting env. episode 2016.000000, reward total was -21.000000. running mean: -20.484205\n",
            "resetting env. episode 2017.000000, reward total was -19.000000. running mean: -20.469363\n",
            "resetting env. episode 2018.000000, reward total was -21.000000. running mean: -20.474670\n",
            "resetting env. episode 2019.000000, reward total was -18.000000. running mean: -20.449923\n",
            "resetting env. episode 2020.000000, reward total was -21.000000. running mean: -20.455424\n",
            "resetting env. episode 2021.000000, reward total was -21.000000. running mean: -20.460869\n",
            "resetting env. episode 2022.000000, reward total was -21.000000. running mean: -20.466261\n",
            "resetting env. episode 2023.000000, reward total was -21.000000. running mean: -20.471598\n",
            "resetting env. episode 2024.000000, reward total was -21.000000. running mean: -20.476882\n",
            "resetting env. episode 2025.000000, reward total was -21.000000. running mean: -20.482113\n",
            "resetting env. episode 2026.000000, reward total was -20.000000. running mean: -20.477292\n",
            "resetting env. episode 2027.000000, reward total was -21.000000. running mean: -20.482519\n",
            "resetting env. episode 2028.000000, reward total was -21.000000. running mean: -20.487694\n",
            "resetting env. episode 2029.000000, reward total was -21.000000. running mean: -20.492817\n",
            "resetting env. episode 2030.000000, reward total was -20.000000. running mean: -20.487889\n",
            "resetting env. episode 2031.000000, reward total was -21.000000. running mean: -20.493010\n",
            "resetting env. episode 2032.000000, reward total was -21.000000. running mean: -20.498080\n",
            "resetting env. episode 2033.000000, reward total was -21.000000. running mean: -20.503099\n",
            "resetting env. episode 2034.000000, reward total was -21.000000. running mean: -20.508068\n",
            "resetting env. episode 2035.000000, reward total was -21.000000. running mean: -20.512987\n",
            "resetting env. episode 2036.000000, reward total was -21.000000. running mean: -20.517858\n",
            "resetting env. episode 2037.000000, reward total was -17.000000. running mean: -20.482679\n",
            "resetting env. episode 2038.000000, reward total was -21.000000. running mean: -20.487852\n",
            "resetting env. episode 2039.000000, reward total was -20.000000. running mean: -20.482974\n",
            "resetting env. episode 2040.000000, reward total was -21.000000. running mean: -20.488144\n",
            "resetting env. episode 2041.000000, reward total was -21.000000. running mean: -20.493263\n",
            "resetting env. episode 2042.000000, reward total was -21.000000. running mean: -20.498330\n",
            "resetting env. episode 2043.000000, reward total was -20.000000. running mean: -20.493347\n",
            "resetting env. episode 2044.000000, reward total was -21.000000. running mean: -20.498413\n",
            "resetting env. episode 2045.000000, reward total was -21.000000. running mean: -20.503429\n",
            "resetting env. episode 2046.000000, reward total was -20.000000. running mean: -20.498395\n",
            "resetting env. episode 2047.000000, reward total was -21.000000. running mean: -20.503411\n",
            "resetting env. episode 2048.000000, reward total was -21.000000. running mean: -20.508377\n",
            "resetting env. episode 2049.000000, reward total was -21.000000. running mean: -20.513293\n",
            "resetting env. episode 2050.000000, reward total was -20.000000. running mean: -20.508160\n",
            "resetting env. episode 2051.000000, reward total was -21.000000. running mean: -20.513078\n",
            "resetting env. episode 2052.000000, reward total was -19.000000. running mean: -20.497948\n",
            "resetting env. episode 2053.000000, reward total was -21.000000. running mean: -20.502968\n",
            "resetting env. episode 2054.000000, reward total was -21.000000. running mean: -20.507938\n",
            "resetting env. episode 2055.000000, reward total was -21.000000. running mean: -20.512859\n",
            "resetting env. episode 2056.000000, reward total was -21.000000. running mean: -20.517730\n",
            "resetting env. episode 2057.000000, reward total was -21.000000. running mean: -20.522553\n",
            "resetting env. episode 2058.000000, reward total was -21.000000. running mean: -20.527328\n",
            "resetting env. episode 2059.000000, reward total was -21.000000. running mean: -20.532054\n",
            "resetting env. episode 2060.000000, reward total was -20.000000. running mean: -20.526734\n",
            "resetting env. episode 2061.000000, reward total was -21.000000. running mean: -20.531466\n",
            "resetting env. episode 2062.000000, reward total was -21.000000. running mean: -20.536152\n",
            "resetting env. episode 2063.000000, reward total was -21.000000. running mean: -20.540790\n",
            "resetting env. episode 2064.000000, reward total was -21.000000. running mean: -20.545382\n",
            "resetting env. episode 2065.000000, reward total was -21.000000. running mean: -20.549929\n",
            "resetting env. episode 2066.000000, reward total was -21.000000. running mean: -20.554429\n",
            "resetting env. episode 2067.000000, reward total was -21.000000. running mean: -20.558885\n",
            "resetting env. episode 2068.000000, reward total was -20.000000. running mean: -20.553296\n",
            "resetting env. episode 2069.000000, reward total was -21.000000. running mean: -20.557763\n",
            "resetting env. episode 2070.000000, reward total was -21.000000. running mean: -20.562186\n",
            "resetting env. episode 2071.000000, reward total was -21.000000. running mean: -20.566564\n",
            "resetting env. episode 2072.000000, reward total was -21.000000. running mean: -20.570898\n",
            "resetting env. episode 2073.000000, reward total was -20.000000. running mean: -20.565189\n",
            "resetting env. episode 2074.000000, reward total was -21.000000. running mean: -20.569537\n",
            "resetting env. episode 2075.000000, reward total was -21.000000. running mean: -20.573842\n",
            "resetting env. episode 2076.000000, reward total was -20.000000. running mean: -20.568103\n",
            "resetting env. episode 2077.000000, reward total was -21.000000. running mean: -20.572422\n",
            "resetting env. episode 2078.000000, reward total was -21.000000. running mean: -20.576698\n",
            "resetting env. episode 2079.000000, reward total was -21.000000. running mean: -20.580931\n",
            "resetting env. episode 2080.000000, reward total was -21.000000. running mean: -20.585122\n",
            "resetting env. episode 2081.000000, reward total was -20.000000. running mean: -20.579271\n",
            "resetting env. episode 2082.000000, reward total was -21.000000. running mean: -20.583478\n",
            "resetting env. episode 2083.000000, reward total was -21.000000. running mean: -20.587643\n",
            "resetting env. episode 2084.000000, reward total was -21.000000. running mean: -20.591767\n",
            "resetting env. episode 2085.000000, reward total was -21.000000. running mean: -20.595849\n",
            "resetting env. episode 2086.000000, reward total was -21.000000. running mean: -20.599891\n",
            "resetting env. episode 2087.000000, reward total was -21.000000. running mean: -20.603892\n",
            "resetting env. episode 2088.000000, reward total was -20.000000. running mean: -20.597853\n",
            "resetting env. episode 2089.000000, reward total was -21.000000. running mean: -20.601874\n",
            "resetting env. episode 2090.000000, reward total was -21.000000. running mean: -20.605855\n",
            "resetting env. episode 2091.000000, reward total was -21.000000. running mean: -20.609797\n",
            "resetting env. episode 2092.000000, reward total was -21.000000. running mean: -20.613699\n",
            "resetting env. episode 2093.000000, reward total was -21.000000. running mean: -20.617562\n",
            "resetting env. episode 2094.000000, reward total was -21.000000. running mean: -20.621386\n",
            "resetting env. episode 2095.000000, reward total was -20.000000. running mean: -20.615172\n",
            "resetting env. episode 2096.000000, reward total was -21.000000. running mean: -20.619021\n",
            "resetting env. episode 2097.000000, reward total was -21.000000. running mean: -20.622831\n",
            "resetting env. episode 2098.000000, reward total was -21.000000. running mean: -20.626602\n",
            "resetting env. episode 2099.000000, reward total was -21.000000. running mean: -20.630336\n",
            "resetting env. episode 2100.000000, reward total was -21.000000. running mean: -20.634033\n",
            "resetting env. episode 2101.000000, reward total was -21.000000. running mean: -20.637692\n",
            "resetting env. episode 2102.000000, reward total was -19.000000. running mean: -20.621316\n",
            "resetting env. episode 2103.000000, reward total was -21.000000. running mean: -20.625102\n",
            "resetting env. episode 2104.000000, reward total was -21.000000. running mean: -20.628851\n",
            "resetting env. episode 2105.000000, reward total was -21.000000. running mean: -20.632563\n",
            "resetting env. episode 2106.000000, reward total was -20.000000. running mean: -20.626237\n",
            "resetting env. episode 2107.000000, reward total was -21.000000. running mean: -20.629975\n",
            "resetting env. episode 2108.000000, reward total was -21.000000. running mean: -20.633675\n",
            "resetting env. episode 2109.000000, reward total was -19.000000. running mean: -20.617338\n",
            "resetting env. episode 2110.000000, reward total was -21.000000. running mean: -20.621165\n",
            "resetting env. episode 2111.000000, reward total was -21.000000. running mean: -20.624953\n",
            "resetting env. episode 2112.000000, reward total was -21.000000. running mean: -20.628704\n",
            "resetting env. episode 2113.000000, reward total was -20.000000. running mean: -20.622417\n",
            "resetting env. episode 2114.000000, reward total was -20.000000. running mean: -20.616193\n",
            "resetting env. episode 2115.000000, reward total was -21.000000. running mean: -20.620031\n",
            "resetting env. episode 2116.000000, reward total was -21.000000. running mean: -20.623830\n",
            "resetting env. episode 2117.000000, reward total was -21.000000. running mean: -20.627592\n",
            "resetting env. episode 2118.000000, reward total was -18.000000. running mean: -20.601316\n",
            "resetting env. episode 2119.000000, reward total was -21.000000. running mean: -20.605303\n",
            "resetting env. episode 2120.000000, reward total was -20.000000. running mean: -20.599250\n",
            "resetting env. episode 2121.000000, reward total was -18.000000. running mean: -20.573257\n",
            "resetting env. episode 2122.000000, reward total was -21.000000. running mean: -20.577525\n",
            "resetting env. episode 2123.000000, reward total was -21.000000. running mean: -20.581750\n",
            "resetting env. episode 2124.000000, reward total was -21.000000. running mean: -20.585932\n",
            "resetting env. episode 2125.000000, reward total was -21.000000. running mean: -20.590073\n",
            "resetting env. episode 2126.000000, reward total was -19.000000. running mean: -20.574172\n",
            "resetting env. episode 2127.000000, reward total was -20.000000. running mean: -20.568430\n",
            "resetting env. episode 2128.000000, reward total was -21.000000. running mean: -20.572746\n",
            "resetting env. episode 2129.000000, reward total was -21.000000. running mean: -20.577019\n",
            "resetting env. episode 2130.000000, reward total was -21.000000. running mean: -20.581248\n",
            "resetting env. episode 2131.000000, reward total was -21.000000. running mean: -20.585436\n",
            "resetting env. episode 2132.000000, reward total was -20.000000. running mean: -20.579582\n",
            "resetting env. episode 2133.000000, reward total was -21.000000. running mean: -20.583786\n",
            "resetting env. episode 2134.000000, reward total was -20.000000. running mean: -20.577948\n",
            "resetting env. episode 2135.000000, reward total was -19.000000. running mean: -20.562168\n",
            "resetting env. episode 2136.000000, reward total was -21.000000. running mean: -20.566547\n",
            "resetting env. episode 2137.000000, reward total was -20.000000. running mean: -20.560881\n",
            "resetting env. episode 2138.000000, reward total was -21.000000. running mean: -20.565272\n",
            "resetting env. episode 2139.000000, reward total was -21.000000. running mean: -20.569620\n",
            "resetting env. episode 2140.000000, reward total was -19.000000. running mean: -20.553924\n",
            "resetting env. episode 2141.000000, reward total was -21.000000. running mean: -20.558384\n",
            "resetting env. episode 2142.000000, reward total was -21.000000. running mean: -20.562800\n",
            "resetting env. episode 2143.000000, reward total was -21.000000. running mean: -20.567172\n",
            "resetting env. episode 2144.000000, reward total was -21.000000. running mean: -20.571501\n",
            "resetting env. episode 2145.000000, reward total was -20.000000. running mean: -20.565786\n",
            "resetting env. episode 2146.000000, reward total was -21.000000. running mean: -20.570128\n",
            "resetting env. episode 2147.000000, reward total was -20.000000. running mean: -20.564427\n",
            "resetting env. episode 2148.000000, reward total was -21.000000. running mean: -20.568782\n",
            "resetting env. episode 2149.000000, reward total was -19.000000. running mean: -20.553094\n",
            "resetting env. episode 2150.000000, reward total was -20.000000. running mean: -20.547564\n",
            "resetting env. episode 2151.000000, reward total was -21.000000. running mean: -20.552088\n",
            "resetting env. episode 2152.000000, reward total was -18.000000. running mean: -20.526567\n",
            "resetting env. episode 2153.000000, reward total was -20.000000. running mean: -20.521301\n",
            "resetting env. episode 2154.000000, reward total was -21.000000. running mean: -20.526088\n",
            "resetting env. episode 2155.000000, reward total was -20.000000. running mean: -20.520827\n",
            "resetting env. episode 2156.000000, reward total was -21.000000. running mean: -20.525619\n",
            "resetting env. episode 2157.000000, reward total was -20.000000. running mean: -20.520363\n",
            "resetting env. episode 2158.000000, reward total was -20.000000. running mean: -20.515159\n",
            "resetting env. episode 2159.000000, reward total was -20.000000. running mean: -20.510008\n",
            "resetting env. episode 2160.000000, reward total was -21.000000. running mean: -20.514908\n",
            "resetting env. episode 2161.000000, reward total was -21.000000. running mean: -20.519759\n",
            "resetting env. episode 2162.000000, reward total was -21.000000. running mean: -20.524561\n",
            "resetting env. episode 2163.000000, reward total was -20.000000. running mean: -20.519315\n",
            "resetting env. episode 2164.000000, reward total was -21.000000. running mean: -20.524122\n",
            "resetting env. episode 2165.000000, reward total was -21.000000. running mean: -20.528881\n",
            "resetting env. episode 2166.000000, reward total was -20.000000. running mean: -20.523592\n",
            "resetting env. episode 2167.000000, reward total was -20.000000. running mean: -20.518356\n",
            "resetting env. episode 2168.000000, reward total was -21.000000. running mean: -20.523173\n",
            "resetting env. episode 2169.000000, reward total was -21.000000. running mean: -20.527941\n",
            "resetting env. episode 2170.000000, reward total was -20.000000. running mean: -20.522662\n",
            "resetting env. episode 2171.000000, reward total was -20.000000. running mean: -20.517435\n",
            "resetting env. episode 2172.000000, reward total was -21.000000. running mean: -20.522261\n",
            "resetting env. episode 2173.000000, reward total was -21.000000. running mean: -20.527038\n",
            "resetting env. episode 2174.000000, reward total was -21.000000. running mean: -20.531768\n",
            "resetting env. episode 2175.000000, reward total was -20.000000. running mean: -20.526450\n",
            "resetting env. episode 2176.000000, reward total was -19.000000. running mean: -20.511185\n",
            "resetting env. episode 2177.000000, reward total was -20.000000. running mean: -20.506074\n",
            "resetting env. episode 2178.000000, reward total was -20.000000. running mean: -20.501013\n",
            "resetting env. episode 2179.000000, reward total was -21.000000. running mean: -20.506003\n",
            "resetting env. episode 2180.000000, reward total was -19.000000. running mean: -20.490943\n",
            "resetting env. episode 2181.000000, reward total was -20.000000. running mean: -20.486033\n",
            "resetting env. episode 2182.000000, reward total was -21.000000. running mean: -20.491173\n",
            "resetting env. episode 2183.000000, reward total was -21.000000. running mean: -20.496261\n",
            "resetting env. episode 2184.000000, reward total was -21.000000. running mean: -20.501299\n",
            "resetting env. episode 2185.000000, reward total was -21.000000. running mean: -20.506286\n",
            "resetting env. episode 2186.000000, reward total was -20.000000. running mean: -20.501223\n",
            "resetting env. episode 2187.000000, reward total was -21.000000. running mean: -20.506211\n",
            "resetting env. episode 2188.000000, reward total was -21.000000. running mean: -20.511148\n",
            "resetting env. episode 2189.000000, reward total was -21.000000. running mean: -20.516037\n",
            "resetting env. episode 2190.000000, reward total was -21.000000. running mean: -20.520877\n",
            "resetting env. episode 2191.000000, reward total was -21.000000. running mean: -20.525668\n",
            "resetting env. episode 2192.000000, reward total was -21.000000. running mean: -20.530411\n",
            "resetting env. episode 2193.000000, reward total was -21.000000. running mean: -20.535107\n",
            "resetting env. episode 2194.000000, reward total was -19.000000. running mean: -20.519756\n",
            "resetting env. episode 2195.000000, reward total was -21.000000. running mean: -20.524558\n",
            "resetting env. episode 2196.000000, reward total was -21.000000. running mean: -20.529313\n",
            "resetting env. episode 2197.000000, reward total was -21.000000. running mean: -20.534020\n",
            "resetting env. episode 2198.000000, reward total was -20.000000. running mean: -20.528680\n",
            "resetting env. episode 2199.000000, reward total was -21.000000. running mean: -20.533393\n",
            "resetting env. episode 2200.000000, reward total was -20.000000. running mean: -20.528059\n",
            "resetting env. episode 2201.000000, reward total was -21.000000. running mean: -20.532778\n",
            "resetting env. episode 2202.000000, reward total was -21.000000. running mean: -20.537450\n",
            "resetting env. episode 2203.000000, reward total was -21.000000. running mean: -20.542076\n",
            "resetting env. episode 2204.000000, reward total was -20.000000. running mean: -20.536655\n",
            "resetting env. episode 2205.000000, reward total was -21.000000. running mean: -20.541289\n",
            "resetting env. episode 2206.000000, reward total was -20.000000. running mean: -20.535876\n",
            "resetting env. episode 2207.000000, reward total was -21.000000. running mean: -20.540517\n",
            "resetting env. episode 2208.000000, reward total was -21.000000. running mean: -20.545112\n",
            "resetting env. episode 2209.000000, reward total was -21.000000. running mean: -20.549661\n",
            "resetting env. episode 2210.000000, reward total was -21.000000. running mean: -20.554164\n",
            "resetting env. episode 2211.000000, reward total was -20.000000. running mean: -20.548622\n",
            "resetting env. episode 2212.000000, reward total was -19.000000. running mean: -20.533136\n",
            "resetting env. episode 2213.000000, reward total was -20.000000. running mean: -20.527805\n",
            "resetting env. episode 2214.000000, reward total was -21.000000. running mean: -20.532527\n",
            "resetting env. episode 2215.000000, reward total was -21.000000. running mean: -20.537202\n",
            "resetting env. episode 2216.000000, reward total was -21.000000. running mean: -20.541830\n",
            "resetting env. episode 2217.000000, reward total was -21.000000. running mean: -20.546411\n",
            "resetting env. episode 2218.000000, reward total was -21.000000. running mean: -20.550947\n",
            "resetting env. episode 2219.000000, reward total was -21.000000. running mean: -20.555438\n",
            "resetting env. episode 2220.000000, reward total was -21.000000. running mean: -20.559883\n",
            "resetting env. episode 2221.000000, reward total was -19.000000. running mean: -20.544284\n",
            "resetting env. episode 2222.000000, reward total was -20.000000. running mean: -20.538842\n",
            "resetting env. episode 2223.000000, reward total was -21.000000. running mean: -20.543453\n",
            "resetting env. episode 2224.000000, reward total was -17.000000. running mean: -20.508019\n",
            "resetting env. episode 2225.000000, reward total was -19.000000. running mean: -20.492938\n",
            "resetting env. episode 2226.000000, reward total was -21.000000. running mean: -20.498009\n",
            "resetting env. episode 2227.000000, reward total was -21.000000. running mean: -20.503029\n",
            "resetting env. episode 2228.000000, reward total was -17.000000. running mean: -20.467999\n",
            "resetting env. episode 2229.000000, reward total was -20.000000. running mean: -20.463319\n",
            "resetting env. episode 2230.000000, reward total was -21.000000. running mean: -20.468686\n",
            "resetting env. episode 2231.000000, reward total was -21.000000. running mean: -20.473999\n",
            "resetting env. episode 2232.000000, reward total was -20.000000. running mean: -20.469259\n",
            "resetting env. episode 2233.000000, reward total was -21.000000. running mean: -20.474566\n",
            "resetting env. episode 2234.000000, reward total was -21.000000. running mean: -20.479820\n",
            "resetting env. episode 2235.000000, reward total was -19.000000. running mean: -20.465022\n",
            "resetting env. episode 2236.000000, reward total was -20.000000. running mean: -20.460372\n",
            "resetting env. episode 2237.000000, reward total was -21.000000. running mean: -20.465768\n",
            "resetting env. episode 2238.000000, reward total was -18.000000. running mean: -20.441111\n",
            "resetting env. episode 2239.000000, reward total was -20.000000. running mean: -20.436699\n",
            "resetting env. episode 2240.000000, reward total was -21.000000. running mean: -20.442332\n",
            "resetting env. episode 2241.000000, reward total was -21.000000. running mean: -20.447909\n",
            "resetting env. episode 2242.000000, reward total was -21.000000. running mean: -20.453430\n",
            "resetting env. episode 2243.000000, reward total was -21.000000. running mean: -20.458896\n",
            "resetting env. episode 2244.000000, reward total was -18.000000. running mean: -20.434307\n",
            "resetting env. episode 2245.000000, reward total was -21.000000. running mean: -20.439964\n",
            "resetting env. episode 2246.000000, reward total was -21.000000. running mean: -20.445564\n",
            "resetting env. episode 2247.000000, reward total was -20.000000. running mean: -20.441108\n",
            "resetting env. episode 2248.000000, reward total was -19.000000. running mean: -20.426697\n",
            "resetting env. episode 2249.000000, reward total was -21.000000. running mean: -20.432430\n",
            "resetting env. episode 2250.000000, reward total was -20.000000. running mean: -20.428106\n",
            "resetting env. episode 2251.000000, reward total was -18.000000. running mean: -20.403825\n",
            "resetting env. episode 2252.000000, reward total was -21.000000. running mean: -20.409787\n",
            "resetting env. episode 2253.000000, reward total was -21.000000. running mean: -20.415689\n",
            "resetting env. episode 2254.000000, reward total was -21.000000. running mean: -20.421532\n",
            "resetting env. episode 2255.000000, reward total was -21.000000. running mean: -20.427317\n",
            "resetting env. episode 2256.000000, reward total was -21.000000. running mean: -20.433044\n",
            "resetting env. episode 2257.000000, reward total was -21.000000. running mean: -20.438713\n",
            "resetting env. episode 2258.000000, reward total was -19.000000. running mean: -20.424326\n",
            "resetting env. episode 2259.000000, reward total was -20.000000. running mean: -20.420083\n",
            "resetting env. episode 2260.000000, reward total was -18.000000. running mean: -20.395882\n",
            "resetting env. episode 2261.000000, reward total was -21.000000. running mean: -20.401923\n",
            "resetting env. episode 2262.000000, reward total was -21.000000. running mean: -20.407904\n",
            "resetting env. episode 2263.000000, reward total was -21.000000. running mean: -20.413825\n",
            "resetting env. episode 2264.000000, reward total was -21.000000. running mean: -20.419687\n",
            "resetting env. episode 2265.000000, reward total was -21.000000. running mean: -20.425490\n",
            "resetting env. episode 2266.000000, reward total was -20.000000. running mean: -20.421235\n",
            "resetting env. episode 2267.000000, reward total was -21.000000. running mean: -20.427022\n",
            "resetting env. episode 2268.000000, reward total was -20.000000. running mean: -20.422752\n",
            "resetting env. episode 2269.000000, reward total was -21.000000. running mean: -20.428525\n",
            "resetting env. episode 2270.000000, reward total was -21.000000. running mean: -20.434239\n",
            "resetting env. episode 2271.000000, reward total was -18.000000. running mean: -20.409897\n",
            "resetting env. episode 2272.000000, reward total was -20.000000. running mean: -20.405798\n",
            "resetting env. episode 2273.000000, reward total was -21.000000. running mean: -20.411740\n",
            "resetting env. episode 2274.000000, reward total was -21.000000. running mean: -20.417623\n",
            "resetting env. episode 2275.000000, reward total was -21.000000. running mean: -20.423446\n",
            "resetting env. episode 2276.000000, reward total was -20.000000. running mean: -20.419212\n",
            "resetting env. episode 2277.000000, reward total was -21.000000. running mean: -20.425020\n",
            "resetting env. episode 2278.000000, reward total was -20.000000. running mean: -20.420770\n",
            "resetting env. episode 2279.000000, reward total was -21.000000. running mean: -20.426562\n",
            "resetting env. episode 2280.000000, reward total was -21.000000. running mean: -20.432296\n",
            "resetting env. episode 2281.000000, reward total was -20.000000. running mean: -20.427973\n",
            "resetting env. episode 2282.000000, reward total was -20.000000. running mean: -20.423694\n",
            "resetting env. episode 2283.000000, reward total was -19.000000. running mean: -20.409457\n",
            "resetting env. episode 2284.000000, reward total was -19.000000. running mean: -20.395362\n",
            "resetting env. episode 2285.000000, reward total was -21.000000. running mean: -20.401409\n",
            "resetting env. episode 2286.000000, reward total was -20.000000. running mean: -20.397394\n",
            "resetting env. episode 2287.000000, reward total was -20.000000. running mean: -20.393421\n",
            "resetting env. episode 2288.000000, reward total was -21.000000. running mean: -20.399486\n",
            "resetting env. episode 2289.000000, reward total was -21.000000. running mean: -20.405491\n",
            "resetting env. episode 2290.000000, reward total was -21.000000. running mean: -20.411437\n",
            "resetting env. episode 2291.000000, reward total was -20.000000. running mean: -20.407322\n",
            "resetting env. episode 2292.000000, reward total was -21.000000. running mean: -20.413249\n",
            "resetting env. episode 2293.000000, reward total was -21.000000. running mean: -20.419116\n",
            "resetting env. episode 2294.000000, reward total was -20.000000. running mean: -20.414925\n",
            "resetting env. episode 2295.000000, reward total was -20.000000. running mean: -20.410776\n",
            "resetting env. episode 2296.000000, reward total was -20.000000. running mean: -20.406668\n",
            "resetting env. episode 2297.000000, reward total was -20.000000. running mean: -20.402602\n",
            "resetting env. episode 2298.000000, reward total was -20.000000. running mean: -20.398576\n",
            "resetting env. episode 2299.000000, reward total was -20.000000. running mean: -20.394590\n",
            "resetting env. episode 2300.000000, reward total was -20.000000. running mean: -20.390644\n",
            "resetting env. episode 2301.000000, reward total was -21.000000. running mean: -20.396737\n",
            "resetting env. episode 2302.000000, reward total was -20.000000. running mean: -20.392770\n",
            "resetting env. episode 2303.000000, reward total was -20.000000. running mean: -20.388842\n",
            "resetting env. episode 2304.000000, reward total was -20.000000. running mean: -20.384954\n",
            "resetting env. episode 2305.000000, reward total was -21.000000. running mean: -20.391104\n",
            "resetting env. episode 2306.000000, reward total was -19.000000. running mean: -20.377193\n",
            "resetting env. episode 2307.000000, reward total was -18.000000. running mean: -20.353421\n",
            "resetting env. episode 2308.000000, reward total was -21.000000. running mean: -20.359887\n",
            "resetting env. episode 2309.000000, reward total was -21.000000. running mean: -20.366288\n",
            "resetting env. episode 2310.000000, reward total was -21.000000. running mean: -20.372626\n",
            "resetting env. episode 2311.000000, reward total was -21.000000. running mean: -20.378899\n",
            "resetting env. episode 2312.000000, reward total was -21.000000. running mean: -20.385110\n",
            "resetting env. episode 2313.000000, reward total was -20.000000. running mean: -20.381259\n",
            "resetting env. episode 2314.000000, reward total was -20.000000. running mean: -20.377447\n",
            "resetting env. episode 2315.000000, reward total was -21.000000. running mean: -20.383672\n",
            "resetting env. episode 2316.000000, reward total was -21.000000. running mean: -20.389835\n",
            "resetting env. episode 2317.000000, reward total was -21.000000. running mean: -20.395937\n",
            "resetting env. episode 2318.000000, reward total was -21.000000. running mean: -20.401978\n",
            "resetting env. episode 2319.000000, reward total was -20.000000. running mean: -20.397958\n",
            "resetting env. episode 2320.000000, reward total was -21.000000. running mean: -20.403978\n",
            "resetting env. episode 2321.000000, reward total was -21.000000. running mean: -20.409939\n",
            "resetting env. episode 2322.000000, reward total was -21.000000. running mean: -20.415839\n",
            "resetting env. episode 2323.000000, reward total was -21.000000. running mean: -20.421681\n",
            "resetting env. episode 2324.000000, reward total was -20.000000. running mean: -20.417464\n",
            "resetting env. episode 2325.000000, reward total was -21.000000. running mean: -20.423289\n",
            "resetting env. episode 2326.000000, reward total was -21.000000. running mean: -20.429056\n",
            "resetting env. episode 2327.000000, reward total was -21.000000. running mean: -20.434766\n",
            "resetting env. episode 2328.000000, reward total was -20.000000. running mean: -20.430418\n",
            "resetting env. episode 2329.000000, reward total was -20.000000. running mean: -20.426114\n",
            "resetting env. episode 2330.000000, reward total was -21.000000. running mean: -20.431853\n",
            "resetting env. episode 2331.000000, reward total was -21.000000. running mean: -20.437534\n",
            "resetting env. episode 2332.000000, reward total was -21.000000. running mean: -20.443159\n",
            "resetting env. episode 2333.000000, reward total was -21.000000. running mean: -20.448727\n",
            "resetting env. episode 2334.000000, reward total was -20.000000. running mean: -20.444240\n",
            "resetting env. episode 2335.000000, reward total was -20.000000. running mean: -20.439798\n",
            "resetting env. episode 2336.000000, reward total was -21.000000. running mean: -20.445400\n",
            "resetting env. episode 2337.000000, reward total was -19.000000. running mean: -20.430946\n",
            "resetting env. episode 2338.000000, reward total was -21.000000. running mean: -20.436636\n",
            "resetting env. episode 2339.000000, reward total was -18.000000. running mean: -20.412270\n",
            "resetting env. episode 2340.000000, reward total was -20.000000. running mean: -20.408147\n",
            "resetting env. episode 2341.000000, reward total was -21.000000. running mean: -20.414066\n",
            "resetting env. episode 2342.000000, reward total was -21.000000. running mean: -20.419925\n",
            "resetting env. episode 2343.000000, reward total was -20.000000. running mean: -20.415726\n",
            "resetting env. episode 2344.000000, reward total was -21.000000. running mean: -20.421569\n",
            "resetting env. episode 2345.000000, reward total was -20.000000. running mean: -20.417353\n",
            "resetting env. episode 2346.000000, reward total was -21.000000. running mean: -20.423179\n",
            "resetting env. episode 2347.000000, reward total was -18.000000. running mean: -20.398948\n",
            "resetting env. episode 2348.000000, reward total was -21.000000. running mean: -20.404958\n",
            "resetting env. episode 2349.000000, reward total was -20.000000. running mean: -20.400909\n",
            "resetting env. episode 2350.000000, reward total was -21.000000. running mean: -20.406899\n",
            "resetting env. episode 2351.000000, reward total was -20.000000. running mean: -20.402830\n",
            "resetting env. episode 2352.000000, reward total was -21.000000. running mean: -20.408802\n",
            "resetting env. episode 2353.000000, reward total was -18.000000. running mean: -20.384714\n",
            "resetting env. episode 2354.000000, reward total was -20.000000. running mean: -20.380867\n",
            "resetting env. episode 2355.000000, reward total was -21.000000. running mean: -20.387058\n",
            "resetting env. episode 2356.000000, reward total was -19.000000. running mean: -20.373188\n",
            "resetting env. episode 2357.000000, reward total was -21.000000. running mean: -20.379456\n",
            "resetting env. episode 2358.000000, reward total was -21.000000. running mean: -20.385661\n",
            "resetting env. episode 2359.000000, reward total was -20.000000. running mean: -20.381805\n",
            "resetting env. episode 2360.000000, reward total was -19.000000. running mean: -20.367987\n",
            "resetting env. episode 2361.000000, reward total was -21.000000. running mean: -20.374307\n",
            "resetting env. episode 2362.000000, reward total was -21.000000. running mean: -20.380564\n",
            "resetting env. episode 2363.000000, reward total was -18.000000. running mean: -20.356758\n",
            "resetting env. episode 2364.000000, reward total was -21.000000. running mean: -20.363190\n",
            "resetting env. episode 2365.000000, reward total was -21.000000. running mean: -20.369559\n",
            "resetting env. episode 2366.000000, reward total was -19.000000. running mean: -20.355863\n",
            "resetting env. episode 2367.000000, reward total was -21.000000. running mean: -20.362304\n",
            "resetting env. episode 2368.000000, reward total was -21.000000. running mean: -20.368681\n",
            "resetting env. episode 2369.000000, reward total was -20.000000. running mean: -20.364994\n",
            "resetting env. episode 2370.000000, reward total was -21.000000. running mean: -20.371345\n",
            "resetting env. episode 2371.000000, reward total was -20.000000. running mean: -20.367631\n",
            "resetting env. episode 2372.000000, reward total was -21.000000. running mean: -20.373955\n",
            "resetting env. episode 2373.000000, reward total was -20.000000. running mean: -20.370215\n",
            "resetting env. episode 2374.000000, reward total was -20.000000. running mean: -20.366513\n",
            "resetting env. episode 2375.000000, reward total was -21.000000. running mean: -20.372848\n",
            "resetting env. episode 2376.000000, reward total was -21.000000. running mean: -20.379119\n",
            "resetting env. episode 2377.000000, reward total was -20.000000. running mean: -20.375328\n",
            "resetting env. episode 2378.000000, reward total was -20.000000. running mean: -20.371575\n",
            "resetting env. episode 2379.000000, reward total was -21.000000. running mean: -20.377859\n",
            "resetting env. episode 2380.000000, reward total was -21.000000. running mean: -20.384081\n",
            "resetting env. episode 2381.000000, reward total was -21.000000. running mean: -20.390240\n",
            "resetting env. episode 2382.000000, reward total was -21.000000. running mean: -20.396337\n",
            "resetting env. episode 2383.000000, reward total was -20.000000. running mean: -20.392374\n",
            "resetting env. episode 2384.000000, reward total was -21.000000. running mean: -20.398450\n",
            "resetting env. episode 2385.000000, reward total was -21.000000. running mean: -20.404466\n",
            "resetting env. episode 2386.000000, reward total was -20.000000. running mean: -20.400421\n",
            "resetting env. episode 2387.000000, reward total was -20.000000. running mean: -20.396417\n",
            "resetting env. episode 2388.000000, reward total was -20.000000. running mean: -20.392453\n",
            "resetting env. episode 2389.000000, reward total was -20.000000. running mean: -20.388528\n",
            "resetting env. episode 2390.000000, reward total was -21.000000. running mean: -20.394643\n",
            "resetting env. episode 2391.000000, reward total was -21.000000. running mean: -20.400697\n",
            "resetting env. episode 2392.000000, reward total was -21.000000. running mean: -20.406690\n",
            "resetting env. episode 2393.000000, reward total was -20.000000. running mean: -20.402623\n",
            "resetting env. episode 2394.000000, reward total was -20.000000. running mean: -20.398596\n",
            "resetting env. episode 2395.000000, reward total was -20.000000. running mean: -20.394611\n",
            "resetting env. episode 2396.000000, reward total was -21.000000. running mean: -20.400664\n",
            "resetting env. episode 2397.000000, reward total was -21.000000. running mean: -20.406658\n",
            "resetting env. episode 2398.000000, reward total was -21.000000. running mean: -20.412591\n",
            "resetting env. episode 2399.000000, reward total was -21.000000. running mean: -20.418465\n",
            "resetting env. episode 2400.000000, reward total was -20.000000. running mean: -20.414281\n",
            "resetting env. episode 2401.000000, reward total was -21.000000. running mean: -20.420138\n",
            "resetting env. episode 2402.000000, reward total was -21.000000. running mean: -20.425936\n",
            "resetting env. episode 2403.000000, reward total was -19.000000. running mean: -20.411677\n",
            "resetting env. episode 2404.000000, reward total was -21.000000. running mean: -20.417560\n",
            "resetting env. episode 2405.000000, reward total was -21.000000. running mean: -20.423385\n",
            "resetting env. episode 2406.000000, reward total was -21.000000. running mean: -20.429151\n",
            "resetting env. episode 2407.000000, reward total was -21.000000. running mean: -20.434859\n",
            "resetting env. episode 2408.000000, reward total was -20.000000. running mean: -20.430511\n",
            "resetting env. episode 2409.000000, reward total was -20.000000. running mean: -20.426206\n",
            "resetting env. episode 2410.000000, reward total was -21.000000. running mean: -20.431944\n",
            "resetting env. episode 2411.000000, reward total was -21.000000. running mean: -20.437624\n",
            "resetting env. episode 2412.000000, reward total was -21.000000. running mean: -20.443248\n",
            "resetting env. episode 2413.000000, reward total was -21.000000. running mean: -20.448815\n",
            "resetting env. episode 2414.000000, reward total was -21.000000. running mean: -20.454327\n",
            "resetting env. episode 2415.000000, reward total was -21.000000. running mean: -20.459784\n",
            "resetting env. episode 2416.000000, reward total was -19.000000. running mean: -20.445186\n",
            "resetting env. episode 2417.000000, reward total was -21.000000. running mean: -20.450734\n",
            "resetting env. episode 2418.000000, reward total was -20.000000. running mean: -20.446227\n",
            "resetting env. episode 2419.000000, reward total was -19.000000. running mean: -20.431765\n",
            "resetting env. episode 2420.000000, reward total was -18.000000. running mean: -20.407447\n",
            "resetting env. episode 2421.000000, reward total was -19.000000. running mean: -20.393373\n",
            "resetting env. episode 2422.000000, reward total was -20.000000. running mean: -20.389439\n",
            "resetting env. episode 2423.000000, reward total was -21.000000. running mean: -20.395544\n",
            "resetting env. episode 2424.000000, reward total was -21.000000. running mean: -20.401589\n",
            "resetting env. episode 2425.000000, reward total was -21.000000. running mean: -20.407573\n",
            "resetting env. episode 2426.000000, reward total was -21.000000. running mean: -20.413497\n",
            "resetting env. episode 2427.000000, reward total was -21.000000. running mean: -20.419362\n",
            "resetting env. episode 2428.000000, reward total was -21.000000. running mean: -20.425169\n",
            "resetting env. episode 2429.000000, reward total was -21.000000. running mean: -20.430917\n",
            "resetting env. episode 2430.000000, reward total was -21.000000. running mean: -20.436608\n",
            "resetting env. episode 2431.000000, reward total was -20.000000. running mean: -20.432242\n",
            "resetting env. episode 2432.000000, reward total was -21.000000. running mean: -20.437919\n",
            "resetting env. episode 2433.000000, reward total was -19.000000. running mean: -20.423540\n",
            "resetting env. episode 2434.000000, reward total was -20.000000. running mean: -20.419305\n",
            "resetting env. episode 2435.000000, reward total was -21.000000. running mean: -20.425112\n",
            "resetting env. episode 2436.000000, reward total was -18.000000. running mean: -20.400861\n",
            "resetting env. episode 2437.000000, reward total was -21.000000. running mean: -20.406852\n",
            "resetting env. episode 2438.000000, reward total was -19.000000. running mean: -20.392784\n",
            "resetting env. episode 2439.000000, reward total was -19.000000. running mean: -20.378856\n",
            "resetting env. episode 2440.000000, reward total was -21.000000. running mean: -20.385067\n",
            "resetting env. episode 2441.000000, reward total was -21.000000. running mean: -20.391216\n",
            "resetting env. episode 2442.000000, reward total was -20.000000. running mean: -20.387304\n",
            "resetting env. episode 2443.000000, reward total was -21.000000. running mean: -20.393431\n",
            "resetting env. episode 2444.000000, reward total was -19.000000. running mean: -20.379497\n",
            "resetting env. episode 2445.000000, reward total was -20.000000. running mean: -20.375702\n",
            "resetting env. episode 2446.000000, reward total was -21.000000. running mean: -20.381945\n",
            "resetting env. episode 2447.000000, reward total was -21.000000. running mean: -20.388126\n",
            "resetting env. episode 2448.000000, reward total was -21.000000. running mean: -20.394244\n",
            "resetting env. episode 2449.000000, reward total was -21.000000. running mean: -20.400302\n",
            "resetting env. episode 2450.000000, reward total was -21.000000. running mean: -20.406299\n",
            "resetting env. episode 2451.000000, reward total was -21.000000. running mean: -20.412236\n",
            "resetting env. episode 2452.000000, reward total was -21.000000. running mean: -20.418113\n",
            "resetting env. episode 2453.000000, reward total was -21.000000. running mean: -20.423932\n",
            "resetting env. episode 2454.000000, reward total was -21.000000. running mean: -20.429693\n",
            "resetting env. episode 2455.000000, reward total was -21.000000. running mean: -20.435396\n",
            "resetting env. episode 2456.000000, reward total was -21.000000. running mean: -20.441042\n",
            "resetting env. episode 2457.000000, reward total was -21.000000. running mean: -20.446632\n",
            "resetting env. episode 2458.000000, reward total was -21.000000. running mean: -20.452165\n",
            "resetting env. episode 2459.000000, reward total was -21.000000. running mean: -20.457644\n",
            "resetting env. episode 2460.000000, reward total was -20.000000. running mean: -20.453067\n",
            "resetting env. episode 2461.000000, reward total was -20.000000. running mean: -20.448537\n",
            "resetting env. episode 2462.000000, reward total was -21.000000. running mean: -20.454051\n",
            "resetting env. episode 2463.000000, reward total was -20.000000. running mean: -20.449511\n",
            "resetting env. episode 2464.000000, reward total was -20.000000. running mean: -20.445016\n",
            "resetting env. episode 2465.000000, reward total was -21.000000. running mean: -20.450565\n",
            "resetting env. episode 2466.000000, reward total was -17.000000. running mean: -20.416060\n",
            "resetting env. episode 2467.000000, reward total was -20.000000. running mean: -20.411899\n",
            "resetting env. episode 2468.000000, reward total was -19.000000. running mean: -20.397780\n",
            "resetting env. episode 2469.000000, reward total was -21.000000. running mean: -20.403802\n",
            "resetting env. episode 2470.000000, reward total was -21.000000. running mean: -20.409764\n",
            "resetting env. episode 2471.000000, reward total was -20.000000. running mean: -20.405667\n",
            "resetting env. episode 2472.000000, reward total was -21.000000. running mean: -20.411610\n",
            "resetting env. episode 2473.000000, reward total was -21.000000. running mean: -20.417494\n",
            "resetting env. episode 2474.000000, reward total was -20.000000. running mean: -20.413319\n",
            "resetting env. episode 2475.000000, reward total was -18.000000. running mean: -20.389186\n",
            "resetting env. episode 2476.000000, reward total was -21.000000. running mean: -20.395294\n",
            "resetting env. episode 2477.000000, reward total was -21.000000. running mean: -20.401341\n",
            "resetting env. episode 2478.000000, reward total was -21.000000. running mean: -20.407328\n",
            "resetting env. episode 2479.000000, reward total was -18.000000. running mean: -20.383254\n",
            "resetting env. episode 2480.000000, reward total was -21.000000. running mean: -20.389422\n",
            "resetting env. episode 2481.000000, reward total was -21.000000. running mean: -20.395528\n",
            "resetting env. episode 2482.000000, reward total was -20.000000. running mean: -20.391572\n",
            "resetting env. episode 2483.000000, reward total was -20.000000. running mean: -20.387657\n",
            "resetting env. episode 2484.000000, reward total was -21.000000. running mean: -20.393780\n",
            "resetting env. episode 2485.000000, reward total was -19.000000. running mean: -20.379842\n",
            "resetting env. episode 2486.000000, reward total was -19.000000. running mean: -20.366044\n",
            "resetting env. episode 2487.000000, reward total was -21.000000. running mean: -20.372383\n",
            "resetting env. episode 2488.000000, reward total was -20.000000. running mean: -20.368660\n",
            "resetting env. episode 2489.000000, reward total was -21.000000. running mean: -20.374973\n",
            "resetting env. episode 2490.000000, reward total was -21.000000. running mean: -20.381223\n",
            "resetting env. episode 2491.000000, reward total was -21.000000. running mean: -20.387411\n",
            "resetting env. episode 2492.000000, reward total was -19.000000. running mean: -20.373537\n",
            "resetting env. episode 2493.000000, reward total was -20.000000. running mean: -20.369802\n",
            "resetting env. episode 2494.000000, reward total was -21.000000. running mean: -20.376103\n",
            "resetting env. episode 2495.000000, reward total was -21.000000. running mean: -20.382342\n",
            "resetting env. episode 2496.000000, reward total was -19.000000. running mean: -20.368519\n",
            "resetting env. episode 2497.000000, reward total was -20.000000. running mean: -20.364834\n",
            "resetting env. episode 2498.000000, reward total was -21.000000. running mean: -20.371186\n",
            "resetting env. episode 2499.000000, reward total was -21.000000. running mean: -20.377474\n",
            "resetting env. episode 2500.000000, reward total was -21.000000. running mean: -20.383699\n",
            "resetting env. episode 2501.000000, reward total was -20.000000. running mean: -20.379862\n",
            "resetting env. episode 2502.000000, reward total was -20.000000. running mean: -20.376063\n",
            "resetting env. episode 2503.000000, reward total was -21.000000. running mean: -20.382303\n",
            "resetting env. episode 2504.000000, reward total was -20.000000. running mean: -20.378480\n",
            "resetting env. episode 2505.000000, reward total was -21.000000. running mean: -20.384695\n",
            "resetting env. episode 2506.000000, reward total was -20.000000. running mean: -20.380848\n",
            "resetting env. episode 2507.000000, reward total was -21.000000. running mean: -20.387039\n",
            "resetting env. episode 2508.000000, reward total was -21.000000. running mean: -20.393169\n",
            "resetting env. episode 2509.000000, reward total was -21.000000. running mean: -20.399237\n",
            "resetting env. episode 2510.000000, reward total was -21.000000. running mean: -20.405245\n",
            "resetting env. episode 2511.000000, reward total was -21.000000. running mean: -20.411193\n",
            "resetting env. episode 2512.000000, reward total was -20.000000. running mean: -20.407081\n",
            "resetting env. episode 2513.000000, reward total was -21.000000. running mean: -20.413010\n",
            "resetting env. episode 2514.000000, reward total was -21.000000. running mean: -20.418880\n",
            "resetting env. episode 2515.000000, reward total was -21.000000. running mean: -20.424691\n",
            "resetting env. episode 2516.000000, reward total was -20.000000. running mean: -20.420444\n",
            "resetting env. episode 2517.000000, reward total was -21.000000. running mean: -20.426240\n",
            "resetting env. episode 2518.000000, reward total was -21.000000. running mean: -20.431977\n",
            "resetting env. episode 2519.000000, reward total was -21.000000. running mean: -20.437657\n",
            "resetting env. episode 2520.000000, reward total was -21.000000. running mean: -20.443281\n",
            "resetting env. episode 2521.000000, reward total was -21.000000. running mean: -20.448848\n",
            "resetting env. episode 2522.000000, reward total was -21.000000. running mean: -20.454360\n",
            "resetting env. episode 2523.000000, reward total was -20.000000. running mean: -20.449816\n",
            "resetting env. episode 2524.000000, reward total was -19.000000. running mean: -20.435318\n",
            "resetting env. episode 2525.000000, reward total was -20.000000. running mean: -20.430965\n",
            "resetting env. episode 2526.000000, reward total was -21.000000. running mean: -20.436655\n",
            "resetting env. episode 2527.000000, reward total was -21.000000. running mean: -20.442288\n",
            "resetting env. episode 2528.000000, reward total was -20.000000. running mean: -20.437865\n",
            "resetting env. episode 2529.000000, reward total was -20.000000. running mean: -20.433487\n",
            "resetting env. episode 2530.000000, reward total was -21.000000. running mean: -20.439152\n",
            "resetting env. episode 2531.000000, reward total was -21.000000. running mean: -20.444760\n",
            "resetting env. episode 2532.000000, reward total was -21.000000. running mean: -20.450313\n",
            "resetting env. episode 2533.000000, reward total was -20.000000. running mean: -20.445810\n",
            "resetting env. episode 2534.000000, reward total was -19.000000. running mean: -20.431352\n",
            "resetting env. episode 2535.000000, reward total was -21.000000. running mean: -20.437038\n",
            "resetting env. episode 2536.000000, reward total was -21.000000. running mean: -20.442668\n",
            "resetting env. episode 2537.000000, reward total was -21.000000. running mean: -20.448241\n",
            "resetting env. episode 2538.000000, reward total was -20.000000. running mean: -20.443759\n",
            "resetting env. episode 2539.000000, reward total was -18.000000. running mean: -20.419321\n",
            "resetting env. episode 2540.000000, reward total was -21.000000. running mean: -20.425128\n",
            "resetting env. episode 2541.000000, reward total was -21.000000. running mean: -20.430877\n",
            "resetting env. episode 2542.000000, reward total was -21.000000. running mean: -20.436568\n",
            "resetting env. episode 2543.000000, reward total was -21.000000. running mean: -20.442202\n",
            "resetting env. episode 2544.000000, reward total was -21.000000. running mean: -20.447780\n",
            "resetting env. episode 2545.000000, reward total was -21.000000. running mean: -20.453302\n",
            "resetting env. episode 2546.000000, reward total was -20.000000. running mean: -20.448769\n",
            "resetting env. episode 2547.000000, reward total was -21.000000. running mean: -20.454282\n",
            "resetting env. episode 2548.000000, reward total was -21.000000. running mean: -20.459739\n",
            "resetting env. episode 2549.000000, reward total was -19.000000. running mean: -20.445141\n",
            "resetting env. episode 2550.000000, reward total was -21.000000. running mean: -20.450690\n",
            "resetting env. episode 2551.000000, reward total was -21.000000. running mean: -20.456183\n",
            "resetting env. episode 2552.000000, reward total was -21.000000. running mean: -20.461621\n",
            "resetting env. episode 2553.000000, reward total was -20.000000. running mean: -20.457005\n",
            "resetting env. episode 2554.000000, reward total was -21.000000. running mean: -20.462435\n",
            "resetting env. episode 2555.000000, reward total was -20.000000. running mean: -20.457811\n",
            "resetting env. episode 2556.000000, reward total was -21.000000. running mean: -20.463233\n",
            "resetting env. episode 2557.000000, reward total was -19.000000. running mean: -20.448600\n",
            "resetting env. episode 2558.000000, reward total was -21.000000. running mean: -20.454114\n",
            "resetting env. episode 2559.000000, reward total was -21.000000. running mean: -20.459573\n",
            "resetting env. episode 2560.000000, reward total was -20.000000. running mean: -20.454977\n",
            "resetting env. episode 2561.000000, reward total was -21.000000. running mean: -20.460428\n",
            "resetting env. episode 2562.000000, reward total was -21.000000. running mean: -20.465823\n",
            "resetting env. episode 2563.000000, reward total was -20.000000. running mean: -20.461165\n",
            "resetting env. episode 2564.000000, reward total was -21.000000. running mean: -20.466553\n",
            "resetting env. episode 2565.000000, reward total was -19.000000. running mean: -20.451888\n",
            "resetting env. episode 2566.000000, reward total was -20.000000. running mean: -20.447369\n",
            "resetting env. episode 2567.000000, reward total was -20.000000. running mean: -20.442895\n",
            "resetting env. episode 2568.000000, reward total was -19.000000. running mean: -20.428466\n",
            "resetting env. episode 2569.000000, reward total was -21.000000. running mean: -20.434182\n",
            "resetting env. episode 2570.000000, reward total was -21.000000. running mean: -20.439840\n",
            "resetting env. episode 2571.000000, reward total was -21.000000. running mean: -20.445441\n",
            "resetting env. episode 2572.000000, reward total was -21.000000. running mean: -20.450987\n",
            "resetting env. episode 2573.000000, reward total was -19.000000. running mean: -20.436477\n",
            "resetting env. episode 2574.000000, reward total was -21.000000. running mean: -20.442112\n",
            "resetting env. episode 2575.000000, reward total was -21.000000. running mean: -20.447691\n",
            "resetting env. episode 2576.000000, reward total was -21.000000. running mean: -20.453214\n",
            "resetting env. episode 2577.000000, reward total was -21.000000. running mean: -20.458682\n",
            "resetting env. episode 2578.000000, reward total was -19.000000. running mean: -20.444095\n",
            "resetting env. episode 2579.000000, reward total was -20.000000. running mean: -20.439654\n",
            "resetting env. episode 2580.000000, reward total was -20.000000. running mean: -20.435258\n",
            "resetting env. episode 2581.000000, reward total was -20.000000. running mean: -20.430905\n",
            "resetting env. episode 2582.000000, reward total was -19.000000. running mean: -20.416596\n",
            "resetting env. episode 2583.000000, reward total was -21.000000. running mean: -20.422430\n",
            "resetting env. episode 2584.000000, reward total was -21.000000. running mean: -20.428206\n",
            "resetting env. episode 2585.000000, reward total was -21.000000. running mean: -20.433924\n",
            "resetting env. episode 2586.000000, reward total was -21.000000. running mean: -20.439585\n",
            "resetting env. episode 2587.000000, reward total was -21.000000. running mean: -20.445189\n",
            "resetting env. episode 2588.000000, reward total was -20.000000. running mean: -20.440737\n",
            "resetting env. episode 2589.000000, reward total was -21.000000. running mean: -20.446330\n",
            "resetting env. episode 2590.000000, reward total was -21.000000. running mean: -20.451866\n",
            "resetting env. episode 2591.000000, reward total was -21.000000. running mean: -20.457348\n",
            "resetting env. episode 2592.000000, reward total was -20.000000. running mean: -20.452774\n",
            "resetting env. episode 2593.000000, reward total was -21.000000. running mean: -20.458246\n",
            "resetting env. episode 2594.000000, reward total was -20.000000. running mean: -20.453664\n",
            "resetting env. episode 2595.000000, reward total was -20.000000. running mean: -20.449127\n",
            "resetting env. episode 2596.000000, reward total was -21.000000. running mean: -20.454636\n",
            "resetting env. episode 2597.000000, reward total was -21.000000. running mean: -20.460090\n",
            "resetting env. episode 2598.000000, reward total was -21.000000. running mean: -20.465489\n",
            "resetting env. episode 2599.000000, reward total was -19.000000. running mean: -20.450834\n",
            "resetting env. episode 2600.000000, reward total was -21.000000. running mean: -20.456326\n",
            "resetting env. episode 2601.000000, reward total was -19.000000. running mean: -20.441762\n",
            "resetting env. episode 2602.000000, reward total was -21.000000. running mean: -20.447345\n",
            "resetting env. episode 2603.000000, reward total was -21.000000. running mean: -20.452871\n",
            "resetting env. episode 2604.000000, reward total was -19.000000. running mean: -20.438343\n",
            "resetting env. episode 2605.000000, reward total was -19.000000. running mean: -20.423959\n",
            "resetting env. episode 2606.000000, reward total was -20.000000. running mean: -20.419720\n",
            "resetting env. episode 2607.000000, reward total was -20.000000. running mean: -20.415522\n",
            "resetting env. episode 2608.000000, reward total was -21.000000. running mean: -20.421367\n",
            "resetting env. episode 2609.000000, reward total was -21.000000. running mean: -20.427153\n",
            "resetting env. episode 2610.000000, reward total was -21.000000. running mean: -20.432882\n",
            "resetting env. episode 2611.000000, reward total was -18.000000. running mean: -20.408553\n",
            "resetting env. episode 2612.000000, reward total was -21.000000. running mean: -20.414468\n",
            "resetting env. episode 2613.000000, reward total was -19.000000. running mean: -20.400323\n",
            "resetting env. episode 2614.000000, reward total was -19.000000. running mean: -20.386320\n",
            "resetting env. episode 2615.000000, reward total was -20.000000. running mean: -20.382456\n",
            "resetting env. episode 2616.000000, reward total was -20.000000. running mean: -20.378632\n",
            "resetting env. episode 2617.000000, reward total was -21.000000. running mean: -20.384846\n",
            "resetting env. episode 2618.000000, reward total was -21.000000. running mean: -20.390997\n",
            "resetting env. episode 2619.000000, reward total was -21.000000. running mean: -20.397087\n",
            "resetting env. episode 2620.000000, reward total was -21.000000. running mean: -20.403116\n",
            "resetting env. episode 2621.000000, reward total was -21.000000. running mean: -20.409085\n",
            "resetting env. episode 2622.000000, reward total was -21.000000. running mean: -20.414994\n",
            "resetting env. episode 2623.000000, reward total was -21.000000. running mean: -20.420844\n",
            "resetting env. episode 2624.000000, reward total was -20.000000. running mean: -20.416636\n",
            "resetting env. episode 2625.000000, reward total was -21.000000. running mean: -20.422469\n",
            "resetting env. episode 2626.000000, reward total was -21.000000. running mean: -20.428245\n",
            "resetting env. episode 2627.000000, reward total was -21.000000. running mean: -20.433962\n",
            "resetting env. episode 2628.000000, reward total was -21.000000. running mean: -20.439623\n",
            "resetting env. episode 2629.000000, reward total was -20.000000. running mean: -20.435226\n",
            "resetting env. episode 2630.000000, reward total was -21.000000. running mean: -20.440874\n",
            "resetting env. episode 2631.000000, reward total was -21.000000. running mean: -20.446465\n",
            "resetting env. episode 2632.000000, reward total was -20.000000. running mean: -20.442001\n",
            "resetting env. episode 2633.000000, reward total was -20.000000. running mean: -20.437581\n",
            "resetting env. episode 2634.000000, reward total was -21.000000. running mean: -20.443205\n",
            "resetting env. episode 2635.000000, reward total was -20.000000. running mean: -20.438773\n",
            "resetting env. episode 2636.000000, reward total was -21.000000. running mean: -20.444385\n",
            "resetting env. episode 2637.000000, reward total was -20.000000. running mean: -20.439941\n",
            "resetting env. episode 2638.000000, reward total was -21.000000. running mean: -20.445542\n",
            "resetting env. episode 2639.000000, reward total was -21.000000. running mean: -20.451087\n",
            "resetting env. episode 2640.000000, reward total was -20.000000. running mean: -20.446576\n",
            "resetting env. episode 2641.000000, reward total was -21.000000. running mean: -20.452110\n",
            "resetting env. episode 2642.000000, reward total was -20.000000. running mean: -20.447589\n",
            "resetting env. episode 2643.000000, reward total was -21.000000. running mean: -20.453113\n",
            "resetting env. episode 2644.000000, reward total was -20.000000. running mean: -20.448582\n",
            "resetting env. episode 2645.000000, reward total was -20.000000. running mean: -20.444096\n",
            "resetting env. episode 2646.000000, reward total was -21.000000. running mean: -20.449655\n",
            "resetting env. episode 2647.000000, reward total was -18.000000. running mean: -20.425158\n",
            "resetting env. episode 2648.000000, reward total was -21.000000. running mean: -20.430907\n",
            "resetting env. episode 2649.000000, reward total was -20.000000. running mean: -20.426598\n",
            "resetting env. episode 2650.000000, reward total was -21.000000. running mean: -20.432332\n",
            "resetting env. episode 2651.000000, reward total was -21.000000. running mean: -20.438009\n",
            "resetting env. episode 2652.000000, reward total was -21.000000. running mean: -20.443628\n",
            "resetting env. episode 2653.000000, reward total was -21.000000. running mean: -20.449192\n",
            "resetting env. episode 2654.000000, reward total was -19.000000. running mean: -20.434700\n",
            "resetting env. episode 2655.000000, reward total was -21.000000. running mean: -20.440353\n",
            "resetting env. episode 2656.000000, reward total was -20.000000. running mean: -20.435950\n",
            "resetting env. episode 2657.000000, reward total was -20.000000. running mean: -20.431590\n",
            "resetting env. episode 2658.000000, reward total was -20.000000. running mean: -20.427274\n",
            "resetting env. episode 2659.000000, reward total was -21.000000. running mean: -20.433002\n",
            "resetting env. episode 2660.000000, reward total was -21.000000. running mean: -20.438672\n",
            "resetting env. episode 2661.000000, reward total was -21.000000. running mean: -20.444285\n",
            "resetting env. episode 2662.000000, reward total was -21.000000. running mean: -20.449842\n",
            "resetting env. episode 2663.000000, reward total was -21.000000. running mean: -20.455344\n",
            "resetting env. episode 2664.000000, reward total was -21.000000. running mean: -20.460790\n",
            "resetting env. episode 2665.000000, reward total was -21.000000. running mean: -20.466182\n",
            "resetting env. episode 2666.000000, reward total was -20.000000. running mean: -20.461520\n",
            "resetting env. episode 2667.000000, reward total was -21.000000. running mean: -20.466905\n",
            "resetting env. episode 2668.000000, reward total was -21.000000. running mean: -20.472236\n",
            "resetting env. episode 2669.000000, reward total was -21.000000. running mean: -20.477514\n",
            "resetting env. episode 2670.000000, reward total was -20.000000. running mean: -20.472739\n",
            "resetting env. episode 2671.000000, reward total was -20.000000. running mean: -20.468011\n",
            "resetting env. episode 2672.000000, reward total was -21.000000. running mean: -20.473331\n",
            "resetting env. episode 2673.000000, reward total was -20.000000. running mean: -20.468598\n",
            "resetting env. episode 2674.000000, reward total was -21.000000. running mean: -20.473912\n",
            "resetting env. episode 2675.000000, reward total was -19.000000. running mean: -20.459173\n",
            "resetting env. episode 2676.000000, reward total was -21.000000. running mean: -20.464581\n",
            "resetting env. episode 2677.000000, reward total was -21.000000. running mean: -20.469935\n",
            "resetting env. episode 2678.000000, reward total was -21.000000. running mean: -20.475236\n",
            "resetting env. episode 2679.000000, reward total was -21.000000. running mean: -20.480483\n",
            "resetting env. episode 2680.000000, reward total was -21.000000. running mean: -20.485679\n",
            "resetting env. episode 2681.000000, reward total was -21.000000. running mean: -20.490822\n",
            "resetting env. episode 2682.000000, reward total was -20.000000. running mean: -20.485914\n",
            "resetting env. episode 2683.000000, reward total was -21.000000. running mean: -20.491055\n",
            "resetting env. episode 2684.000000, reward total was -21.000000. running mean: -20.496144\n",
            "resetting env. episode 2685.000000, reward total was -21.000000. running mean: -20.501183\n",
            "resetting env. episode 2686.000000, reward total was -21.000000. running mean: -20.506171\n",
            "resetting env. episode 2687.000000, reward total was -21.000000. running mean: -20.511109\n",
            "resetting env. episode 2688.000000, reward total was -21.000000. running mean: -20.515998\n",
            "resetting env. episode 2689.000000, reward total was -21.000000. running mean: -20.520838\n",
            "resetting env. episode 2690.000000, reward total was -21.000000. running mean: -20.525630\n",
            "resetting env. episode 2691.000000, reward total was -21.000000. running mean: -20.530373\n",
            "resetting env. episode 2692.000000, reward total was -21.000000. running mean: -20.535070\n",
            "resetting env. episode 2693.000000, reward total was -20.000000. running mean: -20.529719\n",
            "resetting env. episode 2694.000000, reward total was -21.000000. running mean: -20.534422\n",
            "resetting env. episode 2695.000000, reward total was -18.000000. running mean: -20.509077\n",
            "resetting env. episode 2696.000000, reward total was -20.000000. running mean: -20.503987\n",
            "resetting env. episode 2697.000000, reward total was -19.000000. running mean: -20.488947\n",
            "resetting env. episode 2698.000000, reward total was -20.000000. running mean: -20.484057\n",
            "resetting env. episode 2699.000000, reward total was -21.000000. running mean: -20.489217\n",
            "resetting env. episode 2700.000000, reward total was -20.000000. running mean: -20.484325\n",
            "resetting env. episode 2701.000000, reward total was -20.000000. running mean: -20.479481\n",
            "resetting env. episode 2702.000000, reward total was -21.000000. running mean: -20.484687\n",
            "resetting env. episode 2703.000000, reward total was -21.000000. running mean: -20.489840\n",
            "resetting env. episode 2704.000000, reward total was -20.000000. running mean: -20.484941\n",
            "resetting env. episode 2705.000000, reward total was -21.000000. running mean: -20.490092\n",
            "resetting env. episode 2706.000000, reward total was -21.000000. running mean: -20.495191\n",
            "resetting env. episode 2707.000000, reward total was -20.000000. running mean: -20.490239\n",
            "resetting env. episode 2708.000000, reward total was -19.000000. running mean: -20.475337\n",
            "resetting env. episode 2709.000000, reward total was -19.000000. running mean: -20.460583\n",
            "resetting env. episode 2710.000000, reward total was -21.000000. running mean: -20.465977\n",
            "resetting env. episode 2711.000000, reward total was -19.000000. running mean: -20.451318\n",
            "resetting env. episode 2712.000000, reward total was -21.000000. running mean: -20.456804\n",
            "resetting env. episode 2713.000000, reward total was -20.000000. running mean: -20.452236\n",
            "resetting env. episode 2714.000000, reward total was -21.000000. running mean: -20.457714\n",
            "resetting env. episode 2715.000000, reward total was -21.000000. running mean: -20.463137\n",
            "resetting env. episode 2716.000000, reward total was -21.000000. running mean: -20.468506\n",
            "resetting env. episode 2717.000000, reward total was -20.000000. running mean: -20.463821\n",
            "resetting env. episode 2718.000000, reward total was -21.000000. running mean: -20.469182\n",
            "resetting env. episode 2719.000000, reward total was -21.000000. running mean: -20.474490\n",
            "resetting env. episode 2720.000000, reward total was -20.000000. running mean: -20.469746\n",
            "resetting env. episode 2721.000000, reward total was -21.000000. running mean: -20.475048\n",
            "resetting env. episode 2722.000000, reward total was -19.000000. running mean: -20.460298\n",
            "resetting env. episode 2723.000000, reward total was -20.000000. running mean: -20.455695\n",
            "resetting env. episode 2724.000000, reward total was -18.000000. running mean: -20.431138\n",
            "resetting env. episode 2725.000000, reward total was -21.000000. running mean: -20.436826\n",
            "resetting env. episode 2726.000000, reward total was -20.000000. running mean: -20.432458\n",
            "resetting env. episode 2727.000000, reward total was -19.000000. running mean: -20.418133\n",
            "resetting env. episode 2728.000000, reward total was -19.000000. running mean: -20.403952\n",
            "resetting env. episode 2729.000000, reward total was -21.000000. running mean: -20.409913\n",
            "resetting env. episode 2730.000000, reward total was -20.000000. running mean: -20.405814\n",
            "resetting env. episode 2731.000000, reward total was -20.000000. running mean: -20.401755\n",
            "resetting env. episode 2732.000000, reward total was -19.000000. running mean: -20.387738\n",
            "resetting env. episode 2733.000000, reward total was -21.000000. running mean: -20.393860\n",
            "resetting env. episode 2734.000000, reward total was -21.000000. running mean: -20.399922\n",
            "resetting env. episode 2735.000000, reward total was -20.000000. running mean: -20.395923\n",
            "resetting env. episode 2736.000000, reward total was -21.000000. running mean: -20.401963\n",
            "resetting env. episode 2737.000000, reward total was -21.000000. running mean: -20.407944\n",
            "resetting env. episode 2738.000000, reward total was -21.000000. running mean: -20.413864\n",
            "resetting env. episode 2739.000000, reward total was -20.000000. running mean: -20.409726\n",
            "resetting env. episode 2740.000000, reward total was -20.000000. running mean: -20.405628\n",
            "resetting env. episode 2741.000000, reward total was -21.000000. running mean: -20.411572\n",
            "resetting env. episode 2742.000000, reward total was -21.000000. running mean: -20.417456\n",
            "resetting env. episode 2743.000000, reward total was -20.000000. running mean: -20.413282\n",
            "resetting env. episode 2744.000000, reward total was -20.000000. running mean: -20.409149\n",
            "resetting env. episode 2745.000000, reward total was -21.000000. running mean: -20.415058\n",
            "resetting env. episode 2746.000000, reward total was -20.000000. running mean: -20.410907\n",
            "resetting env. episode 2747.000000, reward total was -21.000000. running mean: -20.416798\n",
            "resetting env. episode 2748.000000, reward total was -21.000000. running mean: -20.422630\n",
            "resetting env. episode 2749.000000, reward total was -20.000000. running mean: -20.418404\n",
            "resetting env. episode 2750.000000, reward total was -20.000000. running mean: -20.414220\n",
            "resetting env. episode 2751.000000, reward total was -20.000000. running mean: -20.410077\n",
            "resetting env. episode 2752.000000, reward total was -21.000000. running mean: -20.415977\n",
            "resetting env. episode 2753.000000, reward total was -21.000000. running mean: -20.421817\n",
            "resetting env. episode 2754.000000, reward total was -20.000000. running mean: -20.417599\n",
            "resetting env. episode 2755.000000, reward total was -21.000000. running mean: -20.423423\n",
            "resetting env. episode 2756.000000, reward total was -21.000000. running mean: -20.429188\n",
            "resetting env. episode 2757.000000, reward total was -21.000000. running mean: -20.434897\n",
            "resetting env. episode 2758.000000, reward total was -21.000000. running mean: -20.440548\n",
            "resetting env. episode 2759.000000, reward total was -21.000000. running mean: -20.446142\n",
            "resetting env. episode 2760.000000, reward total was -21.000000. running mean: -20.451681\n",
            "resetting env. episode 2761.000000, reward total was -20.000000. running mean: -20.447164\n",
            "resetting env. episode 2762.000000, reward total was -21.000000. running mean: -20.452692\n",
            "resetting env. episode 2763.000000, reward total was -21.000000. running mean: -20.458165\n",
            "resetting env. episode 2764.000000, reward total was -21.000000. running mean: -20.463584\n",
            "resetting env. episode 2765.000000, reward total was -21.000000. running mean: -20.468948\n",
            "resetting env. episode 2766.000000, reward total was -18.000000. running mean: -20.444258\n",
            "resetting env. episode 2767.000000, reward total was -21.000000. running mean: -20.449816\n",
            "resetting env. episode 2768.000000, reward total was -20.000000. running mean: -20.445318\n",
            "resetting env. episode 2769.000000, reward total was -19.000000. running mean: -20.430864\n",
            "resetting env. episode 2770.000000, reward total was -21.000000. running mean: -20.436556\n",
            "resetting env. episode 2771.000000, reward total was -21.000000. running mean: -20.442190\n",
            "resetting env. episode 2772.000000, reward total was -21.000000. running mean: -20.447768\n",
            "resetting env. episode 2773.000000, reward total was -21.000000. running mean: -20.453291\n",
            "resetting env. episode 2774.000000, reward total was -21.000000. running mean: -20.458758\n",
            "resetting env. episode 2775.000000, reward total was -20.000000. running mean: -20.454170\n",
            "resetting env. episode 2776.000000, reward total was -20.000000. running mean: -20.449628\n",
            "resetting env. episode 2777.000000, reward total was -21.000000. running mean: -20.455132\n",
            "resetting env. episode 2778.000000, reward total was -21.000000. running mean: -20.460581\n",
            "resetting env. episode 2779.000000, reward total was -18.000000. running mean: -20.435975\n",
            "resetting env. episode 2780.000000, reward total was -20.000000. running mean: -20.431615\n",
            "resetting env. episode 2781.000000, reward total was -20.000000. running mean: -20.427299\n",
            "resetting env. episode 2782.000000, reward total was -20.000000. running mean: -20.423026\n",
            "resetting env. episode 2783.000000, reward total was -20.000000. running mean: -20.418796\n",
            "resetting env. episode 2784.000000, reward total was -21.000000. running mean: -20.424608\n",
            "resetting env. episode 2785.000000, reward total was -21.000000. running mean: -20.430362\n",
            "resetting env. episode 2786.000000, reward total was -20.000000. running mean: -20.426058\n",
            "resetting env. episode 2787.000000, reward total was -21.000000. running mean: -20.431798\n",
            "resetting env. episode 2788.000000, reward total was -21.000000. running mean: -20.437480\n",
            "resetting env. episode 2789.000000, reward total was -21.000000. running mean: -20.443105\n",
            "resetting env. episode 2790.000000, reward total was -21.000000. running mean: -20.448674\n",
            "resetting env. episode 2791.000000, reward total was -20.000000. running mean: -20.444187\n",
            "resetting env. episode 2792.000000, reward total was -20.000000. running mean: -20.439745\n",
            "resetting env. episode 2793.000000, reward total was -19.000000. running mean: -20.425348\n",
            "resetting env. episode 2794.000000, reward total was -21.000000. running mean: -20.431094\n",
            "resetting env. episode 2795.000000, reward total was -21.000000. running mean: -20.436783\n",
            "resetting env. episode 2796.000000, reward total was -20.000000. running mean: -20.432416\n",
            "resetting env. episode 2797.000000, reward total was -20.000000. running mean: -20.428091\n",
            "resetting env. episode 2798.000000, reward total was -21.000000. running mean: -20.433810\n",
            "resetting env. episode 2799.000000, reward total was -20.000000. running mean: -20.429472\n",
            "resetting env. episode 2800.000000, reward total was -20.000000. running mean: -20.425178\n",
            "resetting env. episode 2801.000000, reward total was -21.000000. running mean: -20.430926\n",
            "resetting env. episode 2802.000000, reward total was -20.000000. running mean: -20.426617\n",
            "resetting env. episode 2803.000000, reward total was -21.000000. running mean: -20.432350\n",
            "resetting env. episode 2804.000000, reward total was -21.000000. running mean: -20.438027\n",
            "resetting env. episode 2805.000000, reward total was -21.000000. running mean: -20.443647\n",
            "resetting env. episode 2806.000000, reward total was -19.000000. running mean: -20.429210\n",
            "resetting env. episode 2807.000000, reward total was -18.000000. running mean: -20.404918\n",
            "resetting env. episode 2808.000000, reward total was -21.000000. running mean: -20.410869\n",
            "resetting env. episode 2809.000000, reward total was -21.000000. running mean: -20.416760\n",
            "resetting env. episode 2810.000000, reward total was -21.000000. running mean: -20.422593\n",
            "resetting env. episode 2811.000000, reward total was -18.000000. running mean: -20.398367\n",
            "resetting env. episode 2812.000000, reward total was -21.000000. running mean: -20.404383\n",
            "resetting env. episode 2813.000000, reward total was -21.000000. running mean: -20.410339\n",
            "resetting env. episode 2814.000000, reward total was -20.000000. running mean: -20.406236\n",
            "resetting env. episode 2815.000000, reward total was -21.000000. running mean: -20.412173\n",
            "resetting env. episode 2816.000000, reward total was -19.000000. running mean: -20.398052\n",
            "resetting env. episode 2817.000000, reward total was -20.000000. running mean: -20.394071\n",
            "resetting env. episode 2818.000000, reward total was -21.000000. running mean: -20.400130\n",
            "resetting env. episode 2819.000000, reward total was -21.000000. running mean: -20.406129\n",
            "resetting env. episode 2820.000000, reward total was -21.000000. running mean: -20.412068\n",
            "resetting env. episode 2821.000000, reward total was -19.000000. running mean: -20.397947\n",
            "resetting env. episode 2822.000000, reward total was -21.000000. running mean: -20.403968\n",
            "resetting env. episode 2823.000000, reward total was -21.000000. running mean: -20.409928\n",
            "resetting env. episode 2824.000000, reward total was -21.000000. running mean: -20.415829\n",
            "resetting env. episode 2825.000000, reward total was -21.000000. running mean: -20.421670\n",
            "resetting env. episode 2826.000000, reward total was -20.000000. running mean: -20.417454\n",
            "resetting env. episode 2827.000000, reward total was -21.000000. running mean: -20.423279\n",
            "resetting env. episode 2828.000000, reward total was -21.000000. running mean: -20.429046\n",
            "resetting env. episode 2829.000000, reward total was -21.000000. running mean: -20.434756\n",
            "resetting env. episode 2830.000000, reward total was -18.000000. running mean: -20.410408\n",
            "resetting env. episode 2831.000000, reward total was -21.000000. running mean: -20.416304\n",
            "resetting env. episode 2832.000000, reward total was -21.000000. running mean: -20.422141\n",
            "resetting env. episode 2833.000000, reward total was -20.000000. running mean: -20.417920\n",
            "resetting env. episode 2834.000000, reward total was -20.000000. running mean: -20.413741\n",
            "resetting env. episode 2835.000000, reward total was -20.000000. running mean: -20.409603\n",
            "resetting env. episode 2836.000000, reward total was -21.000000. running mean: -20.415507\n",
            "resetting env. episode 2837.000000, reward total was -21.000000. running mean: -20.421352\n",
            "resetting env. episode 2838.000000, reward total was -20.000000. running mean: -20.417139\n",
            "resetting env. episode 2839.000000, reward total was -18.000000. running mean: -20.392967\n",
            "resetting env. episode 2840.000000, reward total was -20.000000. running mean: -20.389038\n",
            "resetting env. episode 2841.000000, reward total was -20.000000. running mean: -20.385147\n",
            "resetting env. episode 2842.000000, reward total was -21.000000. running mean: -20.391296\n",
            "resetting env. episode 2843.000000, reward total was -20.000000. running mean: -20.387383\n",
            "resetting env. episode 2844.000000, reward total was -20.000000. running mean: -20.383509\n",
            "resetting env. episode 2845.000000, reward total was -21.000000. running mean: -20.389674\n",
            "resetting env. episode 2846.000000, reward total was -21.000000. running mean: -20.395777\n",
            "resetting env. episode 2847.000000, reward total was -21.000000. running mean: -20.401819\n",
            "resetting env. episode 2848.000000, reward total was -21.000000. running mean: -20.407801\n",
            "resetting env. episode 2849.000000, reward total was -21.000000. running mean: -20.413723\n",
            "resetting env. episode 2850.000000, reward total was -17.000000. running mean: -20.379586\n",
            "resetting env. episode 2851.000000, reward total was -21.000000. running mean: -20.385790\n",
            "resetting env. episode 2852.000000, reward total was -21.000000. running mean: -20.391932\n",
            "resetting env. episode 2853.000000, reward total was -21.000000. running mean: -20.398013\n",
            "resetting env. episode 2854.000000, reward total was -21.000000. running mean: -20.404033\n",
            "resetting env. episode 2855.000000, reward total was -21.000000. running mean: -20.409992\n",
            "resetting env. episode 2856.000000, reward total was -18.000000. running mean: -20.385892\n",
            "resetting env. episode 2857.000000, reward total was -21.000000. running mean: -20.392034\n",
            "resetting env. episode 2858.000000, reward total was -21.000000. running mean: -20.398113\n",
            "resetting env. episode 2859.000000, reward total was -20.000000. running mean: -20.394132\n",
            "resetting env. episode 2860.000000, reward total was -21.000000. running mean: -20.400191\n",
            "resetting env. episode 2861.000000, reward total was -21.000000. running mean: -20.406189\n",
            "resetting env. episode 2862.000000, reward total was -21.000000. running mean: -20.412127\n",
            "resetting env. episode 2863.000000, reward total was -20.000000. running mean: -20.408006\n",
            "resetting env. episode 2864.000000, reward total was -21.000000. running mean: -20.413926\n",
            "resetting env. episode 2865.000000, reward total was -21.000000. running mean: -20.419786\n",
            "resetting env. episode 2866.000000, reward total was -21.000000. running mean: -20.425589\n",
            "resetting env. episode 2867.000000, reward total was -21.000000. running mean: -20.431333\n",
            "resetting env. episode 2868.000000, reward total was -21.000000. running mean: -20.437019\n",
            "resetting env. episode 2869.000000, reward total was -20.000000. running mean: -20.432649\n",
            "resetting env. episode 2870.000000, reward total was -20.000000. running mean: -20.428323\n",
            "resetting env. episode 2871.000000, reward total was -21.000000. running mean: -20.434039\n",
            "resetting env. episode 2872.000000, reward total was -21.000000. running mean: -20.439699\n",
            "resetting env. episode 2873.000000, reward total was -19.000000. running mean: -20.425302\n",
            "resetting env. episode 2874.000000, reward total was -20.000000. running mean: -20.421049\n",
            "resetting env. episode 2875.000000, reward total was -20.000000. running mean: -20.416838\n",
            "resetting env. episode 2876.000000, reward total was -21.000000. running mean: -20.422670\n",
            "resetting env. episode 2877.000000, reward total was -21.000000. running mean: -20.428443\n",
            "resetting env. episode 2878.000000, reward total was -20.000000. running mean: -20.424159\n",
            "resetting env. episode 2879.000000, reward total was -21.000000. running mean: -20.429917\n",
            "resetting env. episode 2880.000000, reward total was -21.000000. running mean: -20.435618\n",
            "resetting env. episode 2881.000000, reward total was -20.000000. running mean: -20.431262\n",
            "resetting env. episode 2882.000000, reward total was -20.000000. running mean: -20.426949\n",
            "resetting env. episode 2883.000000, reward total was -20.000000. running mean: -20.422680\n",
            "resetting env. episode 2884.000000, reward total was -20.000000. running mean: -20.418453\n",
            "resetting env. episode 2885.000000, reward total was -21.000000. running mean: -20.424269\n",
            "resetting env. episode 2886.000000, reward total was -20.000000. running mean: -20.420026\n",
            "resetting env. episode 2887.000000, reward total was -21.000000. running mean: -20.425826\n",
            "resetting env. episode 2888.000000, reward total was -20.000000. running mean: -20.421567\n",
            "resetting env. episode 2889.000000, reward total was -21.000000. running mean: -20.427352\n",
            "resetting env. episode 2890.000000, reward total was -20.000000. running mean: -20.423078\n",
            "resetting env. episode 2891.000000, reward total was -20.000000. running mean: -20.418847\n",
            "resetting env. episode 2892.000000, reward total was -21.000000. running mean: -20.424659\n",
            "resetting env. episode 2893.000000, reward total was -21.000000. running mean: -20.430412\n",
            "resetting env. episode 2894.000000, reward total was -20.000000. running mean: -20.426108\n",
            "resetting env. episode 2895.000000, reward total was -21.000000. running mean: -20.431847\n",
            "resetting env. episode 2896.000000, reward total was -21.000000. running mean: -20.437529\n",
            "resetting env. episode 2897.000000, reward total was -19.000000. running mean: -20.423153\n",
            "resetting env. episode 2898.000000, reward total was -19.000000. running mean: -20.408922\n",
            "resetting env. episode 2899.000000, reward total was -20.000000. running mean: -20.404833\n",
            "resetting env. episode 2900.000000, reward total was -21.000000. running mean: -20.410784\n",
            "resetting env. episode 2901.000000, reward total was -21.000000. running mean: -20.416676\n",
            "resetting env. episode 2902.000000, reward total was -21.000000. running mean: -20.422510\n",
            "resetting env. episode 2903.000000, reward total was -21.000000. running mean: -20.428285\n",
            "resetting env. episode 2904.000000, reward total was -21.000000. running mean: -20.434002\n",
            "resetting env. episode 2905.000000, reward total was -20.000000. running mean: -20.429662\n",
            "resetting env. episode 2906.000000, reward total was -19.000000. running mean: -20.415365\n",
            "resetting env. episode 2907.000000, reward total was -20.000000. running mean: -20.411211\n",
            "resetting env. episode 2908.000000, reward total was -21.000000. running mean: -20.417099\n",
            "resetting env. episode 2909.000000, reward total was -21.000000. running mean: -20.422928\n",
            "resetting env. episode 2910.000000, reward total was -16.000000. running mean: -20.378699\n",
            "resetting env. episode 2911.000000, reward total was -21.000000. running mean: -20.384912\n",
            "resetting env. episode 2912.000000, reward total was -20.000000. running mean: -20.381063\n",
            "resetting env. episode 2913.000000, reward total was -20.000000. running mean: -20.377252\n",
            "resetting env. episode 2914.000000, reward total was -21.000000. running mean: -20.383480\n",
            "resetting env. episode 2915.000000, reward total was -21.000000. running mean: -20.389645\n",
            "resetting env. episode 2916.000000, reward total was -21.000000. running mean: -20.395749\n",
            "resetting env. episode 2917.000000, reward total was -21.000000. running mean: -20.401791\n",
            "resetting env. episode 2918.000000, reward total was -21.000000. running mean: -20.407773\n",
            "resetting env. episode 2919.000000, reward total was -20.000000. running mean: -20.403695\n",
            "resetting env. episode 2920.000000, reward total was -20.000000. running mean: -20.399658\n",
            "resetting env. episode 2921.000000, reward total was -21.000000. running mean: -20.405662\n",
            "resetting env. episode 2922.000000, reward total was -21.000000. running mean: -20.411605\n",
            "resetting env. episode 2923.000000, reward total was -21.000000. running mean: -20.417489\n",
            "resetting env. episode 2924.000000, reward total was -21.000000. running mean: -20.423314\n",
            "resetting env. episode 2925.000000, reward total was -19.000000. running mean: -20.409081\n",
            "resetting env. episode 2926.000000, reward total was -21.000000. running mean: -20.414990\n",
            "resetting env. episode 2927.000000, reward total was -20.000000. running mean: -20.410840\n",
            "resetting env. episode 2928.000000, reward total was -19.000000. running mean: -20.396732\n",
            "resetting env. episode 2929.000000, reward total was -21.000000. running mean: -20.402765\n",
            "resetting env. episode 2930.000000, reward total was -20.000000. running mean: -20.398737\n",
            "resetting env. episode 2931.000000, reward total was -21.000000. running mean: -20.404750\n",
            "resetting env. episode 2932.000000, reward total was -17.000000. running mean: -20.370702\n",
            "resetting env. episode 2933.000000, reward total was -21.000000. running mean: -20.376995\n",
            "resetting env. episode 2934.000000, reward total was -20.000000. running mean: -20.373225\n",
            "resetting env. episode 2935.000000, reward total was -19.000000. running mean: -20.359493\n",
            "resetting env. episode 2936.000000, reward total was -19.000000. running mean: -20.345898\n",
            "resetting env. episode 2937.000000, reward total was -20.000000. running mean: -20.342439\n",
            "resetting env. episode 2938.000000, reward total was -21.000000. running mean: -20.349015\n",
            "resetting env. episode 2939.000000, reward total was -21.000000. running mean: -20.355525\n",
            "resetting env. episode 2940.000000, reward total was -21.000000. running mean: -20.361969\n",
            "resetting env. episode 2941.000000, reward total was -21.000000. running mean: -20.368350\n",
            "resetting env. episode 2942.000000, reward total was -21.000000. running mean: -20.374666\n",
            "resetting env. episode 2943.000000, reward total was -21.000000. running mean: -20.380919\n",
            "resetting env. episode 2944.000000, reward total was -20.000000. running mean: -20.377110\n",
            "resetting env. episode 2945.000000, reward total was -19.000000. running mean: -20.363339\n",
            "resetting env. episode 2946.000000, reward total was -21.000000. running mean: -20.369706\n",
            "resetting env. episode 2947.000000, reward total was -21.000000. running mean: -20.376009\n",
            "resetting env. episode 2948.000000, reward total was -21.000000. running mean: -20.382249\n",
            "resetting env. episode 2949.000000, reward total was -18.000000. running mean: -20.358426\n",
            "resetting env. episode 2950.000000, reward total was -21.000000. running mean: -20.364842\n",
            "resetting env. episode 2951.000000, reward total was -21.000000. running mean: -20.371193\n",
            "resetting env. episode 2952.000000, reward total was -20.000000. running mean: -20.367482\n",
            "resetting env. episode 2953.000000, reward total was -21.000000. running mean: -20.373807\n",
            "resetting env. episode 2954.000000, reward total was -21.000000. running mean: -20.380069\n",
            "resetting env. episode 2955.000000, reward total was -20.000000. running mean: -20.376268\n",
            "resetting env. episode 2956.000000, reward total was -21.000000. running mean: -20.382505\n",
            "resetting env. episode 2957.000000, reward total was -20.000000. running mean: -20.378680\n",
            "resetting env. episode 2958.000000, reward total was -21.000000. running mean: -20.384893\n",
            "resetting env. episode 2959.000000, reward total was -20.000000. running mean: -20.381044\n",
            "resetting env. episode 2960.000000, reward total was -20.000000. running mean: -20.377234\n",
            "resetting env. episode 2961.000000, reward total was -20.000000. running mean: -20.373462\n",
            "resetting env. episode 2962.000000, reward total was -21.000000. running mean: -20.379727\n",
            "resetting env. episode 2963.000000, reward total was -21.000000. running mean: -20.385930\n",
            "resetting env. episode 2964.000000, reward total was -21.000000. running mean: -20.392071\n",
            "resetting env. episode 2965.000000, reward total was -21.000000. running mean: -20.398150\n",
            "resetting env. episode 2966.000000, reward total was -18.000000. running mean: -20.374168\n",
            "resetting env. episode 2967.000000, reward total was -21.000000. running mean: -20.380427\n",
            "resetting env. episode 2968.000000, reward total was -21.000000. running mean: -20.386622\n",
            "resetting env. episode 2969.000000, reward total was -21.000000. running mean: -20.392756\n",
            "resetting env. episode 2970.000000, reward total was -21.000000. running mean: -20.398829\n",
            "resetting env. episode 2971.000000, reward total was -21.000000. running mean: -20.404840\n",
            "resetting env. episode 2972.000000, reward total was -21.000000. running mean: -20.410792\n",
            "resetting env. episode 2973.000000, reward total was -21.000000. running mean: -20.416684\n",
            "resetting env. episode 2974.000000, reward total was -20.000000. running mean: -20.412517\n",
            "resetting env. episode 2975.000000, reward total was -21.000000. running mean: -20.418392\n",
            "resetting env. episode 2976.000000, reward total was -21.000000. running mean: -20.424208\n",
            "resetting env. episode 2977.000000, reward total was -21.000000. running mean: -20.429966\n",
            "resetting env. episode 2978.000000, reward total was -21.000000. running mean: -20.435666\n",
            "resetting env. episode 2979.000000, reward total was -19.000000. running mean: -20.421310\n",
            "resetting env. episode 2980.000000, reward total was -21.000000. running mean: -20.427097\n",
            "resetting env. episode 2981.000000, reward total was -19.000000. running mean: -20.412826\n",
            "resetting env. episode 2982.000000, reward total was -21.000000. running mean: -20.418697\n",
            "resetting env. episode 2983.000000, reward total was -19.000000. running mean: -20.404510\n",
            "resetting env. episode 2984.000000, reward total was -20.000000. running mean: -20.400465\n",
            "resetting env. episode 2985.000000, reward total was -20.000000. running mean: -20.396461\n",
            "resetting env. episode 2986.000000, reward total was -21.000000. running mean: -20.402496\n",
            "resetting env. episode 2987.000000, reward total was -21.000000. running mean: -20.408471\n",
            "resetting env. episode 2988.000000, reward total was -21.000000. running mean: -20.414386\n",
            "resetting env. episode 2989.000000, reward total was -21.000000. running mean: -20.420242\n",
            "resetting env. episode 2990.000000, reward total was -21.000000. running mean: -20.426040\n",
            "resetting env. episode 2991.000000, reward total was -19.000000. running mean: -20.411780\n",
            "resetting env. episode 2992.000000, reward total was -18.000000. running mean: -20.387662\n",
            "resetting env. episode 2993.000000, reward total was -21.000000. running mean: -20.393785\n",
            "resetting env. episode 2994.000000, reward total was -19.000000. running mean: -20.379847\n",
            "resetting env. episode 2995.000000, reward total was -20.000000. running mean: -20.376049\n",
            "resetting env. episode 2996.000000, reward total was -20.000000. running mean: -20.372288\n",
            "resetting env. episode 2997.000000, reward total was -21.000000. running mean: -20.378566\n",
            "resetting env. episode 2998.000000, reward total was -20.000000. running mean: -20.374780\n",
            "resetting env. episode 2999.000000, reward total was -21.000000. running mean: -20.381032\n",
            "resetting env. episode 3000.000000, reward total was -20.000000. running mean: -20.377222\n",
            "resetting env. episode 3001.000000, reward total was -21.000000. running mean: -20.383450\n",
            "resetting env. episode 3002.000000, reward total was -21.000000. running mean: -20.389615\n",
            "resetting env. episode 3003.000000, reward total was -21.000000. running mean: -20.395719\n",
            "resetting env. episode 3004.000000, reward total was -21.000000. running mean: -20.401762\n",
            "resetting env. episode 3005.000000, reward total was -21.000000. running mean: -20.407744\n",
            "resetting env. episode 3006.000000, reward total was -21.000000. running mean: -20.413667\n",
            "resetting env. episode 3007.000000, reward total was -21.000000. running mean: -20.419530\n",
            "resetting env. episode 3008.000000, reward total was -21.000000. running mean: -20.425335\n",
            "resetting env. episode 3009.000000, reward total was -19.000000. running mean: -20.411081\n",
            "resetting env. episode 3010.000000, reward total was -21.000000. running mean: -20.416971\n",
            "resetting env. episode 3011.000000, reward total was -20.000000. running mean: -20.412801\n",
            "resetting env. episode 3012.000000, reward total was -20.000000. running mean: -20.408673\n",
            "resetting env. episode 3013.000000, reward total was -20.000000. running mean: -20.404586\n",
            "resetting env. episode 3014.000000, reward total was -21.000000. running mean: -20.410540\n",
            "resetting env. episode 3015.000000, reward total was -21.000000. running mean: -20.416435\n",
            "resetting env. episode 3016.000000, reward total was -20.000000. running mean: -20.412270\n",
            "resetting env. episode 3017.000000, reward total was -21.000000. running mean: -20.418148\n",
            "resetting env. episode 3018.000000, reward total was -21.000000. running mean: -20.423966\n",
            "resetting env. episode 3019.000000, reward total was -21.000000. running mean: -20.429727\n",
            "resetting env. episode 3020.000000, reward total was -21.000000. running mean: -20.435429\n",
            "resetting env. episode 3021.000000, reward total was -20.000000. running mean: -20.431075\n",
            "resetting env. episode 3022.000000, reward total was -20.000000. running mean: -20.426764\n",
            "resetting env. episode 3023.000000, reward total was -21.000000. running mean: -20.432497\n",
            "resetting env. episode 3024.000000, reward total was -21.000000. running mean: -20.438172\n",
            "resetting env. episode 3025.000000, reward total was -21.000000. running mean: -20.443790\n",
            "resetting env. episode 3026.000000, reward total was -21.000000. running mean: -20.449352\n",
            "resetting env. episode 3027.000000, reward total was -20.000000. running mean: -20.444859\n",
            "resetting env. episode 3028.000000, reward total was -20.000000. running mean: -20.440410\n",
            "resetting env. episode 3029.000000, reward total was -21.000000. running mean: -20.446006\n",
            "resetting env. episode 3030.000000, reward total was -20.000000. running mean: -20.441546\n",
            "resetting env. episode 3031.000000, reward total was -20.000000. running mean: -20.437130\n",
            "resetting env. episode 3032.000000, reward total was -21.000000. running mean: -20.442759\n",
            "resetting env. episode 3033.000000, reward total was -21.000000. running mean: -20.448331\n",
            "resetting env. episode 3034.000000, reward total was -21.000000. running mean: -20.453848\n",
            "resetting env. episode 3035.000000, reward total was -21.000000. running mean: -20.459310\n",
            "resetting env. episode 3036.000000, reward total was -20.000000. running mean: -20.454717\n",
            "resetting env. episode 3037.000000, reward total was -21.000000. running mean: -20.460169\n",
            "resetting env. episode 3038.000000, reward total was -20.000000. running mean: -20.455568\n",
            "resetting env. episode 3039.000000, reward total was -19.000000. running mean: -20.441012\n",
            "resetting env. episode 3040.000000, reward total was -20.000000. running mean: -20.436602\n",
            "resetting env. episode 3041.000000, reward total was -21.000000. running mean: -20.442236\n",
            "resetting env. episode 3042.000000, reward total was -20.000000. running mean: -20.437814\n",
            "resetting env. episode 3043.000000, reward total was -21.000000. running mean: -20.443435\n",
            "resetting env. episode 3044.000000, reward total was -21.000000. running mean: -20.449001\n",
            "resetting env. episode 3045.000000, reward total was -21.000000. running mean: -20.454511\n",
            "resetting env. episode 3046.000000, reward total was -21.000000. running mean: -20.459966\n",
            "resetting env. episode 3047.000000, reward total was -19.000000. running mean: -20.445366\n",
            "resetting env. episode 3048.000000, reward total was -19.000000. running mean: -20.430913\n",
            "resetting env. episode 3049.000000, reward total was -20.000000. running mean: -20.426603\n",
            "resetting env. episode 3050.000000, reward total was -21.000000. running mean: -20.432337\n",
            "resetting env. episode 3051.000000, reward total was -21.000000. running mean: -20.438014\n",
            "resetting env. episode 3052.000000, reward total was -21.000000. running mean: -20.443634\n",
            "resetting env. episode 3053.000000, reward total was -20.000000. running mean: -20.439198\n",
            "resetting env. episode 3054.000000, reward total was -21.000000. running mean: -20.444806\n",
            "resetting env. episode 3055.000000, reward total was -21.000000. running mean: -20.450358\n",
            "resetting env. episode 3056.000000, reward total was -20.000000. running mean: -20.445854\n",
            "resetting env. episode 3057.000000, reward total was -21.000000. running mean: -20.451395\n",
            "resetting env. episode 3058.000000, reward total was -21.000000. running mean: -20.456881\n",
            "resetting env. episode 3059.000000, reward total was -21.000000. running mean: -20.462313\n",
            "resetting env. episode 3060.000000, reward total was -21.000000. running mean: -20.467690\n",
            "resetting env. episode 3061.000000, reward total was -21.000000. running mean: -20.473013\n",
            "resetting env. episode 3062.000000, reward total was -20.000000. running mean: -20.468283\n",
            "resetting env. episode 3063.000000, reward total was -21.000000. running mean: -20.473600\n",
            "resetting env. episode 3064.000000, reward total was -21.000000. running mean: -20.478864\n",
            "resetting env. episode 3065.000000, reward total was -20.000000. running mean: -20.474075\n",
            "resetting env. episode 3066.000000, reward total was -20.000000. running mean: -20.469334\n",
            "resetting env. episode 3067.000000, reward total was -21.000000. running mean: -20.474641\n",
            "resetting env. episode 3068.000000, reward total was -21.000000. running mean: -20.479895\n",
            "resetting env. episode 3069.000000, reward total was -21.000000. running mean: -20.485096\n",
            "resetting env. episode 3070.000000, reward total was -21.000000. running mean: -20.490245\n",
            "resetting env. episode 3071.000000, reward total was -20.000000. running mean: -20.485342\n",
            "resetting env. episode 3072.000000, reward total was -21.000000. running mean: -20.490489\n",
            "resetting env. episode 3073.000000, reward total was -21.000000. running mean: -20.495584\n",
            "resetting env. episode 3074.000000, reward total was -21.000000. running mean: -20.500628\n",
            "resetting env. episode 3075.000000, reward total was -21.000000. running mean: -20.505622\n",
            "resetting env. episode 3076.000000, reward total was -21.000000. running mean: -20.510566\n",
            "resetting env. episode 3077.000000, reward total was -21.000000. running mean: -20.515460\n",
            "resetting env. episode 3078.000000, reward total was -20.000000. running mean: -20.510305\n",
            "resetting env. episode 3079.000000, reward total was -20.000000. running mean: -20.505202\n",
            "resetting env. episode 3080.000000, reward total was -21.000000. running mean: -20.510150\n",
            "resetting env. episode 3081.000000, reward total was -21.000000. running mean: -20.515049\n",
            "resetting env. episode 3082.000000, reward total was -21.000000. running mean: -20.519898\n",
            "resetting env. episode 3083.000000, reward total was -21.000000. running mean: -20.524699\n",
            "resetting env. episode 3084.000000, reward total was -21.000000. running mean: -20.529452\n",
            "resetting env. episode 3085.000000, reward total was -21.000000. running mean: -20.534158\n",
            "resetting env. episode 3086.000000, reward total was -20.000000. running mean: -20.528816\n",
            "resetting env. episode 3087.000000, reward total was -21.000000. running mean: -20.533528\n",
            "resetting env. episode 3088.000000, reward total was -21.000000. running mean: -20.538193\n",
            "resetting env. episode 3089.000000, reward total was -19.000000. running mean: -20.522811\n",
            "resetting env. episode 3090.000000, reward total was -20.000000. running mean: -20.517583\n",
            "resetting env. episode 3091.000000, reward total was -19.000000. running mean: -20.502407\n",
            "resetting env. episode 3092.000000, reward total was -19.000000. running mean: -20.487383\n",
            "resetting env. episode 3093.000000, reward total was -21.000000. running mean: -20.492509\n",
            "resetting env. episode 3094.000000, reward total was -21.000000. running mean: -20.497584\n",
            "resetting env. episode 3095.000000, reward total was -21.000000. running mean: -20.502608\n",
            "resetting env. episode 3096.000000, reward total was -21.000000. running mean: -20.507582\n",
            "resetting env. episode 3097.000000, reward total was -20.000000. running mean: -20.502506\n",
            "resetting env. episode 3098.000000, reward total was -21.000000. running mean: -20.507481\n",
            "resetting env. episode 3099.000000, reward total was -21.000000. running mean: -20.512406\n",
            "resetting env. episode 3100.000000, reward total was -20.000000. running mean: -20.507282\n",
            "resetting env. episode 3101.000000, reward total was -21.000000. running mean: -20.512209\n",
            "resetting env. episode 3102.000000, reward total was -21.000000. running mean: -20.517087\n",
            "resetting env. episode 3103.000000, reward total was -21.000000. running mean: -20.521916\n",
            "resetting env. episode 3104.000000, reward total was -20.000000. running mean: -20.516697\n",
            "resetting env. episode 3105.000000, reward total was -21.000000. running mean: -20.521530\n",
            "resetting env. episode 3106.000000, reward total was -19.000000. running mean: -20.506315\n",
            "resetting env. episode 3107.000000, reward total was -21.000000. running mean: -20.511252\n",
            "resetting env. episode 3108.000000, reward total was -21.000000. running mean: -20.516139\n",
            "resetting env. episode 3109.000000, reward total was -21.000000. running mean: -20.520978\n",
            "resetting env. episode 3110.000000, reward total was -21.000000. running mean: -20.525768\n",
            "resetting env. episode 3111.000000, reward total was -20.000000. running mean: -20.520510\n",
            "resetting env. episode 3112.000000, reward total was -21.000000. running mean: -20.525305\n",
            "resetting env. episode 3113.000000, reward total was -20.000000. running mean: -20.520052\n",
            "resetting env. episode 3114.000000, reward total was -21.000000. running mean: -20.524852\n",
            "resetting env. episode 3115.000000, reward total was -19.000000. running mean: -20.509603\n",
            "resetting env. episode 3116.000000, reward total was -21.000000. running mean: -20.514507\n",
            "resetting env. episode 3117.000000, reward total was -21.000000. running mean: -20.519362\n",
            "resetting env. episode 3118.000000, reward total was -20.000000. running mean: -20.514169\n",
            "resetting env. episode 3119.000000, reward total was -19.000000. running mean: -20.499027\n",
            "resetting env. episode 3120.000000, reward total was -21.000000. running mean: -20.504037\n",
            "resetting env. episode 3121.000000, reward total was -20.000000. running mean: -20.498996\n",
            "resetting env. episode 3122.000000, reward total was -21.000000. running mean: -20.504006\n",
            "resetting env. episode 3123.000000, reward total was -21.000000. running mean: -20.508966\n",
            "resetting env. episode 3124.000000, reward total was -20.000000. running mean: -20.503877\n",
            "resetting env. episode 3125.000000, reward total was -20.000000. running mean: -20.498838\n",
            "resetting env. episode 3126.000000, reward total was -21.000000. running mean: -20.503849\n",
            "resetting env. episode 3127.000000, reward total was -18.000000. running mean: -20.478811\n",
            "resetting env. episode 3128.000000, reward total was -21.000000. running mean: -20.484023\n",
            "resetting env. episode 3129.000000, reward total was -21.000000. running mean: -20.489183\n",
            "resetting env. episode 3130.000000, reward total was -21.000000. running mean: -20.494291\n",
            "resetting env. episode 3131.000000, reward total was -21.000000. running mean: -20.499348\n",
            "resetting env. episode 3132.000000, reward total was -20.000000. running mean: -20.494354\n",
            "resetting env. episode 3133.000000, reward total was -19.000000. running mean: -20.479411\n",
            "resetting env. episode 3134.000000, reward total was -20.000000. running mean: -20.474617\n",
            "resetting env. episode 3135.000000, reward total was -21.000000. running mean: -20.479871\n",
            "resetting env. episode 3136.000000, reward total was -20.000000. running mean: -20.475072\n",
            "resetting env. episode 3137.000000, reward total was -21.000000. running mean: -20.480321\n",
            "resetting env. episode 3138.000000, reward total was -19.000000. running mean: -20.465518\n",
            "resetting env. episode 3139.000000, reward total was -21.000000. running mean: -20.470863\n",
            "resetting env. episode 3140.000000, reward total was -20.000000. running mean: -20.466154\n",
            "resetting env. episode 3141.000000, reward total was -21.000000. running mean: -20.471493\n",
            "resetting env. episode 3142.000000, reward total was -21.000000. running mean: -20.476778\n",
            "resetting env. episode 3143.000000, reward total was -21.000000. running mean: -20.482010\n",
            "resetting env. episode 3144.000000, reward total was -21.000000. running mean: -20.487190\n",
            "resetting env. episode 3145.000000, reward total was -21.000000. running mean: -20.492318\n",
            "resetting env. episode 3146.000000, reward total was -21.000000. running mean: -20.497395\n",
            "resetting env. episode 3147.000000, reward total was -20.000000. running mean: -20.492421\n",
            "resetting env. episode 3148.000000, reward total was -20.000000. running mean: -20.487497\n",
            "resetting env. episode 3149.000000, reward total was -21.000000. running mean: -20.492622\n",
            "resetting env. episode 3150.000000, reward total was -21.000000. running mean: -20.497695\n",
            "resetting env. episode 3151.000000, reward total was -20.000000. running mean: -20.492718\n",
            "resetting env. episode 3152.000000, reward total was -21.000000. running mean: -20.497791\n",
            "resetting env. episode 3153.000000, reward total was -21.000000. running mean: -20.502813\n",
            "resetting env. episode 3154.000000, reward total was -21.000000. running mean: -20.507785\n",
            "resetting env. episode 3155.000000, reward total was -21.000000. running mean: -20.512707\n",
            "resetting env. episode 3156.000000, reward total was -21.000000. running mean: -20.517580\n",
            "resetting env. episode 3157.000000, reward total was -21.000000. running mean: -20.522404\n",
            "resetting env. episode 3158.000000, reward total was -21.000000. running mean: -20.527180\n",
            "resetting env. episode 3159.000000, reward total was -21.000000. running mean: -20.531909\n",
            "resetting env. episode 3160.000000, reward total was -20.000000. running mean: -20.526589\n",
            "resetting env. episode 3161.000000, reward total was -20.000000. running mean: -20.521324\n",
            "resetting env. episode 3162.000000, reward total was -21.000000. running mean: -20.526110\n",
            "resetting env. episode 3163.000000, reward total was -21.000000. running mean: -20.530849\n",
            "resetting env. episode 3164.000000, reward total was -19.000000. running mean: -20.515541\n",
            "resetting env. episode 3165.000000, reward total was -21.000000. running mean: -20.520385\n",
            "resetting env. episode 3166.000000, reward total was -21.000000. running mean: -20.525181\n",
            "resetting env. episode 3167.000000, reward total was -21.000000. running mean: -20.529930\n",
            "resetting env. episode 3168.000000, reward total was -19.000000. running mean: -20.514630\n",
            "resetting env. episode 3169.000000, reward total was -20.000000. running mean: -20.509484\n",
            "resetting env. episode 3170.000000, reward total was -21.000000. running mean: -20.514389\n",
            "resetting env. episode 3171.000000, reward total was -21.000000. running mean: -20.519245\n",
            "resetting env. episode 3172.000000, reward total was -21.000000. running mean: -20.524053\n",
            "resetting env. episode 3173.000000, reward total was -19.000000. running mean: -20.508812\n",
            "resetting env. episode 3174.000000, reward total was -21.000000. running mean: -20.513724\n",
            "resetting env. episode 3175.000000, reward total was -21.000000. running mean: -20.518587\n",
            "resetting env. episode 3176.000000, reward total was -21.000000. running mean: -20.523401\n",
            "resetting env. episode 3177.000000, reward total was -21.000000. running mean: -20.528167\n",
            "resetting env. episode 3178.000000, reward total was -20.000000. running mean: -20.522885\n",
            "resetting env. episode 3179.000000, reward total was -21.000000. running mean: -20.527657\n",
            "resetting env. episode 3180.000000, reward total was -21.000000. running mean: -20.532380\n",
            "resetting env. episode 3181.000000, reward total was -21.000000. running mean: -20.537056\n",
            "resetting env. episode 3182.000000, reward total was -21.000000. running mean: -20.541686\n",
            "resetting env. episode 3183.000000, reward total was -21.000000. running mean: -20.546269\n",
            "resetting env. episode 3184.000000, reward total was -21.000000. running mean: -20.550806\n",
            "resetting env. episode 3185.000000, reward total was -21.000000. running mean: -20.555298\n",
            "resetting env. episode 3186.000000, reward total was -19.000000. running mean: -20.539745\n",
            "resetting env. episode 3187.000000, reward total was -20.000000. running mean: -20.534348\n",
            "resetting env. episode 3188.000000, reward total was -20.000000. running mean: -20.529004\n",
            "resetting env. episode 3189.000000, reward total was -18.000000. running mean: -20.503714\n",
            "resetting env. episode 3190.000000, reward total was -21.000000. running mean: -20.508677\n",
            "resetting env. episode 3191.000000, reward total was -20.000000. running mean: -20.503590\n",
            "resetting env. episode 3192.000000, reward total was -21.000000. running mean: -20.508554\n",
            "resetting env. episode 3193.000000, reward total was -18.000000. running mean: -20.483469\n",
            "resetting env. episode 3194.000000, reward total was -20.000000. running mean: -20.478634\n",
            "resetting env. episode 3195.000000, reward total was -21.000000. running mean: -20.483848\n",
            "resetting env. episode 3196.000000, reward total was -20.000000. running mean: -20.479009\n",
            "resetting env. episode 3197.000000, reward total was -20.000000. running mean: -20.474219\n",
            "resetting env. episode 3198.000000, reward total was -18.000000. running mean: -20.449477\n",
            "resetting env. episode 3199.000000, reward total was -21.000000. running mean: -20.454982\n",
            "resetting env. episode 3200.000000, reward total was -18.000000. running mean: -20.430432\n",
            "resetting env. episode 3201.000000, reward total was -21.000000. running mean: -20.436128\n",
            "resetting env. episode 3202.000000, reward total was -21.000000. running mean: -20.441767\n",
            "resetting env. episode 3203.000000, reward total was -20.000000. running mean: -20.437349\n",
            "resetting env. episode 3204.000000, reward total was -21.000000. running mean: -20.442976\n",
            "resetting env. episode 3205.000000, reward total was -21.000000. running mean: -20.448546\n",
            "resetting env. episode 3206.000000, reward total was -20.000000. running mean: -20.444060\n",
            "resetting env. episode 3207.000000, reward total was -19.000000. running mean: -20.429620\n",
            "resetting env. episode 3208.000000, reward total was -21.000000. running mean: -20.435324\n",
            "resetting env. episode 3209.000000, reward total was -21.000000. running mean: -20.440970\n",
            "resetting env. episode 3210.000000, reward total was -21.000000. running mean: -20.446561\n",
            "resetting env. episode 3211.000000, reward total was -21.000000. running mean: -20.452095\n",
            "resetting env. episode 3212.000000, reward total was -21.000000. running mean: -20.457574\n",
            "resetting env. episode 3213.000000, reward total was -20.000000. running mean: -20.452998\n",
            "resetting env. episode 3214.000000, reward total was -20.000000. running mean: -20.448468\n",
            "resetting env. episode 3215.000000, reward total was -21.000000. running mean: -20.453984\n",
            "resetting env. episode 3216.000000, reward total was -20.000000. running mean: -20.449444\n",
            "resetting env. episode 3217.000000, reward total was -21.000000. running mean: -20.454949\n",
            "resetting env. episode 3218.000000, reward total was -20.000000. running mean: -20.450400\n",
            "resetting env. episode 3219.000000, reward total was -21.000000. running mean: -20.455896\n",
            "resetting env. episode 3220.000000, reward total was -20.000000. running mean: -20.451337\n",
            "resetting env. episode 3221.000000, reward total was -19.000000. running mean: -20.436824\n",
            "resetting env. episode 3222.000000, reward total was -20.000000. running mean: -20.432455\n",
            "resetting env. episode 3223.000000, reward total was -20.000000. running mean: -20.428131\n",
            "resetting env. episode 3224.000000, reward total was -21.000000. running mean: -20.433849\n",
            "resetting env. episode 3225.000000, reward total was -21.000000. running mean: -20.439511\n",
            "resetting env. episode 3226.000000, reward total was -21.000000. running mean: -20.445116\n",
            "resetting env. episode 3227.000000, reward total was -21.000000. running mean: -20.450665\n",
            "resetting env. episode 3228.000000, reward total was -20.000000. running mean: -20.446158\n",
            "resetting env. episode 3229.000000, reward total was -20.000000. running mean: -20.441697\n",
            "resetting env. episode 3230.000000, reward total was -21.000000. running mean: -20.447280\n",
            "resetting env. episode 3231.000000, reward total was -21.000000. running mean: -20.452807\n",
            "resetting env. episode 3232.000000, reward total was -19.000000. running mean: -20.438279\n",
            "resetting env. episode 3233.000000, reward total was -20.000000. running mean: -20.433896\n",
            "resetting env. episode 3234.000000, reward total was -21.000000. running mean: -20.439557\n",
            "resetting env. episode 3235.000000, reward total was -21.000000. running mean: -20.445161\n",
            "resetting env. episode 3236.000000, reward total was -18.000000. running mean: -20.420710\n",
            "resetting env. episode 3237.000000, reward total was -19.000000. running mean: -20.406503\n",
            "resetting env. episode 3238.000000, reward total was -21.000000. running mean: -20.412438\n",
            "resetting env. episode 3239.000000, reward total was -19.000000. running mean: -20.398313\n",
            "resetting env. episode 3240.000000, reward total was -19.000000. running mean: -20.384330\n",
            "resetting env. episode 3241.000000, reward total was -21.000000. running mean: -20.390487\n",
            "resetting env. episode 3242.000000, reward total was -21.000000. running mean: -20.396582\n",
            "resetting env. episode 3243.000000, reward total was -21.000000. running mean: -20.402616\n",
            "resetting env. episode 3244.000000, reward total was -20.000000. running mean: -20.398590\n",
            "resetting env. episode 3245.000000, reward total was -20.000000. running mean: -20.394604\n",
            "resetting env. episode 3246.000000, reward total was -20.000000. running mean: -20.390658\n",
            "resetting env. episode 3247.000000, reward total was -21.000000. running mean: -20.396751\n",
            "resetting env. episode 3248.000000, reward total was -21.000000. running mean: -20.402784\n",
            "resetting env. episode 3249.000000, reward total was -20.000000. running mean: -20.398756\n",
            "resetting env. episode 3250.000000, reward total was -21.000000. running mean: -20.404769\n",
            "resetting env. episode 3251.000000, reward total was -21.000000. running mean: -20.410721\n",
            "resetting env. episode 3252.000000, reward total was -21.000000. running mean: -20.416614\n",
            "resetting env. episode 3253.000000, reward total was -21.000000. running mean: -20.422447\n",
            "resetting env. episode 3254.000000, reward total was -20.000000. running mean: -20.418223\n",
            "resetting env. episode 3255.000000, reward total was -21.000000. running mean: -20.424041\n",
            "resetting env. episode 3256.000000, reward total was -19.000000. running mean: -20.409800\n",
            "resetting env. episode 3257.000000, reward total was -21.000000. running mean: -20.415702\n",
            "resetting env. episode 3258.000000, reward total was -20.000000. running mean: -20.411545\n",
            "resetting env. episode 3259.000000, reward total was -20.000000. running mean: -20.407430\n",
            "resetting env. episode 3260.000000, reward total was -19.000000. running mean: -20.393356\n",
            "resetting env. episode 3261.000000, reward total was -21.000000. running mean: -20.399422\n",
            "resetting env. episode 3262.000000, reward total was -20.000000. running mean: -20.395428\n",
            "resetting env. episode 3263.000000, reward total was -20.000000. running mean: -20.391474\n",
            "resetting env. episode 3264.000000, reward total was -19.000000. running mean: -20.377559\n",
            "resetting env. episode 3265.000000, reward total was -20.000000. running mean: -20.373783\n",
            "resetting env. episode 3266.000000, reward total was -21.000000. running mean: -20.380045\n",
            "resetting env. episode 3267.000000, reward total was -21.000000. running mean: -20.386245\n",
            "resetting env. episode 3268.000000, reward total was -21.000000. running mean: -20.392382\n",
            "resetting env. episode 3269.000000, reward total was -20.000000. running mean: -20.388459\n",
            "resetting env. episode 3270.000000, reward total was -19.000000. running mean: -20.374574\n",
            "resetting env. episode 3271.000000, reward total was -21.000000. running mean: -20.380828\n",
            "resetting env. episode 3272.000000, reward total was -18.000000. running mean: -20.357020\n",
            "resetting env. episode 3273.000000, reward total was -20.000000. running mean: -20.353450\n",
            "resetting env. episode 3274.000000, reward total was -21.000000. running mean: -20.359915\n",
            "resetting env. episode 3275.000000, reward total was -20.000000. running mean: -20.356316\n",
            "resetting env. episode 3276.000000, reward total was -21.000000. running mean: -20.362753\n",
            "resetting env. episode 3277.000000, reward total was -20.000000. running mean: -20.359126\n",
            "resetting env. episode 3278.000000, reward total was -18.000000. running mean: -20.335534\n",
            "resetting env. episode 3279.000000, reward total was -21.000000. running mean: -20.342179\n",
            "resetting env. episode 3280.000000, reward total was -21.000000. running mean: -20.348757\n",
            "resetting env. episode 3281.000000, reward total was -20.000000. running mean: -20.345270\n",
            "resetting env. episode 3282.000000, reward total was -21.000000. running mean: -20.351817\n",
            "resetting env. episode 3283.000000, reward total was -21.000000. running mean: -20.358299\n",
            "resetting env. episode 3284.000000, reward total was -20.000000. running mean: -20.354716\n",
            "resetting env. episode 3285.000000, reward total was -21.000000. running mean: -20.361169\n",
            "resetting env. episode 3286.000000, reward total was -21.000000. running mean: -20.367557\n",
            "resetting env. episode 3287.000000, reward total was -19.000000. running mean: -20.353881\n",
            "resetting env. episode 3288.000000, reward total was -19.000000. running mean: -20.340342\n",
            "resetting env. episode 3289.000000, reward total was -21.000000. running mean: -20.346939\n",
            "resetting env. episode 3290.000000, reward total was -21.000000. running mean: -20.353470\n",
            "resetting env. episode 3291.000000, reward total was -21.000000. running mean: -20.359935\n",
            "resetting env. episode 3292.000000, reward total was -21.000000. running mean: -20.366336\n",
            "resetting env. episode 3293.000000, reward total was -21.000000. running mean: -20.372672\n",
            "resetting env. episode 3294.000000, reward total was -21.000000. running mean: -20.378946\n",
            "resetting env. episode 3295.000000, reward total was -21.000000. running mean: -20.385156\n",
            "resetting env. episode 3296.000000, reward total was -21.000000. running mean: -20.391305\n",
            "resetting env. episode 3297.000000, reward total was -21.000000. running mean: -20.397391\n",
            "resetting env. episode 3298.000000, reward total was -21.000000. running mean: -20.403418\n",
            "resetting env. episode 3299.000000, reward total was -18.000000. running mean: -20.379383\n",
            "resetting env. episode 3300.000000, reward total was -20.000000. running mean: -20.375590\n",
            "resetting env. episode 3301.000000, reward total was -21.000000. running mean: -20.381834\n",
            "resetting env. episode 3302.000000, reward total was -20.000000. running mean: -20.378015\n",
            "resetting env. episode 3303.000000, reward total was -21.000000. running mean: -20.384235\n",
            "resetting env. episode 3304.000000, reward total was -20.000000. running mean: -20.380393\n",
            "resetting env. episode 3305.000000, reward total was -20.000000. running mean: -20.376589\n",
            "resetting env. episode 3306.000000, reward total was -21.000000. running mean: -20.382823\n",
            "resetting env. episode 3307.000000, reward total was -21.000000. running mean: -20.388995\n",
            "resetting env. episode 3308.000000, reward total was -19.000000. running mean: -20.375105\n",
            "resetting env. episode 3309.000000, reward total was -20.000000. running mean: -20.371354\n",
            "resetting env. episode 3310.000000, reward total was -21.000000. running mean: -20.377640\n",
            "resetting env. episode 3311.000000, reward total was -20.000000. running mean: -20.373864\n",
            "resetting env. episode 3312.000000, reward total was -19.000000. running mean: -20.360125\n",
            "resetting env. episode 3313.000000, reward total was -20.000000. running mean: -20.356524\n",
            "resetting env. episode 3314.000000, reward total was -20.000000. running mean: -20.352959\n",
            "resetting env. episode 3315.000000, reward total was -19.000000. running mean: -20.339429\n",
            "resetting env. episode 3316.000000, reward total was -18.000000. running mean: -20.316035\n",
            "resetting env. episode 3317.000000, reward total was -20.000000. running mean: -20.312874\n",
            "resetting env. episode 3318.000000, reward total was -21.000000. running mean: -20.319746\n",
            "resetting env. episode 3319.000000, reward total was -21.000000. running mean: -20.326548\n",
            "resetting env. episode 3320.000000, reward total was -21.000000. running mean: -20.333283\n",
            "resetting env. episode 3321.000000, reward total was -20.000000. running mean: -20.329950\n",
            "resetting env. episode 3322.000000, reward total was -21.000000. running mean: -20.336650\n",
            "resetting env. episode 3323.000000, reward total was -21.000000. running mean: -20.343284\n",
            "resetting env. episode 3324.000000, reward total was -21.000000. running mean: -20.349851\n",
            "resetting env. episode 3325.000000, reward total was -21.000000. running mean: -20.356353\n",
            "resetting env. episode 3326.000000, reward total was -21.000000. running mean: -20.362789\n",
            "resetting env. episode 3327.000000, reward total was -21.000000. running mean: -20.369161\n",
            "resetting env. episode 3328.000000, reward total was -21.000000. running mean: -20.375470\n",
            "resetting env. episode 3329.000000, reward total was -21.000000. running mean: -20.381715\n",
            "resetting env. episode 3330.000000, reward total was -19.000000. running mean: -20.367898\n",
            "resetting env. episode 3331.000000, reward total was -21.000000. running mean: -20.374219\n",
            "resetting env. episode 3332.000000, reward total was -21.000000. running mean: -20.380477\n",
            "resetting env. episode 3333.000000, reward total was -21.000000. running mean: -20.386672\n",
            "resetting env. episode 3334.000000, reward total was -19.000000. running mean: -20.372805\n",
            "resetting env. episode 3335.000000, reward total was -20.000000. running mean: -20.369077\n",
            "resetting env. episode 3336.000000, reward total was -21.000000. running mean: -20.375386\n",
            "resetting env. episode 3337.000000, reward total was -21.000000. running mean: -20.381632\n",
            "resetting env. episode 3338.000000, reward total was -21.000000. running mean: -20.387816\n",
            "resetting env. episode 3339.000000, reward total was -21.000000. running mean: -20.393938\n",
            "resetting env. episode 3340.000000, reward total was -20.000000. running mean: -20.389999\n",
            "resetting env. episode 3341.000000, reward total was -20.000000. running mean: -20.386099\n",
            "resetting env. episode 3342.000000, reward total was -19.000000. running mean: -20.372238\n",
            "resetting env. episode 3343.000000, reward total was -20.000000. running mean: -20.368515\n",
            "resetting env. episode 3344.000000, reward total was -19.000000. running mean: -20.354830\n",
            "resetting env. episode 3345.000000, reward total was -19.000000. running mean: -20.341282\n",
            "resetting env. episode 3346.000000, reward total was -21.000000. running mean: -20.347869\n",
            "resetting env. episode 3347.000000, reward total was -19.000000. running mean: -20.334390\n",
            "resetting env. episode 3348.000000, reward total was -18.000000. running mean: -20.311046\n",
            "resetting env. episode 3349.000000, reward total was -21.000000. running mean: -20.317936\n",
            "resetting env. episode 3350.000000, reward total was -21.000000. running mean: -20.324757\n",
            "resetting env. episode 3351.000000, reward total was -21.000000. running mean: -20.331509\n",
            "resetting env. episode 3352.000000, reward total was -21.000000. running mean: -20.338194\n",
            "resetting env. episode 3353.000000, reward total was -19.000000. running mean: -20.324812\n",
            "resetting env. episode 3354.000000, reward total was -20.000000. running mean: -20.321564\n",
            "resetting env. episode 3355.000000, reward total was -18.000000. running mean: -20.298348\n",
            "resetting env. episode 3356.000000, reward total was -20.000000. running mean: -20.295365\n",
            "resetting env. episode 3357.000000, reward total was -21.000000. running mean: -20.302411\n",
            "resetting env. episode 3358.000000, reward total was -19.000000. running mean: -20.289387\n",
            "resetting env. episode 3359.000000, reward total was -21.000000. running mean: -20.296493\n",
            "resetting env. episode 3360.000000, reward total was -21.000000. running mean: -20.303528\n",
            "resetting env. episode 3361.000000, reward total was -20.000000. running mean: -20.300493\n",
            "resetting env. episode 3362.000000, reward total was -21.000000. running mean: -20.307488\n",
            "resetting env. episode 3363.000000, reward total was -20.000000. running mean: -20.304413\n",
            "resetting env. episode 3364.000000, reward total was -20.000000. running mean: -20.301369\n",
            "resetting env. episode 3365.000000, reward total was -18.000000. running mean: -20.278355\n",
            "resetting env. episode 3366.000000, reward total was -21.000000. running mean: -20.285572\n",
            "resetting env. episode 3367.000000, reward total was -21.000000. running mean: -20.292716\n",
            "resetting env. episode 3368.000000, reward total was -21.000000. running mean: -20.299789\n",
            "resetting env. episode 3369.000000, reward total was -21.000000. running mean: -20.306791\n",
            "resetting env. episode 3370.000000, reward total was -20.000000. running mean: -20.303723\n",
            "resetting env. episode 3371.000000, reward total was -19.000000. running mean: -20.290686\n",
            "resetting env. episode 3372.000000, reward total was -21.000000. running mean: -20.297779\n",
            "resetting env. episode 3373.000000, reward total was -20.000000. running mean: -20.294801\n",
            "resetting env. episode 3374.000000, reward total was -20.000000. running mean: -20.291853\n",
            "resetting env. episode 3375.000000, reward total was -21.000000. running mean: -20.298935\n",
            "resetting env. episode 3376.000000, reward total was -21.000000. running mean: -20.305945\n",
            "resetting env. episode 3377.000000, reward total was -21.000000. running mean: -20.312886\n",
            "resetting env. episode 3378.000000, reward total was -21.000000. running mean: -20.319757\n",
            "resetting env. episode 3379.000000, reward total was -20.000000. running mean: -20.316559\n",
            "resetting env. episode 3380.000000, reward total was -21.000000. running mean: -20.323394\n",
            "resetting env. episode 3381.000000, reward total was -21.000000. running mean: -20.330160\n",
            "resetting env. episode 3382.000000, reward total was -20.000000. running mean: -20.326858\n",
            "resetting env. episode 3383.000000, reward total was -20.000000. running mean: -20.323590\n",
            "resetting env. episode 3384.000000, reward total was -21.000000. running mean: -20.330354\n",
            "resetting env. episode 3385.000000, reward total was -18.000000. running mean: -20.307050\n",
            "resetting env. episode 3386.000000, reward total was -18.000000. running mean: -20.283980\n",
            "resetting env. episode 3387.000000, reward total was -21.000000. running mean: -20.291140\n",
            "resetting env. episode 3388.000000, reward total was -21.000000. running mean: -20.298229\n",
            "resetting env. episode 3389.000000, reward total was -21.000000. running mean: -20.305246\n",
            "resetting env. episode 3390.000000, reward total was -20.000000. running mean: -20.302194\n",
            "resetting env. episode 3391.000000, reward total was -21.000000. running mean: -20.309172\n",
            "resetting env. episode 3392.000000, reward total was -20.000000. running mean: -20.306080\n",
            "resetting env. episode 3393.000000, reward total was -21.000000. running mean: -20.313019\n",
            "resetting env. episode 3394.000000, reward total was -20.000000. running mean: -20.309889\n",
            "resetting env. episode 3395.000000, reward total was -21.000000. running mean: -20.316790\n",
            "resetting env. episode 3396.000000, reward total was -21.000000. running mean: -20.323622\n",
            "resetting env. episode 3397.000000, reward total was -20.000000. running mean: -20.320386\n",
            "resetting env. episode 3398.000000, reward total was -21.000000. running mean: -20.327182\n",
            "resetting env. episode 3399.000000, reward total was -21.000000. running mean: -20.333910\n",
            "resetting env. episode 3400.000000, reward total was -18.000000. running mean: -20.310571\n",
            "resetting env. episode 3401.000000, reward total was -21.000000. running mean: -20.317466\n",
            "resetting env. episode 3402.000000, reward total was -21.000000. running mean: -20.324291\n",
            "resetting env. episode 3403.000000, reward total was -21.000000. running mean: -20.331048\n",
            "resetting env. episode 3404.000000, reward total was -21.000000. running mean: -20.337738\n",
            "resetting env. episode 3405.000000, reward total was -21.000000. running mean: -20.344360\n",
            "resetting env. episode 3406.000000, reward total was -21.000000. running mean: -20.350917\n",
            "resetting env. episode 3407.000000, reward total was -20.000000. running mean: -20.347407\n",
            "resetting env. episode 3408.000000, reward total was -21.000000. running mean: -20.353933\n",
            "resetting env. episode 3409.000000, reward total was -20.000000. running mean: -20.350394\n",
            "resetting env. episode 3410.000000, reward total was -20.000000. running mean: -20.346890\n",
            "resetting env. episode 3411.000000, reward total was -21.000000. running mean: -20.353421\n",
            "resetting env. episode 3412.000000, reward total was -21.000000. running mean: -20.359887\n",
            "resetting env. episode 3413.000000, reward total was -21.000000. running mean: -20.366288\n",
            "resetting env. episode 3414.000000, reward total was -20.000000. running mean: -20.362625\n",
            "resetting env. episode 3415.000000, reward total was -20.000000. running mean: -20.358999\n",
            "resetting env. episode 3416.000000, reward total was -21.000000. running mean: -20.365409\n",
            "resetting env. episode 3417.000000, reward total was -20.000000. running mean: -20.361755\n",
            "resetting env. episode 3418.000000, reward total was -19.000000. running mean: -20.348137\n",
            "resetting env. episode 3419.000000, reward total was -19.000000. running mean: -20.334656\n",
            "resetting env. episode 3420.000000, reward total was -21.000000. running mean: -20.341309\n",
            "resetting env. episode 3421.000000, reward total was -21.000000. running mean: -20.347896\n",
            "resetting env. episode 3422.000000, reward total was -21.000000. running mean: -20.354417\n",
            "resetting env. episode 3423.000000, reward total was -19.000000. running mean: -20.340873\n",
            "resetting env. episode 3424.000000, reward total was -21.000000. running mean: -20.347464\n",
            "resetting env. episode 3425.000000, reward total was -20.000000. running mean: -20.343990\n",
            "resetting env. episode 3426.000000, reward total was -21.000000. running mean: -20.350550\n",
            "resetting env. episode 3427.000000, reward total was -21.000000. running mean: -20.357044\n",
            "resetting env. episode 3428.000000, reward total was -20.000000. running mean: -20.353474\n",
            "resetting env. episode 3429.000000, reward total was -21.000000. running mean: -20.359939\n",
            "resetting env. episode 3430.000000, reward total was -21.000000. running mean: -20.366340\n",
            "resetting env. episode 3431.000000, reward total was -21.000000. running mean: -20.372676\n",
            "resetting env. episode 3432.000000, reward total was -21.000000. running mean: -20.378950\n",
            "resetting env. episode 3433.000000, reward total was -21.000000. running mean: -20.385160\n",
            "resetting env. episode 3434.000000, reward total was -21.000000. running mean: -20.391309\n",
            "resetting env. episode 3435.000000, reward total was -21.000000. running mean: -20.397395\n",
            "resetting env. episode 3436.000000, reward total was -20.000000. running mean: -20.393422\n",
            "resetting env. episode 3437.000000, reward total was -21.000000. running mean: -20.399487\n",
            "resetting env. episode 3438.000000, reward total was -21.000000. running mean: -20.405492\n",
            "resetting env. episode 3439.000000, reward total was -21.000000. running mean: -20.411437\n",
            "resetting env. episode 3440.000000, reward total was -19.000000. running mean: -20.397323\n",
            "resetting env. episode 3441.000000, reward total was -21.000000. running mean: -20.403350\n",
            "resetting env. episode 3442.000000, reward total was -21.000000. running mean: -20.409316\n",
            "resetting env. episode 3443.000000, reward total was -20.000000. running mean: -20.405223\n",
            "resetting env. episode 3444.000000, reward total was -20.000000. running mean: -20.401171\n",
            "resetting env. episode 3445.000000, reward total was -17.000000. running mean: -20.367159\n",
            "resetting env. episode 3446.000000, reward total was -21.000000. running mean: -20.373488\n",
            "resetting env. episode 3447.000000, reward total was -20.000000. running mean: -20.369753\n",
            "resetting env. episode 3448.000000, reward total was -20.000000. running mean: -20.366055\n",
            "resetting env. episode 3449.000000, reward total was -21.000000. running mean: -20.372395\n",
            "resetting env. episode 3450.000000, reward total was -19.000000. running mean: -20.358671\n",
            "resetting env. episode 3451.000000, reward total was -21.000000. running mean: -20.365084\n",
            "resetting env. episode 3452.000000, reward total was -21.000000. running mean: -20.371433\n",
            "resetting env. episode 3453.000000, reward total was -20.000000. running mean: -20.367719\n",
            "resetting env. episode 3454.000000, reward total was -21.000000. running mean: -20.374042\n",
            "resetting env. episode 3455.000000, reward total was -21.000000. running mean: -20.380301\n",
            "resetting env. episode 3456.000000, reward total was -20.000000. running mean: -20.376498\n",
            "resetting env. episode 3457.000000, reward total was -21.000000. running mean: -20.382733\n",
            "resetting env. episode 3458.000000, reward total was -21.000000. running mean: -20.388906\n",
            "resetting env. episode 3459.000000, reward total was -21.000000. running mean: -20.395017\n",
            "resetting env. episode 3460.000000, reward total was -21.000000. running mean: -20.401067\n",
            "resetting env. episode 3461.000000, reward total was -21.000000. running mean: -20.407056\n",
            "resetting env. episode 3462.000000, reward total was -21.000000. running mean: -20.412986\n",
            "resetting env. episode 3463.000000, reward total was -21.000000. running mean: -20.418856\n",
            "resetting env. episode 3464.000000, reward total was -21.000000. running mean: -20.424667\n",
            "resetting env. episode 3465.000000, reward total was -21.000000. running mean: -20.430420\n",
            "resetting env. episode 3466.000000, reward total was -21.000000. running mean: -20.436116\n",
            "resetting env. episode 3467.000000, reward total was -21.000000. running mean: -20.441755\n",
            "resetting env. episode 3468.000000, reward total was -19.000000. running mean: -20.427338\n",
            "resetting env. episode 3469.000000, reward total was -21.000000. running mean: -20.433064\n",
            "resetting env. episode 3470.000000, reward total was -21.000000. running mean: -20.438733\n",
            "resetting env. episode 3471.000000, reward total was -21.000000. running mean: -20.444346\n",
            "resetting env. episode 3472.000000, reward total was -19.000000. running mean: -20.429903\n",
            "resetting env. episode 3473.000000, reward total was -20.000000. running mean: -20.425604\n",
            "resetting env. episode 3474.000000, reward total was -20.000000. running mean: -20.421348\n",
            "resetting env. episode 3475.000000, reward total was -21.000000. running mean: -20.427134\n",
            "resetting env. episode 3476.000000, reward total was -20.000000. running mean: -20.422863\n",
            "resetting env. episode 3477.000000, reward total was -20.000000. running mean: -20.418634\n",
            "resetting env. episode 3478.000000, reward total was -21.000000. running mean: -20.424448\n",
            "resetting env. episode 3479.000000, reward total was -21.000000. running mean: -20.430203\n",
            "resetting env. episode 3480.000000, reward total was -21.000000. running mean: -20.435901\n",
            "resetting env. episode 3481.000000, reward total was -21.000000. running mean: -20.441542\n",
            "resetting env. episode 3482.000000, reward total was -21.000000. running mean: -20.447127\n",
            "resetting env. episode 3483.000000, reward total was -21.000000. running mean: -20.452656\n",
            "resetting env. episode 3484.000000, reward total was -20.000000. running mean: -20.448129\n",
            "resetting env. episode 3485.000000, reward total was -21.000000. running mean: -20.453648\n",
            "resetting env. episode 3486.000000, reward total was -21.000000. running mean: -20.459111\n",
            "resetting env. episode 3487.000000, reward total was -21.000000. running mean: -20.464520\n",
            "resetting env. episode 3488.000000, reward total was -21.000000. running mean: -20.469875\n",
            "resetting env. episode 3489.000000, reward total was -19.000000. running mean: -20.455176\n",
            "resetting env. episode 3490.000000, reward total was -19.000000. running mean: -20.440624\n",
            "resetting env. episode 3491.000000, reward total was -21.000000. running mean: -20.446218\n",
            "resetting env. episode 3492.000000, reward total was -21.000000. running mean: -20.451756\n",
            "resetting env. episode 3493.000000, reward total was -17.000000. running mean: -20.417238\n",
            "resetting env. episode 3494.000000, reward total was -21.000000. running mean: -20.423066\n",
            "resetting env. episode 3495.000000, reward total was -20.000000. running mean: -20.418835\n",
            "resetting env. episode 3496.000000, reward total was -21.000000. running mean: -20.424647\n",
            "resetting env. episode 3497.000000, reward total was -20.000000. running mean: -20.420401\n",
            "resetting env. episode 3498.000000, reward total was -20.000000. running mean: -20.416197\n",
            "resetting env. episode 3499.000000, reward total was -20.000000. running mean: -20.412035\n",
            "resetting env. episode 3500.000000, reward total was -20.000000. running mean: -20.407914\n",
            "resetting env. episode 3501.000000, reward total was -19.000000. running mean: -20.393835\n",
            "resetting env. episode 3502.000000, reward total was -21.000000. running mean: -20.399897\n",
            "resetting env. episode 3503.000000, reward total was -19.000000. running mean: -20.385898\n",
            "resetting env. episode 3504.000000, reward total was -19.000000. running mean: -20.372039\n",
            "resetting env. episode 3505.000000, reward total was -19.000000. running mean: -20.358318\n",
            "resetting env. episode 3506.000000, reward total was -20.000000. running mean: -20.354735\n",
            "resetting env. episode 3507.000000, reward total was -21.000000. running mean: -20.361188\n",
            "resetting env. episode 3508.000000, reward total was -20.000000. running mean: -20.357576\n",
            "resetting env. episode 3509.000000, reward total was -21.000000. running mean: -20.364000\n",
            "resetting env. episode 3510.000000, reward total was -20.000000. running mean: -20.360360\n",
            "resetting env. episode 3511.000000, reward total was -21.000000. running mean: -20.366757\n",
            "resetting env. episode 3512.000000, reward total was -21.000000. running mean: -20.373089\n",
            "resetting env. episode 3513.000000, reward total was -21.000000. running mean: -20.379358\n",
            "resetting env. episode 3514.000000, reward total was -21.000000. running mean: -20.385565\n",
            "resetting env. episode 3515.000000, reward total was -21.000000. running mean: -20.391709\n",
            "resetting env. episode 3516.000000, reward total was -19.000000. running mean: -20.377792\n",
            "resetting env. episode 3517.000000, reward total was -19.000000. running mean: -20.364014\n",
            "resetting env. episode 3518.000000, reward total was -21.000000. running mean: -20.370374\n",
            "resetting env. episode 3519.000000, reward total was -19.000000. running mean: -20.356670\n",
            "resetting env. episode 3520.000000, reward total was -20.000000. running mean: -20.353103\n",
            "resetting env. episode 3521.000000, reward total was -21.000000. running mean: -20.359572\n",
            "resetting env. episode 3522.000000, reward total was -21.000000. running mean: -20.365977\n",
            "resetting env. episode 3523.000000, reward total was -21.000000. running mean: -20.372317\n",
            "resetting env. episode 3524.000000, reward total was -19.000000. running mean: -20.358594\n",
            "resetting env. episode 3525.000000, reward total was -21.000000. running mean: -20.365008\n",
            "resetting env. episode 3526.000000, reward total was -21.000000. running mean: -20.371358\n",
            "resetting env. episode 3527.000000, reward total was -21.000000. running mean: -20.377644\n",
            "resetting env. episode 3528.000000, reward total was -19.000000. running mean: -20.363868\n",
            "resetting env. episode 3529.000000, reward total was -21.000000. running mean: -20.370229\n",
            "resetting env. episode 3530.000000, reward total was -21.000000. running mean: -20.376527\n",
            "resetting env. episode 3531.000000, reward total was -21.000000. running mean: -20.382761\n",
            "resetting env. episode 3532.000000, reward total was -21.000000. running mean: -20.388934\n",
            "resetting env. episode 3533.000000, reward total was -21.000000. running mean: -20.395044\n",
            "resetting env. episode 3534.000000, reward total was -21.000000. running mean: -20.401094\n",
            "resetting env. episode 3535.000000, reward total was -21.000000. running mean: -20.407083\n",
            "resetting env. episode 3536.000000, reward total was -21.000000. running mean: -20.413012\n",
            "resetting env. episode 3537.000000, reward total was -21.000000. running mean: -20.418882\n",
            "resetting env. episode 3538.000000, reward total was -21.000000. running mean: -20.424693\n",
            "resetting env. episode 3539.000000, reward total was -21.000000. running mean: -20.430446\n",
            "resetting env. episode 3540.000000, reward total was -21.000000. running mean: -20.436142\n",
            "resetting env. episode 3541.000000, reward total was -21.000000. running mean: -20.441781\n",
            "resetting env. episode 3542.000000, reward total was -20.000000. running mean: -20.437363\n",
            "resetting env. episode 3543.000000, reward total was -21.000000. running mean: -20.442989\n",
            "resetting env. episode 3544.000000, reward total was -21.000000. running mean: -20.448559\n",
            "resetting env. episode 3545.000000, reward total was -21.000000. running mean: -20.454074\n",
            "resetting env. episode 3546.000000, reward total was -21.000000. running mean: -20.459533\n",
            "resetting env. episode 3547.000000, reward total was -21.000000. running mean: -20.464938\n",
            "resetting env. episode 3548.000000, reward total was -19.000000. running mean: -20.450288\n",
            "resetting env. episode 3549.000000, reward total was -20.000000. running mean: -20.445785\n",
            "resetting env. episode 3550.000000, reward total was -21.000000. running mean: -20.451327\n",
            "resetting env. episode 3551.000000, reward total was -21.000000. running mean: -20.456814\n",
            "resetting env. episode 3552.000000, reward total was -21.000000. running mean: -20.462246\n",
            "resetting env. episode 3553.000000, reward total was -21.000000. running mean: -20.467624\n",
            "resetting env. episode 3554.000000, reward total was -20.000000. running mean: -20.462947\n",
            "resetting env. episode 3555.000000, reward total was -20.000000. running mean: -20.458318\n",
            "resetting env. episode 3556.000000, reward total was -21.000000. running mean: -20.463735\n",
            "resetting env. episode 3557.000000, reward total was -21.000000. running mean: -20.469097\n",
            "resetting env. episode 3558.000000, reward total was -21.000000. running mean: -20.474406\n",
            "resetting env. episode 3559.000000, reward total was -21.000000. running mean: -20.479662\n",
            "resetting env. episode 3560.000000, reward total was -20.000000. running mean: -20.474866\n",
            "resetting env. episode 3561.000000, reward total was -21.000000. running mean: -20.480117\n",
            "resetting env. episode 3562.000000, reward total was -21.000000. running mean: -20.485316\n",
            "resetting env. episode 3563.000000, reward total was -21.000000. running mean: -20.490463\n",
            "resetting env. episode 3564.000000, reward total was -21.000000. running mean: -20.495558\n",
            "resetting env. episode 3565.000000, reward total was -21.000000. running mean: -20.500602\n",
            "resetting env. episode 3566.000000, reward total was -19.000000. running mean: -20.485596\n",
            "resetting env. episode 3567.000000, reward total was -20.000000. running mean: -20.480740\n",
            "resetting env. episode 3568.000000, reward total was -21.000000. running mean: -20.485933\n",
            "resetting env. episode 3569.000000, reward total was -21.000000. running mean: -20.491074\n",
            "resetting env. episode 3570.000000, reward total was -21.000000. running mean: -20.496163\n",
            "resetting env. episode 3571.000000, reward total was -21.000000. running mean: -20.501201\n",
            "resetting env. episode 3572.000000, reward total was -21.000000. running mean: -20.506189\n",
            "resetting env. episode 3573.000000, reward total was -21.000000. running mean: -20.511127\n",
            "resetting env. episode 3574.000000, reward total was -14.000000. running mean: -20.446016\n",
            "resetting env. episode 3575.000000, reward total was -20.000000. running mean: -20.441556\n",
            "resetting env. episode 3576.000000, reward total was -21.000000. running mean: -20.447140\n",
            "resetting env. episode 3577.000000, reward total was -21.000000. running mean: -20.452669\n",
            "resetting env. episode 3578.000000, reward total was -21.000000. running mean: -20.458142\n",
            "resetting env. episode 3579.000000, reward total was -20.000000. running mean: -20.453561\n",
            "resetting env. episode 3580.000000, reward total was -21.000000. running mean: -20.459025\n",
            "resetting env. episode 3581.000000, reward total was -20.000000. running mean: -20.454435\n",
            "resetting env. episode 3582.000000, reward total was -21.000000. running mean: -20.459891\n",
            "resetting env. episode 3583.000000, reward total was -20.000000. running mean: -20.455292\n",
            "resetting env. episode 3584.000000, reward total was -21.000000. running mean: -20.460739\n",
            "resetting env. episode 3585.000000, reward total was -20.000000. running mean: -20.456132\n",
            "resetting env. episode 3586.000000, reward total was -21.000000. running mean: -20.461570\n",
            "resetting env. episode 3587.000000, reward total was -21.000000. running mean: -20.466955\n",
            "resetting env. episode 3588.000000, reward total was -21.000000. running mean: -20.472285\n",
            "resetting env. episode 3589.000000, reward total was -21.000000. running mean: -20.477562\n",
            "resetting env. episode 3590.000000, reward total was -20.000000. running mean: -20.472786\n",
            "resetting env. episode 3591.000000, reward total was -21.000000. running mean: -20.478059\n",
            "resetting env. episode 3592.000000, reward total was -20.000000. running mean: -20.473278\n",
            "resetting env. episode 3593.000000, reward total was -21.000000. running mean: -20.478545\n",
            "resetting env. episode 3594.000000, reward total was -21.000000. running mean: -20.483760\n",
            "resetting env. episode 3595.000000, reward total was -21.000000. running mean: -20.488922\n",
            "resetting env. episode 3596.000000, reward total was -21.000000. running mean: -20.494033\n",
            "resetting env. episode 3597.000000, reward total was -18.000000. running mean: -20.469093\n",
            "resetting env. episode 3598.000000, reward total was -18.000000. running mean: -20.444402\n",
            "resetting env. episode 3599.000000, reward total was -20.000000. running mean: -20.439958\n",
            "resetting env. episode 3600.000000, reward total was -21.000000. running mean: -20.445558\n",
            "resetting env. episode 3601.000000, reward total was -21.000000. running mean: -20.451103\n",
            "resetting env. episode 3602.000000, reward total was -17.000000. running mean: -20.416592\n",
            "resetting env. episode 3603.000000, reward total was -20.000000. running mean: -20.412426\n",
            "resetting env. episode 3604.000000, reward total was -20.000000. running mean: -20.408301\n",
            "resetting env. episode 3605.000000, reward total was -20.000000. running mean: -20.404218\n",
            "resetting env. episode 3606.000000, reward total was -19.000000. running mean: -20.390176\n",
            "resetting env. episode 3607.000000, reward total was -21.000000. running mean: -20.396274\n",
            "resetting env. episode 3608.000000, reward total was -21.000000. running mean: -20.402312\n",
            "resetting env. episode 3609.000000, reward total was -21.000000. running mean: -20.408289\n",
            "resetting env. episode 3610.000000, reward total was -19.000000. running mean: -20.394206\n",
            "resetting env. episode 3611.000000, reward total was -21.000000. running mean: -20.400264\n",
            "resetting env. episode 3612.000000, reward total was -21.000000. running mean: -20.406261\n",
            "resetting env. episode 3613.000000, reward total was -21.000000. running mean: -20.412198\n",
            "resetting env. episode 3614.000000, reward total was -20.000000. running mean: -20.408076\n",
            "resetting env. episode 3615.000000, reward total was -21.000000. running mean: -20.413996\n",
            "resetting env. episode 3616.000000, reward total was -21.000000. running mean: -20.419856\n",
            "resetting env. episode 3617.000000, reward total was -21.000000. running mean: -20.425657\n",
            "resetting env. episode 3618.000000, reward total was -21.000000. running mean: -20.431401\n",
            "resetting env. episode 3619.000000, reward total was -21.000000. running mean: -20.437087\n",
            "resetting env. episode 3620.000000, reward total was -20.000000. running mean: -20.432716\n",
            "resetting env. episode 3621.000000, reward total was -19.000000. running mean: -20.418388\n",
            "resetting env. episode 3622.000000, reward total was -20.000000. running mean: -20.414205\n",
            "resetting env. episode 3623.000000, reward total was -21.000000. running mean: -20.420063\n",
            "resetting env. episode 3624.000000, reward total was -21.000000. running mean: -20.425862\n",
            "resetting env. episode 3625.000000, reward total was -21.000000. running mean: -20.431603\n",
            "resetting env. episode 3626.000000, reward total was -20.000000. running mean: -20.427287\n",
            "resetting env. episode 3627.000000, reward total was -20.000000. running mean: -20.423014\n",
            "resetting env. episode 3628.000000, reward total was -21.000000. running mean: -20.428784\n",
            "resetting env. episode 3629.000000, reward total was -21.000000. running mean: -20.434496\n",
            "resetting env. episode 3630.000000, reward total was -20.000000. running mean: -20.430151\n",
            "resetting env. episode 3631.000000, reward total was -20.000000. running mean: -20.425850\n",
            "resetting env. episode 3632.000000, reward total was -21.000000. running mean: -20.431591\n",
            "resetting env. episode 3633.000000, reward total was -21.000000. running mean: -20.437276\n",
            "resetting env. episode 3634.000000, reward total was -20.000000. running mean: -20.432903\n",
            "resetting env. episode 3635.000000, reward total was -20.000000. running mean: -20.428574\n",
            "resetting env. episode 3636.000000, reward total was -21.000000. running mean: -20.434288\n",
            "resetting env. episode 3637.000000, reward total was -21.000000. running mean: -20.439945\n",
            "resetting env. episode 3638.000000, reward total was -21.000000. running mean: -20.445546\n",
            "resetting env. episode 3639.000000, reward total was -21.000000. running mean: -20.451090\n",
            "resetting env. episode 3640.000000, reward total was -20.000000. running mean: -20.446579\n",
            "resetting env. episode 3641.000000, reward total was -21.000000. running mean: -20.452114\n",
            "resetting env. episode 3642.000000, reward total was -21.000000. running mean: -20.457592\n",
            "resetting env. episode 3643.000000, reward total was -21.000000. running mean: -20.463016\n",
            "resetting env. episode 3644.000000, reward total was -18.000000. running mean: -20.438386\n",
            "resetting env. episode 3645.000000, reward total was -19.000000. running mean: -20.424002\n",
            "resetting env. episode 3646.000000, reward total was -20.000000. running mean: -20.419762\n",
            "resetting env. episode 3647.000000, reward total was -18.000000. running mean: -20.395565\n",
            "resetting env. episode 3648.000000, reward total was -20.000000. running mean: -20.391609\n",
            "resetting env. episode 3649.000000, reward total was -21.000000. running mean: -20.397693\n",
            "resetting env. episode 3650.000000, reward total was -21.000000. running mean: -20.403716\n",
            "resetting env. episode 3651.000000, reward total was -20.000000. running mean: -20.399679\n",
            "resetting env. episode 3652.000000, reward total was -21.000000. running mean: -20.405682\n",
            "resetting env. episode 3653.000000, reward total was -20.000000. running mean: -20.401625\n",
            "resetting env. episode 3654.000000, reward total was -20.000000. running mean: -20.397609\n",
            "resetting env. episode 3655.000000, reward total was -19.000000. running mean: -20.383633\n",
            "resetting env. episode 3656.000000, reward total was -20.000000. running mean: -20.379797\n",
            "resetting env. episode 3657.000000, reward total was -21.000000. running mean: -20.385999\n",
            "resetting env. episode 3658.000000, reward total was -21.000000. running mean: -20.392139\n",
            "resetting env. episode 3659.000000, reward total was -21.000000. running mean: -20.398217\n",
            "resetting env. episode 3660.000000, reward total was -21.000000. running mean: -20.404235\n",
            "resetting env. episode 3661.000000, reward total was -21.000000. running mean: -20.410193\n",
            "resetting env. episode 3662.000000, reward total was -20.000000. running mean: -20.406091\n",
            "resetting env. episode 3663.000000, reward total was -21.000000. running mean: -20.412030\n",
            "resetting env. episode 3664.000000, reward total was -21.000000. running mean: -20.417910\n",
            "resetting env. episode 3665.000000, reward total was -21.000000. running mean: -20.423731\n",
            "resetting env. episode 3666.000000, reward total was -20.000000. running mean: -20.419493\n",
            "resetting env. episode 3667.000000, reward total was -20.000000. running mean: -20.415298\n",
            "resetting env. episode 3668.000000, reward total was -21.000000. running mean: -20.421145\n",
            "resetting env. episode 3669.000000, reward total was -17.000000. running mean: -20.386934\n",
            "resetting env. episode 3670.000000, reward total was -21.000000. running mean: -20.393065\n",
            "resetting env. episode 3671.000000, reward total was -21.000000. running mean: -20.399134\n",
            "resetting env. episode 3672.000000, reward total was -19.000000. running mean: -20.385143\n",
            "resetting env. episode 3673.000000, reward total was -18.000000. running mean: -20.361291\n",
            "resetting env. episode 3674.000000, reward total was -21.000000. running mean: -20.367678\n",
            "resetting env. episode 3675.000000, reward total was -21.000000. running mean: -20.374001\n",
            "resetting env. episode 3676.000000, reward total was -20.000000. running mean: -20.370261\n",
            "resetting env. episode 3677.000000, reward total was -21.000000. running mean: -20.376559\n",
            "resetting env. episode 3678.000000, reward total was -20.000000. running mean: -20.372793\n",
            "resetting env. episode 3679.000000, reward total was -19.000000. running mean: -20.359065\n",
            "resetting env. episode 3680.000000, reward total was -21.000000. running mean: -20.365475\n",
            "resetting env. episode 3681.000000, reward total was -19.000000. running mean: -20.351820\n",
            "resetting env. episode 3682.000000, reward total was -21.000000. running mean: -20.358302\n",
            "resetting env. episode 3683.000000, reward total was -21.000000. running mean: -20.364719\n",
            "resetting env. episode 3684.000000, reward total was -21.000000. running mean: -20.371072\n",
            "resetting env. episode 3685.000000, reward total was -20.000000. running mean: -20.367361\n",
            "resetting env. episode 3686.000000, reward total was -21.000000. running mean: -20.373687\n",
            "resetting env. episode 3687.000000, reward total was -21.000000. running mean: -20.379950\n",
            "resetting env. episode 3688.000000, reward total was -20.000000. running mean: -20.376151\n",
            "resetting env. episode 3689.000000, reward total was -21.000000. running mean: -20.382389\n",
            "resetting env. episode 3690.000000, reward total was -21.000000. running mean: -20.388565\n",
            "resetting env. episode 3691.000000, reward total was -21.000000. running mean: -20.394680\n",
            "resetting env. episode 3692.000000, reward total was -21.000000. running mean: -20.400733\n",
            "resetting env. episode 3693.000000, reward total was -21.000000. running mean: -20.406726\n",
            "resetting env. episode 3694.000000, reward total was -20.000000. running mean: -20.402658\n",
            "resetting env. episode 3695.000000, reward total was -21.000000. running mean: -20.408632\n",
            "resetting env. episode 3696.000000, reward total was -21.000000. running mean: -20.414545\n",
            "resetting env. episode 3697.000000, reward total was -20.000000. running mean: -20.410400\n",
            "resetting env. episode 3698.000000, reward total was -18.000000. running mean: -20.386296\n",
            "resetting env. episode 3699.000000, reward total was -21.000000. running mean: -20.392433\n",
            "resetting env. episode 3700.000000, reward total was -17.000000. running mean: -20.358509\n",
            "resetting env. episode 3701.000000, reward total was -20.000000. running mean: -20.354924\n",
            "resetting env. episode 3702.000000, reward total was -21.000000. running mean: -20.361374\n",
            "resetting env. episode 3703.000000, reward total was -21.000000. running mean: -20.367761\n",
            "resetting env. episode 3704.000000, reward total was -20.000000. running mean: -20.364083\n",
            "resetting env. episode 3705.000000, reward total was -21.000000. running mean: -20.370442\n",
            "resetting env. episode 3706.000000, reward total was -20.000000. running mean: -20.366738\n",
            "resetting env. episode 3707.000000, reward total was -20.000000. running mean: -20.363070\n",
            "resetting env. episode 3708.000000, reward total was -21.000000. running mean: -20.369440\n",
            "resetting env. episode 3709.000000, reward total was -21.000000. running mean: -20.375745\n",
            "resetting env. episode 3710.000000, reward total was -21.000000. running mean: -20.381988\n",
            "resetting env. episode 3711.000000, reward total was -20.000000. running mean: -20.378168\n",
            "resetting env. episode 3712.000000, reward total was -21.000000. running mean: -20.384386\n",
            "resetting env. episode 3713.000000, reward total was -21.000000. running mean: -20.390542\n",
            "resetting env. episode 3714.000000, reward total was -21.000000. running mean: -20.396637\n",
            "resetting env. episode 3715.000000, reward total was -21.000000. running mean: -20.402671\n",
            "resetting env. episode 3716.000000, reward total was -19.000000. running mean: -20.388644\n",
            "resetting env. episode 3717.000000, reward total was -21.000000. running mean: -20.394758\n",
            "resetting env. episode 3718.000000, reward total was -21.000000. running mean: -20.400810\n",
            "resetting env. episode 3719.000000, reward total was -21.000000. running mean: -20.406802\n",
            "resetting env. episode 3720.000000, reward total was -21.000000. running mean: -20.412734\n",
            "resetting env. episode 3721.000000, reward total was -21.000000. running mean: -20.418606\n",
            "resetting env. episode 3722.000000, reward total was -20.000000. running mean: -20.414420\n",
            "resetting env. episode 3723.000000, reward total was -20.000000. running mean: -20.410276\n",
            "resetting env. episode 3724.000000, reward total was -18.000000. running mean: -20.386173\n",
            "resetting env. episode 3725.000000, reward total was -21.000000. running mean: -20.392312\n",
            "resetting env. episode 3726.000000, reward total was -21.000000. running mean: -20.398389\n",
            "resetting env. episode 3727.000000, reward total was -21.000000. running mean: -20.404405\n",
            "resetting env. episode 3728.000000, reward total was -21.000000. running mean: -20.410361\n",
            "resetting env. episode 3729.000000, reward total was -20.000000. running mean: -20.406257\n",
            "resetting env. episode 3730.000000, reward total was -21.000000. running mean: -20.412194\n",
            "resetting env. episode 3731.000000, reward total was -21.000000. running mean: -20.418073\n",
            "resetting env. episode 3732.000000, reward total was -20.000000. running mean: -20.413892\n",
            "resetting env. episode 3733.000000, reward total was -21.000000. running mean: -20.419753\n",
            "resetting env. episode 3734.000000, reward total was -21.000000. running mean: -20.425555\n",
            "resetting env. episode 3735.000000, reward total was -18.000000. running mean: -20.401300\n",
            "resetting env. episode 3736.000000, reward total was -21.000000. running mean: -20.407287\n",
            "resetting env. episode 3737.000000, reward total was -20.000000. running mean: -20.403214\n",
            "resetting env. episode 3738.000000, reward total was -19.000000. running mean: -20.389182\n",
            "resetting env. episode 3739.000000, reward total was -19.000000. running mean: -20.375290\n",
            "resetting env. episode 3740.000000, reward total was -18.000000. running mean: -20.351537\n",
            "resetting env. episode 3741.000000, reward total was -21.000000. running mean: -20.358022\n",
            "resetting env. episode 3742.000000, reward total was -21.000000. running mean: -20.364441\n",
            "resetting env. episode 3743.000000, reward total was -21.000000. running mean: -20.370797\n",
            "resetting env. episode 3744.000000, reward total was -20.000000. running mean: -20.367089\n",
            "resetting env. episode 3745.000000, reward total was -21.000000. running mean: -20.373418\n",
            "resetting env. episode 3746.000000, reward total was -21.000000. running mean: -20.379684\n",
            "resetting env. episode 3747.000000, reward total was -21.000000. running mean: -20.385887\n",
            "resetting env. episode 3748.000000, reward total was -21.000000. running mean: -20.392028\n",
            "resetting env. episode 3749.000000, reward total was -21.000000. running mean: -20.398108\n",
            "resetting env. episode 3750.000000, reward total was -19.000000. running mean: -20.384127\n",
            "resetting env. episode 3751.000000, reward total was -21.000000. running mean: -20.390286\n",
            "resetting env. episode 3752.000000, reward total was -21.000000. running mean: -20.396383\n",
            "resetting env. episode 3753.000000, reward total was -20.000000. running mean: -20.392419\n",
            "resetting env. episode 3754.000000, reward total was -20.000000. running mean: -20.388495\n",
            "resetting env. episode 3755.000000, reward total was -20.000000. running mean: -20.384610\n",
            "resetting env. episode 3756.000000, reward total was -21.000000. running mean: -20.390764\n",
            "resetting env. episode 3757.000000, reward total was -21.000000. running mean: -20.396856\n",
            "resetting env. episode 3758.000000, reward total was -20.000000. running mean: -20.392888\n",
            "resetting env. episode 3759.000000, reward total was -21.000000. running mean: -20.398959\n",
            "resetting env. episode 3760.000000, reward total was -20.000000. running mean: -20.394969\n",
            "resetting env. episode 3761.000000, reward total was -20.000000. running mean: -20.391019\n",
            "resetting env. episode 3762.000000, reward total was -21.000000. running mean: -20.397109\n",
            "resetting env. episode 3763.000000, reward total was -20.000000. running mean: -20.393138\n",
            "resetting env. episode 3764.000000, reward total was -21.000000. running mean: -20.399207\n",
            "resetting env. episode 3765.000000, reward total was -20.000000. running mean: -20.395215\n",
            "resetting env. episode 3766.000000, reward total was -21.000000. running mean: -20.401263\n",
            "resetting env. episode 3767.000000, reward total was -20.000000. running mean: -20.397250\n",
            "resetting env. episode 3768.000000, reward total was -21.000000. running mean: -20.403277\n",
            "resetting env. episode 3769.000000, reward total was -20.000000. running mean: -20.399245\n",
            "resetting env. episode 3770.000000, reward total was -21.000000. running mean: -20.405252\n",
            "resetting env. episode 3771.000000, reward total was -21.000000. running mean: -20.411200\n",
            "resetting env. episode 3772.000000, reward total was -21.000000. running mean: -20.417088\n",
            "resetting env. episode 3773.000000, reward total was -20.000000. running mean: -20.412917\n",
            "resetting env. episode 3774.000000, reward total was -21.000000. running mean: -20.418788\n",
            "resetting env. episode 3775.000000, reward total was -18.000000. running mean: -20.394600\n",
            "resetting env. episode 3776.000000, reward total was -21.000000. running mean: -20.400654\n",
            "resetting env. episode 3777.000000, reward total was -21.000000. running mean: -20.406647\n",
            "resetting env. episode 3778.000000, reward total was -21.000000. running mean: -20.412581\n",
            "resetting env. episode 3779.000000, reward total was -20.000000. running mean: -20.408455\n",
            "resetting env. episode 3780.000000, reward total was -21.000000. running mean: -20.414370\n",
            "resetting env. episode 3781.000000, reward total was -21.000000. running mean: -20.420227\n",
            "resetting env. episode 3782.000000, reward total was -21.000000. running mean: -20.426024\n",
            "resetting env. episode 3783.000000, reward total was -21.000000. running mean: -20.431764\n",
            "resetting env. episode 3784.000000, reward total was -20.000000. running mean: -20.427447\n",
            "resetting env. episode 3785.000000, reward total was -21.000000. running mean: -20.433172\n",
            "resetting env. episode 3786.000000, reward total was -21.000000. running mean: -20.438840\n",
            "resetting env. episode 3787.000000, reward total was -21.000000. running mean: -20.444452\n",
            "resetting env. episode 3788.000000, reward total was -20.000000. running mean: -20.440007\n",
            "resetting env. episode 3789.000000, reward total was -20.000000. running mean: -20.435607\n",
            "resetting env. episode 3790.000000, reward total was -20.000000. running mean: -20.431251\n",
            "resetting env. episode 3791.000000, reward total was -21.000000. running mean: -20.436939\n",
            "resetting env. episode 3792.000000, reward total was -20.000000. running mean: -20.432569\n",
            "resetting env. episode 3793.000000, reward total was -19.000000. running mean: -20.418244\n",
            "resetting env. episode 3794.000000, reward total was -21.000000. running mean: -20.424061\n",
            "resetting env. episode 3795.000000, reward total was -21.000000. running mean: -20.429821\n",
            "resetting env. episode 3796.000000, reward total was -20.000000. running mean: -20.425522\n",
            "resetting env. episode 3797.000000, reward total was -19.000000. running mean: -20.411267\n",
            "resetting env. episode 3798.000000, reward total was -21.000000. running mean: -20.417155\n",
            "resetting env. episode 3799.000000, reward total was -20.000000. running mean: -20.412983\n",
            "resetting env. episode 3800.000000, reward total was -21.000000. running mean: -20.418853\n",
            "resetting env. episode 3801.000000, reward total was -21.000000. running mean: -20.424665\n",
            "resetting env. episode 3802.000000, reward total was -20.000000. running mean: -20.420418\n",
            "resetting env. episode 3803.000000, reward total was -19.000000. running mean: -20.406214\n",
            "resetting env. episode 3804.000000, reward total was -19.000000. running mean: -20.392152\n",
            "resetting env. episode 3805.000000, reward total was -21.000000. running mean: -20.398230\n",
            "resetting env. episode 3806.000000, reward total was -21.000000. running mean: -20.404248\n",
            "resetting env. episode 3807.000000, reward total was -21.000000. running mean: -20.410205\n",
            "resetting env. episode 3808.000000, reward total was -21.000000. running mean: -20.416103\n",
            "resetting env. episode 3809.000000, reward total was -20.000000. running mean: -20.411942\n",
            "resetting env. episode 3810.000000, reward total was -19.000000. running mean: -20.397823\n",
            "resetting env. episode 3811.000000, reward total was -21.000000. running mean: -20.403845\n",
            "resetting env. episode 3812.000000, reward total was -20.000000. running mean: -20.399806\n",
            "resetting env. episode 3813.000000, reward total was -21.000000. running mean: -20.405808\n",
            "resetting env. episode 3814.000000, reward total was -20.000000. running mean: -20.401750\n",
            "resetting env. episode 3815.000000, reward total was -18.000000. running mean: -20.377733\n",
            "resetting env. episode 3816.000000, reward total was -21.000000. running mean: -20.383955\n",
            "resetting env. episode 3817.000000, reward total was -21.000000. running mean: -20.390116\n",
            "resetting env. episode 3818.000000, reward total was -21.000000. running mean: -20.396214\n",
            "resetting env. episode 3819.000000, reward total was -21.000000. running mean: -20.402252\n",
            "resetting env. episode 3820.000000, reward total was -20.000000. running mean: -20.398230\n",
            "resetting env. episode 3821.000000, reward total was -21.000000. running mean: -20.404248\n",
            "resetting env. episode 3822.000000, reward total was -21.000000. running mean: -20.410205\n",
            "resetting env. episode 3823.000000, reward total was -19.000000. running mean: -20.396103\n",
            "resetting env. episode 3824.000000, reward total was -20.000000. running mean: -20.392142\n",
            "resetting env. episode 3825.000000, reward total was -20.000000. running mean: -20.388221\n",
            "resetting env. episode 3826.000000, reward total was -20.000000. running mean: -20.384338\n",
            "resetting env. episode 3827.000000, reward total was -21.000000. running mean: -20.390495\n",
            "resetting env. episode 3828.000000, reward total was -20.000000. running mean: -20.386590\n",
            "resetting env. episode 3829.000000, reward total was -20.000000. running mean: -20.382724\n",
            "resetting env. episode 3830.000000, reward total was -20.000000. running mean: -20.378897\n",
            "resetting env. episode 3831.000000, reward total was -20.000000. running mean: -20.375108\n",
            "resetting env. episode 3832.000000, reward total was -21.000000. running mean: -20.381357\n",
            "resetting env. episode 3833.000000, reward total was -20.000000. running mean: -20.377543\n",
            "resetting env. episode 3834.000000, reward total was -21.000000. running mean: -20.383768\n",
            "resetting env. episode 3835.000000, reward total was -21.000000. running mean: -20.389930\n",
            "resetting env. episode 3836.000000, reward total was -21.000000. running mean: -20.396031\n",
            "resetting env. episode 3837.000000, reward total was -20.000000. running mean: -20.392071\n",
            "resetting env. episode 3838.000000, reward total was -21.000000. running mean: -20.398150\n",
            "resetting env. episode 3839.000000, reward total was -21.000000. running mean: -20.404168\n",
            "resetting env. episode 3840.000000, reward total was -21.000000. running mean: -20.410127\n",
            "resetting env. episode 3841.000000, reward total was -21.000000. running mean: -20.416025\n",
            "resetting env. episode 3842.000000, reward total was -21.000000. running mean: -20.421865\n",
            "resetting env. episode 3843.000000, reward total was -21.000000. running mean: -20.427646\n",
            "resetting env. episode 3844.000000, reward total was -20.000000. running mean: -20.423370\n",
            "resetting env. episode 3845.000000, reward total was -21.000000. running mean: -20.429136\n",
            "resetting env. episode 3846.000000, reward total was -21.000000. running mean: -20.434845\n",
            "resetting env. episode 3847.000000, reward total was -21.000000. running mean: -20.440497\n",
            "resetting env. episode 3848.000000, reward total was -21.000000. running mean: -20.446092\n",
            "resetting env. episode 3849.000000, reward total was -21.000000. running mean: -20.451631\n",
            "resetting env. episode 3850.000000, reward total was -20.000000. running mean: -20.447114\n",
            "resetting env. episode 3851.000000, reward total was -21.000000. running mean: -20.452643\n",
            "resetting env. episode 3852.000000, reward total was -21.000000. running mean: -20.458117\n",
            "resetting env. episode 3853.000000, reward total was -20.000000. running mean: -20.453536\n",
            "resetting env. episode 3854.000000, reward total was -21.000000. running mean: -20.459000\n",
            "resetting env. episode 3855.000000, reward total was -21.000000. running mean: -20.464410\n",
            "resetting env. episode 3856.000000, reward total was -17.000000. running mean: -20.429766\n",
            "resetting env. episode 3857.000000, reward total was -21.000000. running mean: -20.435468\n",
            "resetting env. episode 3858.000000, reward total was -18.000000. running mean: -20.411114\n",
            "resetting env. episode 3859.000000, reward total was -21.000000. running mean: -20.417003\n",
            "resetting env. episode 3860.000000, reward total was -19.000000. running mean: -20.402833\n",
            "resetting env. episode 3861.000000, reward total was -21.000000. running mean: -20.408804\n",
            "resetting env. episode 3862.000000, reward total was -17.000000. running mean: -20.374716\n",
            "resetting env. episode 3863.000000, reward total was -21.000000. running mean: -20.380969\n",
            "resetting env. episode 3864.000000, reward total was -21.000000. running mean: -20.387159\n",
            "resetting env. episode 3865.000000, reward total was -20.000000. running mean: -20.383288\n",
            "resetting env. episode 3866.000000, reward total was -21.000000. running mean: -20.389455\n",
            "resetting env. episode 3867.000000, reward total was -21.000000. running mean: -20.395560\n",
            "resetting env. episode 3868.000000, reward total was -19.000000. running mean: -20.381605\n",
            "resetting env. episode 3869.000000, reward total was -21.000000. running mean: -20.387789\n",
            "resetting env. episode 3870.000000, reward total was -21.000000. running mean: -20.393911\n",
            "resetting env. episode 3871.000000, reward total was -21.000000. running mean: -20.399972\n",
            "resetting env. episode 3872.000000, reward total was -21.000000. running mean: -20.405972\n",
            "resetting env. episode 3873.000000, reward total was -18.000000. running mean: -20.381912\n",
            "resetting env. episode 3874.000000, reward total was -20.000000. running mean: -20.378093\n",
            "resetting env. episode 3875.000000, reward total was -21.000000. running mean: -20.384312\n",
            "resetting env. episode 3876.000000, reward total was -21.000000. running mean: -20.390469\n",
            "resetting env. episode 3877.000000, reward total was -20.000000. running mean: -20.386564\n",
            "resetting env. episode 3878.000000, reward total was -20.000000. running mean: -20.382699\n",
            "resetting env. episode 3879.000000, reward total was -18.000000. running mean: -20.358872\n",
            "resetting env. episode 3880.000000, reward total was -21.000000. running mean: -20.365283\n",
            "resetting env. episode 3881.000000, reward total was -21.000000. running mean: -20.371630\n",
            "resetting env. episode 3882.000000, reward total was -21.000000. running mean: -20.377914\n",
            "resetting env. episode 3883.000000, reward total was -21.000000. running mean: -20.384135\n",
            "resetting env. episode 3884.000000, reward total was -20.000000. running mean: -20.380293\n",
            "resetting env. episode 3885.000000, reward total was -21.000000. running mean: -20.386491\n",
            "resetting env. episode 3886.000000, reward total was -20.000000. running mean: -20.382626\n",
            "resetting env. episode 3887.000000, reward total was -21.000000. running mean: -20.388799\n",
            "resetting env. episode 3888.000000, reward total was -20.000000. running mean: -20.384911\n",
            "resetting env. episode 3889.000000, reward total was -20.000000. running mean: -20.381062\n",
            "resetting env. episode 3890.000000, reward total was -19.000000. running mean: -20.367252\n",
            "resetting env. episode 3891.000000, reward total was -21.000000. running mean: -20.373579\n",
            "resetting env. episode 3892.000000, reward total was -19.000000. running mean: -20.359843\n",
            "resetting env. episode 3893.000000, reward total was -20.000000. running mean: -20.356245\n",
            "resetting env. episode 3894.000000, reward total was -20.000000. running mean: -20.352682\n",
            "resetting env. episode 3895.000000, reward total was -21.000000. running mean: -20.359156\n",
            "resetting env. episode 3896.000000, reward total was -21.000000. running mean: -20.365564\n",
            "resetting env. episode 3897.000000, reward total was -21.000000. running mean: -20.371908\n",
            "resetting env. episode 3898.000000, reward total was -21.000000. running mean: -20.378189\n",
            "resetting env. episode 3899.000000, reward total was -20.000000. running mean: -20.374407\n",
            "resetting env. episode 3900.000000, reward total was -21.000000. running mean: -20.380663\n",
            "resetting env. episode 3901.000000, reward total was -21.000000. running mean: -20.386857\n",
            "resetting env. episode 3902.000000, reward total was -21.000000. running mean: -20.392988\n",
            "resetting env. episode 3903.000000, reward total was -21.000000. running mean: -20.399058\n",
            "resetting env. episode 3904.000000, reward total was -21.000000. running mean: -20.405068\n",
            "resetting env. episode 3905.000000, reward total was -21.000000. running mean: -20.411017\n",
            "resetting env. episode 3906.000000, reward total was -21.000000. running mean: -20.416907\n",
            "resetting env. episode 3907.000000, reward total was -19.000000. running mean: -20.402738\n",
            "resetting env. episode 3908.000000, reward total was -20.000000. running mean: -20.398710\n",
            "resetting env. episode 3909.000000, reward total was -20.000000. running mean: -20.394723\n",
            "resetting env. episode 3910.000000, reward total was -20.000000. running mean: -20.390776\n",
            "resetting env. episode 3911.000000, reward total was -20.000000. running mean: -20.386868\n",
            "resetting env. episode 3912.000000, reward total was -21.000000. running mean: -20.393000\n",
            "resetting env. episode 3913.000000, reward total was -19.000000. running mean: -20.379070\n",
            "resetting env. episode 3914.000000, reward total was -21.000000. running mean: -20.385279\n",
            "resetting env. episode 3915.000000, reward total was -20.000000. running mean: -20.381426\n",
            "resetting env. episode 3916.000000, reward total was -20.000000. running mean: -20.377612\n",
            "resetting env. episode 3917.000000, reward total was -21.000000. running mean: -20.383836\n",
            "resetting env. episode 3918.000000, reward total was -21.000000. running mean: -20.389997\n",
            "resetting env. episode 3919.000000, reward total was -20.000000. running mean: -20.386097\n",
            "resetting env. episode 3920.000000, reward total was -20.000000. running mean: -20.382236\n",
            "resetting env. episode 3921.000000, reward total was -21.000000. running mean: -20.388414\n",
            "resetting env. episode 3922.000000, reward total was -20.000000. running mean: -20.384530\n",
            "resetting env. episode 3923.000000, reward total was -21.000000. running mean: -20.390685\n",
            "resetting env. episode 3924.000000, reward total was -21.000000. running mean: -20.396778\n",
            "resetting env. episode 3925.000000, reward total was -21.000000. running mean: -20.402810\n",
            "resetting env. episode 3926.000000, reward total was -21.000000. running mean: -20.408782\n",
            "resetting env. episode 3927.000000, reward total was -21.000000. running mean: -20.414694\n",
            "resetting env. episode 3928.000000, reward total was -21.000000. running mean: -20.420547\n",
            "resetting env. episode 3929.000000, reward total was -21.000000. running mean: -20.426342\n",
            "resetting env. episode 3930.000000, reward total was -20.000000. running mean: -20.422078\n",
            "resetting env. episode 3931.000000, reward total was -19.000000. running mean: -20.407857\n",
            "resetting env. episode 3932.000000, reward total was -20.000000. running mean: -20.403779\n",
            "resetting env. episode 3933.000000, reward total was -21.000000. running mean: -20.409741\n",
            "resetting env. episode 3934.000000, reward total was -20.000000. running mean: -20.405644\n",
            "resetting env. episode 3935.000000, reward total was -21.000000. running mean: -20.411587\n",
            "resetting env. episode 3936.000000, reward total was -19.000000. running mean: -20.397471\n",
            "resetting env. episode 3937.000000, reward total was -20.000000. running mean: -20.393497\n",
            "resetting env. episode 3938.000000, reward total was -21.000000. running mean: -20.399562\n",
            "resetting env. episode 3939.000000, reward total was -21.000000. running mean: -20.405566\n",
            "resetting env. episode 3940.000000, reward total was -20.000000. running mean: -20.401510\n",
            "resetting env. episode 3941.000000, reward total was -21.000000. running mean: -20.407495\n",
            "resetting env. episode 3942.000000, reward total was -20.000000. running mean: -20.403420\n",
            "resetting env. episode 3943.000000, reward total was -20.000000. running mean: -20.399386\n",
            "resetting env. episode 3944.000000, reward total was -21.000000. running mean: -20.405392\n",
            "resetting env. episode 3945.000000, reward total was -21.000000. running mean: -20.411338\n",
            "resetting env. episode 3946.000000, reward total was -21.000000. running mean: -20.417225\n",
            "resetting env. episode 3947.000000, reward total was -21.000000. running mean: -20.423053\n",
            "resetting env. episode 3948.000000, reward total was -21.000000. running mean: -20.428822\n",
            "resetting env. episode 3949.000000, reward total was -21.000000. running mean: -20.434534\n",
            "resetting env. episode 3950.000000, reward total was -20.000000. running mean: -20.430189\n",
            "resetting env. episode 3951.000000, reward total was -19.000000. running mean: -20.415887\n",
            "resetting env. episode 3952.000000, reward total was -21.000000. running mean: -20.421728\n",
            "resetting env. episode 3953.000000, reward total was -21.000000. running mean: -20.427511\n",
            "resetting env. episode 3954.000000, reward total was -19.000000. running mean: -20.413236\n",
            "resetting env. episode 3955.000000, reward total was -21.000000. running mean: -20.419103\n",
            "resetting env. episode 3956.000000, reward total was -21.000000. running mean: -20.424912\n",
            "resetting env. episode 3957.000000, reward total was -21.000000. running mean: -20.430663\n",
            "resetting env. episode 3958.000000, reward total was -21.000000. running mean: -20.436356\n",
            "resetting env. episode 3959.000000, reward total was -21.000000. running mean: -20.441993\n",
            "resetting env. episode 3960.000000, reward total was -21.000000. running mean: -20.447573\n",
            "resetting env. episode 3961.000000, reward total was -21.000000. running mean: -20.453097\n",
            "resetting env. episode 3962.000000, reward total was -18.000000. running mean: -20.428566\n",
            "resetting env. episode 3963.000000, reward total was -21.000000. running mean: -20.434281\n",
            "resetting env. episode 3964.000000, reward total was -21.000000. running mean: -20.439938\n",
            "resetting env. episode 3965.000000, reward total was -21.000000. running mean: -20.445538\n",
            "resetting env. episode 3966.000000, reward total was -21.000000. running mean: -20.451083\n",
            "resetting env. episode 3967.000000, reward total was -21.000000. running mean: -20.456572\n",
            "resetting env. episode 3968.000000, reward total was -20.000000. running mean: -20.452006\n",
            "resetting env. episode 3969.000000, reward total was -21.000000. running mean: -20.457486\n",
            "resetting env. episode 3970.000000, reward total was -21.000000. running mean: -20.462911\n",
            "resetting env. episode 3971.000000, reward total was -21.000000. running mean: -20.468282\n",
            "resetting env. episode 3972.000000, reward total was -17.000000. running mean: -20.433600\n",
            "resetting env. episode 3973.000000, reward total was -21.000000. running mean: -20.439264\n",
            "resetting env. episode 3974.000000, reward total was -20.000000. running mean: -20.434871\n",
            "resetting env. episode 3975.000000, reward total was -21.000000. running mean: -20.440522\n",
            "resetting env. episode 3976.000000, reward total was -21.000000. running mean: -20.446117\n",
            "resetting env. episode 3977.000000, reward total was -20.000000. running mean: -20.441656\n",
            "resetting env. episode 3978.000000, reward total was -21.000000. running mean: -20.447239\n",
            "resetting env. episode 3979.000000, reward total was -21.000000. running mean: -20.452767\n",
            "resetting env. episode 3980.000000, reward total was -21.000000. running mean: -20.458239\n",
            "resetting env. episode 3981.000000, reward total was -21.000000. running mean: -20.463657\n",
            "resetting env. episode 3982.000000, reward total was -21.000000. running mean: -20.469020\n",
            "resetting env. episode 3983.000000, reward total was -21.000000. running mean: -20.474330\n",
            "resetting env. episode 3984.000000, reward total was -20.000000. running mean: -20.469587\n",
            "resetting env. episode 3985.000000, reward total was -21.000000. running mean: -20.474891\n",
            "resetting env. episode 3986.000000, reward total was -21.000000. running mean: -20.480142\n",
            "resetting env. episode 3987.000000, reward total was -21.000000. running mean: -20.485341\n",
            "resetting env. episode 3988.000000, reward total was -21.000000. running mean: -20.490487\n",
            "resetting env. episode 3989.000000, reward total was -21.000000. running mean: -20.495582\n",
            "resetting env. episode 3990.000000, reward total was -20.000000. running mean: -20.490626\n",
            "resetting env. episode 3991.000000, reward total was -19.000000. running mean: -20.475720\n",
            "resetting env. episode 3992.000000, reward total was -21.000000. running mean: -20.480963\n",
            "resetting env. episode 3993.000000, reward total was -20.000000. running mean: -20.476153\n",
            "resetting env. episode 3994.000000, reward total was -21.000000. running mean: -20.481392\n",
            "resetting env. episode 3995.000000, reward total was -21.000000. running mean: -20.486578\n",
            "resetting env. episode 3996.000000, reward total was -21.000000. running mean: -20.491712\n",
            "resetting env. episode 3997.000000, reward total was -20.000000. running mean: -20.486795\n",
            "resetting env. episode 3998.000000, reward total was -20.000000. running mean: -20.481927\n",
            "resetting env. episode 3999.000000, reward total was -21.000000. running mean: -20.487108\n",
            "resetting env. episode 4000.000000, reward total was -21.000000. running mean: -20.492237\n",
            "CPU times: user 3h 13min 6s, sys: 1h 31min 4s, total: 4h 44min 10s\n",
            "Wall time: 2h 28min\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "8fheN9DRlWXQ",
        "outputId": "83332ddd-a10f-4315-807a-a67d9d3b8c80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "cell_type": "code",
      "source": [
        "play_game(env, model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode finished without success, accumulated reward = -18.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 320x420 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}