{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VIJAYA_C0851848_200_Neurons_(1e-4).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "cWACPRL869I4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebb1e369-f770-48fb-9cfc-d2a0c980dcdf"
      },
      "cell_type": "code",
      "source": [
        "!pip install gym >/dev/null\n",
        "!pip install JSAnimation >/dev/null\n",
        "%pip install -U gym>=0.21.0\n",
        "%pip install -U gym[atari,accept-rom-license]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.7/dist-packages (0.25.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (4.12.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.21.6)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (0.0.8)\n",
            "Collecting ale-py~=0.7.5\n",
            "  Downloading ale_py-0.7.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 26.3 MB/s \n",
            "\u001b[?25hCollecting autorom[accept-rom-license]~=0.4.2\n",
            "  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py~=0.7.5->gym[accept-rom-license,atari]) (5.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (4.64.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (7.1.2)\n",
            "Collecting AutoROM.accept-rom-license\n",
            "  Downloading AutoROM.accept-rom-license-0.4.2.tar.gz (9.8 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (4.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2022.6.15)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.4.2-py3-none-any.whl size=441027 sha256=06bbdf7b4d150d3a35152d733730fad60e1c978df04496e80d438a324bd97c88\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/67/2e/6147e7912fe37f5408b80d07527dab807c1d25f5c403a9538a\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: AutoROM.accept-rom-license, autorom, ale-py\n",
            "Successfully installed AutoROM.accept-rom-license-0.4.2 ale-py-0.7.5 autorom-0.4.2\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "wotUOa_e6edP"
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from JSAnimation.IPython_display import display_animation\n",
        "from matplotlib import animation\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML\n",
        "\n",
        "def display_frames_as_gif(frames):\n",
        "    \"\"\"\n",
        "    Displays a list of frames as a gif, with controls\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 144)\n",
        "    patch = plt.imshow(frames[0])\n",
        "    plt.axis('off')\n",
        "\n",
        "    def animate(i):\n",
        "        patch.set_data(frames[i])\n",
        "\n",
        "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
        "    HTML(anim.to_jshtml())"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R66_INeZ9nYX"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 2: Playing Pong"
      ]
    },
    {
      "metadata": {
        "id": "MtT2GyK_6edc",
        "outputId": "70aa1210-868a-4c71-ab8d-005277741906",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import gym\n",
        "env = gym.make('Pong-v0')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py:594: UserWarning: \u001b[33mWARN: The environment Pong-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  f\"The environment {id} is out of date. You should consider \"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:330: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "oRE6WmXQJ1Z0",
        "outputId": "1afb0f43-a143-4a9a-cf2d-843400048b77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "env.action_space"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discrete(6)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "yl_9d4HFJ31W",
        "outputId": "ff5e8a1c-f3dc-4c19-cef8-89825aa90dd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "env.observation_space"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Box(0, 255, (210, 160, 3), uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "trwRXI-h6eeI",
        "outputId": "2296dbae-3330-4288-9f2f-f8ee9218efe5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# Run a demo of the environment\n",
        "observation = env.reset()\n",
        "cumulated_reward = 0\n",
        "\n",
        "frames = []\n",
        "for t in range(1000):\n",
        "#     print(observation)\n",
        "    frames.append(env.render(mode = 'rgb_array'))\n",
        "    # very stupid agent, just makes a random action within the allowd action space\n",
        "    action = env.action_space.sample()\n",
        "#     print(\"Action: {}\".format(t+1))    \n",
        "    observation, reward, done, info = env.step(action)\n",
        "#     print(reward)\n",
        "    cumulated_reward += reward\n",
        "    if done:\n",
        "        print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n",
        "        break\n",
        "print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n",
        "\n",
        "env.close()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  \"The argument mode in render method is deprecated; \"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:298: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
            "  \"No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  \"Core environment is written in old step API which returns one bool instead of two. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode finished without success, accumulated reward = -15.0\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "3zZTecVWLLes"
      },
      "cell_type": "code",
      "source": [
        "def sigmoid(x): \n",
        "  return 1.0 / (1.0 + np.exp(-x)) # sigmoid \"squashing\" function to interval [0,1]\n",
        "\n",
        "def prepro(I):\n",
        "  \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n",
        "  I = I[35:195] # crop\n",
        "  I = I[::2,::2,0] # downsample by factor of 2\n",
        "  I[I == 144] = 0 # erase background (background type 1)\n",
        "  I[I == 109] = 0 # erase background (background type 2)\n",
        "  I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
        "  return I.astype(np.float).ravel()\n",
        "\n",
        "def policy_forward(x):\n",
        "  h = np.dot(model['W1'], x)\n",
        "  h[h<0] = 0 # ReLU nonlinearity\n",
        "  logp = np.dot(model['W2'], h)\n",
        "  p = sigmoid(logp)\n",
        "  return p, h # return probability of taking action 2, and hidden state\n",
        "\n",
        "def model_step(model, observation, prev_x):\n",
        "  # preprocess the observation, set input to network to be difference image\n",
        "  cur_x = prepro(observation)\n",
        "  x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
        "  prev_x = cur_x\n",
        "  \n",
        "  # forward the policy network and sample an action from the returned probability\n",
        "  aprob, _ = policy_forward(x)\n",
        "  action = 2 if aprob >= 0.5 else 3 # roll the dice!\n",
        "  \n",
        "  return action, prev_x\n",
        "\n",
        "def play_game(env, model):\n",
        "  observation = env.reset()\n",
        "\n",
        "  frames = []\n",
        "  cumulated_reward = 0\n",
        "\n",
        "  prev_x = None # used in computing the difference frame\n",
        "\n",
        "  for t in range(1000):\n",
        "      frames.append(env.render(mode = 'rgb_array'))\n",
        "      action, prev_x = model_step(model, observation, prev_x)\n",
        "      observation, reward, done, info = env.step(action)\n",
        "      cumulated_reward += reward\n",
        "      if done:\n",
        "          print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n",
        "          break\n",
        "  print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n",
        "  display_frames_as_gif(frames)\n",
        "  env.close()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6gWvZQ7AQLQt"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 3: Policy Gradient from Scratch"
      ]
    },
    {
      "metadata": {
        "id": "eqFm7hqcItWl"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# model initialization\n",
        "H = 200 # number of hidden layer neurons\n",
        "D = 80 * 80 # input dimensionality: 80x80 grid\n",
        "model = {}\n",
        "model['W1'] = np.random.randn(H,D) / np.sqrt(D) # \"Xavier\" initialization\n",
        "model['W2'] = np.random.randn(H) / np.sqrt(H)\n",
        "\n",
        "# import pickle\n",
        "# model = pickle.load(open('model.pkl', 'rb'))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TwjiwKisQM19"
      },
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "batch_size = 10 # every how many episodes to do a param update?\n",
        "# learning_rate = 1e-4\n",
        "learning_rate = 1e-4\n",
        " \n",
        "gamma = 0.99 # discount factor for reward\n",
        "decay_rate = 0.99 # decay factor for RMSProp leaky sum of grad^2\n",
        "  \n",
        "grad_buffer = { k : np.zeros_like(v) for k,v in model.items() } # update buffers that add up gradients over a batch\n",
        "rmsprop_cache = { k : np.zeros_like(v) for k,v in model.items() } # rmsprop memory\n",
        "\n",
        "\n",
        "def policy_backward(epx, eph, epdlogp):\n",
        "  \"\"\" backward pass. (eph is array of intermediate hidden states) \"\"\"\n",
        "  dW2 = np.dot(eph.T, epdlogp).ravel()\n",
        "  dh = np.outer(epdlogp, model['W2'])\n",
        "  dh[eph <= 0] = 0 # backpro prelu\n",
        "  dW1 = np.dot(dh.T, epx)\n",
        "  return {'W1':dW1, 'W2':dW2}\n",
        "\n",
        "def discount_rewards(r):\n",
        "  \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
        "  discounted_r = np.zeros_like(r, dtype=np.float32)\n",
        "  running_add = 0\n",
        "  for t in reversed(range(0, r.size)):\n",
        "    if r[t] != 0: running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n",
        "    running_add = running_add * gamma + r[t]\n",
        "    discounted_r[t] = running_add\n",
        "  return discounted_r\n",
        "\n",
        "def train_model(env, model, total_episodes = 100):\n",
        "  hist = []\n",
        "  observation = env.reset()\n",
        "\n",
        "  prev_x = None # used in computing the difference frame\n",
        "  xs,hs,dlogps,drs = [],[],[],[]\n",
        "  running_reward = None\n",
        "  reward_sum = 0\n",
        "  episode_number = 0\n",
        "\n",
        "  while True:\n",
        "    # preprocess the observation, set input to network to be difference image\n",
        "    cur_x = prepro(observation)\n",
        "    x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
        "    prev_x = cur_x\n",
        "\n",
        "    # forward the policy network and sample an action from the returned probability\n",
        "    aprob, h = policy_forward(x)\n",
        "    action = 2 if np.random.uniform() < aprob else 3 # roll the dice!\n",
        "\n",
        "    # record various intermediates (needed later for backprop)\n",
        "    xs.append(x) # observation\n",
        "    hs.append(h) # hidden state\n",
        "    y = 1 if action == 2 else 0 # a \"fake label\"\n",
        "    dlogps.append(y - aprob) # grad that encourages the action that was taken to be taken (see http://cs231n.github.io/neural-networks-2/#losses if confused)\n",
        "\n",
        "    # step the environment and get new measurements\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    reward_sum += reward\n",
        "\n",
        "    drs.append(reward) # record reward (has to be done after we call step() to get reward for previous action)\n",
        "\n",
        "    if done: # an episode finished\n",
        "      episode_number += 1\n",
        "\n",
        "      # stack together all inputs, hidden states, action gradients, and rewards for this episode\n",
        "      epx = np.vstack(xs)\n",
        "      eph = np.vstack(hs)\n",
        "      epdlogp = np.vstack(dlogps)\n",
        "      epr = np.vstack(drs)\n",
        "      xs,hs,dlogps,drs = [],[],[],[] # reset array memory\n",
        "\n",
        "      # compute the discounted reward backwards through time\n",
        "      discounted_epr = discount_rewards(epr)\n",
        "      # standardize the rewards to be unit normal (helps control the gradient estimator variance)\n",
        "      discounted_epr -= np.mean(discounted_epr)\n",
        "      discounted_epr /= np.std(discounted_epr)\n",
        "\n",
        "      epdlogp *= discounted_epr # modulate the gradient with advantage (PG magic happens right here.)\n",
        "      grad = policy_backward(epx, eph, epdlogp)\n",
        "      for k in model: grad_buffer[k] += grad[k] # accumulate grad over batch\n",
        "\n",
        "      # perform rmsprop parameter update every batch_size episodes\n",
        "      if episode_number % batch_size == 0:\n",
        "        for k,v in model.items():\n",
        "          g = grad_buffer[k] # gradient\n",
        "          rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1 - decay_rate) * g**2\n",
        "          model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n",
        "          grad_buffer[k] = np.zeros_like(v) # reset batch gradient buffer\n",
        "\n",
        "      # boring book-keeping\n",
        "      running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
        "      hist.append((episode_number, reward_sum, running_reward))\n",
        "      print ('resetting env. episode %f, reward total was %f. running mean: %f' % (episode_number, reward_sum, running_reward))\n",
        "      reward_sum = 0\n",
        "      observation = env.reset() # reset env\n",
        "      prev_x = None\n",
        "      if episode_number == total_episodes: return hist\n",
        "\n",
        "      if reward != 0: # Pong has either +1 or -1 reward exactly when game ends.\n",
        "        print (('ep %d: game finished, reward: %f' % (episode_number, reward)) + ('' if reward == -1 else ' !!!!!!!!'))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G6Ka_5Vl9Orm",
        "outputId": "7677f096-473d-4f62-c5ca-b88a3e24f697",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "%time hist1 = train_model(env, model, total_episodes=4000)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resetting env. episode 1.000000, reward total was -21.000000. running mean: -21.000000\n",
            "resetting env. episode 2.000000, reward total was -20.000000. running mean: -20.990000\n",
            "resetting env. episode 3.000000, reward total was -21.000000. running mean: -20.990100\n",
            "resetting env. episode 4.000000, reward total was -20.000000. running mean: -20.980199\n",
            "resetting env. episode 5.000000, reward total was -20.000000. running mean: -20.970397\n",
            "resetting env. episode 6.000000, reward total was -20.000000. running mean: -20.960693\n",
            "resetting env. episode 7.000000, reward total was -21.000000. running mean: -20.961086\n",
            "resetting env. episode 8.000000, reward total was -21.000000. running mean: -20.961475\n",
            "resetting env. episode 9.000000, reward total was -19.000000. running mean: -20.941860\n",
            "resetting env. episode 10.000000, reward total was -18.000000. running mean: -20.912442\n",
            "resetting env. episode 11.000000, reward total was -21.000000. running mean: -20.913317\n",
            "resetting env. episode 12.000000, reward total was -21.000000. running mean: -20.914184\n",
            "resetting env. episode 13.000000, reward total was -21.000000. running mean: -20.915042\n",
            "resetting env. episode 14.000000, reward total was -21.000000. running mean: -20.915892\n",
            "resetting env. episode 15.000000, reward total was -20.000000. running mean: -20.906733\n",
            "resetting env. episode 16.000000, reward total was -21.000000. running mean: -20.907666\n",
            "resetting env. episode 17.000000, reward total was -21.000000. running mean: -20.908589\n",
            "resetting env. episode 18.000000, reward total was -20.000000. running mean: -20.899503\n",
            "resetting env. episode 19.000000, reward total was -21.000000. running mean: -20.900508\n",
            "resetting env. episode 20.000000, reward total was -21.000000. running mean: -20.901503\n",
            "resetting env. episode 21.000000, reward total was -21.000000. running mean: -20.902488\n",
            "resetting env. episode 22.000000, reward total was -19.000000. running mean: -20.883463\n",
            "resetting env. episode 23.000000, reward total was -21.000000. running mean: -20.884629\n",
            "resetting env. episode 24.000000, reward total was -21.000000. running mean: -20.885782\n",
            "resetting env. episode 25.000000, reward total was -21.000000. running mean: -20.886924\n",
            "resetting env. episode 26.000000, reward total was -21.000000. running mean: -20.888055\n",
            "resetting env. episode 27.000000, reward total was -21.000000. running mean: -20.889175\n",
            "resetting env. episode 28.000000, reward total was -21.000000. running mean: -20.890283\n",
            "resetting env. episode 29.000000, reward total was -20.000000. running mean: -20.881380\n",
            "resetting env. episode 30.000000, reward total was -20.000000. running mean: -20.872566\n",
            "resetting env. episode 31.000000, reward total was -21.000000. running mean: -20.873841\n",
            "resetting env. episode 32.000000, reward total was -20.000000. running mean: -20.865102\n",
            "resetting env. episode 33.000000, reward total was -20.000000. running mean: -20.856451\n",
            "resetting env. episode 34.000000, reward total was -21.000000. running mean: -20.857887\n",
            "resetting env. episode 35.000000, reward total was -18.000000. running mean: -20.829308\n",
            "resetting env. episode 36.000000, reward total was -19.000000. running mean: -20.811015\n",
            "resetting env. episode 37.000000, reward total was -21.000000. running mean: -20.812905\n",
            "resetting env. episode 38.000000, reward total was -21.000000. running mean: -20.814776\n",
            "resetting env. episode 39.000000, reward total was -21.000000. running mean: -20.816628\n",
            "resetting env. episode 40.000000, reward total was -21.000000. running mean: -20.818462\n",
            "resetting env. episode 41.000000, reward total was -20.000000. running mean: -20.810277\n",
            "resetting env. episode 42.000000, reward total was -21.000000. running mean: -20.812174\n",
            "resetting env. episode 43.000000, reward total was -21.000000. running mean: -20.814052\n",
            "resetting env. episode 44.000000, reward total was -17.000000. running mean: -20.775912\n",
            "resetting env. episode 45.000000, reward total was -21.000000. running mean: -20.778153\n",
            "resetting env. episode 46.000000, reward total was -19.000000. running mean: -20.760371\n",
            "resetting env. episode 47.000000, reward total was -21.000000. running mean: -20.762768\n",
            "resetting env. episode 48.000000, reward total was -21.000000. running mean: -20.765140\n",
            "resetting env. episode 49.000000, reward total was -21.000000. running mean: -20.767488\n",
            "resetting env. episode 50.000000, reward total was -21.000000. running mean: -20.769814\n",
            "resetting env. episode 51.000000, reward total was -21.000000. running mean: -20.772115\n",
            "resetting env. episode 52.000000, reward total was -19.000000. running mean: -20.754394\n",
            "resetting env. episode 53.000000, reward total was -21.000000. running mean: -20.756850\n",
            "resetting env. episode 54.000000, reward total was -20.000000. running mean: -20.749282\n",
            "resetting env. episode 55.000000, reward total was -20.000000. running mean: -20.741789\n",
            "resetting env. episode 56.000000, reward total was -21.000000. running mean: -20.744371\n",
            "resetting env. episode 57.000000, reward total was -20.000000. running mean: -20.736927\n",
            "resetting env. episode 58.000000, reward total was -18.000000. running mean: -20.709558\n",
            "resetting env. episode 59.000000, reward total was -21.000000. running mean: -20.712463\n",
            "resetting env. episode 60.000000, reward total was -20.000000. running mean: -20.705338\n",
            "resetting env. episode 61.000000, reward total was -21.000000. running mean: -20.708285\n",
            "resetting env. episode 62.000000, reward total was -20.000000. running mean: -20.701202\n",
            "resetting env. episode 63.000000, reward total was -21.000000. running mean: -20.704190\n",
            "resetting env. episode 64.000000, reward total was -21.000000. running mean: -20.707148\n",
            "resetting env. episode 65.000000, reward total was -21.000000. running mean: -20.710076\n",
            "resetting env. episode 66.000000, reward total was -16.000000. running mean: -20.662976\n",
            "resetting env. episode 67.000000, reward total was -18.000000. running mean: -20.636346\n",
            "resetting env. episode 68.000000, reward total was -20.000000. running mean: -20.629982\n",
            "resetting env. episode 69.000000, reward total was -21.000000. running mean: -20.633682\n",
            "resetting env. episode 70.000000, reward total was -21.000000. running mean: -20.637346\n",
            "resetting env. episode 71.000000, reward total was -20.000000. running mean: -20.630972\n",
            "resetting env. episode 72.000000, reward total was -18.000000. running mean: -20.604662\n",
            "resetting env. episode 73.000000, reward total was -21.000000. running mean: -20.608616\n",
            "resetting env. episode 74.000000, reward total was -19.000000. running mean: -20.592530\n",
            "resetting env. episode 75.000000, reward total was -20.000000. running mean: -20.586604\n",
            "resetting env. episode 76.000000, reward total was -19.000000. running mean: -20.570738\n",
            "resetting env. episode 77.000000, reward total was -20.000000. running mean: -20.565031\n",
            "resetting env. episode 78.000000, reward total was -21.000000. running mean: -20.569381\n",
            "resetting env. episode 79.000000, reward total was -21.000000. running mean: -20.573687\n",
            "resetting env. episode 80.000000, reward total was -20.000000. running mean: -20.567950\n",
            "resetting env. episode 81.000000, reward total was -18.000000. running mean: -20.542271\n",
            "resetting env. episode 82.000000, reward total was -21.000000. running mean: -20.546848\n",
            "resetting env. episode 83.000000, reward total was -21.000000. running mean: -20.551379\n",
            "resetting env. episode 84.000000, reward total was -21.000000. running mean: -20.555866\n",
            "resetting env. episode 85.000000, reward total was -17.000000. running mean: -20.520307\n",
            "resetting env. episode 86.000000, reward total was -18.000000. running mean: -20.495104\n",
            "resetting env. episode 87.000000, reward total was -21.000000. running mean: -20.500153\n",
            "resetting env. episode 88.000000, reward total was -21.000000. running mean: -20.505151\n",
            "resetting env. episode 89.000000, reward total was -21.000000. running mean: -20.510100\n",
            "resetting env. episode 90.000000, reward total was -21.000000. running mean: -20.514999\n",
            "resetting env. episode 91.000000, reward total was -21.000000. running mean: -20.519849\n",
            "resetting env. episode 92.000000, reward total was -20.000000. running mean: -20.514650\n",
            "resetting env. episode 93.000000, reward total was -20.000000. running mean: -20.509504\n",
            "resetting env. episode 94.000000, reward total was -21.000000. running mean: -20.514409\n",
            "resetting env. episode 95.000000, reward total was -20.000000. running mean: -20.509265\n",
            "resetting env. episode 96.000000, reward total was -19.000000. running mean: -20.494172\n",
            "resetting env. episode 97.000000, reward total was -21.000000. running mean: -20.499230\n",
            "resetting env. episode 98.000000, reward total was -19.000000. running mean: -20.484238\n",
            "resetting env. episode 99.000000, reward total was -20.000000. running mean: -20.479396\n",
            "resetting env. episode 100.000000, reward total was -21.000000. running mean: -20.484602\n",
            "resetting env. episode 101.000000, reward total was -19.000000. running mean: -20.469756\n",
            "resetting env. episode 102.000000, reward total was -21.000000. running mean: -20.475058\n",
            "resetting env. episode 103.000000, reward total was -21.000000. running mean: -20.480307\n",
            "resetting env. episode 104.000000, reward total was -20.000000. running mean: -20.475504\n",
            "resetting env. episode 105.000000, reward total was -21.000000. running mean: -20.480749\n",
            "resetting env. episode 106.000000, reward total was -21.000000. running mean: -20.485942\n",
            "resetting env. episode 107.000000, reward total was -18.000000. running mean: -20.461082\n",
            "resetting env. episode 108.000000, reward total was -20.000000. running mean: -20.456472\n",
            "resetting env. episode 109.000000, reward total was -21.000000. running mean: -20.461907\n",
            "resetting env. episode 110.000000, reward total was -21.000000. running mean: -20.467288\n",
            "resetting env. episode 111.000000, reward total was -21.000000. running mean: -20.472615\n",
            "resetting env. episode 112.000000, reward total was -21.000000. running mean: -20.477889\n",
            "resetting env. episode 113.000000, reward total was -20.000000. running mean: -20.473110\n",
            "resetting env. episode 114.000000, reward total was -21.000000. running mean: -20.478379\n",
            "resetting env. episode 115.000000, reward total was -21.000000. running mean: -20.483595\n",
            "resetting env. episode 116.000000, reward total was -21.000000. running mean: -20.488759\n",
            "resetting env. episode 117.000000, reward total was -21.000000. running mean: -20.493871\n",
            "resetting env. episode 118.000000, reward total was -21.000000. running mean: -20.498933\n",
            "resetting env. episode 119.000000, reward total was -19.000000. running mean: -20.483943\n",
            "resetting env. episode 120.000000, reward total was -19.000000. running mean: -20.469104\n",
            "resetting env. episode 121.000000, reward total was -21.000000. running mean: -20.474413\n",
            "resetting env. episode 122.000000, reward total was -20.000000. running mean: -20.469669\n",
            "resetting env. episode 123.000000, reward total was -19.000000. running mean: -20.454972\n",
            "resetting env. episode 124.000000, reward total was -21.000000. running mean: -20.460422\n",
            "resetting env. episode 125.000000, reward total was -19.000000. running mean: -20.445818\n",
            "resetting env. episode 126.000000, reward total was -20.000000. running mean: -20.441360\n",
            "resetting env. episode 127.000000, reward total was -20.000000. running mean: -20.436946\n",
            "resetting env. episode 128.000000, reward total was -21.000000. running mean: -20.442577\n",
            "resetting env. episode 129.000000, reward total was -21.000000. running mean: -20.448151\n",
            "resetting env. episode 130.000000, reward total was -21.000000. running mean: -20.453670\n",
            "resetting env. episode 131.000000, reward total was -20.000000. running mean: -20.449133\n",
            "resetting env. episode 132.000000, reward total was -21.000000. running mean: -20.454642\n",
            "resetting env. episode 133.000000, reward total was -21.000000. running mean: -20.460095\n",
            "resetting env. episode 134.000000, reward total was -21.000000. running mean: -20.465494\n",
            "resetting env. episode 135.000000, reward total was -21.000000. running mean: -20.470839\n",
            "resetting env. episode 136.000000, reward total was -19.000000. running mean: -20.456131\n",
            "resetting env. episode 137.000000, reward total was -21.000000. running mean: -20.461570\n",
            "resetting env. episode 138.000000, reward total was -21.000000. running mean: -20.466954\n",
            "resetting env. episode 139.000000, reward total was -21.000000. running mean: -20.472284\n",
            "resetting env. episode 140.000000, reward total was -21.000000. running mean: -20.477562\n",
            "resetting env. episode 141.000000, reward total was -21.000000. running mean: -20.482786\n",
            "resetting env. episode 142.000000, reward total was -20.000000. running mean: -20.477958\n",
            "resetting env. episode 143.000000, reward total was -21.000000. running mean: -20.483178\n",
            "resetting env. episode 144.000000, reward total was -20.000000. running mean: -20.478347\n",
            "resetting env. episode 145.000000, reward total was -19.000000. running mean: -20.463563\n",
            "resetting env. episode 146.000000, reward total was -18.000000. running mean: -20.438928\n",
            "resetting env. episode 147.000000, reward total was -21.000000. running mean: -20.444538\n",
            "resetting env. episode 148.000000, reward total was -21.000000. running mean: -20.450093\n",
            "resetting env. episode 149.000000, reward total was -21.000000. running mean: -20.455592\n",
            "resetting env. episode 150.000000, reward total was -19.000000. running mean: -20.441036\n",
            "resetting env. episode 151.000000, reward total was -21.000000. running mean: -20.446626\n",
            "resetting env. episode 152.000000, reward total was -20.000000. running mean: -20.442159\n",
            "resetting env. episode 153.000000, reward total was -21.000000. running mean: -20.447738\n",
            "resetting env. episode 154.000000, reward total was -21.000000. running mean: -20.453261\n",
            "resetting env. episode 155.000000, reward total was -20.000000. running mean: -20.448728\n",
            "resetting env. episode 156.000000, reward total was -21.000000. running mean: -20.454241\n",
            "resetting env. episode 157.000000, reward total was -20.000000. running mean: -20.449698\n",
            "resetting env. episode 158.000000, reward total was -19.000000. running mean: -20.435201\n",
            "resetting env. episode 159.000000, reward total was -20.000000. running mean: -20.430849\n",
            "resetting env. episode 160.000000, reward total was -21.000000. running mean: -20.436541\n",
            "resetting env. episode 161.000000, reward total was -18.000000. running mean: -20.412175\n",
            "resetting env. episode 162.000000, reward total was -19.000000. running mean: -20.398054\n",
            "resetting env. episode 163.000000, reward total was -21.000000. running mean: -20.404073\n",
            "resetting env. episode 164.000000, reward total was -21.000000. running mean: -20.410032\n",
            "resetting env. episode 165.000000, reward total was -21.000000. running mean: -20.415932\n",
            "resetting env. episode 166.000000, reward total was -21.000000. running mean: -20.421773\n",
            "resetting env. episode 167.000000, reward total was -20.000000. running mean: -20.417555\n",
            "resetting env. episode 168.000000, reward total was -21.000000. running mean: -20.423379\n",
            "resetting env. episode 169.000000, reward total was -20.000000. running mean: -20.419146\n",
            "resetting env. episode 170.000000, reward total was -21.000000. running mean: -20.424954\n",
            "resetting env. episode 171.000000, reward total was -21.000000. running mean: -20.430705\n",
            "resetting env. episode 172.000000, reward total was -21.000000. running mean: -20.436398\n",
            "resetting env. episode 173.000000, reward total was -21.000000. running mean: -20.442034\n",
            "resetting env. episode 174.000000, reward total was -21.000000. running mean: -20.447613\n",
            "resetting env. episode 175.000000, reward total was -20.000000. running mean: -20.443137\n",
            "resetting env. episode 176.000000, reward total was -19.000000. running mean: -20.428706\n",
            "resetting env. episode 177.000000, reward total was -20.000000. running mean: -20.424419\n",
            "resetting env. episode 178.000000, reward total was -21.000000. running mean: -20.430174\n",
            "resetting env. episode 179.000000, reward total was -21.000000. running mean: -20.435873\n",
            "resetting env. episode 180.000000, reward total was -19.000000. running mean: -20.421514\n",
            "resetting env. episode 181.000000, reward total was -21.000000. running mean: -20.427299\n",
            "resetting env. episode 182.000000, reward total was -20.000000. running mean: -20.423026\n",
            "resetting env. episode 183.000000, reward total was -21.000000. running mean: -20.428796\n",
            "resetting env. episode 184.000000, reward total was -21.000000. running mean: -20.434508\n",
            "resetting env. episode 185.000000, reward total was -21.000000. running mean: -20.440163\n",
            "resetting env. episode 186.000000, reward total was -21.000000. running mean: -20.445761\n",
            "resetting env. episode 187.000000, reward total was -20.000000. running mean: -20.441303\n",
            "resetting env. episode 188.000000, reward total was -21.000000. running mean: -20.446890\n",
            "resetting env. episode 189.000000, reward total was -21.000000. running mean: -20.452421\n",
            "resetting env. episode 190.000000, reward total was -20.000000. running mean: -20.447897\n",
            "resetting env. episode 191.000000, reward total was -20.000000. running mean: -20.443418\n",
            "resetting env. episode 192.000000, reward total was -20.000000. running mean: -20.438984\n",
            "resetting env. episode 193.000000, reward total was -21.000000. running mean: -20.444594\n",
            "resetting env. episode 194.000000, reward total was -21.000000. running mean: -20.450148\n",
            "resetting env. episode 195.000000, reward total was -21.000000. running mean: -20.455647\n",
            "resetting env. episode 196.000000, reward total was -21.000000. running mean: -20.461090\n",
            "resetting env. episode 197.000000, reward total was -20.000000. running mean: -20.456479\n",
            "resetting env. episode 198.000000, reward total was -20.000000. running mean: -20.451915\n",
            "resetting env. episode 199.000000, reward total was -21.000000. running mean: -20.457395\n",
            "resetting env. episode 200.000000, reward total was -20.000000. running mean: -20.452822\n",
            "resetting env. episode 201.000000, reward total was -20.000000. running mean: -20.448293\n",
            "resetting env. episode 202.000000, reward total was -21.000000. running mean: -20.453810\n",
            "resetting env. episode 203.000000, reward total was -19.000000. running mean: -20.439272\n",
            "resetting env. episode 204.000000, reward total was -21.000000. running mean: -20.444880\n",
            "resetting env. episode 205.000000, reward total was -21.000000. running mean: -20.450431\n",
            "resetting env. episode 206.000000, reward total was -21.000000. running mean: -20.455926\n",
            "resetting env. episode 207.000000, reward total was -19.000000. running mean: -20.441367\n",
            "resetting env. episode 208.000000, reward total was -20.000000. running mean: -20.436954\n",
            "resetting env. episode 209.000000, reward total was -20.000000. running mean: -20.432584\n",
            "resetting env. episode 210.000000, reward total was -18.000000. running mean: -20.408258\n",
            "resetting env. episode 211.000000, reward total was -21.000000. running mean: -20.414176\n",
            "resetting env. episode 212.000000, reward total was -21.000000. running mean: -20.420034\n",
            "resetting env. episode 213.000000, reward total was -21.000000. running mean: -20.425833\n",
            "resetting env. episode 214.000000, reward total was -21.000000. running mean: -20.431575\n",
            "resetting env. episode 215.000000, reward total was -20.000000. running mean: -20.427259\n",
            "resetting env. episode 216.000000, reward total was -21.000000. running mean: -20.432987\n",
            "resetting env. episode 217.000000, reward total was -20.000000. running mean: -20.428657\n",
            "resetting env. episode 218.000000, reward total was -21.000000. running mean: -20.434370\n",
            "resetting env. episode 219.000000, reward total was -20.000000. running mean: -20.430027\n",
            "resetting env. episode 220.000000, reward total was -20.000000. running mean: -20.425726\n",
            "resetting env. episode 221.000000, reward total was -21.000000. running mean: -20.431469\n",
            "resetting env. episode 222.000000, reward total was -21.000000. running mean: -20.437154\n",
            "resetting env. episode 223.000000, reward total was -20.000000. running mean: -20.432783\n",
            "resetting env. episode 224.000000, reward total was -20.000000. running mean: -20.428455\n",
            "resetting env. episode 225.000000, reward total was -21.000000. running mean: -20.434170\n",
            "resetting env. episode 226.000000, reward total was -20.000000. running mean: -20.429829\n",
            "resetting env. episode 227.000000, reward total was -21.000000. running mean: -20.435531\n",
            "resetting env. episode 228.000000, reward total was -21.000000. running mean: -20.441175\n",
            "resetting env. episode 229.000000, reward total was -21.000000. running mean: -20.446763\n",
            "resetting env. episode 230.000000, reward total was -21.000000. running mean: -20.452296\n",
            "resetting env. episode 231.000000, reward total was -21.000000. running mean: -20.457773\n",
            "resetting env. episode 232.000000, reward total was -21.000000. running mean: -20.463195\n",
            "resetting env. episode 233.000000, reward total was -19.000000. running mean: -20.448563\n",
            "resetting env. episode 234.000000, reward total was -21.000000. running mean: -20.454078\n",
            "resetting env. episode 235.000000, reward total was -19.000000. running mean: -20.439537\n",
            "resetting env. episode 236.000000, reward total was -20.000000. running mean: -20.435141\n",
            "resetting env. episode 237.000000, reward total was -19.000000. running mean: -20.420790\n",
            "resetting env. episode 238.000000, reward total was -20.000000. running mean: -20.416582\n",
            "resetting env. episode 239.000000, reward total was -20.000000. running mean: -20.412416\n",
            "resetting env. episode 240.000000, reward total was -21.000000. running mean: -20.418292\n",
            "resetting env. episode 241.000000, reward total was -21.000000. running mean: -20.424109\n",
            "resetting env. episode 242.000000, reward total was -21.000000. running mean: -20.429868\n",
            "resetting env. episode 243.000000, reward total was -21.000000. running mean: -20.435569\n",
            "resetting env. episode 244.000000, reward total was -21.000000. running mean: -20.441214\n",
            "resetting env. episode 245.000000, reward total was -19.000000. running mean: -20.426802\n",
            "resetting env. episode 246.000000, reward total was -19.000000. running mean: -20.412534\n",
            "resetting env. episode 247.000000, reward total was -20.000000. running mean: -20.408408\n",
            "resetting env. episode 248.000000, reward total was -21.000000. running mean: -20.414324\n",
            "resetting env. episode 249.000000, reward total was -19.000000. running mean: -20.400181\n",
            "resetting env. episode 250.000000, reward total was -21.000000. running mean: -20.406179\n",
            "resetting env. episode 251.000000, reward total was -19.000000. running mean: -20.392117\n",
            "resetting env. episode 252.000000, reward total was -20.000000. running mean: -20.388196\n",
            "resetting env. episode 253.000000, reward total was -21.000000. running mean: -20.394314\n",
            "resetting env. episode 254.000000, reward total was -20.000000. running mean: -20.390371\n",
            "resetting env. episode 255.000000, reward total was -20.000000. running mean: -20.386467\n",
            "resetting env. episode 256.000000, reward total was -21.000000. running mean: -20.392603\n",
            "resetting env. episode 257.000000, reward total was -21.000000. running mean: -20.398677\n",
            "resetting env. episode 258.000000, reward total was -19.000000. running mean: -20.384690\n",
            "resetting env. episode 259.000000, reward total was -20.000000. running mean: -20.380843\n",
            "resetting env. episode 260.000000, reward total was -20.000000. running mean: -20.377035\n",
            "resetting env. episode 261.000000, reward total was -21.000000. running mean: -20.383264\n",
            "resetting env. episode 262.000000, reward total was -21.000000. running mean: -20.389432\n",
            "resetting env. episode 263.000000, reward total was -21.000000. running mean: -20.395537\n",
            "resetting env. episode 264.000000, reward total was -21.000000. running mean: -20.401582\n",
            "resetting env. episode 265.000000, reward total was -20.000000. running mean: -20.397566\n",
            "resetting env. episode 266.000000, reward total was -21.000000. running mean: -20.403590\n",
            "resetting env. episode 267.000000, reward total was -21.000000. running mean: -20.409554\n",
            "resetting env. episode 268.000000, reward total was -19.000000. running mean: -20.395459\n",
            "resetting env. episode 269.000000, reward total was -20.000000. running mean: -20.391504\n",
            "resetting env. episode 270.000000, reward total was -20.000000. running mean: -20.387589\n",
            "resetting env. episode 271.000000, reward total was -21.000000. running mean: -20.393713\n",
            "resetting env. episode 272.000000, reward total was -21.000000. running mean: -20.399776\n",
            "resetting env. episode 273.000000, reward total was -20.000000. running mean: -20.395778\n",
            "resetting env. episode 274.000000, reward total was -21.000000. running mean: -20.401821\n",
            "resetting env. episode 275.000000, reward total was -21.000000. running mean: -20.407803\n",
            "resetting env. episode 276.000000, reward total was -20.000000. running mean: -20.403724\n",
            "resetting env. episode 277.000000, reward total was -21.000000. running mean: -20.409687\n",
            "resetting env. episode 278.000000, reward total was -20.000000. running mean: -20.405590\n",
            "resetting env. episode 279.000000, reward total was -20.000000. running mean: -20.401534\n",
            "resetting env. episode 280.000000, reward total was -19.000000. running mean: -20.387519\n",
            "resetting env. episode 281.000000, reward total was -19.000000. running mean: -20.373644\n",
            "resetting env. episode 282.000000, reward total was -21.000000. running mean: -20.379907\n",
            "resetting env. episode 283.000000, reward total was -21.000000. running mean: -20.386108\n",
            "resetting env. episode 284.000000, reward total was -20.000000. running mean: -20.382247\n",
            "resetting env. episode 285.000000, reward total was -21.000000. running mean: -20.388425\n",
            "resetting env. episode 286.000000, reward total was -20.000000. running mean: -20.384541\n",
            "resetting env. episode 287.000000, reward total was -19.000000. running mean: -20.370695\n",
            "resetting env. episode 288.000000, reward total was -21.000000. running mean: -20.376988\n",
            "resetting env. episode 289.000000, reward total was -20.000000. running mean: -20.373218\n",
            "resetting env. episode 290.000000, reward total was -21.000000. running mean: -20.379486\n",
            "resetting env. episode 291.000000, reward total was -21.000000. running mean: -20.385691\n",
            "resetting env. episode 292.000000, reward total was -20.000000. running mean: -20.381834\n",
            "resetting env. episode 293.000000, reward total was -21.000000. running mean: -20.388016\n",
            "resetting env. episode 294.000000, reward total was -19.000000. running mean: -20.374136\n",
            "resetting env. episode 295.000000, reward total was -19.000000. running mean: -20.360395\n",
            "resetting env. episode 296.000000, reward total was -21.000000. running mean: -20.366791\n",
            "resetting env. episode 297.000000, reward total was -21.000000. running mean: -20.373123\n",
            "resetting env. episode 298.000000, reward total was -21.000000. running mean: -20.379391\n",
            "resetting env. episode 299.000000, reward total was -21.000000. running mean: -20.385598\n",
            "resetting env. episode 300.000000, reward total was -19.000000. running mean: -20.371742\n",
            "resetting env. episode 301.000000, reward total was -18.000000. running mean: -20.348024\n",
            "resetting env. episode 302.000000, reward total was -19.000000. running mean: -20.334544\n",
            "resetting env. episode 303.000000, reward total was -19.000000. running mean: -20.321198\n",
            "resetting env. episode 304.000000, reward total was -21.000000. running mean: -20.327986\n",
            "resetting env. episode 305.000000, reward total was -21.000000. running mean: -20.334707\n",
            "resetting env. episode 306.000000, reward total was -21.000000. running mean: -20.341360\n",
            "resetting env. episode 307.000000, reward total was -21.000000. running mean: -20.347946\n",
            "resetting env. episode 308.000000, reward total was -20.000000. running mean: -20.344467\n",
            "resetting env. episode 309.000000, reward total was -20.000000. running mean: -20.341022\n",
            "resetting env. episode 310.000000, reward total was -21.000000. running mean: -20.347612\n",
            "resetting env. episode 311.000000, reward total was -21.000000. running mean: -20.354136\n",
            "resetting env. episode 312.000000, reward total was -20.000000. running mean: -20.350594\n",
            "resetting env. episode 313.000000, reward total was -20.000000. running mean: -20.347088\n",
            "resetting env. episode 314.000000, reward total was -21.000000. running mean: -20.353617\n",
            "resetting env. episode 315.000000, reward total was -21.000000. running mean: -20.360081\n",
            "resetting env. episode 316.000000, reward total was -20.000000. running mean: -20.356480\n",
            "resetting env. episode 317.000000, reward total was -21.000000. running mean: -20.362916\n",
            "resetting env. episode 318.000000, reward total was -21.000000. running mean: -20.369286\n",
            "resetting env. episode 319.000000, reward total was -21.000000. running mean: -20.375594\n",
            "resetting env. episode 320.000000, reward total was -21.000000. running mean: -20.381838\n",
            "resetting env. episode 321.000000, reward total was -18.000000. running mean: -20.358019\n",
            "resetting env. episode 322.000000, reward total was -21.000000. running mean: -20.364439\n",
            "resetting env. episode 323.000000, reward total was -21.000000. running mean: -20.370795\n",
            "resetting env. episode 324.000000, reward total was -21.000000. running mean: -20.377087\n",
            "resetting env. episode 325.000000, reward total was -20.000000. running mean: -20.373316\n",
            "resetting env. episode 326.000000, reward total was -19.000000. running mean: -20.359583\n",
            "resetting env. episode 327.000000, reward total was -21.000000. running mean: -20.365987\n",
            "resetting env. episode 328.000000, reward total was -20.000000. running mean: -20.362327\n",
            "resetting env. episode 329.000000, reward total was -19.000000. running mean: -20.348704\n",
            "resetting env. episode 330.000000, reward total was -19.000000. running mean: -20.335217\n",
            "resetting env. episode 331.000000, reward total was -21.000000. running mean: -20.341864\n",
            "resetting env. episode 332.000000, reward total was -21.000000. running mean: -20.348446\n",
            "resetting env. episode 333.000000, reward total was -18.000000. running mean: -20.324961\n",
            "resetting env. episode 334.000000, reward total was -21.000000. running mean: -20.331712\n",
            "resetting env. episode 335.000000, reward total was -19.000000. running mean: -20.318395\n",
            "resetting env. episode 336.000000, reward total was -20.000000. running mean: -20.315211\n",
            "resetting env. episode 337.000000, reward total was -20.000000. running mean: -20.312059\n",
            "resetting env. episode 338.000000, reward total was -21.000000. running mean: -20.318938\n",
            "resetting env. episode 339.000000, reward total was -20.000000. running mean: -20.315749\n",
            "resetting env. episode 340.000000, reward total was -21.000000. running mean: -20.322591\n",
            "resetting env. episode 341.000000, reward total was -19.000000. running mean: -20.309365\n",
            "resetting env. episode 342.000000, reward total was -21.000000. running mean: -20.316272\n",
            "resetting env. episode 343.000000, reward total was -19.000000. running mean: -20.303109\n",
            "resetting env. episode 344.000000, reward total was -21.000000. running mean: -20.310078\n",
            "resetting env. episode 345.000000, reward total was -21.000000. running mean: -20.316977\n",
            "resetting env. episode 346.000000, reward total was -21.000000. running mean: -20.323807\n",
            "resetting env. episode 347.000000, reward total was -21.000000. running mean: -20.330569\n",
            "resetting env. episode 348.000000, reward total was -21.000000. running mean: -20.337263\n",
            "resetting env. episode 349.000000, reward total was -21.000000. running mean: -20.343891\n",
            "resetting env. episode 350.000000, reward total was -19.000000. running mean: -20.330452\n",
            "resetting env. episode 351.000000, reward total was -21.000000. running mean: -20.337147\n",
            "resetting env. episode 352.000000, reward total was -20.000000. running mean: -20.333776\n",
            "resetting env. episode 353.000000, reward total was -21.000000. running mean: -20.340438\n",
            "resetting env. episode 354.000000, reward total was -21.000000. running mean: -20.347034\n",
            "resetting env. episode 355.000000, reward total was -20.000000. running mean: -20.343563\n",
            "resetting env. episode 356.000000, reward total was -21.000000. running mean: -20.350128\n",
            "resetting env. episode 357.000000, reward total was -20.000000. running mean: -20.346627\n",
            "resetting env. episode 358.000000, reward total was -21.000000. running mean: -20.353160\n",
            "resetting env. episode 359.000000, reward total was -19.000000. running mean: -20.339629\n",
            "resetting env. episode 360.000000, reward total was -20.000000. running mean: -20.336232\n",
            "resetting env. episode 361.000000, reward total was -21.000000. running mean: -20.342870\n",
            "resetting env. episode 362.000000, reward total was -19.000000. running mean: -20.329441\n",
            "resetting env. episode 363.000000, reward total was -21.000000. running mean: -20.336147\n",
            "resetting env. episode 364.000000, reward total was -21.000000. running mean: -20.342785\n",
            "resetting env. episode 365.000000, reward total was -21.000000. running mean: -20.349358\n",
            "resetting env. episode 366.000000, reward total was -20.000000. running mean: -20.345864\n",
            "resetting env. episode 367.000000, reward total was -20.000000. running mean: -20.342405\n",
            "resetting env. episode 368.000000, reward total was -21.000000. running mean: -20.348981\n",
            "resetting env. episode 369.000000, reward total was -21.000000. running mean: -20.355492\n",
            "resetting env. episode 370.000000, reward total was -21.000000. running mean: -20.361937\n",
            "resetting env. episode 371.000000, reward total was -21.000000. running mean: -20.368317\n",
            "resetting env. episode 372.000000, reward total was -21.000000. running mean: -20.374634\n",
            "resetting env. episode 373.000000, reward total was -21.000000. running mean: -20.380888\n",
            "resetting env. episode 374.000000, reward total was -21.000000. running mean: -20.387079\n",
            "resetting env. episode 375.000000, reward total was -21.000000. running mean: -20.393208\n",
            "resetting env. episode 376.000000, reward total was -21.000000. running mean: -20.399276\n",
            "resetting env. episode 377.000000, reward total was -21.000000. running mean: -20.405283\n",
            "resetting env. episode 378.000000, reward total was -21.000000. running mean: -20.411230\n",
            "resetting env. episode 379.000000, reward total was -20.000000. running mean: -20.407118\n",
            "resetting env. episode 380.000000, reward total was -19.000000. running mean: -20.393047\n",
            "resetting env. episode 381.000000, reward total was -21.000000. running mean: -20.399116\n",
            "resetting env. episode 382.000000, reward total was -20.000000. running mean: -20.395125\n",
            "resetting env. episode 383.000000, reward total was -21.000000. running mean: -20.401174\n",
            "resetting env. episode 384.000000, reward total was -16.000000. running mean: -20.357162\n",
            "resetting env. episode 385.000000, reward total was -20.000000. running mean: -20.353591\n",
            "resetting env. episode 386.000000, reward total was -20.000000. running mean: -20.350055\n",
            "resetting env. episode 387.000000, reward total was -19.000000. running mean: -20.336554\n",
            "resetting env. episode 388.000000, reward total was -21.000000. running mean: -20.343189\n",
            "resetting env. episode 389.000000, reward total was -20.000000. running mean: -20.339757\n",
            "resetting env. episode 390.000000, reward total was -21.000000. running mean: -20.346359\n",
            "resetting env. episode 391.000000, reward total was -18.000000. running mean: -20.322896\n",
            "resetting env. episode 392.000000, reward total was -20.000000. running mean: -20.319667\n",
            "resetting env. episode 393.000000, reward total was -19.000000. running mean: -20.306470\n",
            "resetting env. episode 394.000000, reward total was -21.000000. running mean: -20.313405\n",
            "resetting env. episode 395.000000, reward total was -21.000000. running mean: -20.320271\n",
            "resetting env. episode 396.000000, reward total was -21.000000. running mean: -20.327069\n",
            "resetting env. episode 397.000000, reward total was -21.000000. running mean: -20.333798\n",
            "resetting env. episode 398.000000, reward total was -21.000000. running mean: -20.340460\n",
            "resetting env. episode 399.000000, reward total was -21.000000. running mean: -20.347055\n",
            "resetting env. episode 400.000000, reward total was -20.000000. running mean: -20.343585\n",
            "resetting env. episode 401.000000, reward total was -21.000000. running mean: -20.350149\n",
            "resetting env. episode 402.000000, reward total was -21.000000. running mean: -20.356647\n",
            "resetting env. episode 403.000000, reward total was -20.000000. running mean: -20.353081\n",
            "resetting env. episode 404.000000, reward total was -19.000000. running mean: -20.339550\n",
            "resetting env. episode 405.000000, reward total was -21.000000. running mean: -20.346155\n",
            "resetting env. episode 406.000000, reward total was -20.000000. running mean: -20.342693\n",
            "resetting env. episode 407.000000, reward total was -20.000000. running mean: -20.339266\n",
            "resetting env. episode 408.000000, reward total was -18.000000. running mean: -20.315873\n",
            "resetting env. episode 409.000000, reward total was -21.000000. running mean: -20.322715\n",
            "resetting env. episode 410.000000, reward total was -21.000000. running mean: -20.329488\n",
            "resetting env. episode 411.000000, reward total was -21.000000. running mean: -20.336193\n",
            "resetting env. episode 412.000000, reward total was -20.000000. running mean: -20.332831\n",
            "resetting env. episode 413.000000, reward total was -20.000000. running mean: -20.329502\n",
            "resetting env. episode 414.000000, reward total was -21.000000. running mean: -20.336207\n",
            "resetting env. episode 415.000000, reward total was -20.000000. running mean: -20.332845\n",
            "resetting env. episode 416.000000, reward total was -20.000000. running mean: -20.329517\n",
            "resetting env. episode 417.000000, reward total was -21.000000. running mean: -20.336222\n",
            "resetting env. episode 418.000000, reward total was -21.000000. running mean: -20.342860\n",
            "resetting env. episode 419.000000, reward total was -20.000000. running mean: -20.339431\n",
            "resetting env. episode 420.000000, reward total was -21.000000. running mean: -20.346037\n",
            "resetting env. episode 421.000000, reward total was -21.000000. running mean: -20.352576\n",
            "resetting env. episode 422.000000, reward total was -21.000000. running mean: -20.359050\n",
            "resetting env. episode 423.000000, reward total was -21.000000. running mean: -20.365460\n",
            "resetting env. episode 424.000000, reward total was -21.000000. running mean: -20.371805\n",
            "resetting env. episode 425.000000, reward total was -18.000000. running mean: -20.348087\n",
            "resetting env. episode 426.000000, reward total was -21.000000. running mean: -20.354606\n",
            "resetting env. episode 427.000000, reward total was -21.000000. running mean: -20.361060\n",
            "resetting env. episode 428.000000, reward total was -19.000000. running mean: -20.347450\n",
            "resetting env. episode 429.000000, reward total was -19.000000. running mean: -20.333975\n",
            "resetting env. episode 430.000000, reward total was -21.000000. running mean: -20.340636\n",
            "resetting env. episode 431.000000, reward total was -21.000000. running mean: -20.347229\n",
            "resetting env. episode 432.000000, reward total was -21.000000. running mean: -20.353757\n",
            "resetting env. episode 433.000000, reward total was -21.000000. running mean: -20.360219\n",
            "resetting env. episode 434.000000, reward total was -21.000000. running mean: -20.366617\n",
            "resetting env. episode 435.000000, reward total was -20.000000. running mean: -20.362951\n",
            "resetting env. episode 436.000000, reward total was -19.000000. running mean: -20.349321\n",
            "resetting env. episode 437.000000, reward total was -21.000000. running mean: -20.355828\n",
            "resetting env. episode 438.000000, reward total was -20.000000. running mean: -20.352270\n",
            "resetting env. episode 439.000000, reward total was -21.000000. running mean: -20.358747\n",
            "resetting env. episode 440.000000, reward total was -20.000000. running mean: -20.355160\n",
            "resetting env. episode 441.000000, reward total was -17.000000. running mean: -20.321608\n",
            "resetting env. episode 442.000000, reward total was -21.000000. running mean: -20.328392\n",
            "resetting env. episode 443.000000, reward total was -20.000000. running mean: -20.325108\n",
            "resetting env. episode 444.000000, reward total was -18.000000. running mean: -20.301857\n",
            "resetting env. episode 445.000000, reward total was -19.000000. running mean: -20.288839\n",
            "resetting env. episode 446.000000, reward total was -21.000000. running mean: -20.295950\n",
            "resetting env. episode 447.000000, reward total was -21.000000. running mean: -20.302991\n",
            "resetting env. episode 448.000000, reward total was -21.000000. running mean: -20.309961\n",
            "resetting env. episode 449.000000, reward total was -21.000000. running mean: -20.316861\n",
            "resetting env. episode 450.000000, reward total was -21.000000. running mean: -20.323693\n",
            "resetting env. episode 451.000000, reward total was -21.000000. running mean: -20.330456\n",
            "resetting env. episode 452.000000, reward total was -21.000000. running mean: -20.337151\n",
            "resetting env. episode 453.000000, reward total was -21.000000. running mean: -20.343780\n",
            "resetting env. episode 454.000000, reward total was -20.000000. running mean: -20.340342\n",
            "resetting env. episode 455.000000, reward total was -20.000000. running mean: -20.336938\n",
            "resetting env. episode 456.000000, reward total was -20.000000. running mean: -20.333569\n",
            "resetting env. episode 457.000000, reward total was -19.000000. running mean: -20.320233\n",
            "resetting env. episode 458.000000, reward total was -21.000000. running mean: -20.327031\n",
            "resetting env. episode 459.000000, reward total was -21.000000. running mean: -20.333761\n",
            "resetting env. episode 460.000000, reward total was -21.000000. running mean: -20.340423\n",
            "resetting env. episode 461.000000, reward total was -20.000000. running mean: -20.337019\n",
            "resetting env. episode 462.000000, reward total was -21.000000. running mean: -20.343649\n",
            "resetting env. episode 463.000000, reward total was -20.000000. running mean: -20.340212\n",
            "resetting env. episode 464.000000, reward total was -20.000000. running mean: -20.336810\n",
            "resetting env. episode 465.000000, reward total was -21.000000. running mean: -20.343442\n",
            "resetting env. episode 466.000000, reward total was -21.000000. running mean: -20.350007\n",
            "resetting env. episode 467.000000, reward total was -20.000000. running mean: -20.346507\n",
            "resetting env. episode 468.000000, reward total was -20.000000. running mean: -20.343042\n",
            "resetting env. episode 469.000000, reward total was -20.000000. running mean: -20.339612\n",
            "resetting env. episode 470.000000, reward total was -21.000000. running mean: -20.346216\n",
            "resetting env. episode 471.000000, reward total was -21.000000. running mean: -20.352754\n",
            "resetting env. episode 472.000000, reward total was -21.000000. running mean: -20.359226\n",
            "resetting env. episode 473.000000, reward total was -21.000000. running mean: -20.365634\n",
            "resetting env. episode 474.000000, reward total was -20.000000. running mean: -20.361977\n",
            "resetting env. episode 475.000000, reward total was -20.000000. running mean: -20.358358\n",
            "resetting env. episode 476.000000, reward total was -20.000000. running mean: -20.354774\n",
            "resetting env. episode 477.000000, reward total was -19.000000. running mean: -20.341226\n",
            "resetting env. episode 478.000000, reward total was -20.000000. running mean: -20.337814\n",
            "resetting env. episode 479.000000, reward total was -19.000000. running mean: -20.324436\n",
            "resetting env. episode 480.000000, reward total was -18.000000. running mean: -20.301192\n",
            "resetting env. episode 481.000000, reward total was -19.000000. running mean: -20.288180\n",
            "resetting env. episode 482.000000, reward total was -21.000000. running mean: -20.295298\n",
            "resetting env. episode 483.000000, reward total was -21.000000. running mean: -20.302345\n",
            "resetting env. episode 484.000000, reward total was -21.000000. running mean: -20.309321\n",
            "resetting env. episode 485.000000, reward total was -21.000000. running mean: -20.316228\n",
            "resetting env. episode 486.000000, reward total was -21.000000. running mean: -20.323066\n",
            "resetting env. episode 487.000000, reward total was -19.000000. running mean: -20.309835\n",
            "resetting env. episode 488.000000, reward total was -21.000000. running mean: -20.316737\n",
            "resetting env. episode 489.000000, reward total was -21.000000. running mean: -20.323570\n",
            "resetting env. episode 490.000000, reward total was -21.000000. running mean: -20.330334\n",
            "resetting env. episode 491.000000, reward total was -20.000000. running mean: -20.327031\n",
            "resetting env. episode 492.000000, reward total was -21.000000. running mean: -20.333760\n",
            "resetting env. episode 493.000000, reward total was -21.000000. running mean: -20.340423\n",
            "resetting env. episode 494.000000, reward total was -19.000000. running mean: -20.327018\n",
            "resetting env. episode 495.000000, reward total was -21.000000. running mean: -20.333748\n",
            "resetting env. episode 496.000000, reward total was -21.000000. running mean: -20.340411\n",
            "resetting env. episode 497.000000, reward total was -18.000000. running mean: -20.317007\n",
            "resetting env. episode 498.000000, reward total was -19.000000. running mean: -20.303837\n",
            "resetting env. episode 499.000000, reward total was -20.000000. running mean: -20.300798\n",
            "resetting env. episode 500.000000, reward total was -21.000000. running mean: -20.307790\n",
            "resetting env. episode 501.000000, reward total was -21.000000. running mean: -20.314712\n",
            "resetting env. episode 502.000000, reward total was -20.000000. running mean: -20.311565\n",
            "resetting env. episode 503.000000, reward total was -21.000000. running mean: -20.318450\n",
            "resetting env. episode 504.000000, reward total was -19.000000. running mean: -20.305265\n",
            "resetting env. episode 505.000000, reward total was -21.000000. running mean: -20.312212\n",
            "resetting env. episode 506.000000, reward total was -21.000000. running mean: -20.319090\n",
            "resetting env. episode 507.000000, reward total was -19.000000. running mean: -20.305899\n",
            "resetting env. episode 508.000000, reward total was -18.000000. running mean: -20.282840\n",
            "resetting env. episode 509.000000, reward total was -20.000000. running mean: -20.280012\n",
            "resetting env. episode 510.000000, reward total was -19.000000. running mean: -20.267212\n",
            "resetting env. episode 511.000000, reward total was -21.000000. running mean: -20.274540\n",
            "resetting env. episode 512.000000, reward total was -21.000000. running mean: -20.281794\n",
            "resetting env. episode 513.000000, reward total was -21.000000. running mean: -20.288976\n",
            "resetting env. episode 514.000000, reward total was -20.000000. running mean: -20.286087\n",
            "resetting env. episode 515.000000, reward total was -21.000000. running mean: -20.293226\n",
            "resetting env. episode 516.000000, reward total was -18.000000. running mean: -20.270294\n",
            "resetting env. episode 517.000000, reward total was -21.000000. running mean: -20.277591\n",
            "resetting env. episode 518.000000, reward total was -20.000000. running mean: -20.274815\n",
            "resetting env. episode 519.000000, reward total was -19.000000. running mean: -20.262067\n",
            "resetting env. episode 520.000000, reward total was -21.000000. running mean: -20.269446\n",
            "resetting env. episode 521.000000, reward total was -19.000000. running mean: -20.256751\n",
            "resetting env. episode 522.000000, reward total was -21.000000. running mean: -20.264184\n",
            "resetting env. episode 523.000000, reward total was -21.000000. running mean: -20.271542\n",
            "resetting env. episode 524.000000, reward total was -21.000000. running mean: -20.278827\n",
            "resetting env. episode 525.000000, reward total was -20.000000. running mean: -20.276038\n",
            "resetting env. episode 526.000000, reward total was -17.000000. running mean: -20.243278\n",
            "resetting env. episode 527.000000, reward total was -21.000000. running mean: -20.250845\n",
            "resetting env. episode 528.000000, reward total was -21.000000. running mean: -20.258337\n",
            "resetting env. episode 529.000000, reward total was -19.000000. running mean: -20.245753\n",
            "resetting env. episode 530.000000, reward total was -21.000000. running mean: -20.253296\n",
            "resetting env. episode 531.000000, reward total was -21.000000. running mean: -20.260763\n",
            "resetting env. episode 532.000000, reward total was -21.000000. running mean: -20.268155\n",
            "resetting env. episode 533.000000, reward total was -21.000000. running mean: -20.275474\n",
            "resetting env. episode 534.000000, reward total was -21.000000. running mean: -20.282719\n",
            "resetting env. episode 535.000000, reward total was -21.000000. running mean: -20.289892\n",
            "resetting env. episode 536.000000, reward total was -21.000000. running mean: -20.296993\n",
            "resetting env. episode 537.000000, reward total was -21.000000. running mean: -20.304023\n",
            "resetting env. episode 538.000000, reward total was -19.000000. running mean: -20.290983\n",
            "resetting env. episode 539.000000, reward total was -20.000000. running mean: -20.288073\n",
            "resetting env. episode 540.000000, reward total was -21.000000. running mean: -20.295192\n",
            "resetting env. episode 541.000000, reward total was -20.000000. running mean: -20.292240\n",
            "resetting env. episode 542.000000, reward total was -21.000000. running mean: -20.299318\n",
            "resetting env. episode 543.000000, reward total was -18.000000. running mean: -20.276325\n",
            "resetting env. episode 544.000000, reward total was -20.000000. running mean: -20.273561\n",
            "resetting env. episode 545.000000, reward total was -20.000000. running mean: -20.270826\n",
            "resetting env. episode 546.000000, reward total was -20.000000. running mean: -20.268118\n",
            "resetting env. episode 547.000000, reward total was -21.000000. running mean: -20.275436\n",
            "resetting env. episode 548.000000, reward total was -21.000000. running mean: -20.282682\n",
            "resetting env. episode 549.000000, reward total was -21.000000. running mean: -20.289855\n",
            "resetting env. episode 550.000000, reward total was -19.000000. running mean: -20.276957\n",
            "resetting env. episode 551.000000, reward total was -21.000000. running mean: -20.284187\n",
            "resetting env. episode 552.000000, reward total was -19.000000. running mean: -20.271345\n",
            "resetting env. episode 553.000000, reward total was -20.000000. running mean: -20.268632\n",
            "resetting env. episode 554.000000, reward total was -21.000000. running mean: -20.275945\n",
            "resetting env. episode 555.000000, reward total was -21.000000. running mean: -20.283186\n",
            "resetting env. episode 556.000000, reward total was -19.000000. running mean: -20.270354\n",
            "resetting env. episode 557.000000, reward total was -20.000000. running mean: -20.267651\n",
            "resetting env. episode 558.000000, reward total was -20.000000. running mean: -20.264974\n",
            "resetting env. episode 559.000000, reward total was -21.000000. running mean: -20.272324\n",
            "resetting env. episode 560.000000, reward total was -21.000000. running mean: -20.279601\n",
            "resetting env. episode 561.000000, reward total was -20.000000. running mean: -20.276805\n",
            "resetting env. episode 562.000000, reward total was -21.000000. running mean: -20.284037\n",
            "resetting env. episode 563.000000, reward total was -21.000000. running mean: -20.291197\n",
            "resetting env. episode 564.000000, reward total was -21.000000. running mean: -20.298285\n",
            "resetting env. episode 565.000000, reward total was -21.000000. running mean: -20.305302\n",
            "resetting env. episode 566.000000, reward total was -21.000000. running mean: -20.312249\n",
            "resetting env. episode 567.000000, reward total was -21.000000. running mean: -20.319126\n",
            "resetting env. episode 568.000000, reward total was -21.000000. running mean: -20.325935\n",
            "resetting env. episode 569.000000, reward total was -21.000000. running mean: -20.332676\n",
            "resetting env. episode 570.000000, reward total was -21.000000. running mean: -20.339349\n",
            "resetting env. episode 571.000000, reward total was -20.000000. running mean: -20.335955\n",
            "resetting env. episode 572.000000, reward total was -18.000000. running mean: -20.312596\n",
            "resetting env. episode 573.000000, reward total was -20.000000. running mean: -20.309470\n",
            "resetting env. episode 574.000000, reward total was -19.000000. running mean: -20.296375\n",
            "resetting env. episode 575.000000, reward total was -21.000000. running mean: -20.303411\n",
            "resetting env. episode 576.000000, reward total was -18.000000. running mean: -20.280377\n",
            "resetting env. episode 577.000000, reward total was -21.000000. running mean: -20.287574\n",
            "resetting env. episode 578.000000, reward total was -21.000000. running mean: -20.294698\n",
            "resetting env. episode 579.000000, reward total was -19.000000. running mean: -20.281751\n",
            "resetting env. episode 580.000000, reward total was -21.000000. running mean: -20.288933\n",
            "resetting env. episode 581.000000, reward total was -21.000000. running mean: -20.296044\n",
            "resetting env. episode 582.000000, reward total was -20.000000. running mean: -20.293084\n",
            "resetting env. episode 583.000000, reward total was -21.000000. running mean: -20.300153\n",
            "resetting env. episode 584.000000, reward total was -21.000000. running mean: -20.307151\n",
            "resetting env. episode 585.000000, reward total was -21.000000. running mean: -20.314080\n",
            "resetting env. episode 586.000000, reward total was -20.000000. running mean: -20.310939\n",
            "resetting env. episode 587.000000, reward total was -21.000000. running mean: -20.317830\n",
            "resetting env. episode 588.000000, reward total was -20.000000. running mean: -20.314651\n",
            "resetting env. episode 589.000000, reward total was -21.000000. running mean: -20.321505\n",
            "resetting env. episode 590.000000, reward total was -17.000000. running mean: -20.288290\n",
            "resetting env. episode 591.000000, reward total was -20.000000. running mean: -20.285407\n",
            "resetting env. episode 592.000000, reward total was -20.000000. running mean: -20.282553\n",
            "resetting env. episode 593.000000, reward total was -21.000000. running mean: -20.289727\n",
            "resetting env. episode 594.000000, reward total was -21.000000. running mean: -20.296830\n",
            "resetting env. episode 595.000000, reward total was -19.000000. running mean: -20.283862\n",
            "resetting env. episode 596.000000, reward total was -21.000000. running mean: -20.291023\n",
            "resetting env. episode 597.000000, reward total was -21.000000. running mean: -20.298113\n",
            "resetting env. episode 598.000000, reward total was -20.000000. running mean: -20.295132\n",
            "resetting env. episode 599.000000, reward total was -20.000000. running mean: -20.292180\n",
            "resetting env. episode 600.000000, reward total was -20.000000. running mean: -20.289259\n",
            "resetting env. episode 601.000000, reward total was -21.000000. running mean: -20.296366\n",
            "resetting env. episode 602.000000, reward total was -20.000000. running mean: -20.293402\n",
            "resetting env. episode 603.000000, reward total was -19.000000. running mean: -20.280468\n",
            "resetting env. episode 604.000000, reward total was -21.000000. running mean: -20.287664\n",
            "resetting env. episode 605.000000, reward total was -18.000000. running mean: -20.264787\n",
            "resetting env. episode 606.000000, reward total was -20.000000. running mean: -20.262139\n",
            "resetting env. episode 607.000000, reward total was -19.000000. running mean: -20.249518\n",
            "resetting env. episode 608.000000, reward total was -20.000000. running mean: -20.247023\n",
            "resetting env. episode 609.000000, reward total was -18.000000. running mean: -20.224552\n",
            "resetting env. episode 610.000000, reward total was -21.000000. running mean: -20.232307\n",
            "resetting env. episode 611.000000, reward total was -21.000000. running mean: -20.239984\n",
            "resetting env. episode 612.000000, reward total was -20.000000. running mean: -20.237584\n",
            "resetting env. episode 613.000000, reward total was -21.000000. running mean: -20.245208\n",
            "resetting env. episode 614.000000, reward total was -19.000000. running mean: -20.232756\n",
            "resetting env. episode 615.000000, reward total was -21.000000. running mean: -20.240428\n",
            "resetting env. episode 616.000000, reward total was -20.000000. running mean: -20.238024\n",
            "resetting env. episode 617.000000, reward total was -21.000000. running mean: -20.245644\n",
            "resetting env. episode 618.000000, reward total was -20.000000. running mean: -20.243187\n",
            "resetting env. episode 619.000000, reward total was -21.000000. running mean: -20.250756\n",
            "resetting env. episode 620.000000, reward total was -20.000000. running mean: -20.248248\n",
            "resetting env. episode 621.000000, reward total was -21.000000. running mean: -20.255766\n",
            "resetting env. episode 622.000000, reward total was -20.000000. running mean: -20.253208\n",
            "resetting env. episode 623.000000, reward total was -21.000000. running mean: -20.260676\n",
            "resetting env. episode 624.000000, reward total was -21.000000. running mean: -20.268069\n",
            "resetting env. episode 625.000000, reward total was -20.000000. running mean: -20.265388\n",
            "resetting env. episode 626.000000, reward total was -21.000000. running mean: -20.272734\n",
            "resetting env. episode 627.000000, reward total was -21.000000. running mean: -20.280007\n",
            "resetting env. episode 628.000000, reward total was -20.000000. running mean: -20.277207\n",
            "resetting env. episode 629.000000, reward total was -21.000000. running mean: -20.284435\n",
            "resetting env. episode 630.000000, reward total was -21.000000. running mean: -20.291591\n",
            "resetting env. episode 631.000000, reward total was -21.000000. running mean: -20.298675\n",
            "resetting env. episode 632.000000, reward total was -21.000000. running mean: -20.305688\n",
            "resetting env. episode 633.000000, reward total was -21.000000. running mean: -20.312631\n",
            "resetting env. episode 634.000000, reward total was -20.000000. running mean: -20.309505\n",
            "resetting env. episode 635.000000, reward total was -21.000000. running mean: -20.316410\n",
            "resetting env. episode 636.000000, reward total was -19.000000. running mean: -20.303246\n",
            "resetting env. episode 637.000000, reward total was -21.000000. running mean: -20.310213\n",
            "resetting env. episode 638.000000, reward total was -21.000000. running mean: -20.317111\n",
            "resetting env. episode 639.000000, reward total was -20.000000. running mean: -20.313940\n",
            "resetting env. episode 640.000000, reward total was -21.000000. running mean: -20.320801\n",
            "resetting env. episode 641.000000, reward total was -20.000000. running mean: -20.317593\n",
            "resetting env. episode 642.000000, reward total was -21.000000. running mean: -20.324417\n",
            "resetting env. episode 643.000000, reward total was -19.000000. running mean: -20.311172\n",
            "resetting env. episode 644.000000, reward total was -21.000000. running mean: -20.318061\n",
            "resetting env. episode 645.000000, reward total was -21.000000. running mean: -20.324880\n",
            "resetting env. episode 646.000000, reward total was -18.000000. running mean: -20.301631\n",
            "resetting env. episode 647.000000, reward total was -19.000000. running mean: -20.288615\n",
            "resetting env. episode 648.000000, reward total was -20.000000. running mean: -20.285729\n",
            "resetting env. episode 649.000000, reward total was -21.000000. running mean: -20.292872\n",
            "resetting env. episode 650.000000, reward total was -20.000000. running mean: -20.289943\n",
            "resetting env. episode 651.000000, reward total was -21.000000. running mean: -20.297043\n",
            "resetting env. episode 652.000000, reward total was -21.000000. running mean: -20.304073\n",
            "resetting env. episode 653.000000, reward total was -21.000000. running mean: -20.311032\n",
            "resetting env. episode 654.000000, reward total was -21.000000. running mean: -20.317922\n",
            "resetting env. episode 655.000000, reward total was -21.000000. running mean: -20.324743\n",
            "resetting env. episode 656.000000, reward total was -21.000000. running mean: -20.331495\n",
            "resetting env. episode 657.000000, reward total was -21.000000. running mean: -20.338180\n",
            "resetting env. episode 658.000000, reward total was -21.000000. running mean: -20.344799\n",
            "resetting env. episode 659.000000, reward total was -21.000000. running mean: -20.351351\n",
            "resetting env. episode 660.000000, reward total was -21.000000. running mean: -20.357837\n",
            "resetting env. episode 661.000000, reward total was -20.000000. running mean: -20.354259\n",
            "resetting env. episode 662.000000, reward total was -21.000000. running mean: -20.360716\n",
            "resetting env. episode 663.000000, reward total was -19.000000. running mean: -20.347109\n",
            "resetting env. episode 664.000000, reward total was -21.000000. running mean: -20.353638\n",
            "resetting env. episode 665.000000, reward total was -21.000000. running mean: -20.360101\n",
            "resetting env. episode 666.000000, reward total was -20.000000. running mean: -20.356500\n",
            "resetting env. episode 667.000000, reward total was -17.000000. running mean: -20.322935\n",
            "resetting env. episode 668.000000, reward total was -21.000000. running mean: -20.329706\n",
            "resetting env. episode 669.000000, reward total was -20.000000. running mean: -20.326409\n",
            "resetting env. episode 670.000000, reward total was -21.000000. running mean: -20.333145\n",
            "resetting env. episode 671.000000, reward total was -20.000000. running mean: -20.329813\n",
            "resetting env. episode 672.000000, reward total was -20.000000. running mean: -20.326515\n",
            "resetting env. episode 673.000000, reward total was -21.000000. running mean: -20.333250\n",
            "resetting env. episode 674.000000, reward total was -21.000000. running mean: -20.339918\n",
            "resetting env. episode 675.000000, reward total was -19.000000. running mean: -20.326518\n",
            "resetting env. episode 676.000000, reward total was -21.000000. running mean: -20.333253\n",
            "resetting env. episode 677.000000, reward total was -20.000000. running mean: -20.329921\n",
            "resetting env. episode 678.000000, reward total was -19.000000. running mean: -20.316622\n",
            "resetting env. episode 679.000000, reward total was -20.000000. running mean: -20.313455\n",
            "resetting env. episode 680.000000, reward total was -20.000000. running mean: -20.310321\n",
            "resetting env. episode 681.000000, reward total was -20.000000. running mean: -20.307218\n",
            "resetting env. episode 682.000000, reward total was -20.000000. running mean: -20.304145\n",
            "resetting env. episode 683.000000, reward total was -21.000000. running mean: -20.311104\n",
            "resetting env. episode 684.000000, reward total was -21.000000. running mean: -20.317993\n",
            "resetting env. episode 685.000000, reward total was -20.000000. running mean: -20.314813\n",
            "resetting env. episode 686.000000, reward total was -21.000000. running mean: -20.321665\n",
            "resetting env. episode 687.000000, reward total was -19.000000. running mean: -20.308448\n",
            "resetting env. episode 688.000000, reward total was -20.000000. running mean: -20.305364\n",
            "resetting env. episode 689.000000, reward total was -20.000000. running mean: -20.302310\n",
            "resetting env. episode 690.000000, reward total was -21.000000. running mean: -20.309287\n",
            "resetting env. episode 691.000000, reward total was -21.000000. running mean: -20.316194\n",
            "resetting env. episode 692.000000, reward total was -18.000000. running mean: -20.293032\n",
            "resetting env. episode 693.000000, reward total was -20.000000. running mean: -20.290102\n",
            "resetting env. episode 694.000000, reward total was -21.000000. running mean: -20.297201\n",
            "resetting env. episode 695.000000, reward total was -20.000000. running mean: -20.294229\n",
            "resetting env. episode 696.000000, reward total was -19.000000. running mean: -20.281287\n",
            "resetting env. episode 697.000000, reward total was -21.000000. running mean: -20.288474\n",
            "resetting env. episode 698.000000, reward total was -21.000000. running mean: -20.295589\n",
            "resetting env. episode 699.000000, reward total was -19.000000. running mean: -20.282633\n",
            "resetting env. episode 700.000000, reward total was -21.000000. running mean: -20.289807\n",
            "resetting env. episode 701.000000, reward total was -21.000000. running mean: -20.296909\n",
            "resetting env. episode 702.000000, reward total was -20.000000. running mean: -20.293940\n",
            "resetting env. episode 703.000000, reward total was -21.000000. running mean: -20.301000\n",
            "resetting env. episode 704.000000, reward total was -21.000000. running mean: -20.307990\n",
            "resetting env. episode 705.000000, reward total was -20.000000. running mean: -20.304910\n",
            "resetting env. episode 706.000000, reward total was -20.000000. running mean: -20.301861\n",
            "resetting env. episode 707.000000, reward total was -17.000000. running mean: -20.268843\n",
            "resetting env. episode 708.000000, reward total was -21.000000. running mean: -20.276154\n",
            "resetting env. episode 709.000000, reward total was -20.000000. running mean: -20.273393\n",
            "resetting env. episode 710.000000, reward total was -21.000000. running mean: -20.280659\n",
            "resetting env. episode 711.000000, reward total was -21.000000. running mean: -20.287852\n",
            "resetting env. episode 712.000000, reward total was -21.000000. running mean: -20.294974\n",
            "resetting env. episode 713.000000, reward total was -21.000000. running mean: -20.302024\n",
            "resetting env. episode 714.000000, reward total was -17.000000. running mean: -20.269004\n",
            "resetting env. episode 715.000000, reward total was -20.000000. running mean: -20.266314\n",
            "resetting env. episode 716.000000, reward total was -21.000000. running mean: -20.273650\n",
            "resetting env. episode 717.000000, reward total was -20.000000. running mean: -20.270914\n",
            "resetting env. episode 718.000000, reward total was -20.000000. running mean: -20.268205\n",
            "resetting env. episode 719.000000, reward total was -21.000000. running mean: -20.275523\n",
            "resetting env. episode 720.000000, reward total was -21.000000. running mean: -20.282767\n",
            "resetting env. episode 721.000000, reward total was -18.000000. running mean: -20.259940\n",
            "resetting env. episode 722.000000, reward total was -21.000000. running mean: -20.267340\n",
            "resetting env. episode 723.000000, reward total was -21.000000. running mean: -20.274667\n",
            "resetting env. episode 724.000000, reward total was -21.000000. running mean: -20.281920\n",
            "resetting env. episode 725.000000, reward total was -21.000000. running mean: -20.289101\n",
            "resetting env. episode 726.000000, reward total was -21.000000. running mean: -20.296210\n",
            "resetting env. episode 727.000000, reward total was -19.000000. running mean: -20.283248\n",
            "resetting env. episode 728.000000, reward total was -20.000000. running mean: -20.280416\n",
            "resetting env. episode 729.000000, reward total was -21.000000. running mean: -20.287611\n",
            "resetting env. episode 730.000000, reward total was -18.000000. running mean: -20.264735\n",
            "resetting env. episode 731.000000, reward total was -20.000000. running mean: -20.262088\n",
            "resetting env. episode 732.000000, reward total was -20.000000. running mean: -20.259467\n",
            "resetting env. episode 733.000000, reward total was -21.000000. running mean: -20.266872\n",
            "resetting env. episode 734.000000, reward total was -19.000000. running mean: -20.254204\n",
            "resetting env. episode 735.000000, reward total was -21.000000. running mean: -20.261662\n",
            "resetting env. episode 736.000000, reward total was -21.000000. running mean: -20.269045\n",
            "resetting env. episode 737.000000, reward total was -18.000000. running mean: -20.246355\n",
            "resetting env. episode 738.000000, reward total was -20.000000. running mean: -20.243891\n",
            "resetting env. episode 739.000000, reward total was -20.000000. running mean: -20.241452\n",
            "resetting env. episode 740.000000, reward total was -21.000000. running mean: -20.249038\n",
            "resetting env. episode 741.000000, reward total was -20.000000. running mean: -20.246547\n",
            "resetting env. episode 742.000000, reward total was -21.000000. running mean: -20.254082\n",
            "resetting env. episode 743.000000, reward total was -21.000000. running mean: -20.261541\n",
            "resetting env. episode 744.000000, reward total was -21.000000. running mean: -20.268926\n",
            "resetting env. episode 745.000000, reward total was -20.000000. running mean: -20.266236\n",
            "resetting env. episode 746.000000, reward total was -21.000000. running mean: -20.273574\n",
            "resetting env. episode 747.000000, reward total was -21.000000. running mean: -20.280838\n",
            "resetting env. episode 748.000000, reward total was -18.000000. running mean: -20.258030\n",
            "resetting env. episode 749.000000, reward total was -21.000000. running mean: -20.265449\n",
            "resetting env. episode 750.000000, reward total was -20.000000. running mean: -20.262795\n",
            "resetting env. episode 751.000000, reward total was -21.000000. running mean: -20.270167\n",
            "resetting env. episode 752.000000, reward total was -19.000000. running mean: -20.257465\n",
            "resetting env. episode 753.000000, reward total was -20.000000. running mean: -20.254891\n",
            "resetting env. episode 754.000000, reward total was -21.000000. running mean: -20.262342\n",
            "resetting env. episode 755.000000, reward total was -21.000000. running mean: -20.269718\n",
            "resetting env. episode 756.000000, reward total was -21.000000. running mean: -20.277021\n",
            "resetting env. episode 757.000000, reward total was -21.000000. running mean: -20.284251\n",
            "resetting env. episode 758.000000, reward total was -19.000000. running mean: -20.271408\n",
            "resetting env. episode 759.000000, reward total was -20.000000. running mean: -20.268694\n",
            "resetting env. episode 760.000000, reward total was -20.000000. running mean: -20.266007\n",
            "resetting env. episode 761.000000, reward total was -20.000000. running mean: -20.263347\n",
            "resetting env. episode 762.000000, reward total was -19.000000. running mean: -20.250714\n",
            "resetting env. episode 763.000000, reward total was -21.000000. running mean: -20.258207\n",
            "resetting env. episode 764.000000, reward total was -20.000000. running mean: -20.255625\n",
            "resetting env. episode 765.000000, reward total was -20.000000. running mean: -20.253068\n",
            "resetting env. episode 766.000000, reward total was -21.000000. running mean: -20.260538\n",
            "resetting env. episode 767.000000, reward total was -21.000000. running mean: -20.267932\n",
            "resetting env. episode 768.000000, reward total was -21.000000. running mean: -20.275253\n",
            "resetting env. episode 769.000000, reward total was -20.000000. running mean: -20.272501\n",
            "resetting env. episode 770.000000, reward total was -18.000000. running mean: -20.249776\n",
            "resetting env. episode 771.000000, reward total was -21.000000. running mean: -20.257278\n",
            "resetting env. episode 772.000000, reward total was -20.000000. running mean: -20.254705\n",
            "resetting env. episode 773.000000, reward total was -20.000000. running mean: -20.252158\n",
            "resetting env. episode 774.000000, reward total was -20.000000. running mean: -20.249636\n",
            "resetting env. episode 775.000000, reward total was -21.000000. running mean: -20.257140\n",
            "resetting env. episode 776.000000, reward total was -20.000000. running mean: -20.254569\n",
            "resetting env. episode 777.000000, reward total was -21.000000. running mean: -20.262023\n",
            "resetting env. episode 778.000000, reward total was -19.000000. running mean: -20.249403\n",
            "resetting env. episode 779.000000, reward total was -20.000000. running mean: -20.246909\n",
            "resetting env. episode 780.000000, reward total was -20.000000. running mean: -20.244440\n",
            "resetting env. episode 781.000000, reward total was -21.000000. running mean: -20.251995\n",
            "resetting env. episode 782.000000, reward total was -20.000000. running mean: -20.249475\n",
            "resetting env. episode 783.000000, reward total was -18.000000. running mean: -20.226980\n",
            "resetting env. episode 784.000000, reward total was -21.000000. running mean: -20.234711\n",
            "resetting env. episode 785.000000, reward total was -20.000000. running mean: -20.232364\n",
            "resetting env. episode 786.000000, reward total was -21.000000. running mean: -20.240040\n",
            "resetting env. episode 787.000000, reward total was -20.000000. running mean: -20.237640\n",
            "resetting env. episode 788.000000, reward total was -21.000000. running mean: -20.245263\n",
            "resetting env. episode 789.000000, reward total was -21.000000. running mean: -20.252810\n",
            "resetting env. episode 790.000000, reward total was -21.000000. running mean: -20.260282\n",
            "resetting env. episode 791.000000, reward total was -21.000000. running mean: -20.267680\n",
            "resetting env. episode 792.000000, reward total was -18.000000. running mean: -20.245003\n",
            "resetting env. episode 793.000000, reward total was -21.000000. running mean: -20.252553\n",
            "resetting env. episode 794.000000, reward total was -20.000000. running mean: -20.250027\n",
            "resetting env. episode 795.000000, reward total was -21.000000. running mean: -20.257527\n",
            "resetting env. episode 796.000000, reward total was -21.000000. running mean: -20.264952\n",
            "resetting env. episode 797.000000, reward total was -20.000000. running mean: -20.262302\n",
            "resetting env. episode 798.000000, reward total was -21.000000. running mean: -20.269679\n",
            "resetting env. episode 799.000000, reward total was -21.000000. running mean: -20.276982\n",
            "resetting env. episode 800.000000, reward total was -20.000000. running mean: -20.274213\n",
            "resetting env. episode 801.000000, reward total was -20.000000. running mean: -20.271470\n",
            "resetting env. episode 802.000000, reward total was -21.000000. running mean: -20.278756\n",
            "resetting env. episode 803.000000, reward total was -20.000000. running mean: -20.275968\n",
            "resetting env. episode 804.000000, reward total was -19.000000. running mean: -20.263208\n",
            "resetting env. episode 805.000000, reward total was -21.000000. running mean: -20.270576\n",
            "resetting env. episode 806.000000, reward total was -21.000000. running mean: -20.277871\n",
            "resetting env. episode 807.000000, reward total was -19.000000. running mean: -20.265092\n",
            "resetting env. episode 808.000000, reward total was -19.000000. running mean: -20.252441\n",
            "resetting env. episode 809.000000, reward total was -19.000000. running mean: -20.239917\n",
            "resetting env. episode 810.000000, reward total was -21.000000. running mean: -20.247517\n",
            "resetting env. episode 811.000000, reward total was -21.000000. running mean: -20.255042\n",
            "resetting env. episode 812.000000, reward total was -21.000000. running mean: -20.262492\n",
            "resetting env. episode 813.000000, reward total was -21.000000. running mean: -20.269867\n",
            "resetting env. episode 814.000000, reward total was -21.000000. running mean: -20.277168\n",
            "resetting env. episode 815.000000, reward total was -21.000000. running mean: -20.284397\n",
            "resetting env. episode 816.000000, reward total was -20.000000. running mean: -20.281553\n",
            "resetting env. episode 817.000000, reward total was -20.000000. running mean: -20.278737\n",
            "resetting env. episode 818.000000, reward total was -21.000000. running mean: -20.285950\n",
            "resetting env. episode 819.000000, reward total was -20.000000. running mean: -20.283090\n",
            "resetting env. episode 820.000000, reward total was -21.000000. running mean: -20.290259\n",
            "resetting env. episode 821.000000, reward total was -21.000000. running mean: -20.297357\n",
            "resetting env. episode 822.000000, reward total was -21.000000. running mean: -20.304383\n",
            "resetting env. episode 823.000000, reward total was -21.000000. running mean: -20.311339\n",
            "resetting env. episode 824.000000, reward total was -18.000000. running mean: -20.288226\n",
            "resetting env. episode 825.000000, reward total was -21.000000. running mean: -20.295344\n",
            "resetting env. episode 826.000000, reward total was -19.000000. running mean: -20.282390\n",
            "resetting env. episode 827.000000, reward total was -19.000000. running mean: -20.269566\n",
            "resetting env. episode 828.000000, reward total was -21.000000. running mean: -20.276871\n",
            "resetting env. episode 829.000000, reward total was -21.000000. running mean: -20.284102\n",
            "resetting env. episode 830.000000, reward total was -18.000000. running mean: -20.261261\n",
            "resetting env. episode 831.000000, reward total was -17.000000. running mean: -20.228648\n",
            "resetting env. episode 832.000000, reward total was -21.000000. running mean: -20.236362\n",
            "resetting env. episode 833.000000, reward total was -21.000000. running mean: -20.243998\n",
            "resetting env. episode 834.000000, reward total was -20.000000. running mean: -20.241558\n",
            "resetting env. episode 835.000000, reward total was -19.000000. running mean: -20.229143\n",
            "resetting env. episode 836.000000, reward total was -21.000000. running mean: -20.236851\n",
            "resetting env. episode 837.000000, reward total was -20.000000. running mean: -20.234483\n",
            "resetting env. episode 838.000000, reward total was -20.000000. running mean: -20.232138\n",
            "resetting env. episode 839.000000, reward total was -21.000000. running mean: -20.239816\n",
            "resetting env. episode 840.000000, reward total was -20.000000. running mean: -20.237418\n",
            "resetting env. episode 841.000000, reward total was -21.000000. running mean: -20.245044\n",
            "resetting env. episode 842.000000, reward total was -21.000000. running mean: -20.252594\n",
            "resetting env. episode 843.000000, reward total was -20.000000. running mean: -20.250068\n",
            "resetting env. episode 844.000000, reward total was -20.000000. running mean: -20.247567\n",
            "resetting env. episode 845.000000, reward total was -21.000000. running mean: -20.255091\n",
            "resetting env. episode 846.000000, reward total was -20.000000. running mean: -20.252540\n",
            "resetting env. episode 847.000000, reward total was -19.000000. running mean: -20.240015\n",
            "resetting env. episode 848.000000, reward total was -19.000000. running mean: -20.227615\n",
            "resetting env. episode 849.000000, reward total was -21.000000. running mean: -20.235339\n",
            "resetting env. episode 850.000000, reward total was -21.000000. running mean: -20.242985\n",
            "resetting env. episode 851.000000, reward total was -21.000000. running mean: -20.250556\n",
            "resetting env. episode 852.000000, reward total was -21.000000. running mean: -20.258050\n",
            "resetting env. episode 853.000000, reward total was -20.000000. running mean: -20.255469\n",
            "resetting env. episode 854.000000, reward total was -21.000000. running mean: -20.262915\n",
            "resetting env. episode 855.000000, reward total was -21.000000. running mean: -20.270286\n",
            "resetting env. episode 856.000000, reward total was -20.000000. running mean: -20.267583\n",
            "resetting env. episode 857.000000, reward total was -21.000000. running mean: -20.274907\n",
            "resetting env. episode 858.000000, reward total was -19.000000. running mean: -20.262158\n",
            "resetting env. episode 859.000000, reward total was -21.000000. running mean: -20.269536\n",
            "resetting env. episode 860.000000, reward total was -21.000000. running mean: -20.276841\n",
            "resetting env. episode 861.000000, reward total was -21.000000. running mean: -20.284073\n",
            "resetting env. episode 862.000000, reward total was -20.000000. running mean: -20.281232\n",
            "resetting env. episode 863.000000, reward total was -21.000000. running mean: -20.288420\n",
            "resetting env. episode 864.000000, reward total was -21.000000. running mean: -20.295535\n",
            "resetting env. episode 865.000000, reward total was -19.000000. running mean: -20.282580\n",
            "resetting env. episode 866.000000, reward total was -20.000000. running mean: -20.279754\n",
            "resetting env. episode 867.000000, reward total was -20.000000. running mean: -20.276957\n",
            "resetting env. episode 868.000000, reward total was -21.000000. running mean: -20.284187\n",
            "resetting env. episode 869.000000, reward total was -20.000000. running mean: -20.281345\n",
            "resetting env. episode 870.000000, reward total was -21.000000. running mean: -20.288532\n",
            "resetting env. episode 871.000000, reward total was -20.000000. running mean: -20.285646\n",
            "resetting env. episode 872.000000, reward total was -21.000000. running mean: -20.292790\n",
            "resetting env. episode 873.000000, reward total was -20.000000. running mean: -20.289862\n",
            "resetting env. episode 874.000000, reward total was -20.000000. running mean: -20.286963\n",
            "resetting env. episode 875.000000, reward total was -21.000000. running mean: -20.294094\n",
            "resetting env. episode 876.000000, reward total was -20.000000. running mean: -20.291153\n",
            "resetting env. episode 877.000000, reward total was -20.000000. running mean: -20.288241\n",
            "resetting env. episode 878.000000, reward total was -21.000000. running mean: -20.295359\n",
            "resetting env. episode 879.000000, reward total was -19.000000. running mean: -20.282405\n",
            "resetting env. episode 880.000000, reward total was -21.000000. running mean: -20.289581\n",
            "resetting env. episode 881.000000, reward total was -20.000000. running mean: -20.286685\n",
            "resetting env. episode 882.000000, reward total was -19.000000. running mean: -20.273819\n",
            "resetting env. episode 883.000000, reward total was -21.000000. running mean: -20.281080\n",
            "resetting env. episode 884.000000, reward total was -20.000000. running mean: -20.278270\n",
            "resetting env. episode 885.000000, reward total was -21.000000. running mean: -20.285487\n",
            "resetting env. episode 886.000000, reward total was -20.000000. running mean: -20.282632\n",
            "resetting env. episode 887.000000, reward total was -19.000000. running mean: -20.269806\n",
            "resetting env. episode 888.000000, reward total was -21.000000. running mean: -20.277108\n",
            "resetting env. episode 889.000000, reward total was -21.000000. running mean: -20.284337\n",
            "resetting env. episode 890.000000, reward total was -21.000000. running mean: -20.291493\n",
            "resetting env. episode 891.000000, reward total was -18.000000. running mean: -20.268578\n",
            "resetting env. episode 892.000000, reward total was -20.000000. running mean: -20.265893\n",
            "resetting env. episode 893.000000, reward total was -20.000000. running mean: -20.263234\n",
            "resetting env. episode 894.000000, reward total was -21.000000. running mean: -20.270601\n",
            "resetting env. episode 895.000000, reward total was -20.000000. running mean: -20.267895\n",
            "resetting env. episode 896.000000, reward total was -20.000000. running mean: -20.265216\n",
            "resetting env. episode 897.000000, reward total was -19.000000. running mean: -20.252564\n",
            "resetting env. episode 898.000000, reward total was -21.000000. running mean: -20.260038\n",
            "resetting env. episode 899.000000, reward total was -21.000000. running mean: -20.267438\n",
            "resetting env. episode 900.000000, reward total was -21.000000. running mean: -20.274764\n",
            "resetting env. episode 901.000000, reward total was -21.000000. running mean: -20.282016\n",
            "resetting env. episode 902.000000, reward total was -20.000000. running mean: -20.279196\n",
            "resetting env. episode 903.000000, reward total was -20.000000. running mean: -20.276404\n",
            "resetting env. episode 904.000000, reward total was -21.000000. running mean: -20.283640\n",
            "resetting env. episode 905.000000, reward total was -21.000000. running mean: -20.290804\n",
            "resetting env. episode 906.000000, reward total was -20.000000. running mean: -20.287895\n",
            "resetting env. episode 907.000000, reward total was -20.000000. running mean: -20.285017\n",
            "resetting env. episode 908.000000, reward total was -21.000000. running mean: -20.292166\n",
            "resetting env. episode 909.000000, reward total was -20.000000. running mean: -20.289245\n",
            "resetting env. episode 910.000000, reward total was -21.000000. running mean: -20.296352\n",
            "resetting env. episode 911.000000, reward total was -20.000000. running mean: -20.293389\n",
            "resetting env. episode 912.000000, reward total was -20.000000. running mean: -20.290455\n",
            "resetting env. episode 913.000000, reward total was -21.000000. running mean: -20.297550\n",
            "resetting env. episode 914.000000, reward total was -21.000000. running mean: -20.304575\n",
            "resetting env. episode 915.000000, reward total was -21.000000. running mean: -20.311529\n",
            "resetting env. episode 916.000000, reward total was -21.000000. running mean: -20.318414\n",
            "resetting env. episode 917.000000, reward total was -20.000000. running mean: -20.315230\n",
            "resetting env. episode 918.000000, reward total was -21.000000. running mean: -20.322077\n",
            "resetting env. episode 919.000000, reward total was -21.000000. running mean: -20.328857\n",
            "resetting env. episode 920.000000, reward total was -20.000000. running mean: -20.325568\n",
            "resetting env. episode 921.000000, reward total was -19.000000. running mean: -20.312312\n",
            "resetting env. episode 922.000000, reward total was -17.000000. running mean: -20.279189\n",
            "resetting env. episode 923.000000, reward total was -21.000000. running mean: -20.286397\n",
            "resetting env. episode 924.000000, reward total was -20.000000. running mean: -20.283533\n",
            "resetting env. episode 925.000000, reward total was -21.000000. running mean: -20.290698\n",
            "resetting env. episode 926.000000, reward total was -21.000000. running mean: -20.297791\n",
            "resetting env. episode 927.000000, reward total was -21.000000. running mean: -20.304813\n",
            "resetting env. episode 928.000000, reward total was -20.000000. running mean: -20.301765\n",
            "resetting env. episode 929.000000, reward total was -21.000000. running mean: -20.308747\n",
            "resetting env. episode 930.000000, reward total was -19.000000. running mean: -20.295660\n",
            "resetting env. episode 931.000000, reward total was -21.000000. running mean: -20.302703\n",
            "resetting env. episode 932.000000, reward total was -21.000000. running mean: -20.309676\n",
            "resetting env. episode 933.000000, reward total was -21.000000. running mean: -20.316579\n",
            "resetting env. episode 934.000000, reward total was -20.000000. running mean: -20.313414\n",
            "resetting env. episode 935.000000, reward total was -21.000000. running mean: -20.320280\n",
            "resetting env. episode 936.000000, reward total was -20.000000. running mean: -20.317077\n",
            "resetting env. episode 937.000000, reward total was -21.000000. running mean: -20.323906\n",
            "resetting env. episode 938.000000, reward total was -21.000000. running mean: -20.330667\n",
            "resetting env. episode 939.000000, reward total was -21.000000. running mean: -20.337360\n",
            "resetting env. episode 940.000000, reward total was -21.000000. running mean: -20.343987\n",
            "resetting env. episode 941.000000, reward total was -20.000000. running mean: -20.340547\n",
            "resetting env. episode 942.000000, reward total was -18.000000. running mean: -20.317141\n",
            "resetting env. episode 943.000000, reward total was -21.000000. running mean: -20.323970\n",
            "resetting env. episode 944.000000, reward total was -21.000000. running mean: -20.330730\n",
            "resetting env. episode 945.000000, reward total was -21.000000. running mean: -20.337423\n",
            "resetting env. episode 946.000000, reward total was -21.000000. running mean: -20.344049\n",
            "resetting env. episode 947.000000, reward total was -20.000000. running mean: -20.340608\n",
            "resetting env. episode 948.000000, reward total was -20.000000. running mean: -20.337202\n",
            "resetting env. episode 949.000000, reward total was -18.000000. running mean: -20.313830\n",
            "resetting env. episode 950.000000, reward total was -20.000000. running mean: -20.310692\n",
            "resetting env. episode 951.000000, reward total was -21.000000. running mean: -20.317585\n",
            "resetting env. episode 952.000000, reward total was -20.000000. running mean: -20.314409\n",
            "resetting env. episode 953.000000, reward total was -19.000000. running mean: -20.301265\n",
            "resetting env. episode 954.000000, reward total was -21.000000. running mean: -20.308252\n",
            "resetting env. episode 955.000000, reward total was -19.000000. running mean: -20.295170\n",
            "resetting env. episode 956.000000, reward total was -20.000000. running mean: -20.292218\n",
            "resetting env. episode 957.000000, reward total was -21.000000. running mean: -20.299296\n",
            "resetting env. episode 958.000000, reward total was -21.000000. running mean: -20.306303\n",
            "resetting env. episode 959.000000, reward total was -21.000000. running mean: -20.313240\n",
            "resetting env. episode 960.000000, reward total was -21.000000. running mean: -20.320107\n",
            "resetting env. episode 961.000000, reward total was -21.000000. running mean: -20.326906\n",
            "resetting env. episode 962.000000, reward total was -21.000000. running mean: -20.333637\n",
            "resetting env. episode 963.000000, reward total was -21.000000. running mean: -20.340301\n",
            "resetting env. episode 964.000000, reward total was -21.000000. running mean: -20.346898\n",
            "resetting env. episode 965.000000, reward total was -21.000000. running mean: -20.353429\n",
            "resetting env. episode 966.000000, reward total was -20.000000. running mean: -20.349895\n",
            "resetting env. episode 967.000000, reward total was -20.000000. running mean: -20.346396\n",
            "resetting env. episode 968.000000, reward total was -21.000000. running mean: -20.352932\n",
            "resetting env. episode 969.000000, reward total was -21.000000. running mean: -20.359402\n",
            "resetting env. episode 970.000000, reward total was -21.000000. running mean: -20.365808\n",
            "resetting env. episode 971.000000, reward total was -20.000000. running mean: -20.362150\n",
            "resetting env. episode 972.000000, reward total was -21.000000. running mean: -20.368529\n",
            "resetting env. episode 973.000000, reward total was -21.000000. running mean: -20.374844\n",
            "resetting env. episode 974.000000, reward total was -20.000000. running mean: -20.371095\n",
            "resetting env. episode 975.000000, reward total was -21.000000. running mean: -20.377384\n",
            "resetting env. episode 976.000000, reward total was -19.000000. running mean: -20.363610\n",
            "resetting env. episode 977.000000, reward total was -20.000000. running mean: -20.359974\n",
            "resetting env. episode 978.000000, reward total was -18.000000. running mean: -20.336374\n",
            "resetting env. episode 979.000000, reward total was -21.000000. running mean: -20.343011\n",
            "resetting env. episode 980.000000, reward total was -20.000000. running mean: -20.339581\n",
            "resetting env. episode 981.000000, reward total was -20.000000. running mean: -20.336185\n",
            "resetting env. episode 982.000000, reward total was -20.000000. running mean: -20.332823\n",
            "resetting env. episode 983.000000, reward total was -20.000000. running mean: -20.329495\n",
            "resetting env. episode 984.000000, reward total was -20.000000. running mean: -20.326200\n",
            "resetting env. episode 985.000000, reward total was -21.000000. running mean: -20.332938\n",
            "resetting env. episode 986.000000, reward total was -18.000000. running mean: -20.309608\n",
            "resetting env. episode 987.000000, reward total was -21.000000. running mean: -20.316512\n",
            "resetting env. episode 988.000000, reward total was -21.000000. running mean: -20.323347\n",
            "resetting env. episode 989.000000, reward total was -21.000000. running mean: -20.330114\n",
            "resetting env. episode 990.000000, reward total was -20.000000. running mean: -20.326813\n",
            "resetting env. episode 991.000000, reward total was -21.000000. running mean: -20.333544\n",
            "resetting env. episode 992.000000, reward total was -21.000000. running mean: -20.340209\n",
            "resetting env. episode 993.000000, reward total was -20.000000. running mean: -20.336807\n",
            "resetting env. episode 994.000000, reward total was -21.000000. running mean: -20.343439\n",
            "resetting env. episode 995.000000, reward total was -21.000000. running mean: -20.350004\n",
            "resetting env. episode 996.000000, reward total was -21.000000. running mean: -20.356504\n",
            "resetting env. episode 997.000000, reward total was -21.000000. running mean: -20.362939\n",
            "resetting env. episode 998.000000, reward total was -21.000000. running mean: -20.369310\n",
            "resetting env. episode 999.000000, reward total was -20.000000. running mean: -20.365617\n",
            "resetting env. episode 1000.000000, reward total was -21.000000. running mean: -20.371961\n",
            "resetting env. episode 1001.000000, reward total was -20.000000. running mean: -20.368241\n",
            "resetting env. episode 1002.000000, reward total was -21.000000. running mean: -20.374559\n",
            "resetting env. episode 1003.000000, reward total was -21.000000. running mean: -20.380813\n",
            "resetting env. episode 1004.000000, reward total was -21.000000. running mean: -20.387005\n",
            "resetting env. episode 1005.000000, reward total was -21.000000. running mean: -20.393135\n",
            "resetting env. episode 1006.000000, reward total was -21.000000. running mean: -20.399204\n",
            "resetting env. episode 1007.000000, reward total was -21.000000. running mean: -20.405212\n",
            "resetting env. episode 1008.000000, reward total was -19.000000. running mean: -20.391159\n",
            "resetting env. episode 1009.000000, reward total was -21.000000. running mean: -20.397248\n",
            "resetting env. episode 1010.000000, reward total was -21.000000. running mean: -20.403275\n",
            "resetting env. episode 1011.000000, reward total was -21.000000. running mean: -20.409243\n",
            "resetting env. episode 1012.000000, reward total was -21.000000. running mean: -20.415150\n",
            "resetting env. episode 1013.000000, reward total was -21.000000. running mean: -20.420999\n",
            "resetting env. episode 1014.000000, reward total was -20.000000. running mean: -20.416789\n",
            "resetting env. episode 1015.000000, reward total was -20.000000. running mean: -20.412621\n",
            "resetting env. episode 1016.000000, reward total was -21.000000. running mean: -20.418495\n",
            "resetting env. episode 1017.000000, reward total was -21.000000. running mean: -20.424310\n",
            "resetting env. episode 1018.000000, reward total was -20.000000. running mean: -20.420067\n",
            "resetting env. episode 1019.000000, reward total was -20.000000. running mean: -20.415866\n",
            "resetting env. episode 1020.000000, reward total was -21.000000. running mean: -20.421707\n",
            "resetting env. episode 1021.000000, reward total was -21.000000. running mean: -20.427490\n",
            "resetting env. episode 1022.000000, reward total was -21.000000. running mean: -20.433215\n",
            "resetting env. episode 1023.000000, reward total was -20.000000. running mean: -20.428883\n",
            "resetting env. episode 1024.000000, reward total was -21.000000. running mean: -20.434594\n",
            "resetting env. episode 1025.000000, reward total was -21.000000. running mean: -20.440248\n",
            "resetting env. episode 1026.000000, reward total was -20.000000. running mean: -20.435846\n",
            "resetting env. episode 1027.000000, reward total was -20.000000. running mean: -20.431487\n",
            "resetting env. episode 1028.000000, reward total was -21.000000. running mean: -20.437173\n",
            "resetting env. episode 1029.000000, reward total was -21.000000. running mean: -20.442801\n",
            "resetting env. episode 1030.000000, reward total was -19.000000. running mean: -20.428373\n",
            "resetting env. episode 1031.000000, reward total was -20.000000. running mean: -20.424089\n",
            "resetting env. episode 1032.000000, reward total was -20.000000. running mean: -20.419848\n",
            "resetting env. episode 1033.000000, reward total was -20.000000. running mean: -20.415650\n",
            "resetting env. episode 1034.000000, reward total was -21.000000. running mean: -20.421493\n",
            "resetting env. episode 1035.000000, reward total was -21.000000. running mean: -20.427278\n",
            "resetting env. episode 1036.000000, reward total was -20.000000. running mean: -20.423005\n",
            "resetting env. episode 1037.000000, reward total was -20.000000. running mean: -20.418775\n",
            "resetting env. episode 1038.000000, reward total was -18.000000. running mean: -20.394588\n",
            "resetting env. episode 1039.000000, reward total was -21.000000. running mean: -20.400642\n",
            "resetting env. episode 1040.000000, reward total was -18.000000. running mean: -20.376635\n",
            "resetting env. episode 1041.000000, reward total was -21.000000. running mean: -20.382869\n",
            "resetting env. episode 1042.000000, reward total was -21.000000. running mean: -20.389040\n",
            "resetting env. episode 1043.000000, reward total was -21.000000. running mean: -20.395150\n",
            "resetting env. episode 1044.000000, reward total was -20.000000. running mean: -20.391198\n",
            "resetting env. episode 1045.000000, reward total was -21.000000. running mean: -20.397286\n",
            "resetting env. episode 1046.000000, reward total was -21.000000. running mean: -20.403314\n",
            "resetting env. episode 1047.000000, reward total was -21.000000. running mean: -20.409280\n",
            "resetting env. episode 1048.000000, reward total was -21.000000. running mean: -20.415188\n",
            "resetting env. episode 1049.000000, reward total was -19.000000. running mean: -20.401036\n",
            "resetting env. episode 1050.000000, reward total was -21.000000. running mean: -20.407025\n",
            "resetting env. episode 1051.000000, reward total was -20.000000. running mean: -20.402955\n",
            "resetting env. episode 1052.000000, reward total was -21.000000. running mean: -20.408926\n",
            "resetting env. episode 1053.000000, reward total was -21.000000. running mean: -20.414836\n",
            "resetting env. episode 1054.000000, reward total was -18.000000. running mean: -20.390688\n",
            "resetting env. episode 1055.000000, reward total was -21.000000. running mean: -20.396781\n",
            "resetting env. episode 1056.000000, reward total was -21.000000. running mean: -20.402813\n",
            "resetting env. episode 1057.000000, reward total was -20.000000. running mean: -20.398785\n",
            "resetting env. episode 1058.000000, reward total was -21.000000. running mean: -20.404797\n",
            "resetting env. episode 1059.000000, reward total was -21.000000. running mean: -20.410749\n",
            "resetting env. episode 1060.000000, reward total was -21.000000. running mean: -20.416642\n",
            "resetting env. episode 1061.000000, reward total was -19.000000. running mean: -20.402475\n",
            "resetting env. episode 1062.000000, reward total was -19.000000. running mean: -20.388451\n",
            "resetting env. episode 1063.000000, reward total was -21.000000. running mean: -20.394566\n",
            "resetting env. episode 1064.000000, reward total was -21.000000. running mean: -20.400620\n",
            "resetting env. episode 1065.000000, reward total was -19.000000. running mean: -20.386614\n",
            "resetting env. episode 1066.000000, reward total was -19.000000. running mean: -20.372748\n",
            "resetting env. episode 1067.000000, reward total was -21.000000. running mean: -20.379021\n",
            "resetting env. episode 1068.000000, reward total was -20.000000. running mean: -20.375230\n",
            "resetting env. episode 1069.000000, reward total was -21.000000. running mean: -20.381478\n",
            "resetting env. episode 1070.000000, reward total was -19.000000. running mean: -20.367663\n",
            "resetting env. episode 1071.000000, reward total was -21.000000. running mean: -20.373987\n",
            "resetting env. episode 1072.000000, reward total was -21.000000. running mean: -20.380247\n",
            "resetting env. episode 1073.000000, reward total was -21.000000. running mean: -20.386444\n",
            "resetting env. episode 1074.000000, reward total was -20.000000. running mean: -20.382580\n",
            "resetting env. episode 1075.000000, reward total was -21.000000. running mean: -20.388754\n",
            "resetting env. episode 1076.000000, reward total was -19.000000. running mean: -20.374867\n",
            "resetting env. episode 1077.000000, reward total was -21.000000. running mean: -20.381118\n",
            "resetting env. episode 1078.000000, reward total was -21.000000. running mean: -20.387307\n",
            "resetting env. episode 1079.000000, reward total was -20.000000. running mean: -20.383434\n",
            "resetting env. episode 1080.000000, reward total was -21.000000. running mean: -20.389599\n",
            "resetting env. episode 1081.000000, reward total was -20.000000. running mean: -20.385703\n",
            "resetting env. episode 1082.000000, reward total was -21.000000. running mean: -20.391846\n",
            "resetting env. episode 1083.000000, reward total was -21.000000. running mean: -20.397928\n",
            "resetting env. episode 1084.000000, reward total was -21.000000. running mean: -20.403949\n",
            "resetting env. episode 1085.000000, reward total was -21.000000. running mean: -20.409909\n",
            "resetting env. episode 1086.000000, reward total was -21.000000. running mean: -20.415810\n",
            "resetting env. episode 1087.000000, reward total was -20.000000. running mean: -20.411652\n",
            "resetting env. episode 1088.000000, reward total was -19.000000. running mean: -20.397535\n",
            "resetting env. episode 1089.000000, reward total was -21.000000. running mean: -20.403560\n",
            "resetting env. episode 1090.000000, reward total was -20.000000. running mean: -20.399524\n",
            "resetting env. episode 1091.000000, reward total was -21.000000. running mean: -20.405529\n",
            "resetting env. episode 1092.000000, reward total was -21.000000. running mean: -20.411474\n",
            "resetting env. episode 1093.000000, reward total was -20.000000. running mean: -20.407359\n",
            "resetting env. episode 1094.000000, reward total was -21.000000. running mean: -20.413286\n",
            "resetting env. episode 1095.000000, reward total was -21.000000. running mean: -20.419153\n",
            "resetting env. episode 1096.000000, reward total was -21.000000. running mean: -20.424961\n",
            "resetting env. episode 1097.000000, reward total was -21.000000. running mean: -20.430712\n",
            "resetting env. episode 1098.000000, reward total was -20.000000. running mean: -20.426404\n",
            "resetting env. episode 1099.000000, reward total was -20.000000. running mean: -20.422140\n",
            "resetting env. episode 1100.000000, reward total was -20.000000. running mean: -20.417919\n",
            "resetting env. episode 1101.000000, reward total was -20.000000. running mean: -20.413740\n",
            "resetting env. episode 1102.000000, reward total was -21.000000. running mean: -20.419602\n",
            "resetting env. episode 1103.000000, reward total was -21.000000. running mean: -20.425406\n",
            "resetting env. episode 1104.000000, reward total was -19.000000. running mean: -20.411152\n",
            "resetting env. episode 1105.000000, reward total was -21.000000. running mean: -20.417041\n",
            "resetting env. episode 1106.000000, reward total was -19.000000. running mean: -20.402870\n",
            "resetting env. episode 1107.000000, reward total was -21.000000. running mean: -20.408842\n",
            "resetting env. episode 1108.000000, reward total was -21.000000. running mean: -20.414753\n",
            "resetting env. episode 1109.000000, reward total was -21.000000. running mean: -20.420606\n",
            "resetting env. episode 1110.000000, reward total was -21.000000. running mean: -20.426400\n",
            "resetting env. episode 1111.000000, reward total was -21.000000. running mean: -20.432136\n",
            "resetting env. episode 1112.000000, reward total was -19.000000. running mean: -20.417814\n",
            "resetting env. episode 1113.000000, reward total was -21.000000. running mean: -20.423636\n",
            "resetting env. episode 1114.000000, reward total was -21.000000. running mean: -20.429400\n",
            "resetting env. episode 1115.000000, reward total was -21.000000. running mean: -20.435106\n",
            "resetting env. episode 1116.000000, reward total was -21.000000. running mean: -20.440755\n",
            "resetting env. episode 1117.000000, reward total was -20.000000. running mean: -20.436347\n",
            "resetting env. episode 1118.000000, reward total was -20.000000. running mean: -20.431984\n",
            "resetting env. episode 1119.000000, reward total was -20.000000. running mean: -20.427664\n",
            "resetting env. episode 1120.000000, reward total was -21.000000. running mean: -20.433387\n",
            "resetting env. episode 1121.000000, reward total was -19.000000. running mean: -20.419053\n",
            "resetting env. episode 1122.000000, reward total was -19.000000. running mean: -20.404863\n",
            "resetting env. episode 1123.000000, reward total was -20.000000. running mean: -20.400814\n",
            "resetting env. episode 1124.000000, reward total was -20.000000. running mean: -20.396806\n",
            "resetting env. episode 1125.000000, reward total was -21.000000. running mean: -20.402838\n",
            "resetting env. episode 1126.000000, reward total was -20.000000. running mean: -20.398810\n",
            "resetting env. episode 1127.000000, reward total was -20.000000. running mean: -20.394822\n",
            "resetting env. episode 1128.000000, reward total was -21.000000. running mean: -20.400873\n",
            "resetting env. episode 1129.000000, reward total was -21.000000. running mean: -20.406865\n",
            "resetting env. episode 1130.000000, reward total was -21.000000. running mean: -20.412796\n",
            "resetting env. episode 1131.000000, reward total was -20.000000. running mean: -20.408668\n",
            "resetting env. episode 1132.000000, reward total was -21.000000. running mean: -20.414581\n",
            "resetting env. episode 1133.000000, reward total was -21.000000. running mean: -20.420436\n",
            "resetting env. episode 1134.000000, reward total was -21.000000. running mean: -20.426231\n",
            "resetting env. episode 1135.000000, reward total was -21.000000. running mean: -20.431969\n",
            "resetting env. episode 1136.000000, reward total was -20.000000. running mean: -20.427649\n",
            "resetting env. episode 1137.000000, reward total was -20.000000. running mean: -20.423373\n",
            "resetting env. episode 1138.000000, reward total was -21.000000. running mean: -20.429139\n",
            "resetting env. episode 1139.000000, reward total was -19.000000. running mean: -20.414848\n",
            "resetting env. episode 1140.000000, reward total was -21.000000. running mean: -20.420699\n",
            "resetting env. episode 1141.000000, reward total was -17.000000. running mean: -20.386492\n",
            "resetting env. episode 1142.000000, reward total was -21.000000. running mean: -20.392627\n",
            "resetting env. episode 1143.000000, reward total was -19.000000. running mean: -20.378701\n",
            "resetting env. episode 1144.000000, reward total was -21.000000. running mean: -20.384914\n",
            "resetting env. episode 1145.000000, reward total was -21.000000. running mean: -20.391065\n",
            "resetting env. episode 1146.000000, reward total was -20.000000. running mean: -20.387154\n",
            "resetting env. episode 1147.000000, reward total was -20.000000. running mean: -20.383283\n",
            "resetting env. episode 1148.000000, reward total was -18.000000. running mean: -20.359450\n",
            "resetting env. episode 1149.000000, reward total was -21.000000. running mean: -20.365855\n",
            "resetting env. episode 1150.000000, reward total was -21.000000. running mean: -20.372197\n",
            "resetting env. episode 1151.000000, reward total was -19.000000. running mean: -20.358475\n",
            "resetting env. episode 1152.000000, reward total was -21.000000. running mean: -20.364890\n",
            "resetting env. episode 1153.000000, reward total was -18.000000. running mean: -20.341241\n",
            "resetting env. episode 1154.000000, reward total was -20.000000. running mean: -20.337829\n",
            "resetting env. episode 1155.000000, reward total was -20.000000. running mean: -20.334450\n",
            "resetting env. episode 1156.000000, reward total was -19.000000. running mean: -20.321106\n",
            "resetting env. episode 1157.000000, reward total was -21.000000. running mean: -20.327895\n",
            "resetting env. episode 1158.000000, reward total was -21.000000. running mean: -20.334616\n",
            "resetting env. episode 1159.000000, reward total was -21.000000. running mean: -20.341270\n",
            "resetting env. episode 1160.000000, reward total was -20.000000. running mean: -20.337857\n",
            "resetting env. episode 1161.000000, reward total was -20.000000. running mean: -20.334478\n",
            "resetting env. episode 1162.000000, reward total was -19.000000. running mean: -20.321134\n",
            "resetting env. episode 1163.000000, reward total was -21.000000. running mean: -20.327922\n",
            "resetting env. episode 1164.000000, reward total was -21.000000. running mean: -20.334643\n",
            "resetting env. episode 1165.000000, reward total was -21.000000. running mean: -20.341297\n",
            "resetting env. episode 1166.000000, reward total was -20.000000. running mean: -20.337884\n",
            "resetting env. episode 1167.000000, reward total was -21.000000. running mean: -20.344505\n",
            "resetting env. episode 1168.000000, reward total was -20.000000. running mean: -20.341060\n",
            "resetting env. episode 1169.000000, reward total was -21.000000. running mean: -20.347649\n",
            "resetting env. episode 1170.000000, reward total was -21.000000. running mean: -20.354173\n",
            "resetting env. episode 1171.000000, reward total was -20.000000. running mean: -20.350631\n",
            "resetting env. episode 1172.000000, reward total was -19.000000. running mean: -20.337125\n",
            "resetting env. episode 1173.000000, reward total was -21.000000. running mean: -20.343753\n",
            "resetting env. episode 1174.000000, reward total was -21.000000. running mean: -20.350316\n",
            "resetting env. episode 1175.000000, reward total was -20.000000. running mean: -20.346813\n",
            "resetting env. episode 1176.000000, reward total was -20.000000. running mean: -20.343345\n",
            "resetting env. episode 1177.000000, reward total was -21.000000. running mean: -20.349911\n",
            "resetting env. episode 1178.000000, reward total was -21.000000. running mean: -20.356412\n",
            "resetting env. episode 1179.000000, reward total was -21.000000. running mean: -20.362848\n",
            "resetting env. episode 1180.000000, reward total was -18.000000. running mean: -20.339219\n",
            "resetting env. episode 1181.000000, reward total was -21.000000. running mean: -20.345827\n",
            "resetting env. episode 1182.000000, reward total was -19.000000. running mean: -20.332369\n",
            "resetting env. episode 1183.000000, reward total was -20.000000. running mean: -20.329045\n",
            "resetting env. episode 1184.000000, reward total was -20.000000. running mean: -20.325755\n",
            "resetting env. episode 1185.000000, reward total was -19.000000. running mean: -20.312497\n",
            "resetting env. episode 1186.000000, reward total was -20.000000. running mean: -20.309372\n",
            "resetting env. episode 1187.000000, reward total was -19.000000. running mean: -20.296279\n",
            "resetting env. episode 1188.000000, reward total was -21.000000. running mean: -20.303316\n",
            "resetting env. episode 1189.000000, reward total was -20.000000. running mean: -20.300283\n",
            "resetting env. episode 1190.000000, reward total was -21.000000. running mean: -20.307280\n",
            "resetting env. episode 1191.000000, reward total was -21.000000. running mean: -20.314207\n",
            "resetting env. episode 1192.000000, reward total was -20.000000. running mean: -20.311065\n",
            "resetting env. episode 1193.000000, reward total was -18.000000. running mean: -20.287954\n",
            "resetting env. episode 1194.000000, reward total was -19.000000. running mean: -20.275075\n",
            "resetting env. episode 1195.000000, reward total was -20.000000. running mean: -20.272324\n",
            "resetting env. episode 1196.000000, reward total was -20.000000. running mean: -20.269601\n",
            "resetting env. episode 1197.000000, reward total was -20.000000. running mean: -20.266905\n",
            "resetting env. episode 1198.000000, reward total was -20.000000. running mean: -20.264236\n",
            "resetting env. episode 1199.000000, reward total was -21.000000. running mean: -20.271593\n",
            "resetting env. episode 1200.000000, reward total was -21.000000. running mean: -20.278877\n",
            "resetting env. episode 1201.000000, reward total was -21.000000. running mean: -20.286089\n",
            "resetting env. episode 1202.000000, reward total was -21.000000. running mean: -20.293228\n",
            "resetting env. episode 1203.000000, reward total was -20.000000. running mean: -20.290295\n",
            "resetting env. episode 1204.000000, reward total was -17.000000. running mean: -20.257393\n",
            "resetting env. episode 1205.000000, reward total was -20.000000. running mean: -20.254819\n",
            "resetting env. episode 1206.000000, reward total was -21.000000. running mean: -20.262270\n",
            "resetting env. episode 1207.000000, reward total was -21.000000. running mean: -20.269648\n",
            "resetting env. episode 1208.000000, reward total was -21.000000. running mean: -20.276951\n",
            "resetting env. episode 1209.000000, reward total was -20.000000. running mean: -20.274182\n",
            "resetting env. episode 1210.000000, reward total was -19.000000. running mean: -20.261440\n",
            "resetting env. episode 1211.000000, reward total was -18.000000. running mean: -20.238826\n",
            "resetting env. episode 1212.000000, reward total was -20.000000. running mean: -20.236437\n",
            "resetting env. episode 1213.000000, reward total was -21.000000. running mean: -20.244073\n",
            "resetting env. episode 1214.000000, reward total was -21.000000. running mean: -20.251632\n",
            "resetting env. episode 1215.000000, reward total was -21.000000. running mean: -20.259116\n",
            "resetting env. episode 1216.000000, reward total was -21.000000. running mean: -20.266525\n",
            "resetting env. episode 1217.000000, reward total was -21.000000. running mean: -20.273859\n",
            "resetting env. episode 1218.000000, reward total was -20.000000. running mean: -20.271121\n",
            "resetting env. episode 1219.000000, reward total was -18.000000. running mean: -20.248410\n",
            "resetting env. episode 1220.000000, reward total was -20.000000. running mean: -20.245926\n",
            "resetting env. episode 1221.000000, reward total was -21.000000. running mean: -20.253466\n",
            "resetting env. episode 1222.000000, reward total was -21.000000. running mean: -20.260932\n",
            "resetting env. episode 1223.000000, reward total was -21.000000. running mean: -20.268322\n",
            "resetting env. episode 1224.000000, reward total was -20.000000. running mean: -20.265639\n",
            "resetting env. episode 1225.000000, reward total was -21.000000. running mean: -20.272983\n",
            "resetting env. episode 1226.000000, reward total was -21.000000. running mean: -20.280253\n",
            "resetting env. episode 1227.000000, reward total was -21.000000. running mean: -20.287450\n",
            "resetting env. episode 1228.000000, reward total was -19.000000. running mean: -20.274576\n",
            "resetting env. episode 1229.000000, reward total was -19.000000. running mean: -20.261830\n",
            "resetting env. episode 1230.000000, reward total was -20.000000. running mean: -20.259212\n",
            "resetting env. episode 1231.000000, reward total was -20.000000. running mean: -20.256620\n",
            "resetting env. episode 1232.000000, reward total was -21.000000. running mean: -20.264053\n",
            "resetting env. episode 1233.000000, reward total was -20.000000. running mean: -20.261413\n",
            "resetting env. episode 1234.000000, reward total was -21.000000. running mean: -20.268799\n",
            "resetting env. episode 1235.000000, reward total was -18.000000. running mean: -20.246111\n",
            "resetting env. episode 1236.000000, reward total was -20.000000. running mean: -20.243650\n",
            "resetting env. episode 1237.000000, reward total was -19.000000. running mean: -20.231213\n",
            "resetting env. episode 1238.000000, reward total was -21.000000. running mean: -20.238901\n",
            "resetting env. episode 1239.000000, reward total was -21.000000. running mean: -20.246512\n",
            "resetting env. episode 1240.000000, reward total was -21.000000. running mean: -20.254047\n",
            "resetting env. episode 1241.000000, reward total was -21.000000. running mean: -20.261506\n",
            "resetting env. episode 1242.000000, reward total was -21.000000. running mean: -20.268891\n",
            "resetting env. episode 1243.000000, reward total was -20.000000. running mean: -20.266202\n",
            "resetting env. episode 1244.000000, reward total was -21.000000. running mean: -20.273540\n",
            "resetting env. episode 1245.000000, reward total was -20.000000. running mean: -20.270805\n",
            "resetting env. episode 1246.000000, reward total was -21.000000. running mean: -20.278097\n",
            "resetting env. episode 1247.000000, reward total was -21.000000. running mean: -20.285316\n",
            "resetting env. episode 1248.000000, reward total was -19.000000. running mean: -20.272463\n",
            "resetting env. episode 1249.000000, reward total was -19.000000. running mean: -20.259738\n",
            "resetting env. episode 1250.000000, reward total was -20.000000. running mean: -20.257141\n",
            "resetting env. episode 1251.000000, reward total was -21.000000. running mean: -20.264569\n",
            "resetting env. episode 1252.000000, reward total was -21.000000. running mean: -20.271924\n",
            "resetting env. episode 1253.000000, reward total was -21.000000. running mean: -20.279205\n",
            "resetting env. episode 1254.000000, reward total was -20.000000. running mean: -20.276412\n",
            "resetting env. episode 1255.000000, reward total was -17.000000. running mean: -20.243648\n",
            "resetting env. episode 1256.000000, reward total was -21.000000. running mean: -20.251212\n",
            "resetting env. episode 1257.000000, reward total was -20.000000. running mean: -20.248700\n",
            "resetting env. episode 1258.000000, reward total was -21.000000. running mean: -20.256213\n",
            "resetting env. episode 1259.000000, reward total was -20.000000. running mean: -20.253651\n",
            "resetting env. episode 1260.000000, reward total was -20.000000. running mean: -20.251114\n",
            "resetting env. episode 1261.000000, reward total was -20.000000. running mean: -20.248603\n",
            "resetting env. episode 1262.000000, reward total was -19.000000. running mean: -20.236117\n",
            "resetting env. episode 1263.000000, reward total was -20.000000. running mean: -20.233756\n",
            "resetting env. episode 1264.000000, reward total was -21.000000. running mean: -20.241418\n",
            "resetting env. episode 1265.000000, reward total was -20.000000. running mean: -20.239004\n",
            "resetting env. episode 1266.000000, reward total was -21.000000. running mean: -20.246614\n",
            "resetting env. episode 1267.000000, reward total was -21.000000. running mean: -20.254148\n",
            "resetting env. episode 1268.000000, reward total was -21.000000. running mean: -20.261606\n",
            "resetting env. episode 1269.000000, reward total was -21.000000. running mean: -20.268990\n",
            "resetting env. episode 1270.000000, reward total was -21.000000. running mean: -20.276300\n",
            "resetting env. episode 1271.000000, reward total was -21.000000. running mean: -20.283537\n",
            "resetting env. episode 1272.000000, reward total was -21.000000. running mean: -20.290702\n",
            "resetting env. episode 1273.000000, reward total was -20.000000. running mean: -20.287795\n",
            "resetting env. episode 1274.000000, reward total was -21.000000. running mean: -20.294917\n",
            "resetting env. episode 1275.000000, reward total was -21.000000. running mean: -20.301968\n",
            "resetting env. episode 1276.000000, reward total was -21.000000. running mean: -20.308948\n",
            "resetting env. episode 1277.000000, reward total was -20.000000. running mean: -20.305859\n",
            "resetting env. episode 1278.000000, reward total was -20.000000. running mean: -20.302800\n",
            "resetting env. episode 1279.000000, reward total was -21.000000. running mean: -20.309772\n",
            "resetting env. episode 1280.000000, reward total was -19.000000. running mean: -20.296674\n",
            "resetting env. episode 1281.000000, reward total was -21.000000. running mean: -20.303708\n",
            "resetting env. episode 1282.000000, reward total was -21.000000. running mean: -20.310671\n",
            "resetting env. episode 1283.000000, reward total was -19.000000. running mean: -20.297564\n",
            "resetting env. episode 1284.000000, reward total was -21.000000. running mean: -20.304588\n",
            "resetting env. episode 1285.000000, reward total was -19.000000. running mean: -20.291542\n",
            "resetting env. episode 1286.000000, reward total was -20.000000. running mean: -20.288627\n",
            "resetting env. episode 1287.000000, reward total was -20.000000. running mean: -20.285741\n",
            "resetting env. episode 1288.000000, reward total was -21.000000. running mean: -20.292883\n",
            "resetting env. episode 1289.000000, reward total was -21.000000. running mean: -20.299954\n",
            "resetting env. episode 1290.000000, reward total was -20.000000. running mean: -20.296955\n",
            "resetting env. episode 1291.000000, reward total was -21.000000. running mean: -20.303985\n",
            "resetting env. episode 1292.000000, reward total was -18.000000. running mean: -20.280945\n",
            "resetting env. episode 1293.000000, reward total was -21.000000. running mean: -20.288136\n",
            "resetting env. episode 1294.000000, reward total was -21.000000. running mean: -20.295255\n",
            "resetting env. episode 1295.000000, reward total was -19.000000. running mean: -20.282302\n",
            "resetting env. episode 1296.000000, reward total was -20.000000. running mean: -20.279479\n",
            "resetting env. episode 1297.000000, reward total was -20.000000. running mean: -20.276684\n",
            "resetting env. episode 1298.000000, reward total was -21.000000. running mean: -20.283917\n",
            "resetting env. episode 1299.000000, reward total was -21.000000. running mean: -20.291078\n",
            "resetting env. episode 1300.000000, reward total was -21.000000. running mean: -20.298168\n",
            "resetting env. episode 1301.000000, reward total was -20.000000. running mean: -20.295186\n",
            "resetting env. episode 1302.000000, reward total was -21.000000. running mean: -20.302234\n",
            "resetting env. episode 1303.000000, reward total was -19.000000. running mean: -20.289212\n",
            "resetting env. episode 1304.000000, reward total was -21.000000. running mean: -20.296320\n",
            "resetting env. episode 1305.000000, reward total was -21.000000. running mean: -20.303356\n",
            "resetting env. episode 1306.000000, reward total was -20.000000. running mean: -20.300323\n",
            "resetting env. episode 1307.000000, reward total was -21.000000. running mean: -20.307320\n",
            "resetting env. episode 1308.000000, reward total was -21.000000. running mean: -20.314246\n",
            "resetting env. episode 1309.000000, reward total was -21.000000. running mean: -20.321104\n",
            "resetting env. episode 1310.000000, reward total was -21.000000. running mean: -20.327893\n",
            "resetting env. episode 1311.000000, reward total was -20.000000. running mean: -20.324614\n",
            "resetting env. episode 1312.000000, reward total was -21.000000. running mean: -20.331368\n",
            "resetting env. episode 1313.000000, reward total was -18.000000. running mean: -20.308054\n",
            "resetting env. episode 1314.000000, reward total was -21.000000. running mean: -20.314974\n",
            "resetting env. episode 1315.000000, reward total was -21.000000. running mean: -20.321824\n",
            "resetting env. episode 1316.000000, reward total was -21.000000. running mean: -20.328606\n",
            "resetting env. episode 1317.000000, reward total was -20.000000. running mean: -20.325320\n",
            "resetting env. episode 1318.000000, reward total was -20.000000. running mean: -20.322066\n",
            "resetting env. episode 1319.000000, reward total was -21.000000. running mean: -20.328846\n",
            "resetting env. episode 1320.000000, reward total was -21.000000. running mean: -20.335557\n",
            "resetting env. episode 1321.000000, reward total was -18.000000. running mean: -20.312202\n",
            "resetting env. episode 1322.000000, reward total was -21.000000. running mean: -20.319080\n",
            "resetting env. episode 1323.000000, reward total was -21.000000. running mean: -20.325889\n",
            "resetting env. episode 1324.000000, reward total was -20.000000. running mean: -20.322630\n",
            "resetting env. episode 1325.000000, reward total was -20.000000. running mean: -20.319404\n",
            "resetting env. episode 1326.000000, reward total was -20.000000. running mean: -20.316210\n",
            "resetting env. episode 1327.000000, reward total was -21.000000. running mean: -20.323048\n",
            "resetting env. episode 1328.000000, reward total was -21.000000. running mean: -20.329817\n",
            "resetting env. episode 1329.000000, reward total was -21.000000. running mean: -20.336519\n",
            "resetting env. episode 1330.000000, reward total was -20.000000. running mean: -20.333154\n",
            "resetting env. episode 1331.000000, reward total was -21.000000. running mean: -20.339822\n",
            "resetting env. episode 1332.000000, reward total was -20.000000. running mean: -20.336424\n",
            "resetting env. episode 1333.000000, reward total was -21.000000. running mean: -20.343060\n",
            "resetting env. episode 1334.000000, reward total was -21.000000. running mean: -20.349629\n",
            "resetting env. episode 1335.000000, reward total was -21.000000. running mean: -20.356133\n",
            "resetting env. episode 1336.000000, reward total was -21.000000. running mean: -20.362571\n",
            "resetting env. episode 1337.000000, reward total was -21.000000. running mean: -20.368946\n",
            "resetting env. episode 1338.000000, reward total was -20.000000. running mean: -20.365256\n",
            "resetting env. episode 1339.000000, reward total was -21.000000. running mean: -20.371604\n",
            "resetting env. episode 1340.000000, reward total was -20.000000. running mean: -20.367888\n",
            "resetting env. episode 1341.000000, reward total was -21.000000. running mean: -20.374209\n",
            "resetting env. episode 1342.000000, reward total was -20.000000. running mean: -20.370467\n",
            "resetting env. episode 1343.000000, reward total was -21.000000. running mean: -20.376762\n",
            "resetting env. episode 1344.000000, reward total was -21.000000. running mean: -20.382994\n",
            "resetting env. episode 1345.000000, reward total was -21.000000. running mean: -20.389164\n",
            "resetting env. episode 1346.000000, reward total was -20.000000. running mean: -20.385273\n",
            "resetting env. episode 1347.000000, reward total was -21.000000. running mean: -20.391420\n",
            "resetting env. episode 1348.000000, reward total was -21.000000. running mean: -20.397506\n",
            "resetting env. episode 1349.000000, reward total was -21.000000. running mean: -20.403531\n",
            "resetting env. episode 1350.000000, reward total was -20.000000. running mean: -20.399496\n",
            "resetting env. episode 1351.000000, reward total was -19.000000. running mean: -20.385501\n",
            "resetting env. episode 1352.000000, reward total was -21.000000. running mean: -20.391646\n",
            "resetting env. episode 1353.000000, reward total was -21.000000. running mean: -20.397729\n",
            "resetting env. episode 1354.000000, reward total was -21.000000. running mean: -20.403752\n",
            "resetting env. episode 1355.000000, reward total was -21.000000. running mean: -20.409714\n",
            "resetting env. episode 1356.000000, reward total was -20.000000. running mean: -20.405617\n",
            "resetting env. episode 1357.000000, reward total was -21.000000. running mean: -20.411561\n",
            "resetting env. episode 1358.000000, reward total was -20.000000. running mean: -20.407445\n",
            "resetting env. episode 1359.000000, reward total was -21.000000. running mean: -20.413371\n",
            "resetting env. episode 1360.000000, reward total was -20.000000. running mean: -20.409237\n",
            "resetting env. episode 1361.000000, reward total was -21.000000. running mean: -20.415145\n",
            "resetting env. episode 1362.000000, reward total was -21.000000. running mean: -20.420993\n",
            "resetting env. episode 1363.000000, reward total was -21.000000. running mean: -20.426783\n",
            "resetting env. episode 1364.000000, reward total was -20.000000. running mean: -20.422516\n",
            "resetting env. episode 1365.000000, reward total was -17.000000. running mean: -20.388290\n",
            "resetting env. episode 1366.000000, reward total was -21.000000. running mean: -20.394408\n",
            "resetting env. episode 1367.000000, reward total was -20.000000. running mean: -20.390464\n",
            "resetting env. episode 1368.000000, reward total was -21.000000. running mean: -20.396559\n",
            "resetting env. episode 1369.000000, reward total was -21.000000. running mean: -20.402593\n",
            "resetting env. episode 1370.000000, reward total was -18.000000. running mean: -20.378567\n",
            "resetting env. episode 1371.000000, reward total was -20.000000. running mean: -20.374782\n",
            "resetting env. episode 1372.000000, reward total was -21.000000. running mean: -20.381034\n",
            "resetting env. episode 1373.000000, reward total was -20.000000. running mean: -20.377224\n",
            "resetting env. episode 1374.000000, reward total was -20.000000. running mean: -20.373451\n",
            "resetting env. episode 1375.000000, reward total was -21.000000. running mean: -20.379717\n",
            "resetting env. episode 1376.000000, reward total was -21.000000. running mean: -20.385920\n",
            "resetting env. episode 1377.000000, reward total was -21.000000. running mean: -20.392060\n",
            "resetting env. episode 1378.000000, reward total was -21.000000. running mean: -20.398140\n",
            "resetting env. episode 1379.000000, reward total was -21.000000. running mean: -20.404158\n",
            "resetting env. episode 1380.000000, reward total was -21.000000. running mean: -20.410117\n",
            "resetting env. episode 1381.000000, reward total was -20.000000. running mean: -20.406016\n",
            "resetting env. episode 1382.000000, reward total was -19.000000. running mean: -20.391955\n",
            "resetting env. episode 1383.000000, reward total was -20.000000. running mean: -20.388036\n",
            "resetting env. episode 1384.000000, reward total was -20.000000. running mean: -20.384156\n",
            "resetting env. episode 1385.000000, reward total was -21.000000. running mean: -20.390314\n",
            "resetting env. episode 1386.000000, reward total was -21.000000. running mean: -20.396411\n",
            "resetting env. episode 1387.000000, reward total was -21.000000. running mean: -20.402447\n",
            "resetting env. episode 1388.000000, reward total was -21.000000. running mean: -20.408422\n",
            "resetting env. episode 1389.000000, reward total was -19.000000. running mean: -20.394338\n",
            "resetting env. episode 1390.000000, reward total was -20.000000. running mean: -20.390395\n",
            "resetting env. episode 1391.000000, reward total was -21.000000. running mean: -20.396491\n",
            "resetting env. episode 1392.000000, reward total was -21.000000. running mean: -20.402526\n",
            "resetting env. episode 1393.000000, reward total was -21.000000. running mean: -20.408501\n",
            "resetting env. episode 1394.000000, reward total was -20.000000. running mean: -20.404416\n",
            "resetting env. episode 1395.000000, reward total was -21.000000. running mean: -20.410371\n",
            "resetting env. episode 1396.000000, reward total was -19.000000. running mean: -20.396268\n",
            "resetting env. episode 1397.000000, reward total was -20.000000. running mean: -20.392305\n",
            "resetting env. episode 1398.000000, reward total was -21.000000. running mean: -20.398382\n",
            "resetting env. episode 1399.000000, reward total was -21.000000. running mean: -20.404398\n",
            "resetting env. episode 1400.000000, reward total was -20.000000. running mean: -20.400354\n",
            "resetting env. episode 1401.000000, reward total was -19.000000. running mean: -20.386351\n",
            "resetting env. episode 1402.000000, reward total was -20.000000. running mean: -20.382487\n",
            "resetting env. episode 1403.000000, reward total was -21.000000. running mean: -20.388662\n",
            "resetting env. episode 1404.000000, reward total was -19.000000. running mean: -20.374776\n",
            "resetting env. episode 1405.000000, reward total was -21.000000. running mean: -20.381028\n",
            "resetting env. episode 1406.000000, reward total was -20.000000. running mean: -20.377218\n",
            "resetting env. episode 1407.000000, reward total was -21.000000. running mean: -20.383445\n",
            "resetting env. episode 1408.000000, reward total was -21.000000. running mean: -20.389611\n",
            "resetting env. episode 1409.000000, reward total was -21.000000. running mean: -20.395715\n",
            "resetting env. episode 1410.000000, reward total was -21.000000. running mean: -20.401758\n",
            "resetting env. episode 1411.000000, reward total was -19.000000. running mean: -20.387740\n",
            "resetting env. episode 1412.000000, reward total was -21.000000. running mean: -20.393863\n",
            "resetting env. episode 1413.000000, reward total was -21.000000. running mean: -20.399924\n",
            "resetting env. episode 1414.000000, reward total was -21.000000. running mean: -20.405925\n",
            "resetting env. episode 1415.000000, reward total was -21.000000. running mean: -20.411866\n",
            "resetting env. episode 1416.000000, reward total was -21.000000. running mean: -20.417747\n",
            "resetting env. episode 1417.000000, reward total was -20.000000. running mean: -20.413570\n",
            "resetting env. episode 1418.000000, reward total was -21.000000. running mean: -20.419434\n",
            "resetting env. episode 1419.000000, reward total was -21.000000. running mean: -20.425239\n",
            "resetting env. episode 1420.000000, reward total was -21.000000. running mean: -20.430987\n",
            "resetting env. episode 1421.000000, reward total was -19.000000. running mean: -20.416677\n",
            "resetting env. episode 1422.000000, reward total was -21.000000. running mean: -20.422510\n",
            "resetting env. episode 1423.000000, reward total was -21.000000. running mean: -20.428285\n",
            "resetting env. episode 1424.000000, reward total was -21.000000. running mean: -20.434002\n",
            "resetting env. episode 1425.000000, reward total was -21.000000. running mean: -20.439662\n",
            "resetting env. episode 1426.000000, reward total was -21.000000. running mean: -20.445266\n",
            "resetting env. episode 1427.000000, reward total was -21.000000. running mean: -20.450813\n",
            "resetting env. episode 1428.000000, reward total was -21.000000. running mean: -20.456305\n",
            "resetting env. episode 1429.000000, reward total was -19.000000. running mean: -20.441742\n",
            "resetting env. episode 1430.000000, reward total was -21.000000. running mean: -20.447325\n",
            "resetting env. episode 1431.000000, reward total was -21.000000. running mean: -20.452851\n",
            "resetting env. episode 1432.000000, reward total was -20.000000. running mean: -20.448323\n",
            "resetting env. episode 1433.000000, reward total was -20.000000. running mean: -20.443840\n",
            "resetting env. episode 1434.000000, reward total was -21.000000. running mean: -20.449401\n",
            "resetting env. episode 1435.000000, reward total was -21.000000. running mean: -20.454907\n",
            "resetting env. episode 1436.000000, reward total was -20.000000. running mean: -20.450358\n",
            "resetting env. episode 1437.000000, reward total was -20.000000. running mean: -20.445855\n",
            "resetting env. episode 1438.000000, reward total was -21.000000. running mean: -20.451396\n",
            "resetting env. episode 1439.000000, reward total was -19.000000. running mean: -20.436882\n",
            "resetting env. episode 1440.000000, reward total was -20.000000. running mean: -20.432513\n",
            "resetting env. episode 1441.000000, reward total was -21.000000. running mean: -20.438188\n",
            "resetting env. episode 1442.000000, reward total was -19.000000. running mean: -20.423806\n",
            "resetting env. episode 1443.000000, reward total was -21.000000. running mean: -20.429568\n",
            "resetting env. episode 1444.000000, reward total was -21.000000. running mean: -20.435272\n",
            "resetting env. episode 1445.000000, reward total was -20.000000. running mean: -20.430920\n",
            "resetting env. episode 1446.000000, reward total was -21.000000. running mean: -20.436611\n",
            "resetting env. episode 1447.000000, reward total was -20.000000. running mean: -20.432244\n",
            "resetting env. episode 1448.000000, reward total was -21.000000. running mean: -20.437922\n",
            "resetting env. episode 1449.000000, reward total was -21.000000. running mean: -20.443543\n",
            "resetting env. episode 1450.000000, reward total was -21.000000. running mean: -20.449107\n",
            "resetting env. episode 1451.000000, reward total was -21.000000. running mean: -20.454616\n",
            "resetting env. episode 1452.000000, reward total was -20.000000. running mean: -20.450070\n",
            "resetting env. episode 1453.000000, reward total was -21.000000. running mean: -20.455569\n",
            "resetting env. episode 1454.000000, reward total was -17.000000. running mean: -20.421014\n",
            "resetting env. episode 1455.000000, reward total was -21.000000. running mean: -20.426804\n",
            "resetting env. episode 1456.000000, reward total was -19.000000. running mean: -20.412536\n",
            "resetting env. episode 1457.000000, reward total was -20.000000. running mean: -20.408410\n",
            "resetting env. episode 1458.000000, reward total was -21.000000. running mean: -20.414326\n",
            "resetting env. episode 1459.000000, reward total was -20.000000. running mean: -20.410183\n",
            "resetting env. episode 1460.000000, reward total was -21.000000. running mean: -20.416081\n",
            "resetting env. episode 1461.000000, reward total was -21.000000. running mean: -20.421920\n",
            "resetting env. episode 1462.000000, reward total was -20.000000. running mean: -20.417701\n",
            "resetting env. episode 1463.000000, reward total was -19.000000. running mean: -20.403524\n",
            "resetting env. episode 1464.000000, reward total was -21.000000. running mean: -20.409489\n",
            "resetting env. episode 1465.000000, reward total was -21.000000. running mean: -20.415394\n",
            "resetting env. episode 1466.000000, reward total was -21.000000. running mean: -20.421240\n",
            "resetting env. episode 1467.000000, reward total was -21.000000. running mean: -20.427027\n",
            "resetting env. episode 1468.000000, reward total was -20.000000. running mean: -20.422757\n",
            "resetting env. episode 1469.000000, reward total was -21.000000. running mean: -20.428530\n",
            "resetting env. episode 1470.000000, reward total was -21.000000. running mean: -20.434244\n",
            "resetting env. episode 1471.000000, reward total was -21.000000. running mean: -20.439902\n",
            "resetting env. episode 1472.000000, reward total was -20.000000. running mean: -20.435503\n",
            "resetting env. episode 1473.000000, reward total was -21.000000. running mean: -20.441148\n",
            "resetting env. episode 1474.000000, reward total was -20.000000. running mean: -20.436736\n",
            "resetting env. episode 1475.000000, reward total was -21.000000. running mean: -20.442369\n",
            "resetting env. episode 1476.000000, reward total was -21.000000. running mean: -20.447945\n",
            "resetting env. episode 1477.000000, reward total was -19.000000. running mean: -20.433466\n",
            "resetting env. episode 1478.000000, reward total was -21.000000. running mean: -20.439131\n",
            "resetting env. episode 1479.000000, reward total was -21.000000. running mean: -20.444740\n",
            "resetting env. episode 1480.000000, reward total was -20.000000. running mean: -20.440292\n",
            "resetting env. episode 1481.000000, reward total was -21.000000. running mean: -20.445890\n",
            "resetting env. episode 1482.000000, reward total was -21.000000. running mean: -20.451431\n",
            "resetting env. episode 1483.000000, reward total was -20.000000. running mean: -20.446916\n",
            "resetting env. episode 1484.000000, reward total was -21.000000. running mean: -20.452447\n",
            "resetting env. episode 1485.000000, reward total was -21.000000. running mean: -20.457923\n",
            "resetting env. episode 1486.000000, reward total was -20.000000. running mean: -20.453344\n",
            "resetting env. episode 1487.000000, reward total was -20.000000. running mean: -20.448810\n",
            "resetting env. episode 1488.000000, reward total was -20.000000. running mean: -20.444322\n",
            "resetting env. episode 1489.000000, reward total was -21.000000. running mean: -20.449879\n",
            "resetting env. episode 1490.000000, reward total was -21.000000. running mean: -20.455380\n",
            "resetting env. episode 1491.000000, reward total was -21.000000. running mean: -20.460826\n",
            "resetting env. episode 1492.000000, reward total was -17.000000. running mean: -20.426218\n",
            "resetting env. episode 1493.000000, reward total was -21.000000. running mean: -20.431956\n",
            "resetting env. episode 1494.000000, reward total was -20.000000. running mean: -20.427636\n",
            "resetting env. episode 1495.000000, reward total was -20.000000. running mean: -20.423360\n",
            "resetting env. episode 1496.000000, reward total was -19.000000. running mean: -20.409126\n",
            "resetting env. episode 1497.000000, reward total was -21.000000. running mean: -20.415035\n",
            "resetting env. episode 1498.000000, reward total was -21.000000. running mean: -20.420885\n",
            "resetting env. episode 1499.000000, reward total was -19.000000. running mean: -20.406676\n",
            "resetting env. episode 1500.000000, reward total was -20.000000. running mean: -20.402609\n",
            "resetting env. episode 1501.000000, reward total was -20.000000. running mean: -20.398583\n",
            "resetting env. episode 1502.000000, reward total was -20.000000. running mean: -20.394597\n",
            "resetting env. episode 1503.000000, reward total was -20.000000. running mean: -20.390651\n",
            "resetting env. episode 1504.000000, reward total was -21.000000. running mean: -20.396745\n",
            "resetting env. episode 1505.000000, reward total was -21.000000. running mean: -20.402777\n",
            "resetting env. episode 1506.000000, reward total was -18.000000. running mean: -20.378749\n",
            "resetting env. episode 1507.000000, reward total was -21.000000. running mean: -20.384962\n",
            "resetting env. episode 1508.000000, reward total was -21.000000. running mean: -20.391112\n",
            "resetting env. episode 1509.000000, reward total was -21.000000. running mean: -20.397201\n",
            "resetting env. episode 1510.000000, reward total was -21.000000. running mean: -20.403229\n",
            "resetting env. episode 1511.000000, reward total was -21.000000. running mean: -20.409197\n",
            "resetting env. episode 1512.000000, reward total was -20.000000. running mean: -20.405105\n",
            "resetting env. episode 1513.000000, reward total was -20.000000. running mean: -20.401054\n",
            "resetting env. episode 1514.000000, reward total was -21.000000. running mean: -20.407043\n",
            "resetting env. episode 1515.000000, reward total was -20.000000. running mean: -20.402973\n",
            "resetting env. episode 1516.000000, reward total was -20.000000. running mean: -20.398943\n",
            "resetting env. episode 1517.000000, reward total was -20.000000. running mean: -20.394954\n",
            "resetting env. episode 1518.000000, reward total was -17.000000. running mean: -20.361004\n",
            "resetting env. episode 1519.000000, reward total was -21.000000. running mean: -20.367394\n",
            "resetting env. episode 1520.000000, reward total was -21.000000. running mean: -20.373720\n",
            "resetting env. episode 1521.000000, reward total was -21.000000. running mean: -20.379983\n",
            "resetting env. episode 1522.000000, reward total was -20.000000. running mean: -20.376183\n",
            "resetting env. episode 1523.000000, reward total was -21.000000. running mean: -20.382421\n",
            "resetting env. episode 1524.000000, reward total was -21.000000. running mean: -20.388597\n",
            "resetting env. episode 1525.000000, reward total was -20.000000. running mean: -20.384711\n",
            "resetting env. episode 1526.000000, reward total was -20.000000. running mean: -20.380864\n",
            "resetting env. episode 1527.000000, reward total was -21.000000. running mean: -20.387055\n",
            "resetting env. episode 1528.000000, reward total was -21.000000. running mean: -20.393185\n",
            "resetting env. episode 1529.000000, reward total was -20.000000. running mean: -20.389253\n",
            "resetting env. episode 1530.000000, reward total was -21.000000. running mean: -20.395360\n",
            "resetting env. episode 1531.000000, reward total was -20.000000. running mean: -20.391407\n",
            "resetting env. episode 1532.000000, reward total was -20.000000. running mean: -20.387493\n",
            "resetting env. episode 1533.000000, reward total was -20.000000. running mean: -20.383618\n",
            "resetting env. episode 1534.000000, reward total was -20.000000. running mean: -20.379782\n",
            "resetting env. episode 1535.000000, reward total was -21.000000. running mean: -20.385984\n",
            "resetting env. episode 1536.000000, reward total was -20.000000. running mean: -20.382124\n",
            "resetting env. episode 1537.000000, reward total was -21.000000. running mean: -20.388303\n",
            "resetting env. episode 1538.000000, reward total was -20.000000. running mean: -20.384420\n",
            "resetting env. episode 1539.000000, reward total was -21.000000. running mean: -20.390576\n",
            "resetting env. episode 1540.000000, reward total was -19.000000. running mean: -20.376670\n",
            "resetting env. episode 1541.000000, reward total was -20.000000. running mean: -20.372903\n",
            "resetting env. episode 1542.000000, reward total was -21.000000. running mean: -20.379174\n",
            "resetting env. episode 1543.000000, reward total was -21.000000. running mean: -20.385382\n",
            "resetting env. episode 1544.000000, reward total was -20.000000. running mean: -20.381528\n",
            "resetting env. episode 1545.000000, reward total was -21.000000. running mean: -20.387713\n",
            "resetting env. episode 1546.000000, reward total was -19.000000. running mean: -20.373836\n",
            "resetting env. episode 1547.000000, reward total was -18.000000. running mean: -20.350098\n",
            "resetting env. episode 1548.000000, reward total was -21.000000. running mean: -20.356597\n",
            "resetting env. episode 1549.000000, reward total was -20.000000. running mean: -20.353031\n",
            "resetting env. episode 1550.000000, reward total was -20.000000. running mean: -20.349500\n",
            "resetting env. episode 1551.000000, reward total was -21.000000. running mean: -20.356005\n",
            "resetting env. episode 1552.000000, reward total was -20.000000. running mean: -20.352445\n",
            "resetting env. episode 1553.000000, reward total was -21.000000. running mean: -20.358921\n",
            "resetting env. episode 1554.000000, reward total was -21.000000. running mean: -20.365332\n",
            "resetting env. episode 1555.000000, reward total was -19.000000. running mean: -20.351678\n",
            "resetting env. episode 1556.000000, reward total was -21.000000. running mean: -20.358162\n",
            "resetting env. episode 1557.000000, reward total was -21.000000. running mean: -20.364580\n",
            "resetting env. episode 1558.000000, reward total was -18.000000. running mean: -20.340934\n",
            "resetting env. episode 1559.000000, reward total was -21.000000. running mean: -20.347525\n",
            "resetting env. episode 1560.000000, reward total was -21.000000. running mean: -20.354050\n",
            "resetting env. episode 1561.000000, reward total was -20.000000. running mean: -20.350509\n",
            "resetting env. episode 1562.000000, reward total was -21.000000. running mean: -20.357004\n",
            "resetting env. episode 1563.000000, reward total was -21.000000. running mean: -20.363434\n",
            "resetting env. episode 1564.000000, reward total was -21.000000. running mean: -20.369800\n",
            "resetting env. episode 1565.000000, reward total was -21.000000. running mean: -20.376102\n",
            "resetting env. episode 1566.000000, reward total was -21.000000. running mean: -20.382341\n",
            "resetting env. episode 1567.000000, reward total was -21.000000. running mean: -20.388517\n",
            "resetting env. episode 1568.000000, reward total was -19.000000. running mean: -20.374632\n",
            "resetting env. episode 1569.000000, reward total was -19.000000. running mean: -20.360886\n",
            "resetting env. episode 1570.000000, reward total was -19.000000. running mean: -20.347277\n",
            "resetting env. episode 1571.000000, reward total was -20.000000. running mean: -20.343804\n",
            "resetting env. episode 1572.000000, reward total was -20.000000. running mean: -20.340366\n",
            "resetting env. episode 1573.000000, reward total was -21.000000. running mean: -20.346962\n",
            "resetting env. episode 1574.000000, reward total was -21.000000. running mean: -20.353493\n",
            "resetting env. episode 1575.000000, reward total was -21.000000. running mean: -20.359958\n",
            "resetting env. episode 1576.000000, reward total was -21.000000. running mean: -20.366358\n",
            "resetting env. episode 1577.000000, reward total was -20.000000. running mean: -20.362695\n",
            "resetting env. episode 1578.000000, reward total was -20.000000. running mean: -20.359068\n",
            "resetting env. episode 1579.000000, reward total was -21.000000. running mean: -20.365477\n",
            "resetting env. episode 1580.000000, reward total was -20.000000. running mean: -20.361822\n",
            "resetting env. episode 1581.000000, reward total was -21.000000. running mean: -20.368204\n",
            "resetting env. episode 1582.000000, reward total was -17.000000. running mean: -20.334522\n",
            "resetting env. episode 1583.000000, reward total was -21.000000. running mean: -20.341177\n",
            "resetting env. episode 1584.000000, reward total was -18.000000. running mean: -20.317765\n",
            "resetting env. episode 1585.000000, reward total was -21.000000. running mean: -20.324587\n",
            "resetting env. episode 1586.000000, reward total was -20.000000. running mean: -20.321342\n",
            "resetting env. episode 1587.000000, reward total was -19.000000. running mean: -20.308128\n",
            "resetting env. episode 1588.000000, reward total was -20.000000. running mean: -20.305047\n",
            "resetting env. episode 1589.000000, reward total was -19.000000. running mean: -20.291996\n",
            "resetting env. episode 1590.000000, reward total was -21.000000. running mean: -20.299076\n",
            "resetting env. episode 1591.000000, reward total was -19.000000. running mean: -20.286086\n",
            "resetting env. episode 1592.000000, reward total was -21.000000. running mean: -20.293225\n",
            "resetting env. episode 1593.000000, reward total was -19.000000. running mean: -20.280293\n",
            "resetting env. episode 1594.000000, reward total was -20.000000. running mean: -20.277490\n",
            "resetting env. episode 1595.000000, reward total was -20.000000. running mean: -20.274715\n",
            "resetting env. episode 1596.000000, reward total was -20.000000. running mean: -20.271968\n",
            "resetting env. episode 1597.000000, reward total was -20.000000. running mean: -20.269248\n",
            "resetting env. episode 1598.000000, reward total was -21.000000. running mean: -20.276555\n",
            "resetting env. episode 1599.000000, reward total was -20.000000. running mean: -20.273790\n",
            "resetting env. episode 1600.000000, reward total was -21.000000. running mean: -20.281052\n",
            "resetting env. episode 1601.000000, reward total was -21.000000. running mean: -20.288241\n",
            "resetting env. episode 1602.000000, reward total was -21.000000. running mean: -20.295359\n",
            "resetting env. episode 1603.000000, reward total was -21.000000. running mean: -20.302405\n",
            "resetting env. episode 1604.000000, reward total was -21.000000. running mean: -20.309381\n",
            "resetting env. episode 1605.000000, reward total was -20.000000. running mean: -20.306288\n",
            "resetting env. episode 1606.000000, reward total was -20.000000. running mean: -20.303225\n",
            "resetting env. episode 1607.000000, reward total was -20.000000. running mean: -20.300192\n",
            "resetting env. episode 1608.000000, reward total was -19.000000. running mean: -20.287191\n",
            "resetting env. episode 1609.000000, reward total was -20.000000. running mean: -20.284319\n",
            "resetting env. episode 1610.000000, reward total was -19.000000. running mean: -20.271475\n",
            "resetting env. episode 1611.000000, reward total was -18.000000. running mean: -20.248761\n",
            "resetting env. episode 1612.000000, reward total was -21.000000. running mean: -20.256273\n",
            "resetting env. episode 1613.000000, reward total was -21.000000. running mean: -20.263710\n",
            "resetting env. episode 1614.000000, reward total was -21.000000. running mean: -20.271073\n",
            "resetting env. episode 1615.000000, reward total was -21.000000. running mean: -20.278363\n",
            "resetting env. episode 1616.000000, reward total was -20.000000. running mean: -20.275579\n",
            "resetting env. episode 1617.000000, reward total was -19.000000. running mean: -20.262823\n",
            "resetting env. episode 1618.000000, reward total was -20.000000. running mean: -20.260195\n",
            "resetting env. episode 1619.000000, reward total was -21.000000. running mean: -20.267593\n",
            "resetting env. episode 1620.000000, reward total was -18.000000. running mean: -20.244917\n",
            "resetting env. episode 1621.000000, reward total was -21.000000. running mean: -20.252468\n",
            "resetting env. episode 1622.000000, reward total was -21.000000. running mean: -20.259943\n",
            "resetting env. episode 1623.000000, reward total was -21.000000. running mean: -20.267344\n",
            "resetting env. episode 1624.000000, reward total was -21.000000. running mean: -20.274670\n",
            "resetting env. episode 1625.000000, reward total was -20.000000. running mean: -20.271924\n",
            "resetting env. episode 1626.000000, reward total was -19.000000. running mean: -20.259204\n",
            "resetting env. episode 1627.000000, reward total was -20.000000. running mean: -20.256612\n",
            "resetting env. episode 1628.000000, reward total was -21.000000. running mean: -20.264046\n",
            "resetting env. episode 1629.000000, reward total was -21.000000. running mean: -20.271406\n",
            "resetting env. episode 1630.000000, reward total was -21.000000. running mean: -20.278692\n",
            "resetting env. episode 1631.000000, reward total was -21.000000. running mean: -20.285905\n",
            "resetting env. episode 1632.000000, reward total was -21.000000. running mean: -20.293046\n",
            "resetting env. episode 1633.000000, reward total was -21.000000. running mean: -20.300115\n",
            "resetting env. episode 1634.000000, reward total was -20.000000. running mean: -20.297114\n",
            "resetting env. episode 1635.000000, reward total was -21.000000. running mean: -20.304143\n",
            "resetting env. episode 1636.000000, reward total was -20.000000. running mean: -20.301101\n",
            "resetting env. episode 1637.000000, reward total was -21.000000. running mean: -20.308090\n",
            "resetting env. episode 1638.000000, reward total was -21.000000. running mean: -20.315010\n",
            "resetting env. episode 1639.000000, reward total was -21.000000. running mean: -20.321859\n",
            "resetting env. episode 1640.000000, reward total was -21.000000. running mean: -20.328641\n",
            "resetting env. episode 1641.000000, reward total was -20.000000. running mean: -20.325354\n",
            "resetting env. episode 1642.000000, reward total was -20.000000. running mean: -20.322101\n",
            "resetting env. episode 1643.000000, reward total was -21.000000. running mean: -20.328880\n",
            "resetting env. episode 1644.000000, reward total was -21.000000. running mean: -20.335591\n",
            "resetting env. episode 1645.000000, reward total was -21.000000. running mean: -20.342235\n",
            "resetting env. episode 1646.000000, reward total was -20.000000. running mean: -20.338813\n",
            "resetting env. episode 1647.000000, reward total was -20.000000. running mean: -20.335425\n",
            "resetting env. episode 1648.000000, reward total was -21.000000. running mean: -20.342070\n",
            "resetting env. episode 1649.000000, reward total was -18.000000. running mean: -20.318650\n",
            "resetting env. episode 1650.000000, reward total was -20.000000. running mean: -20.315463\n",
            "resetting env. episode 1651.000000, reward total was -21.000000. running mean: -20.322309\n",
            "resetting env. episode 1652.000000, reward total was -20.000000. running mean: -20.319086\n",
            "resetting env. episode 1653.000000, reward total was -19.000000. running mean: -20.305895\n",
            "resetting env. episode 1654.000000, reward total was -21.000000. running mean: -20.312836\n",
            "resetting env. episode 1655.000000, reward total was -19.000000. running mean: -20.299707\n",
            "resetting env. episode 1656.000000, reward total was -21.000000. running mean: -20.306710\n",
            "resetting env. episode 1657.000000, reward total was -20.000000. running mean: -20.303643\n",
            "resetting env. episode 1658.000000, reward total was -21.000000. running mean: -20.310607\n",
            "resetting env. episode 1659.000000, reward total was -19.000000. running mean: -20.297501\n",
            "resetting env. episode 1660.000000, reward total was -21.000000. running mean: -20.304526\n",
            "resetting env. episode 1661.000000, reward total was -21.000000. running mean: -20.311480\n",
            "resetting env. episode 1662.000000, reward total was -20.000000. running mean: -20.308366\n",
            "resetting env. episode 1663.000000, reward total was -20.000000. running mean: -20.305282\n",
            "resetting env. episode 1664.000000, reward total was -20.000000. running mean: -20.302229\n",
            "resetting env. episode 1665.000000, reward total was -19.000000. running mean: -20.289207\n",
            "resetting env. episode 1666.000000, reward total was -21.000000. running mean: -20.296315\n",
            "resetting env. episode 1667.000000, reward total was -21.000000. running mean: -20.303352\n",
            "resetting env. episode 1668.000000, reward total was -20.000000. running mean: -20.300318\n",
            "resetting env. episode 1669.000000, reward total was -19.000000. running mean: -20.287315\n",
            "resetting env. episode 1670.000000, reward total was -21.000000. running mean: -20.294442\n",
            "resetting env. episode 1671.000000, reward total was -21.000000. running mean: -20.301497\n",
            "resetting env. episode 1672.000000, reward total was -21.000000. running mean: -20.308482\n",
            "resetting env. episode 1673.000000, reward total was -20.000000. running mean: -20.305398\n",
            "resetting env. episode 1674.000000, reward total was -21.000000. running mean: -20.312344\n",
            "resetting env. episode 1675.000000, reward total was -21.000000. running mean: -20.319220\n",
            "resetting env. episode 1676.000000, reward total was -21.000000. running mean: -20.326028\n",
            "resetting env. episode 1677.000000, reward total was -18.000000. running mean: -20.302768\n",
            "resetting env. episode 1678.000000, reward total was -21.000000. running mean: -20.309740\n",
            "resetting env. episode 1679.000000, reward total was -21.000000. running mean: -20.316643\n",
            "resetting env. episode 1680.000000, reward total was -21.000000. running mean: -20.323476\n",
            "resetting env. episode 1681.000000, reward total was -19.000000. running mean: -20.310241\n",
            "resetting env. episode 1682.000000, reward total was -21.000000. running mean: -20.317139\n",
            "resetting env. episode 1683.000000, reward total was -21.000000. running mean: -20.323968\n",
            "resetting env. episode 1684.000000, reward total was -21.000000. running mean: -20.330728\n",
            "resetting env. episode 1685.000000, reward total was -21.000000. running mean: -20.337421\n",
            "resetting env. episode 1686.000000, reward total was -20.000000. running mean: -20.334046\n",
            "resetting env. episode 1687.000000, reward total was -19.000000. running mean: -20.320706\n",
            "resetting env. episode 1688.000000, reward total was -17.000000. running mean: -20.287499\n",
            "resetting env. episode 1689.000000, reward total was -21.000000. running mean: -20.294624\n",
            "resetting env. episode 1690.000000, reward total was -20.000000. running mean: -20.291678\n",
            "resetting env. episode 1691.000000, reward total was -21.000000. running mean: -20.298761\n",
            "resetting env. episode 1692.000000, reward total was -21.000000. running mean: -20.305773\n",
            "resetting env. episode 1693.000000, reward total was -20.000000. running mean: -20.302716\n",
            "resetting env. episode 1694.000000, reward total was -20.000000. running mean: -20.299688\n",
            "resetting env. episode 1695.000000, reward total was -21.000000. running mean: -20.306692\n",
            "resetting env. episode 1696.000000, reward total was -21.000000. running mean: -20.313625\n",
            "resetting env. episode 1697.000000, reward total was -20.000000. running mean: -20.310488\n",
            "resetting env. episode 1698.000000, reward total was -21.000000. running mean: -20.317384\n",
            "resetting env. episode 1699.000000, reward total was -21.000000. running mean: -20.324210\n",
            "resetting env. episode 1700.000000, reward total was -21.000000. running mean: -20.330968\n",
            "resetting env. episode 1701.000000, reward total was -20.000000. running mean: -20.327658\n",
            "resetting env. episode 1702.000000, reward total was -18.000000. running mean: -20.304381\n",
            "resetting env. episode 1703.000000, reward total was -21.000000. running mean: -20.311338\n",
            "resetting env. episode 1704.000000, reward total was -21.000000. running mean: -20.318224\n",
            "resetting env. episode 1705.000000, reward total was -21.000000. running mean: -20.325042\n",
            "resetting env. episode 1706.000000, reward total was -21.000000. running mean: -20.331791\n",
            "resetting env. episode 1707.000000, reward total was -20.000000. running mean: -20.328474\n",
            "resetting env. episode 1708.000000, reward total was -20.000000. running mean: -20.325189\n",
            "resetting env. episode 1709.000000, reward total was -21.000000. running mean: -20.331937\n",
            "resetting env. episode 1710.000000, reward total was -21.000000. running mean: -20.338618\n",
            "resetting env. episode 1711.000000, reward total was -21.000000. running mean: -20.345231\n",
            "resetting env. episode 1712.000000, reward total was -21.000000. running mean: -20.351779\n",
            "resetting env. episode 1713.000000, reward total was -20.000000. running mean: -20.348261\n",
            "resetting env. episode 1714.000000, reward total was -17.000000. running mean: -20.314779\n",
            "resetting env. episode 1715.000000, reward total was -18.000000. running mean: -20.291631\n",
            "resetting env. episode 1716.000000, reward total was -20.000000. running mean: -20.288715\n",
            "resetting env. episode 1717.000000, reward total was -21.000000. running mean: -20.295827\n",
            "resetting env. episode 1718.000000, reward total was -21.000000. running mean: -20.302869\n",
            "resetting env. episode 1719.000000, reward total was -20.000000. running mean: -20.299840\n",
            "resetting env. episode 1720.000000, reward total was -20.000000. running mean: -20.296842\n",
            "resetting env. episode 1721.000000, reward total was -19.000000. running mean: -20.283874\n",
            "resetting env. episode 1722.000000, reward total was -20.000000. running mean: -20.281035\n",
            "resetting env. episode 1723.000000, reward total was -20.000000. running mean: -20.278225\n",
            "resetting env. episode 1724.000000, reward total was -20.000000. running mean: -20.275442\n",
            "resetting env. episode 1725.000000, reward total was -21.000000. running mean: -20.282688\n",
            "resetting env. episode 1726.000000, reward total was -19.000000. running mean: -20.269861\n",
            "resetting env. episode 1727.000000, reward total was -21.000000. running mean: -20.277162\n",
            "resetting env. episode 1728.000000, reward total was -21.000000. running mean: -20.284391\n",
            "resetting env. episode 1729.000000, reward total was -21.000000. running mean: -20.291547\n",
            "resetting env. episode 1730.000000, reward total was -20.000000. running mean: -20.288631\n",
            "resetting env. episode 1731.000000, reward total was -21.000000. running mean: -20.295745\n",
            "resetting env. episode 1732.000000, reward total was -20.000000. running mean: -20.292788\n",
            "resetting env. episode 1733.000000, reward total was -21.000000. running mean: -20.299860\n",
            "resetting env. episode 1734.000000, reward total was -21.000000. running mean: -20.306861\n",
            "resetting env. episode 1735.000000, reward total was -20.000000. running mean: -20.303793\n",
            "resetting env. episode 1736.000000, reward total was -21.000000. running mean: -20.310755\n",
            "resetting env. episode 1737.000000, reward total was -21.000000. running mean: -20.317647\n",
            "resetting env. episode 1738.000000, reward total was -20.000000. running mean: -20.314471\n",
            "resetting env. episode 1739.000000, reward total was -21.000000. running mean: -20.321326\n",
            "resetting env. episode 1740.000000, reward total was -19.000000. running mean: -20.308113\n",
            "resetting env. episode 1741.000000, reward total was -21.000000. running mean: -20.315032\n",
            "resetting env. episode 1742.000000, reward total was -20.000000. running mean: -20.311881\n",
            "resetting env. episode 1743.000000, reward total was -19.000000. running mean: -20.298762\n",
            "resetting env. episode 1744.000000, reward total was -21.000000. running mean: -20.305775\n",
            "resetting env. episode 1745.000000, reward total was -21.000000. running mean: -20.312717\n",
            "resetting env. episode 1746.000000, reward total was -19.000000. running mean: -20.299590\n",
            "resetting env. episode 1747.000000, reward total was -21.000000. running mean: -20.306594\n",
            "resetting env. episode 1748.000000, reward total was -21.000000. running mean: -20.313528\n",
            "resetting env. episode 1749.000000, reward total was -18.000000. running mean: -20.290393\n",
            "resetting env. episode 1750.000000, reward total was -19.000000. running mean: -20.277489\n",
            "resetting env. episode 1751.000000, reward total was -17.000000. running mean: -20.244714\n",
            "resetting env. episode 1752.000000, reward total was -19.000000. running mean: -20.232267\n",
            "resetting env. episode 1753.000000, reward total was -21.000000. running mean: -20.239944\n",
            "resetting env. episode 1754.000000, reward total was -20.000000. running mean: -20.237545\n",
            "resetting env. episode 1755.000000, reward total was -21.000000. running mean: -20.245169\n",
            "resetting env. episode 1756.000000, reward total was -20.000000. running mean: -20.242718\n",
            "resetting env. episode 1757.000000, reward total was -21.000000. running mean: -20.250290\n",
            "resetting env. episode 1758.000000, reward total was -21.000000. running mean: -20.257787\n",
            "resetting env. episode 1759.000000, reward total was -21.000000. running mean: -20.265210\n",
            "resetting env. episode 1760.000000, reward total was -19.000000. running mean: -20.252557\n",
            "resetting env. episode 1761.000000, reward total was -21.000000. running mean: -20.260032\n",
            "resetting env. episode 1762.000000, reward total was -21.000000. running mean: -20.267432\n",
            "resetting env. episode 1763.000000, reward total was -20.000000. running mean: -20.264757\n",
            "resetting env. episode 1764.000000, reward total was -18.000000. running mean: -20.242110\n",
            "resetting env. episode 1765.000000, reward total was -21.000000. running mean: -20.249689\n",
            "resetting env. episode 1766.000000, reward total was -20.000000. running mean: -20.247192\n",
            "resetting env. episode 1767.000000, reward total was -21.000000. running mean: -20.254720\n",
            "resetting env. episode 1768.000000, reward total was -20.000000. running mean: -20.252173\n",
            "resetting env. episode 1769.000000, reward total was -20.000000. running mean: -20.249651\n",
            "resetting env. episode 1770.000000, reward total was -21.000000. running mean: -20.257154\n",
            "resetting env. episode 1771.000000, reward total was -19.000000. running mean: -20.244583\n",
            "resetting env. episode 1772.000000, reward total was -19.000000. running mean: -20.232137\n",
            "resetting env. episode 1773.000000, reward total was -21.000000. running mean: -20.239816\n",
            "resetting env. episode 1774.000000, reward total was -20.000000. running mean: -20.237417\n",
            "resetting env. episode 1775.000000, reward total was -20.000000. running mean: -20.235043\n",
            "resetting env. episode 1776.000000, reward total was -21.000000. running mean: -20.242693\n",
            "resetting env. episode 1777.000000, reward total was -20.000000. running mean: -20.240266\n",
            "resetting env. episode 1778.000000, reward total was -18.000000. running mean: -20.217863\n",
            "resetting env. episode 1779.000000, reward total was -20.000000. running mean: -20.215685\n",
            "resetting env. episode 1780.000000, reward total was -20.000000. running mean: -20.213528\n",
            "resetting env. episode 1781.000000, reward total was -20.000000. running mean: -20.211393\n",
            "resetting env. episode 1782.000000, reward total was -20.000000. running mean: -20.209279\n",
            "resetting env. episode 1783.000000, reward total was -20.000000. running mean: -20.207186\n",
            "resetting env. episode 1784.000000, reward total was -21.000000. running mean: -20.215114\n",
            "resetting env. episode 1785.000000, reward total was -21.000000. running mean: -20.222963\n",
            "resetting env. episode 1786.000000, reward total was -21.000000. running mean: -20.230733\n",
            "resetting env. episode 1787.000000, reward total was -20.000000. running mean: -20.228426\n",
            "resetting env. episode 1788.000000, reward total was -19.000000. running mean: -20.216142\n",
            "resetting env. episode 1789.000000, reward total was -21.000000. running mean: -20.223980\n",
            "resetting env. episode 1790.000000, reward total was -21.000000. running mean: -20.231740\n",
            "resetting env. episode 1791.000000, reward total was -19.000000. running mean: -20.219423\n",
            "resetting env. episode 1792.000000, reward total was -21.000000. running mean: -20.227229\n",
            "resetting env. episode 1793.000000, reward total was -20.000000. running mean: -20.224956\n",
            "resetting env. episode 1794.000000, reward total was -21.000000. running mean: -20.232707\n",
            "resetting env. episode 1795.000000, reward total was -21.000000. running mean: -20.240380\n",
            "resetting env. episode 1796.000000, reward total was -19.000000. running mean: -20.227976\n",
            "resetting env. episode 1797.000000, reward total was -20.000000. running mean: -20.225696\n",
            "resetting env. episode 1798.000000, reward total was -19.000000. running mean: -20.213439\n",
            "resetting env. episode 1799.000000, reward total was -21.000000. running mean: -20.221305\n",
            "resetting env. episode 1800.000000, reward total was -20.000000. running mean: -20.219092\n",
            "resetting env. episode 1801.000000, reward total was -20.000000. running mean: -20.216901\n",
            "resetting env. episode 1802.000000, reward total was -21.000000. running mean: -20.224732\n",
            "resetting env. episode 1803.000000, reward total was -20.000000. running mean: -20.222485\n",
            "resetting env. episode 1804.000000, reward total was -20.000000. running mean: -20.220260\n",
            "resetting env. episode 1805.000000, reward total was -21.000000. running mean: -20.228057\n",
            "resetting env. episode 1806.000000, reward total was -20.000000. running mean: -20.225777\n",
            "resetting env. episode 1807.000000, reward total was -21.000000. running mean: -20.233519\n",
            "resetting env. episode 1808.000000, reward total was -21.000000. running mean: -20.241184\n",
            "resetting env. episode 1809.000000, reward total was -21.000000. running mean: -20.248772\n",
            "resetting env. episode 1810.000000, reward total was -19.000000. running mean: -20.236284\n",
            "resetting env. episode 1811.000000, reward total was -20.000000. running mean: -20.233921\n",
            "resetting env. episode 1812.000000, reward total was -18.000000. running mean: -20.211582\n",
            "resetting env. episode 1813.000000, reward total was -20.000000. running mean: -20.209466\n",
            "resetting env. episode 1814.000000, reward total was -21.000000. running mean: -20.217372\n",
            "resetting env. episode 1815.000000, reward total was -21.000000. running mean: -20.225198\n",
            "resetting env. episode 1816.000000, reward total was -19.000000. running mean: -20.212946\n",
            "resetting env. episode 1817.000000, reward total was -19.000000. running mean: -20.200816\n",
            "resetting env. episode 1818.000000, reward total was -20.000000. running mean: -20.198808\n",
            "resetting env. episode 1819.000000, reward total was -21.000000. running mean: -20.206820\n",
            "resetting env. episode 1820.000000, reward total was -20.000000. running mean: -20.204752\n",
            "resetting env. episode 1821.000000, reward total was -20.000000. running mean: -20.202704\n",
            "resetting env. episode 1822.000000, reward total was -20.000000. running mean: -20.200677\n",
            "resetting env. episode 1823.000000, reward total was -19.000000. running mean: -20.188671\n",
            "resetting env. episode 1824.000000, reward total was -20.000000. running mean: -20.186784\n",
            "resetting env. episode 1825.000000, reward total was -21.000000. running mean: -20.194916\n",
            "resetting env. episode 1826.000000, reward total was -19.000000. running mean: -20.182967\n",
            "resetting env. episode 1827.000000, reward total was -21.000000. running mean: -20.191137\n",
            "resetting env. episode 1828.000000, reward total was -19.000000. running mean: -20.179226\n",
            "resetting env. episode 1829.000000, reward total was -20.000000. running mean: -20.177434\n",
            "resetting env. episode 1830.000000, reward total was -21.000000. running mean: -20.185659\n",
            "resetting env. episode 1831.000000, reward total was -21.000000. running mean: -20.193803\n",
            "resetting env. episode 1832.000000, reward total was -21.000000. running mean: -20.201865\n",
            "resetting env. episode 1833.000000, reward total was -21.000000. running mean: -20.209846\n",
            "resetting env. episode 1834.000000, reward total was -20.000000. running mean: -20.207748\n",
            "resetting env. episode 1835.000000, reward total was -21.000000. running mean: -20.215670\n",
            "resetting env. episode 1836.000000, reward total was -20.000000. running mean: -20.213513\n",
            "resetting env. episode 1837.000000, reward total was -20.000000. running mean: -20.211378\n",
            "resetting env. episode 1838.000000, reward total was -18.000000. running mean: -20.189264\n",
            "resetting env. episode 1839.000000, reward total was -21.000000. running mean: -20.197372\n",
            "resetting env. episode 1840.000000, reward total was -18.000000. running mean: -20.175398\n",
            "resetting env. episode 1841.000000, reward total was -20.000000. running mean: -20.173644\n",
            "resetting env. episode 1842.000000, reward total was -20.000000. running mean: -20.171908\n",
            "resetting env. episode 1843.000000, reward total was -20.000000. running mean: -20.170189\n",
            "resetting env. episode 1844.000000, reward total was -19.000000. running mean: -20.158487\n",
            "resetting env. episode 1845.000000, reward total was -20.000000. running mean: -20.156902\n",
            "resetting env. episode 1846.000000, reward total was -21.000000. running mean: -20.165333\n",
            "resetting env. episode 1847.000000, reward total was -21.000000. running mean: -20.173679\n",
            "resetting env. episode 1848.000000, reward total was -18.000000. running mean: -20.151943\n",
            "resetting env. episode 1849.000000, reward total was -20.000000. running mean: -20.150423\n",
            "resetting env. episode 1850.000000, reward total was -21.000000. running mean: -20.158919\n",
            "resetting env. episode 1851.000000, reward total was -21.000000. running mean: -20.167330\n",
            "resetting env. episode 1852.000000, reward total was -19.000000. running mean: -20.155657\n",
            "resetting env. episode 1853.000000, reward total was -20.000000. running mean: -20.154100\n",
            "resetting env. episode 1854.000000, reward total was -21.000000. running mean: -20.162559\n",
            "resetting env. episode 1855.000000, reward total was -19.000000. running mean: -20.150933\n",
            "resetting env. episode 1856.000000, reward total was -17.000000. running mean: -20.119424\n",
            "resetting env. episode 1857.000000, reward total was -21.000000. running mean: -20.128230\n",
            "resetting env. episode 1858.000000, reward total was -21.000000. running mean: -20.136948\n",
            "resetting env. episode 1859.000000, reward total was -21.000000. running mean: -20.145578\n",
            "resetting env. episode 1860.000000, reward total was -19.000000. running mean: -20.134122\n",
            "resetting env. episode 1861.000000, reward total was -21.000000. running mean: -20.142781\n",
            "resetting env. episode 1862.000000, reward total was -21.000000. running mean: -20.151353\n",
            "resetting env. episode 1863.000000, reward total was -21.000000. running mean: -20.159840\n",
            "resetting env. episode 1864.000000, reward total was -18.000000. running mean: -20.138241\n",
            "resetting env. episode 1865.000000, reward total was -18.000000. running mean: -20.116859\n",
            "resetting env. episode 1866.000000, reward total was -20.000000. running mean: -20.115690\n",
            "resetting env. episode 1867.000000, reward total was -19.000000. running mean: -20.104533\n",
            "resetting env. episode 1868.000000, reward total was -20.000000. running mean: -20.103488\n",
            "resetting env. episode 1869.000000, reward total was -21.000000. running mean: -20.112453\n",
            "resetting env. episode 1870.000000, reward total was -20.000000. running mean: -20.111329\n",
            "resetting env. episode 1871.000000, reward total was -21.000000. running mean: -20.120215\n",
            "resetting env. episode 1872.000000, reward total was -21.000000. running mean: -20.129013\n",
            "resetting env. episode 1873.000000, reward total was -21.000000. running mean: -20.137723\n",
            "resetting env. episode 1874.000000, reward total was -21.000000. running mean: -20.146346\n",
            "resetting env. episode 1875.000000, reward total was -21.000000. running mean: -20.154882\n",
            "resetting env. episode 1876.000000, reward total was -21.000000. running mean: -20.163334\n",
            "resetting env. episode 1877.000000, reward total was -21.000000. running mean: -20.171700\n",
            "resetting env. episode 1878.000000, reward total was -20.000000. running mean: -20.169983\n",
            "resetting env. episode 1879.000000, reward total was -21.000000. running mean: -20.178283\n",
            "resetting env. episode 1880.000000, reward total was -21.000000. running mean: -20.186501\n",
            "resetting env. episode 1881.000000, reward total was -19.000000. running mean: -20.174636\n",
            "resetting env. episode 1882.000000, reward total was -19.000000. running mean: -20.162889\n",
            "resetting env. episode 1883.000000, reward total was -18.000000. running mean: -20.141260\n",
            "resetting env. episode 1884.000000, reward total was -21.000000. running mean: -20.149848\n",
            "resetting env. episode 1885.000000, reward total was -21.000000. running mean: -20.158349\n",
            "resetting env. episode 1886.000000, reward total was -20.000000. running mean: -20.156766\n",
            "resetting env. episode 1887.000000, reward total was -19.000000. running mean: -20.145198\n",
            "resetting env. episode 1888.000000, reward total was -21.000000. running mean: -20.153746\n",
            "resetting env. episode 1889.000000, reward total was -20.000000. running mean: -20.152209\n",
            "resetting env. episode 1890.000000, reward total was -21.000000. running mean: -20.160687\n",
            "resetting env. episode 1891.000000, reward total was -20.000000. running mean: -20.159080\n",
            "resetting env. episode 1892.000000, reward total was -20.000000. running mean: -20.157489\n",
            "resetting env. episode 1893.000000, reward total was -21.000000. running mean: -20.165914\n",
            "resetting env. episode 1894.000000, reward total was -19.000000. running mean: -20.154255\n",
            "resetting env. episode 1895.000000, reward total was -21.000000. running mean: -20.162712\n",
            "resetting env. episode 1896.000000, reward total was -20.000000. running mean: -20.161085\n",
            "resetting env. episode 1897.000000, reward total was -20.000000. running mean: -20.159474\n",
            "resetting env. episode 1898.000000, reward total was -19.000000. running mean: -20.147880\n",
            "resetting env. episode 1899.000000, reward total was -19.000000. running mean: -20.136401\n",
            "resetting env. episode 1900.000000, reward total was -20.000000. running mean: -20.135037\n",
            "resetting env. episode 1901.000000, reward total was -20.000000. running mean: -20.133686\n",
            "resetting env. episode 1902.000000, reward total was -20.000000. running mean: -20.132350\n",
            "resetting env. episode 1903.000000, reward total was -21.000000. running mean: -20.141026\n",
            "resetting env. episode 1904.000000, reward total was -19.000000. running mean: -20.129616\n",
            "resetting env. episode 1905.000000, reward total was -18.000000. running mean: -20.108320\n",
            "resetting env. episode 1906.000000, reward total was -21.000000. running mean: -20.117236\n",
            "resetting env. episode 1907.000000, reward total was -21.000000. running mean: -20.126064\n",
            "resetting env. episode 1908.000000, reward total was -19.000000. running mean: -20.114803\n",
            "resetting env. episode 1909.000000, reward total was -20.000000. running mean: -20.113655\n",
            "resetting env. episode 1910.000000, reward total was -19.000000. running mean: -20.102519\n",
            "resetting env. episode 1911.000000, reward total was -20.000000. running mean: -20.101494\n",
            "resetting env. episode 1912.000000, reward total was -21.000000. running mean: -20.110479\n",
            "resetting env. episode 1913.000000, reward total was -18.000000. running mean: -20.089374\n",
            "resetting env. episode 1914.000000, reward total was -20.000000. running mean: -20.088480\n",
            "resetting env. episode 1915.000000, reward total was -18.000000. running mean: -20.067595\n",
            "resetting env. episode 1916.000000, reward total was -20.000000. running mean: -20.066919\n",
            "resetting env. episode 1917.000000, reward total was -21.000000. running mean: -20.076250\n",
            "resetting env. episode 1918.000000, reward total was -19.000000. running mean: -20.065488\n",
            "resetting env. episode 1919.000000, reward total was -20.000000. running mean: -20.064833\n",
            "resetting env. episode 1920.000000, reward total was -21.000000. running mean: -20.074185\n",
            "resetting env. episode 1921.000000, reward total was -21.000000. running mean: -20.083443\n",
            "resetting env. episode 1922.000000, reward total was -21.000000. running mean: -20.092608\n",
            "resetting env. episode 1923.000000, reward total was -21.000000. running mean: -20.101682\n",
            "resetting env. episode 1924.000000, reward total was -18.000000. running mean: -20.080665\n",
            "resetting env. episode 1925.000000, reward total was -19.000000. running mean: -20.069859\n",
            "resetting env. episode 1926.000000, reward total was -20.000000. running mean: -20.069160\n",
            "resetting env. episode 1927.000000, reward total was -20.000000. running mean: -20.068469\n",
            "resetting env. episode 1928.000000, reward total was -20.000000. running mean: -20.067784\n",
            "resetting env. episode 1929.000000, reward total was -19.000000. running mean: -20.057106\n",
            "resetting env. episode 1930.000000, reward total was -20.000000. running mean: -20.056535\n",
            "resetting env. episode 1931.000000, reward total was -21.000000. running mean: -20.065970\n",
            "resetting env. episode 1932.000000, reward total was -20.000000. running mean: -20.065310\n",
            "resetting env. episode 1933.000000, reward total was -19.000000. running mean: -20.054657\n",
            "resetting env. episode 1934.000000, reward total was -21.000000. running mean: -20.064110\n",
            "resetting env. episode 1935.000000, reward total was -21.000000. running mean: -20.073469\n",
            "resetting env. episode 1936.000000, reward total was -19.000000. running mean: -20.062734\n",
            "resetting env. episode 1937.000000, reward total was -20.000000. running mean: -20.062107\n",
            "resetting env. episode 1938.000000, reward total was -21.000000. running mean: -20.071486\n",
            "resetting env. episode 1939.000000, reward total was -19.000000. running mean: -20.060771\n",
            "resetting env. episode 1940.000000, reward total was -20.000000. running mean: -20.060163\n",
            "resetting env. episode 1941.000000, reward total was -21.000000. running mean: -20.069562\n",
            "resetting env. episode 1942.000000, reward total was -21.000000. running mean: -20.078866\n",
            "resetting env. episode 1943.000000, reward total was -21.000000. running mean: -20.088078\n",
            "resetting env. episode 1944.000000, reward total was -21.000000. running mean: -20.097197\n",
            "resetting env. episode 1945.000000, reward total was -21.000000. running mean: -20.106225\n",
            "resetting env. episode 1946.000000, reward total was -21.000000. running mean: -20.115163\n",
            "resetting env. episode 1947.000000, reward total was -19.000000. running mean: -20.104011\n",
            "resetting env. episode 1948.000000, reward total was -20.000000. running mean: -20.102971\n",
            "resetting env. episode 1949.000000, reward total was -20.000000. running mean: -20.101941\n",
            "resetting env. episode 1950.000000, reward total was -21.000000. running mean: -20.110922\n",
            "resetting env. episode 1951.000000, reward total was -21.000000. running mean: -20.119812\n",
            "resetting env. episode 1952.000000, reward total was -20.000000. running mean: -20.118614\n",
            "resetting env. episode 1953.000000, reward total was -21.000000. running mean: -20.127428\n",
            "resetting env. episode 1954.000000, reward total was -19.000000. running mean: -20.116154\n",
            "resetting env. episode 1955.000000, reward total was -21.000000. running mean: -20.124992\n",
            "resetting env. episode 1956.000000, reward total was -19.000000. running mean: -20.113742\n",
            "resetting env. episode 1957.000000, reward total was -19.000000. running mean: -20.102605\n",
            "resetting env. episode 1958.000000, reward total was -19.000000. running mean: -20.091579\n",
            "resetting env. episode 1959.000000, reward total was -20.000000. running mean: -20.090663\n",
            "resetting env. episode 1960.000000, reward total was -20.000000. running mean: -20.089757\n",
            "resetting env. episode 1961.000000, reward total was -21.000000. running mean: -20.098859\n",
            "resetting env. episode 1962.000000, reward total was -21.000000. running mean: -20.107870\n",
            "resetting env. episode 1963.000000, reward total was -21.000000. running mean: -20.116792\n",
            "resetting env. episode 1964.000000, reward total was -19.000000. running mean: -20.105624\n",
            "resetting env. episode 1965.000000, reward total was -21.000000. running mean: -20.114568\n",
            "resetting env. episode 1966.000000, reward total was -21.000000. running mean: -20.123422\n",
            "resetting env. episode 1967.000000, reward total was -18.000000. running mean: -20.102188\n",
            "resetting env. episode 1968.000000, reward total was -21.000000. running mean: -20.111166\n",
            "resetting env. episode 1969.000000, reward total was -20.000000. running mean: -20.110054\n",
            "resetting env. episode 1970.000000, reward total was -21.000000. running mean: -20.118954\n",
            "resetting env. episode 1971.000000, reward total was -21.000000. running mean: -20.127764\n",
            "resetting env. episode 1972.000000, reward total was -19.000000. running mean: -20.116486\n",
            "resetting env. episode 1973.000000, reward total was -19.000000. running mean: -20.105322\n",
            "resetting env. episode 1974.000000, reward total was -20.000000. running mean: -20.104268\n",
            "resetting env. episode 1975.000000, reward total was -21.000000. running mean: -20.113226\n",
            "resetting env. episode 1976.000000, reward total was -20.000000. running mean: -20.112093\n",
            "resetting env. episode 1977.000000, reward total was -19.000000. running mean: -20.100972\n",
            "resetting env. episode 1978.000000, reward total was -20.000000. running mean: -20.099963\n",
            "resetting env. episode 1979.000000, reward total was -21.000000. running mean: -20.108963\n",
            "resetting env. episode 1980.000000, reward total was -21.000000. running mean: -20.117873\n",
            "resetting env. episode 1981.000000, reward total was -20.000000. running mean: -20.116695\n",
            "resetting env. episode 1982.000000, reward total was -20.000000. running mean: -20.115528\n",
            "resetting env. episode 1983.000000, reward total was -21.000000. running mean: -20.124373\n",
            "resetting env. episode 1984.000000, reward total was -20.000000. running mean: -20.123129\n",
            "resetting env. episode 1985.000000, reward total was -17.000000. running mean: -20.091897\n",
            "resetting env. episode 1986.000000, reward total was -21.000000. running mean: -20.100979\n",
            "resetting env. episode 1987.000000, reward total was -19.000000. running mean: -20.089969\n",
            "resetting env. episode 1988.000000, reward total was -19.000000. running mean: -20.079069\n",
            "resetting env. episode 1989.000000, reward total was -21.000000. running mean: -20.088278\n",
            "resetting env. episode 1990.000000, reward total was -18.000000. running mean: -20.067396\n",
            "resetting env. episode 1991.000000, reward total was -20.000000. running mean: -20.066722\n",
            "resetting env. episode 1992.000000, reward total was -20.000000. running mean: -20.066054\n",
            "resetting env. episode 1993.000000, reward total was -19.000000. running mean: -20.055394\n",
            "resetting env. episode 1994.000000, reward total was -19.000000. running mean: -20.044840\n",
            "resetting env. episode 1995.000000, reward total was -21.000000. running mean: -20.054392\n",
            "resetting env. episode 1996.000000, reward total was -21.000000. running mean: -20.063848\n",
            "resetting env. episode 1997.000000, reward total was -20.000000. running mean: -20.063209\n",
            "resetting env. episode 1998.000000, reward total was -20.000000. running mean: -20.062577\n",
            "resetting env. episode 1999.000000, reward total was -20.000000. running mean: -20.061951\n",
            "resetting env. episode 2000.000000, reward total was -18.000000. running mean: -20.041332\n",
            "resetting env. episode 2001.000000, reward total was -21.000000. running mean: -20.050918\n",
            "resetting env. episode 2002.000000, reward total was -20.000000. running mean: -20.050409\n",
            "resetting env. episode 2003.000000, reward total was -20.000000. running mean: -20.049905\n",
            "resetting env. episode 2004.000000, reward total was -20.000000. running mean: -20.049406\n",
            "resetting env. episode 2005.000000, reward total was -20.000000. running mean: -20.048912\n",
            "resetting env. episode 2006.000000, reward total was -21.000000. running mean: -20.058423\n",
            "resetting env. episode 2007.000000, reward total was -21.000000. running mean: -20.067839\n",
            "resetting env. episode 2008.000000, reward total was -21.000000. running mean: -20.077160\n",
            "resetting env. episode 2009.000000, reward total was -21.000000. running mean: -20.086389\n",
            "resetting env. episode 2010.000000, reward total was -20.000000. running mean: -20.085525\n",
            "resetting env. episode 2011.000000, reward total was -21.000000. running mean: -20.094670\n",
            "resetting env. episode 2012.000000, reward total was -21.000000. running mean: -20.103723\n",
            "resetting env. episode 2013.000000, reward total was -20.000000. running mean: -20.102686\n",
            "resetting env. episode 2014.000000, reward total was -21.000000. running mean: -20.111659\n",
            "resetting env. episode 2015.000000, reward total was -21.000000. running mean: -20.120542\n",
            "resetting env. episode 2016.000000, reward total was -21.000000. running mean: -20.129337\n",
            "resetting env. episode 2017.000000, reward total was -21.000000. running mean: -20.138043\n",
            "resetting env. episode 2018.000000, reward total was -21.000000. running mean: -20.146663\n",
            "resetting env. episode 2019.000000, reward total was -21.000000. running mean: -20.155196\n",
            "resetting env. episode 2020.000000, reward total was -21.000000. running mean: -20.163644\n",
            "resetting env. episode 2021.000000, reward total was -21.000000. running mean: -20.172008\n",
            "resetting env. episode 2022.000000, reward total was -21.000000. running mean: -20.180288\n",
            "resetting env. episode 2023.000000, reward total was -19.000000. running mean: -20.168485\n",
            "resetting env. episode 2024.000000, reward total was -21.000000. running mean: -20.176800\n",
            "resetting env. episode 2025.000000, reward total was -20.000000. running mean: -20.175032\n",
            "resetting env. episode 2026.000000, reward total was -21.000000. running mean: -20.183282\n",
            "resetting env. episode 2027.000000, reward total was -18.000000. running mean: -20.161449\n",
            "resetting env. episode 2028.000000, reward total was -21.000000. running mean: -20.169835\n",
            "resetting env. episode 2029.000000, reward total was -21.000000. running mean: -20.178136\n",
            "resetting env. episode 2030.000000, reward total was -20.000000. running mean: -20.176355\n",
            "resetting env. episode 2031.000000, reward total was -21.000000. running mean: -20.184591\n",
            "resetting env. episode 2032.000000, reward total was -20.000000. running mean: -20.182745\n",
            "resetting env. episode 2033.000000, reward total was -19.000000. running mean: -20.170918\n",
            "resetting env. episode 2034.000000, reward total was -21.000000. running mean: -20.179209\n",
            "resetting env. episode 2035.000000, reward total was -21.000000. running mean: -20.187417\n",
            "resetting env. episode 2036.000000, reward total was -21.000000. running mean: -20.195542\n",
            "resetting env. episode 2037.000000, reward total was -19.000000. running mean: -20.183587\n",
            "resetting env. episode 2038.000000, reward total was -21.000000. running mean: -20.191751\n",
            "resetting env. episode 2039.000000, reward total was -20.000000. running mean: -20.189834\n",
            "resetting env. episode 2040.000000, reward total was -21.000000. running mean: -20.197935\n",
            "resetting env. episode 2041.000000, reward total was -18.000000. running mean: -20.175956\n",
            "resetting env. episode 2042.000000, reward total was -21.000000. running mean: -20.184196\n",
            "resetting env. episode 2043.000000, reward total was -21.000000. running mean: -20.192354\n",
            "resetting env. episode 2044.000000, reward total was -17.000000. running mean: -20.160431\n",
            "resetting env. episode 2045.000000, reward total was -21.000000. running mean: -20.168827\n",
            "resetting env. episode 2046.000000, reward total was -21.000000. running mean: -20.177138\n",
            "resetting env. episode 2047.000000, reward total was -21.000000. running mean: -20.185367\n",
            "resetting env. episode 2048.000000, reward total was -20.000000. running mean: -20.183513\n",
            "resetting env. episode 2049.000000, reward total was -20.000000. running mean: -20.181678\n",
            "resetting env. episode 2050.000000, reward total was -21.000000. running mean: -20.189861\n",
            "resetting env. episode 2051.000000, reward total was -18.000000. running mean: -20.167963\n",
            "resetting env. episode 2052.000000, reward total was -21.000000. running mean: -20.176283\n",
            "resetting env. episode 2053.000000, reward total was -20.000000. running mean: -20.174520\n",
            "resetting env. episode 2054.000000, reward total was -21.000000. running mean: -20.182775\n",
            "resetting env. episode 2055.000000, reward total was -21.000000. running mean: -20.190947\n",
            "resetting env. episode 2056.000000, reward total was -20.000000. running mean: -20.189038\n",
            "resetting env. episode 2057.000000, reward total was -20.000000. running mean: -20.187147\n",
            "resetting env. episode 2058.000000, reward total was -21.000000. running mean: -20.195276\n",
            "resetting env. episode 2059.000000, reward total was -20.000000. running mean: -20.193323\n",
            "resetting env. episode 2060.000000, reward total was -21.000000. running mean: -20.201390\n",
            "resetting env. episode 2061.000000, reward total was -21.000000. running mean: -20.209376\n",
            "resetting env. episode 2062.000000, reward total was -21.000000. running mean: -20.217282\n",
            "resetting env. episode 2063.000000, reward total was -21.000000. running mean: -20.225110\n",
            "resetting env. episode 2064.000000, reward total was -21.000000. running mean: -20.232858\n",
            "resetting env. episode 2065.000000, reward total was -18.000000. running mean: -20.210530\n",
            "resetting env. episode 2066.000000, reward total was -19.000000. running mean: -20.198425\n",
            "resetting env. episode 2067.000000, reward total was -20.000000. running mean: -20.196440\n",
            "resetting env. episode 2068.000000, reward total was -18.000000. running mean: -20.174476\n",
            "resetting env. episode 2069.000000, reward total was -20.000000. running mean: -20.172731\n",
            "resetting env. episode 2070.000000, reward total was -20.000000. running mean: -20.171004\n",
            "resetting env. episode 2071.000000, reward total was -20.000000. running mean: -20.169294\n",
            "resetting env. episode 2072.000000, reward total was -18.000000. running mean: -20.147601\n",
            "resetting env. episode 2073.000000, reward total was -19.000000. running mean: -20.136125\n",
            "resetting env. episode 2074.000000, reward total was -21.000000. running mean: -20.144764\n",
            "resetting env. episode 2075.000000, reward total was -20.000000. running mean: -20.143316\n",
            "resetting env. episode 2076.000000, reward total was -19.000000. running mean: -20.131883\n",
            "resetting env. episode 2077.000000, reward total was -21.000000. running mean: -20.140564\n",
            "resetting env. episode 2078.000000, reward total was -19.000000. running mean: -20.129158\n",
            "resetting env. episode 2079.000000, reward total was -21.000000. running mean: -20.137867\n",
            "resetting env. episode 2080.000000, reward total was -21.000000. running mean: -20.146488\n",
            "resetting env. episode 2081.000000, reward total was -21.000000. running mean: -20.155023\n",
            "resetting env. episode 2082.000000, reward total was -20.000000. running mean: -20.153473\n",
            "resetting env. episode 2083.000000, reward total was -20.000000. running mean: -20.151938\n",
            "resetting env. episode 2084.000000, reward total was -19.000000. running mean: -20.140419\n",
            "resetting env. episode 2085.000000, reward total was -21.000000. running mean: -20.149015\n",
            "resetting env. episode 2086.000000, reward total was -18.000000. running mean: -20.127525\n",
            "resetting env. episode 2087.000000, reward total was -21.000000. running mean: -20.136249\n",
            "resetting env. episode 2088.000000, reward total was -21.000000. running mean: -20.144887\n",
            "resetting env. episode 2089.000000, reward total was -21.000000. running mean: -20.153438\n",
            "resetting env. episode 2090.000000, reward total was -18.000000. running mean: -20.131904\n",
            "resetting env. episode 2091.000000, reward total was -20.000000. running mean: -20.130584\n",
            "resetting env. episode 2092.000000, reward total was -20.000000. running mean: -20.129279\n",
            "resetting env. episode 2093.000000, reward total was -21.000000. running mean: -20.137986\n",
            "resetting env. episode 2094.000000, reward total was -19.000000. running mean: -20.126606\n",
            "resetting env. episode 2095.000000, reward total was -21.000000. running mean: -20.135340\n",
            "resetting env. episode 2096.000000, reward total was -19.000000. running mean: -20.123987\n",
            "resetting env. episode 2097.000000, reward total was -20.000000. running mean: -20.122747\n",
            "resetting env. episode 2098.000000, reward total was -21.000000. running mean: -20.131519\n",
            "resetting env. episode 2099.000000, reward total was -20.000000. running mean: -20.130204\n",
            "resetting env. episode 2100.000000, reward total was -18.000000. running mean: -20.108902\n",
            "resetting env. episode 2101.000000, reward total was -21.000000. running mean: -20.117813\n",
            "resetting env. episode 2102.000000, reward total was -20.000000. running mean: -20.116635\n",
            "resetting env. episode 2103.000000, reward total was -21.000000. running mean: -20.125468\n",
            "resetting env. episode 2104.000000, reward total was -21.000000. running mean: -20.134214\n",
            "resetting env. episode 2105.000000, reward total was -19.000000. running mean: -20.122872\n",
            "resetting env. episode 2106.000000, reward total was -21.000000. running mean: -20.131643\n",
            "resetting env. episode 2107.000000, reward total was -20.000000. running mean: -20.130327\n",
            "resetting env. episode 2108.000000, reward total was -21.000000. running mean: -20.139023\n",
            "resetting env. episode 2109.000000, reward total was -21.000000. running mean: -20.147633\n",
            "resetting env. episode 2110.000000, reward total was -21.000000. running mean: -20.156157\n",
            "resetting env. episode 2111.000000, reward total was -20.000000. running mean: -20.154595\n",
            "resetting env. episode 2112.000000, reward total was -21.000000. running mean: -20.163049\n",
            "resetting env. episode 2113.000000, reward total was -20.000000. running mean: -20.161419\n",
            "resetting env. episode 2114.000000, reward total was -21.000000. running mean: -20.169804\n",
            "resetting env. episode 2115.000000, reward total was -20.000000. running mean: -20.168106\n",
            "resetting env. episode 2116.000000, reward total was -20.000000. running mean: -20.166425\n",
            "resetting env. episode 2117.000000, reward total was -20.000000. running mean: -20.164761\n",
            "resetting env. episode 2118.000000, reward total was -19.000000. running mean: -20.153114\n",
            "resetting env. episode 2119.000000, reward total was -21.000000. running mean: -20.161582\n",
            "resetting env. episode 2120.000000, reward total was -21.000000. running mean: -20.169967\n",
            "resetting env. episode 2121.000000, reward total was -19.000000. running mean: -20.158267\n",
            "resetting env. episode 2122.000000, reward total was -18.000000. running mean: -20.136684\n",
            "resetting env. episode 2123.000000, reward total was -21.000000. running mean: -20.145317\n",
            "resetting env. episode 2124.000000, reward total was -21.000000. running mean: -20.153864\n",
            "resetting env. episode 2125.000000, reward total was -19.000000. running mean: -20.142326\n",
            "resetting env. episode 2126.000000, reward total was -19.000000. running mean: -20.130902\n",
            "resetting env. episode 2127.000000, reward total was -20.000000. running mean: -20.129593\n",
            "resetting env. episode 2128.000000, reward total was -21.000000. running mean: -20.138297\n",
            "resetting env. episode 2129.000000, reward total was -19.000000. running mean: -20.126914\n",
            "resetting env. episode 2130.000000, reward total was -19.000000. running mean: -20.115645\n",
            "resetting env. episode 2131.000000, reward total was -20.000000. running mean: -20.114489\n",
            "resetting env. episode 2132.000000, reward total was -20.000000. running mean: -20.113344\n",
            "resetting env. episode 2133.000000, reward total was -20.000000. running mean: -20.112210\n",
            "resetting env. episode 2134.000000, reward total was -20.000000. running mean: -20.111088\n",
            "resetting env. episode 2135.000000, reward total was -19.000000. running mean: -20.099977\n",
            "resetting env. episode 2136.000000, reward total was -20.000000. running mean: -20.098978\n",
            "resetting env. episode 2137.000000, reward total was -21.000000. running mean: -20.107988\n",
            "resetting env. episode 2138.000000, reward total was -20.000000. running mean: -20.106908\n",
            "resetting env. episode 2139.000000, reward total was -21.000000. running mean: -20.115839\n",
            "resetting env. episode 2140.000000, reward total was -20.000000. running mean: -20.114681\n",
            "resetting env. episode 2141.000000, reward total was -21.000000. running mean: -20.123534\n",
            "resetting env. episode 2142.000000, reward total was -20.000000. running mean: -20.122298\n",
            "resetting env. episode 2143.000000, reward total was -21.000000. running mean: -20.131075\n",
            "resetting env. episode 2144.000000, reward total was -21.000000. running mean: -20.139765\n",
            "resetting env. episode 2145.000000, reward total was -18.000000. running mean: -20.118367\n",
            "resetting env. episode 2146.000000, reward total was -21.000000. running mean: -20.127183\n",
            "resetting env. episode 2147.000000, reward total was -21.000000. running mean: -20.135912\n",
            "resetting env. episode 2148.000000, reward total was -21.000000. running mean: -20.144552\n",
            "resetting env. episode 2149.000000, reward total was -21.000000. running mean: -20.153107\n",
            "resetting env. episode 2150.000000, reward total was -20.000000. running mean: -20.151576\n",
            "resetting env. episode 2151.000000, reward total was -21.000000. running mean: -20.160060\n",
            "resetting env. episode 2152.000000, reward total was -20.000000. running mean: -20.158459\n",
            "resetting env. episode 2153.000000, reward total was -20.000000. running mean: -20.156875\n",
            "resetting env. episode 2154.000000, reward total was -21.000000. running mean: -20.165306\n",
            "resetting env. episode 2155.000000, reward total was -21.000000. running mean: -20.173653\n",
            "resetting env. episode 2156.000000, reward total was -20.000000. running mean: -20.171917\n",
            "resetting env. episode 2157.000000, reward total was -21.000000. running mean: -20.180197\n",
            "resetting env. episode 2158.000000, reward total was -20.000000. running mean: -20.178395\n",
            "resetting env. episode 2159.000000, reward total was -19.000000. running mean: -20.166611\n",
            "resetting env. episode 2160.000000, reward total was -21.000000. running mean: -20.174945\n",
            "resetting env. episode 2161.000000, reward total was -20.000000. running mean: -20.173196\n",
            "resetting env. episode 2162.000000, reward total was -21.000000. running mean: -20.181464\n",
            "resetting env. episode 2163.000000, reward total was -20.000000. running mean: -20.179649\n",
            "resetting env. episode 2164.000000, reward total was -20.000000. running mean: -20.177853\n",
            "resetting env. episode 2165.000000, reward total was -21.000000. running mean: -20.186074\n",
            "resetting env. episode 2166.000000, reward total was -21.000000. running mean: -20.194214\n",
            "resetting env. episode 2167.000000, reward total was -20.000000. running mean: -20.192271\n",
            "resetting env. episode 2168.000000, reward total was -20.000000. running mean: -20.190349\n",
            "resetting env. episode 2169.000000, reward total was -21.000000. running mean: -20.198445\n",
            "resetting env. episode 2170.000000, reward total was -20.000000. running mean: -20.196461\n",
            "resetting env. episode 2171.000000, reward total was -20.000000. running mean: -20.194496\n",
            "resetting env. episode 2172.000000, reward total was -19.000000. running mean: -20.182551\n",
            "resetting env. episode 2173.000000, reward total was -21.000000. running mean: -20.190726\n",
            "resetting env. episode 2174.000000, reward total was -21.000000. running mean: -20.198818\n",
            "resetting env. episode 2175.000000, reward total was -20.000000. running mean: -20.196830\n",
            "resetting env. episode 2176.000000, reward total was -21.000000. running mean: -20.204862\n",
            "resetting env. episode 2177.000000, reward total was -21.000000. running mean: -20.212813\n",
            "resetting env. episode 2178.000000, reward total was -21.000000. running mean: -20.220685\n",
            "resetting env. episode 2179.000000, reward total was -21.000000. running mean: -20.228478\n",
            "resetting env. episode 2180.000000, reward total was -20.000000. running mean: -20.226194\n",
            "resetting env. episode 2181.000000, reward total was -21.000000. running mean: -20.233932\n",
            "resetting env. episode 2182.000000, reward total was -20.000000. running mean: -20.231592\n",
            "resetting env. episode 2183.000000, reward total was -21.000000. running mean: -20.239276\n",
            "resetting env. episode 2184.000000, reward total was -20.000000. running mean: -20.236884\n",
            "resetting env. episode 2185.000000, reward total was -19.000000. running mean: -20.224515\n",
            "resetting env. episode 2186.000000, reward total was -19.000000. running mean: -20.212270\n",
            "resetting env. episode 2187.000000, reward total was -20.000000. running mean: -20.210147\n",
            "resetting env. episode 2188.000000, reward total was -20.000000. running mean: -20.208045\n",
            "resetting env. episode 2189.000000, reward total was -21.000000. running mean: -20.215965\n",
            "resetting env. episode 2190.000000, reward total was -20.000000. running mean: -20.213805\n",
            "resetting env. episode 2191.000000, reward total was -17.000000. running mean: -20.181667\n",
            "resetting env. episode 2192.000000, reward total was -21.000000. running mean: -20.189851\n",
            "resetting env. episode 2193.000000, reward total was -20.000000. running mean: -20.187952\n",
            "resetting env. episode 2194.000000, reward total was -21.000000. running mean: -20.196073\n",
            "resetting env. episode 2195.000000, reward total was -19.000000. running mean: -20.184112\n",
            "resetting env. episode 2196.000000, reward total was -20.000000. running mean: -20.182271\n",
            "resetting env. episode 2197.000000, reward total was -21.000000. running mean: -20.190448\n",
            "resetting env. episode 2198.000000, reward total was -19.000000. running mean: -20.178544\n",
            "resetting env. episode 2199.000000, reward total was -20.000000. running mean: -20.176758\n",
            "resetting env. episode 2200.000000, reward total was -21.000000. running mean: -20.184991\n",
            "resetting env. episode 2201.000000, reward total was -21.000000. running mean: -20.193141\n",
            "resetting env. episode 2202.000000, reward total was -21.000000. running mean: -20.201209\n",
            "resetting env. episode 2203.000000, reward total was -21.000000. running mean: -20.209197\n",
            "resetting env. episode 2204.000000, reward total was -19.000000. running mean: -20.197105\n",
            "resetting env. episode 2205.000000, reward total was -19.000000. running mean: -20.185134\n",
            "resetting env. episode 2206.000000, reward total was -21.000000. running mean: -20.193283\n",
            "resetting env. episode 2207.000000, reward total was -21.000000. running mean: -20.201350\n",
            "resetting env. episode 2208.000000, reward total was -21.000000. running mean: -20.209336\n",
            "resetting env. episode 2209.000000, reward total was -20.000000. running mean: -20.207243\n",
            "resetting env. episode 2210.000000, reward total was -21.000000. running mean: -20.215171\n",
            "resetting env. episode 2211.000000, reward total was -19.000000. running mean: -20.203019\n",
            "resetting env. episode 2212.000000, reward total was -19.000000. running mean: -20.190989\n",
            "resetting env. episode 2213.000000, reward total was -21.000000. running mean: -20.199079\n",
            "resetting env. episode 2214.000000, reward total was -19.000000. running mean: -20.187088\n",
            "resetting env. episode 2215.000000, reward total was -19.000000. running mean: -20.175217\n",
            "resetting env. episode 2216.000000, reward total was -21.000000. running mean: -20.183465\n",
            "resetting env. episode 2217.000000, reward total was -21.000000. running mean: -20.191630\n",
            "resetting env. episode 2218.000000, reward total was -20.000000. running mean: -20.189714\n",
            "resetting env. episode 2219.000000, reward total was -21.000000. running mean: -20.197817\n",
            "resetting env. episode 2220.000000, reward total was -20.000000. running mean: -20.195839\n",
            "resetting env. episode 2221.000000, reward total was -20.000000. running mean: -20.193880\n",
            "resetting env. episode 2222.000000, reward total was -21.000000. running mean: -20.201942\n",
            "resetting env. episode 2223.000000, reward total was -21.000000. running mean: -20.209922\n",
            "resetting env. episode 2224.000000, reward total was -21.000000. running mean: -20.217823\n",
            "resetting env. episode 2225.000000, reward total was -20.000000. running mean: -20.215645\n",
            "resetting env. episode 2226.000000, reward total was -19.000000. running mean: -20.203488\n",
            "resetting env. episode 2227.000000, reward total was -17.000000. running mean: -20.171453\n",
            "resetting env. episode 2228.000000, reward total was -20.000000. running mean: -20.169739\n",
            "resetting env. episode 2229.000000, reward total was -19.000000. running mean: -20.158041\n",
            "resetting env. episode 2230.000000, reward total was -21.000000. running mean: -20.166461\n",
            "resetting env. episode 2231.000000, reward total was -18.000000. running mean: -20.144796\n",
            "resetting env. episode 2232.000000, reward total was -18.000000. running mean: -20.123348\n",
            "resetting env. episode 2233.000000, reward total was -21.000000. running mean: -20.132115\n",
            "resetting env. episode 2234.000000, reward total was -21.000000. running mean: -20.140794\n",
            "resetting env. episode 2235.000000, reward total was -21.000000. running mean: -20.149386\n",
            "resetting env. episode 2236.000000, reward total was -21.000000. running mean: -20.157892\n",
            "resetting env. episode 2237.000000, reward total was -21.000000. running mean: -20.166313\n",
            "resetting env. episode 2238.000000, reward total was -21.000000. running mean: -20.174650\n",
            "resetting env. episode 2239.000000, reward total was -21.000000. running mean: -20.182903\n",
            "resetting env. episode 2240.000000, reward total was -21.000000. running mean: -20.191074\n",
            "resetting env. episode 2241.000000, reward total was -20.000000. running mean: -20.189164\n",
            "resetting env. episode 2242.000000, reward total was -20.000000. running mean: -20.187272\n",
            "resetting env. episode 2243.000000, reward total was -20.000000. running mean: -20.185399\n",
            "resetting env. episode 2244.000000, reward total was -19.000000. running mean: -20.173545\n",
            "resetting env. episode 2245.000000, reward total was -21.000000. running mean: -20.181810\n",
            "resetting env. episode 2246.000000, reward total was -20.000000. running mean: -20.179992\n",
            "resetting env. episode 2247.000000, reward total was -21.000000. running mean: -20.188192\n",
            "resetting env. episode 2248.000000, reward total was -20.000000. running mean: -20.186310\n",
            "resetting env. episode 2249.000000, reward total was -21.000000. running mean: -20.194447\n",
            "resetting env. episode 2250.000000, reward total was -20.000000. running mean: -20.192502\n",
            "resetting env. episode 2251.000000, reward total was -20.000000. running mean: -20.190577\n",
            "resetting env. episode 2252.000000, reward total was -21.000000. running mean: -20.198672\n",
            "resetting env. episode 2253.000000, reward total was -21.000000. running mean: -20.206685\n",
            "resetting env. episode 2254.000000, reward total was -21.000000. running mean: -20.214618\n",
            "resetting env. episode 2255.000000, reward total was -17.000000. running mean: -20.182472\n",
            "resetting env. episode 2256.000000, reward total was -20.000000. running mean: -20.180647\n",
            "resetting env. episode 2257.000000, reward total was -21.000000. running mean: -20.188841\n",
            "resetting env. episode 2258.000000, reward total was -20.000000. running mean: -20.186952\n",
            "resetting env. episode 2259.000000, reward total was -18.000000. running mean: -20.165083\n",
            "resetting env. episode 2260.000000, reward total was -21.000000. running mean: -20.173432\n",
            "resetting env. episode 2261.000000, reward total was -21.000000. running mean: -20.181698\n",
            "resetting env. episode 2262.000000, reward total was -20.000000. running mean: -20.179881\n",
            "resetting env. episode 2263.000000, reward total was -21.000000. running mean: -20.188082\n",
            "resetting env. episode 2264.000000, reward total was -20.000000. running mean: -20.186201\n",
            "resetting env. episode 2265.000000, reward total was -21.000000. running mean: -20.194339\n",
            "resetting env. episode 2266.000000, reward total was -20.000000. running mean: -20.192396\n",
            "resetting env. episode 2267.000000, reward total was -20.000000. running mean: -20.190472\n",
            "resetting env. episode 2268.000000, reward total was -21.000000. running mean: -20.198567\n",
            "resetting env. episode 2269.000000, reward total was -20.000000. running mean: -20.196581\n",
            "resetting env. episode 2270.000000, reward total was -21.000000. running mean: -20.204615\n",
            "resetting env. episode 2271.000000, reward total was -19.000000. running mean: -20.192569\n",
            "resetting env. episode 2272.000000, reward total was -21.000000. running mean: -20.200644\n",
            "resetting env. episode 2273.000000, reward total was -20.000000. running mean: -20.198637\n",
            "resetting env. episode 2274.000000, reward total was -15.000000. running mean: -20.146651\n",
            "resetting env. episode 2275.000000, reward total was -21.000000. running mean: -20.155184\n",
            "resetting env. episode 2276.000000, reward total was -18.000000. running mean: -20.133632\n",
            "resetting env. episode 2277.000000, reward total was -21.000000. running mean: -20.142296\n",
            "resetting env. episode 2278.000000, reward total was -21.000000. running mean: -20.150873\n",
            "resetting env. episode 2279.000000, reward total was -21.000000. running mean: -20.159364\n",
            "resetting env. episode 2280.000000, reward total was -20.000000. running mean: -20.157771\n",
            "resetting env. episode 2281.000000, reward total was -21.000000. running mean: -20.166193\n",
            "resetting env. episode 2282.000000, reward total was -19.000000. running mean: -20.154531\n",
            "resetting env. episode 2283.000000, reward total was -19.000000. running mean: -20.142986\n",
            "resetting env. episode 2284.000000, reward total was -20.000000. running mean: -20.141556\n",
            "resetting env. episode 2285.000000, reward total was -21.000000. running mean: -20.150140\n",
            "resetting env. episode 2286.000000, reward total was -19.000000. running mean: -20.138639\n",
            "resetting env. episode 2287.000000, reward total was -20.000000. running mean: -20.137253\n",
            "resetting env. episode 2288.000000, reward total was -20.000000. running mean: -20.135880\n",
            "resetting env. episode 2289.000000, reward total was -21.000000. running mean: -20.144521\n",
            "resetting env. episode 2290.000000, reward total was -19.000000. running mean: -20.133076\n",
            "resetting env. episode 2291.000000, reward total was -20.000000. running mean: -20.131745\n",
            "resetting env. episode 2292.000000, reward total was -21.000000. running mean: -20.140428\n",
            "resetting env. episode 2293.000000, reward total was -21.000000. running mean: -20.149024\n",
            "resetting env. episode 2294.000000, reward total was -20.000000. running mean: -20.147533\n",
            "resetting env. episode 2295.000000, reward total was -20.000000. running mean: -20.146058\n",
            "resetting env. episode 2296.000000, reward total was -19.000000. running mean: -20.134597\n",
            "resetting env. episode 2297.000000, reward total was -21.000000. running mean: -20.143251\n",
            "resetting env. episode 2298.000000, reward total was -20.000000. running mean: -20.141819\n",
            "resetting env. episode 2299.000000, reward total was -20.000000. running mean: -20.140401\n",
            "resetting env. episode 2300.000000, reward total was -20.000000. running mean: -20.138997\n",
            "resetting env. episode 2301.000000, reward total was -20.000000. running mean: -20.137607\n",
            "resetting env. episode 2302.000000, reward total was -20.000000. running mean: -20.136231\n",
            "resetting env. episode 2303.000000, reward total was -20.000000. running mean: -20.134868\n",
            "resetting env. episode 2304.000000, reward total was -19.000000. running mean: -20.123520\n",
            "resetting env. episode 2305.000000, reward total was -20.000000. running mean: -20.122285\n",
            "resetting env. episode 2306.000000, reward total was -21.000000. running mean: -20.131062\n",
            "resetting env. episode 2307.000000, reward total was -21.000000. running mean: -20.139751\n",
            "resetting env. episode 2308.000000, reward total was -21.000000. running mean: -20.148354\n",
            "resetting env. episode 2309.000000, reward total was -21.000000. running mean: -20.156870\n",
            "resetting env. episode 2310.000000, reward total was -21.000000. running mean: -20.165301\n",
            "resetting env. episode 2311.000000, reward total was -20.000000. running mean: -20.163648\n",
            "resetting env. episode 2312.000000, reward total was -20.000000. running mean: -20.162012\n",
            "resetting env. episode 2313.000000, reward total was -21.000000. running mean: -20.170392\n",
            "resetting env. episode 2314.000000, reward total was -21.000000. running mean: -20.178688\n",
            "resetting env. episode 2315.000000, reward total was -18.000000. running mean: -20.156901\n",
            "resetting env. episode 2316.000000, reward total was -21.000000. running mean: -20.165332\n",
            "resetting env. episode 2317.000000, reward total was -19.000000. running mean: -20.153679\n",
            "resetting env. episode 2318.000000, reward total was -20.000000. running mean: -20.152142\n",
            "resetting env. episode 2319.000000, reward total was -20.000000. running mean: -20.150620\n",
            "resetting env. episode 2320.000000, reward total was -20.000000. running mean: -20.149114\n",
            "resetting env. episode 2321.000000, reward total was -19.000000. running mean: -20.137623\n",
            "resetting env. episode 2322.000000, reward total was -21.000000. running mean: -20.146247\n",
            "resetting env. episode 2323.000000, reward total was -21.000000. running mean: -20.154784\n",
            "resetting env. episode 2324.000000, reward total was -21.000000. running mean: -20.163236\n",
            "resetting env. episode 2325.000000, reward total was -20.000000. running mean: -20.161604\n",
            "resetting env. episode 2326.000000, reward total was -18.000000. running mean: -20.139988\n",
            "resetting env. episode 2327.000000, reward total was -20.000000. running mean: -20.138588\n",
            "resetting env. episode 2328.000000, reward total was -20.000000. running mean: -20.137202\n",
            "resetting env. episode 2329.000000, reward total was -20.000000. running mean: -20.135830\n",
            "resetting env. episode 2330.000000, reward total was -20.000000. running mean: -20.134472\n",
            "resetting env. episode 2331.000000, reward total was -21.000000. running mean: -20.143127\n",
            "resetting env. episode 2332.000000, reward total was -21.000000. running mean: -20.151696\n",
            "resetting env. episode 2333.000000, reward total was -20.000000. running mean: -20.150179\n",
            "resetting env. episode 2334.000000, reward total was -20.000000. running mean: -20.148677\n",
            "resetting env. episode 2335.000000, reward total was -19.000000. running mean: -20.137190\n",
            "resetting env. episode 2336.000000, reward total was -19.000000. running mean: -20.125819\n",
            "resetting env. episode 2337.000000, reward total was -18.000000. running mean: -20.104560\n",
            "resetting env. episode 2338.000000, reward total was -20.000000. running mean: -20.103515\n",
            "resetting env. episode 2339.000000, reward total was -20.000000. running mean: -20.102480\n",
            "resetting env. episode 2340.000000, reward total was -21.000000. running mean: -20.111455\n",
            "resetting env. episode 2341.000000, reward total was -21.000000. running mean: -20.120340\n",
            "resetting env. episode 2342.000000, reward total was -20.000000. running mean: -20.119137\n",
            "resetting env. episode 2343.000000, reward total was -20.000000. running mean: -20.117946\n",
            "resetting env. episode 2344.000000, reward total was -21.000000. running mean: -20.126766\n",
            "resetting env. episode 2345.000000, reward total was -20.000000. running mean: -20.125498\n",
            "resetting env. episode 2346.000000, reward total was -21.000000. running mean: -20.134243\n",
            "resetting env. episode 2347.000000, reward total was -21.000000. running mean: -20.142901\n",
            "resetting env. episode 2348.000000, reward total was -21.000000. running mean: -20.151472\n",
            "resetting env. episode 2349.000000, reward total was -21.000000. running mean: -20.159957\n",
            "resetting env. episode 2350.000000, reward total was -17.000000. running mean: -20.128358\n",
            "resetting env. episode 2351.000000, reward total was -21.000000. running mean: -20.137074\n",
            "resetting env. episode 2352.000000, reward total was -20.000000. running mean: -20.135703\n",
            "resetting env. episode 2353.000000, reward total was -21.000000. running mean: -20.144346\n",
            "resetting env. episode 2354.000000, reward total was -21.000000. running mean: -20.152903\n",
            "resetting env. episode 2355.000000, reward total was -21.000000. running mean: -20.161374\n",
            "resetting env. episode 2356.000000, reward total was -20.000000. running mean: -20.159760\n",
            "resetting env. episode 2357.000000, reward total was -21.000000. running mean: -20.168162\n",
            "resetting env. episode 2358.000000, reward total was -20.000000. running mean: -20.166481\n",
            "resetting env. episode 2359.000000, reward total was -20.000000. running mean: -20.164816\n",
            "resetting env. episode 2360.000000, reward total was -19.000000. running mean: -20.153168\n",
            "resetting env. episode 2361.000000, reward total was -21.000000. running mean: -20.161636\n",
            "resetting env. episode 2362.000000, reward total was -19.000000. running mean: -20.150020\n",
            "resetting env. episode 2363.000000, reward total was -21.000000. running mean: -20.158520\n",
            "resetting env. episode 2364.000000, reward total was -21.000000. running mean: -20.166934\n",
            "resetting env. episode 2365.000000, reward total was -21.000000. running mean: -20.175265\n",
            "resetting env. episode 2366.000000, reward total was -21.000000. running mean: -20.183512\n",
            "resetting env. episode 2367.000000, reward total was -20.000000. running mean: -20.181677\n",
            "resetting env. episode 2368.000000, reward total was -21.000000. running mean: -20.189861\n",
            "resetting env. episode 2369.000000, reward total was -21.000000. running mean: -20.197962\n",
            "resetting env. episode 2370.000000, reward total was -18.000000. running mean: -20.175982\n",
            "resetting env. episode 2371.000000, reward total was -19.000000. running mean: -20.164223\n",
            "resetting env. episode 2372.000000, reward total was -21.000000. running mean: -20.172580\n",
            "resetting env. episode 2373.000000, reward total was -20.000000. running mean: -20.170854\n",
            "resetting env. episode 2374.000000, reward total was -21.000000. running mean: -20.179146\n",
            "resetting env. episode 2375.000000, reward total was -20.000000. running mean: -20.177354\n",
            "resetting env. episode 2376.000000, reward total was -19.000000. running mean: -20.165581\n",
            "resetting env. episode 2377.000000, reward total was -21.000000. running mean: -20.173925\n",
            "resetting env. episode 2378.000000, reward total was -18.000000. running mean: -20.152186\n",
            "resetting env. episode 2379.000000, reward total was -21.000000. running mean: -20.160664\n",
            "resetting env. episode 2380.000000, reward total was -20.000000. running mean: -20.159057\n",
            "resetting env. episode 2381.000000, reward total was -20.000000. running mean: -20.157467\n",
            "resetting env. episode 2382.000000, reward total was -21.000000. running mean: -20.165892\n",
            "resetting env. episode 2383.000000, reward total was -20.000000. running mean: -20.164233\n",
            "resetting env. episode 2384.000000, reward total was -21.000000. running mean: -20.172591\n",
            "resetting env. episode 2385.000000, reward total was -21.000000. running mean: -20.180865\n",
            "resetting env. episode 2386.000000, reward total was -20.000000. running mean: -20.179056\n",
            "resetting env. episode 2387.000000, reward total was -21.000000. running mean: -20.187266\n",
            "resetting env. episode 2388.000000, reward total was -21.000000. running mean: -20.195393\n",
            "resetting env. episode 2389.000000, reward total was -18.000000. running mean: -20.173439\n",
            "resetting env. episode 2390.000000, reward total was -21.000000. running mean: -20.181705\n",
            "resetting env. episode 2391.000000, reward total was -20.000000. running mean: -20.179888\n",
            "resetting env. episode 2392.000000, reward total was -18.000000. running mean: -20.158089\n",
            "resetting env. episode 2393.000000, reward total was -18.000000. running mean: -20.136508\n",
            "resetting env. episode 2394.000000, reward total was -20.000000. running mean: -20.135143\n",
            "resetting env. episode 2395.000000, reward total was -20.000000. running mean: -20.133791\n",
            "resetting env. episode 2396.000000, reward total was -17.000000. running mean: -20.102454\n",
            "resetting env. episode 2397.000000, reward total was -20.000000. running mean: -20.101429\n",
            "resetting env. episode 2398.000000, reward total was -21.000000. running mean: -20.110415\n",
            "resetting env. episode 2399.000000, reward total was -18.000000. running mean: -20.089311\n",
            "resetting env. episode 2400.000000, reward total was -21.000000. running mean: -20.098417\n",
            "resetting env. episode 2401.000000, reward total was -20.000000. running mean: -20.097433\n",
            "resetting env. episode 2402.000000, reward total was -19.000000. running mean: -20.086459\n",
            "resetting env. episode 2403.000000, reward total was -20.000000. running mean: -20.085594\n",
            "resetting env. episode 2404.000000, reward total was -20.000000. running mean: -20.084738\n",
            "resetting env. episode 2405.000000, reward total was -19.000000. running mean: -20.073891\n",
            "resetting env. episode 2406.000000, reward total was -21.000000. running mean: -20.083152\n",
            "resetting env. episode 2407.000000, reward total was -20.000000. running mean: -20.082321\n",
            "resetting env. episode 2408.000000, reward total was -20.000000. running mean: -20.081497\n",
            "resetting env. episode 2409.000000, reward total was -21.000000. running mean: -20.090682\n",
            "resetting env. episode 2410.000000, reward total was -20.000000. running mean: -20.089776\n",
            "resetting env. episode 2411.000000, reward total was -20.000000. running mean: -20.088878\n",
            "resetting env. episode 2412.000000, reward total was -21.000000. running mean: -20.097989\n",
            "resetting env. episode 2413.000000, reward total was -20.000000. running mean: -20.097009\n",
            "resetting env. episode 2414.000000, reward total was -21.000000. running mean: -20.106039\n",
            "resetting env. episode 2415.000000, reward total was -19.000000. running mean: -20.094979\n",
            "resetting env. episode 2416.000000, reward total was -19.000000. running mean: -20.084029\n",
            "resetting env. episode 2417.000000, reward total was -21.000000. running mean: -20.093189\n",
            "resetting env. episode 2418.000000, reward total was -21.000000. running mean: -20.102257\n",
            "resetting env. episode 2419.000000, reward total was -20.000000. running mean: -20.101234\n",
            "resetting env. episode 2420.000000, reward total was -20.000000. running mean: -20.100222\n",
            "resetting env. episode 2421.000000, reward total was -19.000000. running mean: -20.089220\n",
            "resetting env. episode 2422.000000, reward total was -20.000000. running mean: -20.088327\n",
            "resetting env. episode 2423.000000, reward total was -19.000000. running mean: -20.077444\n",
            "resetting env. episode 2424.000000, reward total was -21.000000. running mean: -20.086670\n",
            "resetting env. episode 2425.000000, reward total was -20.000000. running mean: -20.085803\n",
            "resetting env. episode 2426.000000, reward total was -21.000000. running mean: -20.094945\n",
            "resetting env. episode 2427.000000, reward total was -19.000000. running mean: -20.083996\n",
            "resetting env. episode 2428.000000, reward total was -20.000000. running mean: -20.083156\n",
            "resetting env. episode 2429.000000, reward total was -21.000000. running mean: -20.092324\n",
            "resetting env. episode 2430.000000, reward total was -19.000000. running mean: -20.081401\n",
            "resetting env. episode 2431.000000, reward total was -19.000000. running mean: -20.070587\n",
            "resetting env. episode 2432.000000, reward total was -20.000000. running mean: -20.069881\n",
            "resetting env. episode 2433.000000, reward total was -21.000000. running mean: -20.079182\n",
            "resetting env. episode 2434.000000, reward total was -20.000000. running mean: -20.078390\n",
            "resetting env. episode 2435.000000, reward total was -20.000000. running mean: -20.077606\n",
            "resetting env. episode 2436.000000, reward total was -20.000000. running mean: -20.076830\n",
            "resetting env. episode 2437.000000, reward total was -20.000000. running mean: -20.076062\n",
            "resetting env. episode 2438.000000, reward total was -20.000000. running mean: -20.075301\n",
            "resetting env. episode 2439.000000, reward total was -21.000000. running mean: -20.084548\n",
            "resetting env. episode 2440.000000, reward total was -20.000000. running mean: -20.083703\n",
            "resetting env. episode 2441.000000, reward total was -20.000000. running mean: -20.082866\n",
            "resetting env. episode 2442.000000, reward total was -21.000000. running mean: -20.092037\n",
            "resetting env. episode 2443.000000, reward total was -20.000000. running mean: -20.091117\n",
            "resetting env. episode 2444.000000, reward total was -21.000000. running mean: -20.100206\n",
            "resetting env. episode 2445.000000, reward total was -21.000000. running mean: -20.109204\n",
            "resetting env. episode 2446.000000, reward total was -20.000000. running mean: -20.108112\n",
            "resetting env. episode 2447.000000, reward total was -20.000000. running mean: -20.107030\n",
            "resetting env. episode 2448.000000, reward total was -19.000000. running mean: -20.095960\n",
            "resetting env. episode 2449.000000, reward total was -20.000000. running mean: -20.095001\n",
            "resetting env. episode 2450.000000, reward total was -21.000000. running mean: -20.104051\n",
            "resetting env. episode 2451.000000, reward total was -21.000000. running mean: -20.113010\n",
            "resetting env. episode 2452.000000, reward total was -20.000000. running mean: -20.111880\n",
            "resetting env. episode 2453.000000, reward total was -21.000000. running mean: -20.120761\n",
            "resetting env. episode 2454.000000, reward total was -19.000000. running mean: -20.109554\n",
            "resetting env. episode 2455.000000, reward total was -19.000000. running mean: -20.098458\n",
            "resetting env. episode 2456.000000, reward total was -21.000000. running mean: -20.107473\n",
            "resetting env. episode 2457.000000, reward total was -20.000000. running mean: -20.106399\n",
            "resetting env. episode 2458.000000, reward total was -21.000000. running mean: -20.115335\n",
            "resetting env. episode 2459.000000, reward total was -20.000000. running mean: -20.114181\n",
            "resetting env. episode 2460.000000, reward total was -19.000000. running mean: -20.103040\n",
            "resetting env. episode 2461.000000, reward total was -20.000000. running mean: -20.102009\n",
            "resetting env. episode 2462.000000, reward total was -20.000000. running mean: -20.100989\n",
            "resetting env. episode 2463.000000, reward total was -19.000000. running mean: -20.089979\n",
            "resetting env. episode 2464.000000, reward total was -20.000000. running mean: -20.089079\n",
            "resetting env. episode 2465.000000, reward total was -21.000000. running mean: -20.098189\n",
            "resetting env. episode 2466.000000, reward total was -21.000000. running mean: -20.107207\n",
            "resetting env. episode 2467.000000, reward total was -19.000000. running mean: -20.096135\n",
            "resetting env. episode 2468.000000, reward total was -21.000000. running mean: -20.105173\n",
            "resetting env. episode 2469.000000, reward total was -20.000000. running mean: -20.104122\n",
            "resetting env. episode 2470.000000, reward total was -19.000000. running mean: -20.093080\n",
            "resetting env. episode 2471.000000, reward total was -19.000000. running mean: -20.082150\n",
            "resetting env. episode 2472.000000, reward total was -19.000000. running mean: -20.071328\n",
            "resetting env. episode 2473.000000, reward total was -21.000000. running mean: -20.080615\n",
            "resetting env. episode 2474.000000, reward total was -21.000000. running mean: -20.089809\n",
            "resetting env. episode 2475.000000, reward total was -21.000000. running mean: -20.098910\n",
            "resetting env. episode 2476.000000, reward total was -17.000000. running mean: -20.067921\n",
            "resetting env. episode 2477.000000, reward total was -20.000000. running mean: -20.067242\n",
            "resetting env. episode 2478.000000, reward total was -21.000000. running mean: -20.076570\n",
            "resetting env. episode 2479.000000, reward total was -21.000000. running mean: -20.085804\n",
            "resetting env. episode 2480.000000, reward total was -21.000000. running mean: -20.094946\n",
            "resetting env. episode 2481.000000, reward total was -20.000000. running mean: -20.093997\n",
            "resetting env. episode 2482.000000, reward total was -19.000000. running mean: -20.083057\n",
            "resetting env. episode 2483.000000, reward total was -21.000000. running mean: -20.092226\n",
            "resetting env. episode 2484.000000, reward total was -21.000000. running mean: -20.101304\n",
            "resetting env. episode 2485.000000, reward total was -21.000000. running mean: -20.110291\n",
            "resetting env. episode 2486.000000, reward total was -20.000000. running mean: -20.109188\n",
            "resetting env. episode 2487.000000, reward total was -21.000000. running mean: -20.118096\n",
            "resetting env. episode 2488.000000, reward total was -20.000000. running mean: -20.116915\n",
            "resetting env. episode 2489.000000, reward total was -21.000000. running mean: -20.125746\n",
            "resetting env. episode 2490.000000, reward total was -19.000000. running mean: -20.114488\n",
            "resetting env. episode 2491.000000, reward total was -21.000000. running mean: -20.123343\n",
            "resetting env. episode 2492.000000, reward total was -19.000000. running mean: -20.112110\n",
            "resetting env. episode 2493.000000, reward total was -21.000000. running mean: -20.120989\n",
            "resetting env. episode 2494.000000, reward total was -20.000000. running mean: -20.119779\n",
            "resetting env. episode 2495.000000, reward total was -19.000000. running mean: -20.108581\n",
            "resetting env. episode 2496.000000, reward total was -19.000000. running mean: -20.097495\n",
            "resetting env. episode 2497.000000, reward total was -21.000000. running mean: -20.106521\n",
            "resetting env. episode 2498.000000, reward total was -21.000000. running mean: -20.115455\n",
            "resetting env. episode 2499.000000, reward total was -20.000000. running mean: -20.114301\n",
            "resetting env. episode 2500.000000, reward total was -20.000000. running mean: -20.113158\n",
            "resetting env. episode 2501.000000, reward total was -20.000000. running mean: -20.112026\n",
            "resetting env. episode 2502.000000, reward total was -20.000000. running mean: -20.110906\n",
            "resetting env. episode 2503.000000, reward total was -21.000000. running mean: -20.119797\n",
            "resetting env. episode 2504.000000, reward total was -20.000000. running mean: -20.118599\n",
            "resetting env. episode 2505.000000, reward total was -21.000000. running mean: -20.127413\n",
            "resetting env. episode 2506.000000, reward total was -21.000000. running mean: -20.136139\n",
            "resetting env. episode 2507.000000, reward total was -21.000000. running mean: -20.144777\n",
            "resetting env. episode 2508.000000, reward total was -19.000000. running mean: -20.133330\n",
            "resetting env. episode 2509.000000, reward total was -20.000000. running mean: -20.131996\n",
            "resetting env. episode 2510.000000, reward total was -20.000000. running mean: -20.130676\n",
            "resetting env. episode 2511.000000, reward total was -21.000000. running mean: -20.139370\n",
            "resetting env. episode 2512.000000, reward total was -21.000000. running mean: -20.147976\n",
            "resetting env. episode 2513.000000, reward total was -20.000000. running mean: -20.146496\n",
            "resetting env. episode 2514.000000, reward total was -20.000000. running mean: -20.145031\n",
            "resetting env. episode 2515.000000, reward total was -21.000000. running mean: -20.153581\n",
            "resetting env. episode 2516.000000, reward total was -20.000000. running mean: -20.152045\n",
            "resetting env. episode 2517.000000, reward total was -21.000000. running mean: -20.160525\n",
            "resetting env. episode 2518.000000, reward total was -20.000000. running mean: -20.158919\n",
            "resetting env. episode 2519.000000, reward total was -21.000000. running mean: -20.167330\n",
            "resetting env. episode 2520.000000, reward total was -20.000000. running mean: -20.165657\n",
            "resetting env. episode 2521.000000, reward total was -21.000000. running mean: -20.174000\n",
            "resetting env. episode 2522.000000, reward total was -18.000000. running mean: -20.152260\n",
            "resetting env. episode 2523.000000, reward total was -21.000000. running mean: -20.160738\n",
            "resetting env. episode 2524.000000, reward total was -21.000000. running mean: -20.169130\n",
            "resetting env. episode 2525.000000, reward total was -21.000000. running mean: -20.177439\n",
            "resetting env. episode 2526.000000, reward total was -21.000000. running mean: -20.185665\n",
            "resetting env. episode 2527.000000, reward total was -20.000000. running mean: -20.183808\n",
            "resetting env. episode 2528.000000, reward total was -19.000000. running mean: -20.171970\n",
            "resetting env. episode 2529.000000, reward total was -20.000000. running mean: -20.170250\n",
            "resetting env. episode 2530.000000, reward total was -21.000000. running mean: -20.178548\n",
            "resetting env. episode 2531.000000, reward total was -21.000000. running mean: -20.186762\n",
            "resetting env. episode 2532.000000, reward total was -21.000000. running mean: -20.194895\n",
            "resetting env. episode 2533.000000, reward total was -20.000000. running mean: -20.192946\n",
            "resetting env. episode 2534.000000, reward total was -21.000000. running mean: -20.201016\n",
            "resetting env. episode 2535.000000, reward total was -20.000000. running mean: -20.199006\n",
            "resetting env. episode 2536.000000, reward total was -21.000000. running mean: -20.207016\n",
            "resetting env. episode 2537.000000, reward total was -21.000000. running mean: -20.214946\n",
            "resetting env. episode 2538.000000, reward total was -20.000000. running mean: -20.212796\n",
            "resetting env. episode 2539.000000, reward total was -18.000000. running mean: -20.190668\n",
            "resetting env. episode 2540.000000, reward total was -21.000000. running mean: -20.198762\n",
            "resetting env. episode 2541.000000, reward total was -20.000000. running mean: -20.196774\n",
            "resetting env. episode 2542.000000, reward total was -20.000000. running mean: -20.194806\n",
            "resetting env. episode 2543.000000, reward total was -20.000000. running mean: -20.192858\n",
            "resetting env. episode 2544.000000, reward total was -20.000000. running mean: -20.190930\n",
            "resetting env. episode 2545.000000, reward total was -19.000000. running mean: -20.179020\n",
            "resetting env. episode 2546.000000, reward total was -19.000000. running mean: -20.167230\n",
            "resetting env. episode 2547.000000, reward total was -19.000000. running mean: -20.155558\n",
            "resetting env. episode 2548.000000, reward total was -20.000000. running mean: -20.154002\n",
            "resetting env. episode 2549.000000, reward total was -20.000000. running mean: -20.152462\n",
            "resetting env. episode 2550.000000, reward total was -21.000000. running mean: -20.160938\n",
            "resetting env. episode 2551.000000, reward total was -20.000000. running mean: -20.159328\n",
            "resetting env. episode 2552.000000, reward total was -21.000000. running mean: -20.167735\n",
            "resetting env. episode 2553.000000, reward total was -18.000000. running mean: -20.146058\n",
            "resetting env. episode 2554.000000, reward total was -20.000000. running mean: -20.144597\n",
            "resetting env. episode 2555.000000, reward total was -20.000000. running mean: -20.143151\n",
            "resetting env. episode 2556.000000, reward total was -21.000000. running mean: -20.151720\n",
            "resetting env. episode 2557.000000, reward total was -21.000000. running mean: -20.160202\n",
            "resetting env. episode 2558.000000, reward total was -21.000000. running mean: -20.168600\n",
            "resetting env. episode 2559.000000, reward total was -21.000000. running mean: -20.176914\n",
            "resetting env. episode 2560.000000, reward total was -19.000000. running mean: -20.165145\n",
            "resetting env. episode 2561.000000, reward total was -21.000000. running mean: -20.173494\n",
            "resetting env. episode 2562.000000, reward total was -19.000000. running mean: -20.161759\n",
            "resetting env. episode 2563.000000, reward total was -20.000000. running mean: -20.160141\n",
            "resetting env. episode 2564.000000, reward total was -20.000000. running mean: -20.158540\n",
            "resetting env. episode 2565.000000, reward total was -21.000000. running mean: -20.166954\n",
            "resetting env. episode 2566.000000, reward total was -21.000000. running mean: -20.175285\n",
            "resetting env. episode 2567.000000, reward total was -21.000000. running mean: -20.183532\n",
            "resetting env. episode 2568.000000, reward total was -21.000000. running mean: -20.191697\n",
            "resetting env. episode 2569.000000, reward total was -21.000000. running mean: -20.199780\n",
            "resetting env. episode 2570.000000, reward total was -21.000000. running mean: -20.207782\n",
            "resetting env. episode 2571.000000, reward total was -21.000000. running mean: -20.215704\n",
            "resetting env. episode 2572.000000, reward total was -18.000000. running mean: -20.193547\n",
            "resetting env. episode 2573.000000, reward total was -18.000000. running mean: -20.171612\n",
            "resetting env. episode 2574.000000, reward total was -20.000000. running mean: -20.169896\n",
            "resetting env. episode 2575.000000, reward total was -21.000000. running mean: -20.178197\n",
            "resetting env. episode 2576.000000, reward total was -18.000000. running mean: -20.156415\n",
            "resetting env. episode 2577.000000, reward total was -20.000000. running mean: -20.154850\n",
            "resetting env. episode 2578.000000, reward total was -20.000000. running mean: -20.153302\n",
            "resetting env. episode 2579.000000, reward total was -21.000000. running mean: -20.161769\n",
            "resetting env. episode 2580.000000, reward total was -21.000000. running mean: -20.170151\n",
            "resetting env. episode 2581.000000, reward total was -21.000000. running mean: -20.178450\n",
            "resetting env. episode 2582.000000, reward total was -20.000000. running mean: -20.176665\n",
            "resetting env. episode 2583.000000, reward total was -20.000000. running mean: -20.174899\n",
            "resetting env. episode 2584.000000, reward total was -18.000000. running mean: -20.153150\n",
            "resetting env. episode 2585.000000, reward total was -20.000000. running mean: -20.151618\n",
            "resetting env. episode 2586.000000, reward total was -21.000000. running mean: -20.160102\n",
            "resetting env. episode 2587.000000, reward total was -21.000000. running mean: -20.168501\n",
            "resetting env. episode 2588.000000, reward total was -20.000000. running mean: -20.166816\n",
            "resetting env. episode 2589.000000, reward total was -20.000000. running mean: -20.165148\n",
            "resetting env. episode 2590.000000, reward total was -20.000000. running mean: -20.163496\n",
            "resetting env. episode 2591.000000, reward total was -21.000000. running mean: -20.171861\n",
            "resetting env. episode 2592.000000, reward total was -19.000000. running mean: -20.160143\n",
            "resetting env. episode 2593.000000, reward total was -21.000000. running mean: -20.168541\n",
            "resetting env. episode 2594.000000, reward total was -19.000000. running mean: -20.156856\n",
            "resetting env. episode 2595.000000, reward total was -21.000000. running mean: -20.165287\n",
            "resetting env. episode 2596.000000, reward total was -19.000000. running mean: -20.153634\n",
            "resetting env. episode 2597.000000, reward total was -21.000000. running mean: -20.162098\n",
            "resetting env. episode 2598.000000, reward total was -21.000000. running mean: -20.170477\n",
            "resetting env. episode 2599.000000, reward total was -20.000000. running mean: -20.168772\n",
            "resetting env. episode 2600.000000, reward total was -21.000000. running mean: -20.177085\n",
            "resetting env. episode 2601.000000, reward total was -21.000000. running mean: -20.185314\n",
            "resetting env. episode 2602.000000, reward total was -21.000000. running mean: -20.193461\n",
            "resetting env. episode 2603.000000, reward total was -21.000000. running mean: -20.201526\n",
            "resetting env. episode 2604.000000, reward total was -20.000000. running mean: -20.199511\n",
            "resetting env. episode 2605.000000, reward total was -18.000000. running mean: -20.177516\n",
            "resetting env. episode 2606.000000, reward total was -21.000000. running mean: -20.185740\n",
            "resetting env. episode 2607.000000, reward total was -18.000000. running mean: -20.163883\n",
            "resetting env. episode 2608.000000, reward total was -20.000000. running mean: -20.162244\n",
            "resetting env. episode 2609.000000, reward total was -21.000000. running mean: -20.170622\n",
            "resetting env. episode 2610.000000, reward total was -20.000000. running mean: -20.168916\n",
            "resetting env. episode 2611.000000, reward total was -17.000000. running mean: -20.137226\n",
            "resetting env. episode 2612.000000, reward total was -21.000000. running mean: -20.145854\n",
            "resetting env. episode 2613.000000, reward total was -21.000000. running mean: -20.154396\n",
            "resetting env. episode 2614.000000, reward total was -20.000000. running mean: -20.152852\n",
            "resetting env. episode 2615.000000, reward total was -20.000000. running mean: -20.151323\n",
            "resetting env. episode 2616.000000, reward total was -19.000000. running mean: -20.139810\n",
            "resetting env. episode 2617.000000, reward total was -19.000000. running mean: -20.128412\n",
            "resetting env. episode 2618.000000, reward total was -21.000000. running mean: -20.137128\n",
            "resetting env. episode 2619.000000, reward total was -21.000000. running mean: -20.145756\n",
            "resetting env. episode 2620.000000, reward total was -21.000000. running mean: -20.154299\n",
            "resetting env. episode 2621.000000, reward total was -20.000000. running mean: -20.152756\n",
            "resetting env. episode 2622.000000, reward total was -21.000000. running mean: -20.161228\n",
            "resetting env. episode 2623.000000, reward total was -20.000000. running mean: -20.159616\n",
            "resetting env. episode 2624.000000, reward total was -21.000000. running mean: -20.168020\n",
            "resetting env. episode 2625.000000, reward total was -21.000000. running mean: -20.176340\n",
            "resetting env. episode 2626.000000, reward total was -20.000000. running mean: -20.174576\n",
            "resetting env. episode 2627.000000, reward total was -20.000000. running mean: -20.172830\n",
            "resetting env. episode 2628.000000, reward total was -18.000000. running mean: -20.151102\n",
            "resetting env. episode 2629.000000, reward total was -19.000000. running mean: -20.139591\n",
            "resetting env. episode 2630.000000, reward total was -21.000000. running mean: -20.148195\n",
            "resetting env. episode 2631.000000, reward total was -21.000000. running mean: -20.156713\n",
            "resetting env. episode 2632.000000, reward total was -19.000000. running mean: -20.145146\n",
            "resetting env. episode 2633.000000, reward total was -21.000000. running mean: -20.153695\n",
            "resetting env. episode 2634.000000, reward total was -21.000000. running mean: -20.162158\n",
            "resetting env. episode 2635.000000, reward total was -20.000000. running mean: -20.160536\n",
            "resetting env. episode 2636.000000, reward total was -21.000000. running mean: -20.168931\n",
            "resetting env. episode 2637.000000, reward total was -21.000000. running mean: -20.177242\n",
            "resetting env. episode 2638.000000, reward total was -20.000000. running mean: -20.175469\n",
            "resetting env. episode 2639.000000, reward total was -21.000000. running mean: -20.183714\n",
            "resetting env. episode 2640.000000, reward total was -18.000000. running mean: -20.161877\n",
            "resetting env. episode 2641.000000, reward total was -19.000000. running mean: -20.150258\n",
            "resetting env. episode 2642.000000, reward total was -20.000000. running mean: -20.148756\n",
            "resetting env. episode 2643.000000, reward total was -21.000000. running mean: -20.157268\n",
            "resetting env. episode 2644.000000, reward total was -18.000000. running mean: -20.135696\n",
            "resetting env. episode 2645.000000, reward total was -19.000000. running mean: -20.124339\n",
            "resetting env. episode 2646.000000, reward total was -20.000000. running mean: -20.123095\n",
            "resetting env. episode 2647.000000, reward total was -20.000000. running mean: -20.121864\n",
            "resetting env. episode 2648.000000, reward total was -21.000000. running mean: -20.130646\n",
            "resetting env. episode 2649.000000, reward total was -21.000000. running mean: -20.139339\n",
            "resetting env. episode 2650.000000, reward total was -21.000000. running mean: -20.147946\n",
            "resetting env. episode 2651.000000, reward total was -20.000000. running mean: -20.146466\n",
            "resetting env. episode 2652.000000, reward total was -18.000000. running mean: -20.125002\n",
            "resetting env. episode 2653.000000, reward total was -21.000000. running mean: -20.133752\n",
            "resetting env. episode 2654.000000, reward total was -20.000000. running mean: -20.132414\n",
            "resetting env. episode 2655.000000, reward total was -20.000000. running mean: -20.131090\n",
            "resetting env. episode 2656.000000, reward total was -20.000000. running mean: -20.129779\n",
            "resetting env. episode 2657.000000, reward total was -21.000000. running mean: -20.138481\n",
            "resetting env. episode 2658.000000, reward total was -20.000000. running mean: -20.137097\n",
            "resetting env. episode 2659.000000, reward total was -21.000000. running mean: -20.145726\n",
            "resetting env. episode 2660.000000, reward total was -19.000000. running mean: -20.134268\n",
            "resetting env. episode 2661.000000, reward total was -21.000000. running mean: -20.142926\n",
            "resetting env. episode 2662.000000, reward total was -20.000000. running mean: -20.141496\n",
            "resetting env. episode 2663.000000, reward total was -19.000000. running mean: -20.130081\n",
            "resetting env. episode 2664.000000, reward total was -20.000000. running mean: -20.128781\n",
            "resetting env. episode 2665.000000, reward total was -20.000000. running mean: -20.127493\n",
            "resetting env. episode 2666.000000, reward total was -21.000000. running mean: -20.136218\n",
            "resetting env. episode 2667.000000, reward total was -20.000000. running mean: -20.134856\n",
            "resetting env. episode 2668.000000, reward total was -20.000000. running mean: -20.133507\n",
            "resetting env. episode 2669.000000, reward total was -19.000000. running mean: -20.122172\n",
            "resetting env. episode 2670.000000, reward total was -21.000000. running mean: -20.130950\n",
            "resetting env. episode 2671.000000, reward total was -21.000000. running mean: -20.139641\n",
            "resetting env. episode 2672.000000, reward total was -17.000000. running mean: -20.108244\n",
            "resetting env. episode 2673.000000, reward total was -21.000000. running mean: -20.117162\n",
            "resetting env. episode 2674.000000, reward total was -21.000000. running mean: -20.125990\n",
            "resetting env. episode 2675.000000, reward total was -21.000000. running mean: -20.134730\n",
            "resetting env. episode 2676.000000, reward total was -21.000000. running mean: -20.143383\n",
            "resetting env. episode 2677.000000, reward total was -20.000000. running mean: -20.141949\n",
            "resetting env. episode 2678.000000, reward total was -20.000000. running mean: -20.140530\n",
            "resetting env. episode 2679.000000, reward total was -18.000000. running mean: -20.119125\n",
            "resetting env. episode 2680.000000, reward total was -20.000000. running mean: -20.117933\n",
            "resetting env. episode 2681.000000, reward total was -21.000000. running mean: -20.126754\n",
            "resetting env. episode 2682.000000, reward total was -18.000000. running mean: -20.105486\n",
            "resetting env. episode 2683.000000, reward total was -21.000000. running mean: -20.114432\n",
            "resetting env. episode 2684.000000, reward total was -18.000000. running mean: -20.093287\n",
            "resetting env. episode 2685.000000, reward total was -21.000000. running mean: -20.102354\n",
            "resetting env. episode 2686.000000, reward total was -20.000000. running mean: -20.101331\n",
            "resetting env. episode 2687.000000, reward total was -20.000000. running mean: -20.100318\n",
            "resetting env. episode 2688.000000, reward total was -19.000000. running mean: -20.089314\n",
            "resetting env. episode 2689.000000, reward total was -20.000000. running mean: -20.088421\n",
            "resetting env. episode 2690.000000, reward total was -20.000000. running mean: -20.087537\n",
            "resetting env. episode 2691.000000, reward total was -21.000000. running mean: -20.096662\n",
            "resetting env. episode 2692.000000, reward total was -21.000000. running mean: -20.105695\n",
            "resetting env. episode 2693.000000, reward total was -19.000000. running mean: -20.094638\n",
            "resetting env. episode 2694.000000, reward total was -20.000000. running mean: -20.093692\n",
            "resetting env. episode 2695.000000, reward total was -20.000000. running mean: -20.092755\n",
            "resetting env. episode 2696.000000, reward total was -19.000000. running mean: -20.081827\n",
            "resetting env. episode 2697.000000, reward total was -20.000000. running mean: -20.081009\n",
            "resetting env. episode 2698.000000, reward total was -21.000000. running mean: -20.090199\n",
            "resetting env. episode 2699.000000, reward total was -19.000000. running mean: -20.079297\n",
            "resetting env. episode 2700.000000, reward total was -18.000000. running mean: -20.058504\n",
            "resetting env. episode 2701.000000, reward total was -19.000000. running mean: -20.047919\n",
            "resetting env. episode 2702.000000, reward total was -19.000000. running mean: -20.037440\n",
            "resetting env. episode 2703.000000, reward total was -20.000000. running mean: -20.037065\n",
            "resetting env. episode 2704.000000, reward total was -21.000000. running mean: -20.046695\n",
            "resetting env. episode 2705.000000, reward total was -21.000000. running mean: -20.056228\n",
            "resetting env. episode 2706.000000, reward total was -20.000000. running mean: -20.055665\n",
            "resetting env. episode 2707.000000, reward total was -21.000000. running mean: -20.065109\n",
            "resetting env. episode 2708.000000, reward total was -19.000000. running mean: -20.054458\n",
            "resetting env. episode 2709.000000, reward total was -19.000000. running mean: -20.043913\n",
            "resetting env. episode 2710.000000, reward total was -20.000000. running mean: -20.043474\n",
            "resetting env. episode 2711.000000, reward total was -21.000000. running mean: -20.053039\n",
            "resetting env. episode 2712.000000, reward total was -20.000000. running mean: -20.052509\n",
            "resetting env. episode 2713.000000, reward total was -21.000000. running mean: -20.061984\n",
            "resetting env. episode 2714.000000, reward total was -20.000000. running mean: -20.061364\n",
            "resetting env. episode 2715.000000, reward total was -19.000000. running mean: -20.050750\n",
            "resetting env. episode 2716.000000, reward total was -17.000000. running mean: -20.020243\n",
            "resetting env. episode 2717.000000, reward total was -21.000000. running mean: -20.030040\n",
            "resetting env. episode 2718.000000, reward total was -21.000000. running mean: -20.039740\n",
            "resetting env. episode 2719.000000, reward total was -21.000000. running mean: -20.049343\n",
            "resetting env. episode 2720.000000, reward total was -21.000000. running mean: -20.058849\n",
            "resetting env. episode 2721.000000, reward total was -21.000000. running mean: -20.068261\n",
            "resetting env. episode 2722.000000, reward total was -20.000000. running mean: -20.067578\n",
            "resetting env. episode 2723.000000, reward total was -21.000000. running mean: -20.076902\n",
            "resetting env. episode 2724.000000, reward total was -21.000000. running mean: -20.086133\n",
            "resetting env. episode 2725.000000, reward total was -21.000000. running mean: -20.095272\n",
            "resetting env. episode 2726.000000, reward total was -20.000000. running mean: -20.094319\n",
            "resetting env. episode 2727.000000, reward total was -21.000000. running mean: -20.103376\n",
            "resetting env. episode 2728.000000, reward total was -21.000000. running mean: -20.112342\n",
            "resetting env. episode 2729.000000, reward total was -20.000000. running mean: -20.111219\n",
            "resetting env. episode 2730.000000, reward total was -21.000000. running mean: -20.120107\n",
            "resetting env. episode 2731.000000, reward total was -21.000000. running mean: -20.128906\n",
            "resetting env. episode 2732.000000, reward total was -21.000000. running mean: -20.137616\n",
            "resetting env. episode 2733.000000, reward total was -19.000000. running mean: -20.126240\n",
            "resetting env. episode 2734.000000, reward total was -19.000000. running mean: -20.114978\n",
            "resetting env. episode 2735.000000, reward total was -21.000000. running mean: -20.123828\n",
            "resetting env. episode 2736.000000, reward total was -21.000000. running mean: -20.132590\n",
            "resetting env. episode 2737.000000, reward total was -21.000000. running mean: -20.141264\n",
            "resetting env. episode 2738.000000, reward total was -20.000000. running mean: -20.139851\n",
            "resetting env. episode 2739.000000, reward total was -21.000000. running mean: -20.148453\n",
            "resetting env. episode 2740.000000, reward total was -21.000000. running mean: -20.156968\n",
            "resetting env. episode 2741.000000, reward total was -19.000000. running mean: -20.145399\n",
            "resetting env. episode 2742.000000, reward total was -18.000000. running mean: -20.123945\n",
            "resetting env. episode 2743.000000, reward total was -19.000000. running mean: -20.112705\n",
            "resetting env. episode 2744.000000, reward total was -21.000000. running mean: -20.121578\n",
            "resetting env. episode 2745.000000, reward total was -21.000000. running mean: -20.130362\n",
            "resetting env. episode 2746.000000, reward total was -16.000000. running mean: -20.089059\n",
            "resetting env. episode 2747.000000, reward total was -18.000000. running mean: -20.068168\n",
            "resetting env. episode 2748.000000, reward total was -20.000000. running mean: -20.067486\n",
            "resetting env. episode 2749.000000, reward total was -19.000000. running mean: -20.056812\n",
            "resetting env. episode 2750.000000, reward total was -21.000000. running mean: -20.066243\n",
            "resetting env. episode 2751.000000, reward total was -21.000000. running mean: -20.075581\n",
            "resetting env. episode 2752.000000, reward total was -21.000000. running mean: -20.084825\n",
            "resetting env. episode 2753.000000, reward total was -19.000000. running mean: -20.073977\n",
            "resetting env. episode 2754.000000, reward total was -20.000000. running mean: -20.073237\n",
            "resetting env. episode 2755.000000, reward total was -19.000000. running mean: -20.062505\n",
            "resetting env. episode 2756.000000, reward total was -20.000000. running mean: -20.061880\n",
            "resetting env. episode 2757.000000, reward total was -20.000000. running mean: -20.061261\n",
            "resetting env. episode 2758.000000, reward total was -21.000000. running mean: -20.070648\n",
            "resetting env. episode 2759.000000, reward total was -21.000000. running mean: -20.079942\n",
            "resetting env. episode 2760.000000, reward total was -21.000000. running mean: -20.089142\n",
            "resetting env. episode 2761.000000, reward total was -21.000000. running mean: -20.098251\n",
            "resetting env. episode 2762.000000, reward total was -21.000000. running mean: -20.107269\n",
            "resetting env. episode 2763.000000, reward total was -20.000000. running mean: -20.106196\n",
            "resetting env. episode 2764.000000, reward total was -20.000000. running mean: -20.105134\n",
            "resetting env. episode 2765.000000, reward total was -18.000000. running mean: -20.084083\n",
            "resetting env. episode 2766.000000, reward total was -21.000000. running mean: -20.093242\n",
            "resetting env. episode 2767.000000, reward total was -20.000000. running mean: -20.092309\n",
            "resetting env. episode 2768.000000, reward total was -21.000000. running mean: -20.101386\n",
            "resetting env. episode 2769.000000, reward total was -20.000000. running mean: -20.100372\n",
            "resetting env. episode 2770.000000, reward total was -21.000000. running mean: -20.109369\n",
            "resetting env. episode 2771.000000, reward total was -20.000000. running mean: -20.108275\n",
            "resetting env. episode 2772.000000, reward total was -21.000000. running mean: -20.117192\n",
            "resetting env. episode 2773.000000, reward total was -21.000000. running mean: -20.126020\n",
            "resetting env. episode 2774.000000, reward total was -20.000000. running mean: -20.124760\n",
            "resetting env. episode 2775.000000, reward total was -18.000000. running mean: -20.103512\n",
            "resetting env. episode 2776.000000, reward total was -18.000000. running mean: -20.082477\n",
            "resetting env. episode 2777.000000, reward total was -20.000000. running mean: -20.081653\n",
            "resetting env. episode 2778.000000, reward total was -21.000000. running mean: -20.090836\n",
            "resetting env. episode 2779.000000, reward total was -19.000000. running mean: -20.079928\n",
            "resetting env. episode 2780.000000, reward total was -20.000000. running mean: -20.079128\n",
            "resetting env. episode 2781.000000, reward total was -20.000000. running mean: -20.078337\n",
            "resetting env. episode 2782.000000, reward total was -20.000000. running mean: -20.077554\n",
            "resetting env. episode 2783.000000, reward total was -21.000000. running mean: -20.086778\n",
            "resetting env. episode 2784.000000, reward total was -20.000000. running mean: -20.085910\n",
            "resetting env. episode 2785.000000, reward total was -21.000000. running mean: -20.095051\n",
            "resetting env. episode 2786.000000, reward total was -19.000000. running mean: -20.084101\n",
            "resetting env. episode 2787.000000, reward total was -21.000000. running mean: -20.093260\n",
            "resetting env. episode 2788.000000, reward total was -19.000000. running mean: -20.082327\n",
            "resetting env. episode 2789.000000, reward total was -20.000000. running mean: -20.081504\n",
            "resetting env. episode 2790.000000, reward total was -21.000000. running mean: -20.090689\n",
            "resetting env. episode 2791.000000, reward total was -21.000000. running mean: -20.099782\n",
            "resetting env. episode 2792.000000, reward total was -20.000000. running mean: -20.098784\n",
            "resetting env. episode 2793.000000, reward total was -19.000000. running mean: -20.087796\n",
            "resetting env. episode 2794.000000, reward total was -20.000000. running mean: -20.086918\n",
            "resetting env. episode 2795.000000, reward total was -21.000000. running mean: -20.096049\n",
            "resetting env. episode 2796.000000, reward total was -21.000000. running mean: -20.105089\n",
            "resetting env. episode 2797.000000, reward total was -20.000000. running mean: -20.104038\n",
            "resetting env. episode 2798.000000, reward total was -21.000000. running mean: -20.112997\n",
            "resetting env. episode 2799.000000, reward total was -19.000000. running mean: -20.101867\n",
            "resetting env. episode 2800.000000, reward total was -20.000000. running mean: -20.100849\n",
            "resetting env. episode 2801.000000, reward total was -20.000000. running mean: -20.099840\n",
            "resetting env. episode 2802.000000, reward total was -21.000000. running mean: -20.108842\n",
            "resetting env. episode 2803.000000, reward total was -19.000000. running mean: -20.097753\n",
            "resetting env. episode 2804.000000, reward total was -20.000000. running mean: -20.096776\n",
            "resetting env. episode 2805.000000, reward total was -20.000000. running mean: -20.095808\n",
            "resetting env. episode 2806.000000, reward total was -20.000000. running mean: -20.094850\n",
            "resetting env. episode 2807.000000, reward total was -21.000000. running mean: -20.103902\n",
            "resetting env. episode 2808.000000, reward total was -21.000000. running mean: -20.112863\n",
            "resetting env. episode 2809.000000, reward total was -20.000000. running mean: -20.111734\n",
            "resetting env. episode 2810.000000, reward total was -20.000000. running mean: -20.110617\n",
            "resetting env. episode 2811.000000, reward total was -20.000000. running mean: -20.109510\n",
            "resetting env. episode 2812.000000, reward total was -20.000000. running mean: -20.108415\n",
            "resetting env. episode 2813.000000, reward total was -19.000000. running mean: -20.097331\n",
            "resetting env. episode 2814.000000, reward total was -21.000000. running mean: -20.106358\n",
            "resetting env. episode 2815.000000, reward total was -21.000000. running mean: -20.115294\n",
            "resetting env. episode 2816.000000, reward total was -21.000000. running mean: -20.124141\n",
            "resetting env. episode 2817.000000, reward total was -20.000000. running mean: -20.122900\n",
            "resetting env. episode 2818.000000, reward total was -21.000000. running mean: -20.131671\n",
            "resetting env. episode 2819.000000, reward total was -18.000000. running mean: -20.110354\n",
            "resetting env. episode 2820.000000, reward total was -20.000000. running mean: -20.109251\n",
            "resetting env. episode 2821.000000, reward total was -21.000000. running mean: -20.118158\n",
            "resetting env. episode 2822.000000, reward total was -20.000000. running mean: -20.116977\n",
            "resetting env. episode 2823.000000, reward total was -21.000000. running mean: -20.125807\n",
            "resetting env. episode 2824.000000, reward total was -21.000000. running mean: -20.134549\n",
            "resetting env. episode 2825.000000, reward total was -20.000000. running mean: -20.133203\n",
            "resetting env. episode 2826.000000, reward total was -21.000000. running mean: -20.141871\n",
            "resetting env. episode 2827.000000, reward total was -21.000000. running mean: -20.150453\n",
            "resetting env. episode 2828.000000, reward total was -21.000000. running mean: -20.158948\n",
            "resetting env. episode 2829.000000, reward total was -20.000000. running mean: -20.157359\n",
            "resetting env. episode 2830.000000, reward total was -19.000000. running mean: -20.145785\n",
            "resetting env. episode 2831.000000, reward total was -20.000000. running mean: -20.144327\n",
            "resetting env. episode 2832.000000, reward total was -20.000000. running mean: -20.142884\n",
            "resetting env. episode 2833.000000, reward total was -21.000000. running mean: -20.151455\n",
            "resetting env. episode 2834.000000, reward total was -20.000000. running mean: -20.149940\n",
            "resetting env. episode 2835.000000, reward total was -21.000000. running mean: -20.158441\n",
            "resetting env. episode 2836.000000, reward total was -21.000000. running mean: -20.166857\n",
            "resetting env. episode 2837.000000, reward total was -21.000000. running mean: -20.175188\n",
            "resetting env. episode 2838.000000, reward total was -19.000000. running mean: -20.163436\n",
            "resetting env. episode 2839.000000, reward total was -19.000000. running mean: -20.151802\n",
            "resetting env. episode 2840.000000, reward total was -20.000000. running mean: -20.150284\n",
            "resetting env. episode 2841.000000, reward total was -20.000000. running mean: -20.148781\n",
            "resetting env. episode 2842.000000, reward total was -16.000000. running mean: -20.107293\n",
            "resetting env. episode 2843.000000, reward total was -20.000000. running mean: -20.106220\n",
            "resetting env. episode 2844.000000, reward total was -21.000000. running mean: -20.115158\n",
            "resetting env. episode 2845.000000, reward total was -21.000000. running mean: -20.124006\n",
            "resetting env. episode 2846.000000, reward total was -21.000000. running mean: -20.132766\n",
            "resetting env. episode 2847.000000, reward total was -18.000000. running mean: -20.111439\n",
            "resetting env. episode 2848.000000, reward total was -19.000000. running mean: -20.100324\n",
            "resetting env. episode 2849.000000, reward total was -21.000000. running mean: -20.109321\n",
            "resetting env. episode 2850.000000, reward total was -21.000000. running mean: -20.118228\n",
            "resetting env. episode 2851.000000, reward total was -20.000000. running mean: -20.117046\n",
            "resetting env. episode 2852.000000, reward total was -21.000000. running mean: -20.125875\n",
            "resetting env. episode 2853.000000, reward total was -20.000000. running mean: -20.124616\n",
            "resetting env. episode 2854.000000, reward total was -19.000000. running mean: -20.113370\n",
            "resetting env. episode 2855.000000, reward total was -20.000000. running mean: -20.112237\n",
            "resetting env. episode 2856.000000, reward total was -19.000000. running mean: -20.101114\n",
            "resetting env. episode 2857.000000, reward total was -19.000000. running mean: -20.090103\n",
            "resetting env. episode 2858.000000, reward total was -19.000000. running mean: -20.079202\n",
            "resetting env. episode 2859.000000, reward total was -21.000000. running mean: -20.088410\n",
            "resetting env. episode 2860.000000, reward total was -21.000000. running mean: -20.097526\n",
            "resetting env. episode 2861.000000, reward total was -20.000000. running mean: -20.096551\n",
            "resetting env. episode 2862.000000, reward total was -17.000000. running mean: -20.065585\n",
            "resetting env. episode 2863.000000, reward total was -19.000000. running mean: -20.054929\n",
            "resetting env. episode 2864.000000, reward total was -20.000000. running mean: -20.054380\n",
            "resetting env. episode 2865.000000, reward total was -20.000000. running mean: -20.053836\n",
            "resetting env. episode 2866.000000, reward total was -21.000000. running mean: -20.063298\n",
            "resetting env. episode 2867.000000, reward total was -21.000000. running mean: -20.072665\n",
            "resetting env. episode 2868.000000, reward total was -21.000000. running mean: -20.081938\n",
            "resetting env. episode 2869.000000, reward total was -20.000000. running mean: -20.081119\n",
            "resetting env. episode 2870.000000, reward total was -19.000000. running mean: -20.070308\n",
            "resetting env. episode 2871.000000, reward total was -21.000000. running mean: -20.079605\n",
            "resetting env. episode 2872.000000, reward total was -21.000000. running mean: -20.088808\n",
            "resetting env. episode 2873.000000, reward total was -16.000000. running mean: -20.047920\n",
            "resetting env. episode 2874.000000, reward total was -20.000000. running mean: -20.047441\n",
            "resetting env. episode 2875.000000, reward total was -21.000000. running mean: -20.056967\n",
            "resetting env. episode 2876.000000, reward total was -21.000000. running mean: -20.066397\n",
            "resetting env. episode 2877.000000, reward total was -20.000000. running mean: -20.065733\n",
            "resetting env. episode 2878.000000, reward total was -21.000000. running mean: -20.075076\n",
            "resetting env. episode 2879.000000, reward total was -21.000000. running mean: -20.084325\n",
            "resetting env. episode 2880.000000, reward total was -21.000000. running mean: -20.093482\n",
            "resetting env. episode 2881.000000, reward total was -19.000000. running mean: -20.082547\n",
            "resetting env. episode 2882.000000, reward total was -20.000000. running mean: -20.081722\n",
            "resetting env. episode 2883.000000, reward total was -19.000000. running mean: -20.070904\n",
            "resetting env. episode 2884.000000, reward total was -20.000000. running mean: -20.070195\n",
            "resetting env. episode 2885.000000, reward total was -18.000000. running mean: -20.049493\n",
            "resetting env. episode 2886.000000, reward total was -20.000000. running mean: -20.048998\n",
            "resetting env. episode 2887.000000, reward total was -21.000000. running mean: -20.058508\n",
            "resetting env. episode 2888.000000, reward total was -21.000000. running mean: -20.067923\n",
            "resetting env. episode 2889.000000, reward total was -19.000000. running mean: -20.057244\n",
            "resetting env. episode 2890.000000, reward total was -20.000000. running mean: -20.056672\n",
            "resetting env. episode 2891.000000, reward total was -21.000000. running mean: -20.066105\n",
            "resetting env. episode 2892.000000, reward total was -20.000000. running mean: -20.065444\n",
            "resetting env. episode 2893.000000, reward total was -20.000000. running mean: -20.064789\n",
            "resetting env. episode 2894.000000, reward total was -21.000000. running mean: -20.074142\n",
            "resetting env. episode 2895.000000, reward total was -21.000000. running mean: -20.083400\n",
            "resetting env. episode 2896.000000, reward total was -20.000000. running mean: -20.082566\n",
            "resetting env. episode 2897.000000, reward total was -19.000000. running mean: -20.071740\n",
            "resetting env. episode 2898.000000, reward total was -19.000000. running mean: -20.061023\n",
            "resetting env. episode 2899.000000, reward total was -19.000000. running mean: -20.050413\n",
            "resetting env. episode 2900.000000, reward total was -20.000000. running mean: -20.049909\n",
            "resetting env. episode 2901.000000, reward total was -21.000000. running mean: -20.059410\n",
            "resetting env. episode 2902.000000, reward total was -21.000000. running mean: -20.068815\n",
            "resetting env. episode 2903.000000, reward total was -21.000000. running mean: -20.078127\n",
            "resetting env. episode 2904.000000, reward total was -19.000000. running mean: -20.067346\n",
            "resetting env. episode 2905.000000, reward total was -20.000000. running mean: -20.066673\n",
            "resetting env. episode 2906.000000, reward total was -19.000000. running mean: -20.056006\n",
            "resetting env. episode 2907.000000, reward total was -21.000000. running mean: -20.065446\n",
            "resetting env. episode 2908.000000, reward total was -19.000000. running mean: -20.054791\n",
            "resetting env. episode 2909.000000, reward total was -18.000000. running mean: -20.034243\n",
            "resetting env. episode 2910.000000, reward total was -20.000000. running mean: -20.033901\n",
            "resetting env. episode 2911.000000, reward total was -20.000000. running mean: -20.033562\n",
            "resetting env. episode 2912.000000, reward total was -18.000000. running mean: -20.013226\n",
            "resetting env. episode 2913.000000, reward total was -20.000000. running mean: -20.013094\n",
            "resetting env. episode 2914.000000, reward total was -21.000000. running mean: -20.022963\n",
            "resetting env. episode 2915.000000, reward total was -19.000000. running mean: -20.012734\n",
            "resetting env. episode 2916.000000, reward total was -20.000000. running mean: -20.012606\n",
            "resetting env. episode 2917.000000, reward total was -21.000000. running mean: -20.022480\n",
            "resetting env. episode 2918.000000, reward total was -20.000000. running mean: -20.022255\n",
            "resetting env. episode 2919.000000, reward total was -21.000000. running mean: -20.032033\n",
            "resetting env. episode 2920.000000, reward total was -21.000000. running mean: -20.041712\n",
            "resetting env. episode 2921.000000, reward total was -21.000000. running mean: -20.051295\n",
            "resetting env. episode 2922.000000, reward total was -19.000000. running mean: -20.040782\n",
            "resetting env. episode 2923.000000, reward total was -21.000000. running mean: -20.050375\n",
            "resetting env. episode 2924.000000, reward total was -20.000000. running mean: -20.049871\n",
            "resetting env. episode 2925.000000, reward total was -20.000000. running mean: -20.049372\n",
            "resetting env. episode 2926.000000, reward total was -19.000000. running mean: -20.038878\n",
            "resetting env. episode 2927.000000, reward total was -21.000000. running mean: -20.048490\n",
            "resetting env. episode 2928.000000, reward total was -19.000000. running mean: -20.038005\n",
            "resetting env. episode 2929.000000, reward total was -21.000000. running mean: -20.047625\n",
            "resetting env. episode 2930.000000, reward total was -20.000000. running mean: -20.047148\n",
            "resetting env. episode 2931.000000, reward total was -21.000000. running mean: -20.056677\n",
            "resetting env. episode 2932.000000, reward total was -21.000000. running mean: -20.066110\n",
            "resetting env. episode 2933.000000, reward total was -21.000000. running mean: -20.075449\n",
            "resetting env. episode 2934.000000, reward total was -20.000000. running mean: -20.074695\n",
            "resetting env. episode 2935.000000, reward total was -21.000000. running mean: -20.083948\n",
            "resetting env. episode 2936.000000, reward total was -20.000000. running mean: -20.083108\n",
            "resetting env. episode 2937.000000, reward total was -21.000000. running mean: -20.092277\n",
            "resetting env. episode 2938.000000, reward total was -19.000000. running mean: -20.081354\n",
            "resetting env. episode 2939.000000, reward total was -19.000000. running mean: -20.070541\n",
            "resetting env. episode 2940.000000, reward total was -21.000000. running mean: -20.079835\n",
            "resetting env. episode 2941.000000, reward total was -21.000000. running mean: -20.089037\n",
            "resetting env. episode 2942.000000, reward total was -21.000000. running mean: -20.098147\n",
            "resetting env. episode 2943.000000, reward total was -20.000000. running mean: -20.097165\n",
            "resetting env. episode 2944.000000, reward total was -21.000000. running mean: -20.106194\n",
            "resetting env. episode 2945.000000, reward total was -21.000000. running mean: -20.115132\n",
            "resetting env. episode 2946.000000, reward total was -21.000000. running mean: -20.123980\n",
            "resetting env. episode 2947.000000, reward total was -21.000000. running mean: -20.132740\n",
            "resetting env. episode 2948.000000, reward total was -21.000000. running mean: -20.141413\n",
            "resetting env. episode 2949.000000, reward total was -21.000000. running mean: -20.149999\n",
            "resetting env. episode 2950.000000, reward total was -21.000000. running mean: -20.158499\n",
            "resetting env. episode 2951.000000, reward total was -20.000000. running mean: -20.156914\n",
            "resetting env. episode 2952.000000, reward total was -21.000000. running mean: -20.165345\n",
            "resetting env. episode 2953.000000, reward total was -18.000000. running mean: -20.143691\n",
            "resetting env. episode 2954.000000, reward total was -19.000000. running mean: -20.132254\n",
            "resetting env. episode 2955.000000, reward total was -21.000000. running mean: -20.140932\n",
            "resetting env. episode 2956.000000, reward total was -20.000000. running mean: -20.139523\n",
            "resetting env. episode 2957.000000, reward total was -20.000000. running mean: -20.138127\n",
            "resetting env. episode 2958.000000, reward total was -19.000000. running mean: -20.126746\n",
            "resetting env. episode 2959.000000, reward total was -18.000000. running mean: -20.105479\n",
            "resetting env. episode 2960.000000, reward total was -21.000000. running mean: -20.114424\n",
            "resetting env. episode 2961.000000, reward total was -21.000000. running mean: -20.123280\n",
            "resetting env. episode 2962.000000, reward total was -20.000000. running mean: -20.122047\n",
            "resetting env. episode 2963.000000, reward total was -20.000000. running mean: -20.120826\n",
            "resetting env. episode 2964.000000, reward total was -21.000000. running mean: -20.129618\n",
            "resetting env. episode 2965.000000, reward total was -20.000000. running mean: -20.128322\n",
            "resetting env. episode 2966.000000, reward total was -19.000000. running mean: -20.117039\n",
            "resetting env. episode 2967.000000, reward total was -21.000000. running mean: -20.125868\n",
            "resetting env. episode 2968.000000, reward total was -19.000000. running mean: -20.114610\n",
            "resetting env. episode 2969.000000, reward total was -20.000000. running mean: -20.113463\n",
            "resetting env. episode 2970.000000, reward total was -20.000000. running mean: -20.112329\n",
            "resetting env. episode 2971.000000, reward total was -19.000000. running mean: -20.101206\n",
            "resetting env. episode 2972.000000, reward total was -19.000000. running mean: -20.090194\n",
            "resetting env. episode 2973.000000, reward total was -21.000000. running mean: -20.099292\n",
            "resetting env. episode 2974.000000, reward total was -18.000000. running mean: -20.078299\n",
            "resetting env. episode 2975.000000, reward total was -20.000000. running mean: -20.077516\n",
            "resetting env. episode 2976.000000, reward total was -20.000000. running mean: -20.076741\n",
            "resetting env. episode 2977.000000, reward total was -20.000000. running mean: -20.075973\n",
            "resetting env. episode 2978.000000, reward total was -21.000000. running mean: -20.085213\n",
            "resetting env. episode 2979.000000, reward total was -20.000000. running mean: -20.084361\n",
            "resetting env. episode 2980.000000, reward total was -21.000000. running mean: -20.093518\n",
            "resetting env. episode 2981.000000, reward total was -21.000000. running mean: -20.102582\n",
            "resetting env. episode 2982.000000, reward total was -18.000000. running mean: -20.081557\n",
            "resetting env. episode 2983.000000, reward total was -20.000000. running mean: -20.080741\n",
            "resetting env. episode 2984.000000, reward total was -21.000000. running mean: -20.089934\n",
            "resetting env. episode 2985.000000, reward total was -21.000000. running mean: -20.099034\n",
            "resetting env. episode 2986.000000, reward total was -18.000000. running mean: -20.078044\n",
            "resetting env. episode 2987.000000, reward total was -20.000000. running mean: -20.077264\n",
            "resetting env. episode 2988.000000, reward total was -19.000000. running mean: -20.066491\n",
            "resetting env. episode 2989.000000, reward total was -21.000000. running mean: -20.075826\n",
            "resetting env. episode 2990.000000, reward total was -19.000000. running mean: -20.065068\n",
            "resetting env. episode 2991.000000, reward total was -21.000000. running mean: -20.074417\n",
            "resetting env. episode 2992.000000, reward total was -21.000000. running mean: -20.083673\n",
            "resetting env. episode 2993.000000, reward total was -21.000000. running mean: -20.092836\n",
            "resetting env. episode 2994.000000, reward total was -18.000000. running mean: -20.071908\n",
            "resetting env. episode 2995.000000, reward total was -19.000000. running mean: -20.061189\n",
            "resetting env. episode 2996.000000, reward total was -20.000000. running mean: -20.060577\n",
            "resetting env. episode 2997.000000, reward total was -21.000000. running mean: -20.069971\n",
            "resetting env. episode 2998.000000, reward total was -21.000000. running mean: -20.079271\n",
            "resetting env. episode 2999.000000, reward total was -20.000000. running mean: -20.078479\n",
            "resetting env. episode 3000.000000, reward total was -20.000000. running mean: -20.077694\n",
            "resetting env. episode 3001.000000, reward total was -20.000000. running mean: -20.076917\n",
            "resetting env. episode 3002.000000, reward total was -21.000000. running mean: -20.086148\n",
            "resetting env. episode 3003.000000, reward total was -20.000000. running mean: -20.085286\n",
            "resetting env. episode 3004.000000, reward total was -18.000000. running mean: -20.064433\n",
            "resetting env. episode 3005.000000, reward total was -20.000000. running mean: -20.063789\n",
            "resetting env. episode 3006.000000, reward total was -21.000000. running mean: -20.073151\n",
            "resetting env. episode 3007.000000, reward total was -19.000000. running mean: -20.062420\n",
            "resetting env. episode 3008.000000, reward total was -21.000000. running mean: -20.071795\n",
            "resetting env. episode 3009.000000, reward total was -21.000000. running mean: -20.081078\n",
            "resetting env. episode 3010.000000, reward total was -20.000000. running mean: -20.080267\n",
            "resetting env. episode 3011.000000, reward total was -20.000000. running mean: -20.079464\n",
            "resetting env. episode 3012.000000, reward total was -19.000000. running mean: -20.068669\n",
            "resetting env. episode 3013.000000, reward total was -16.000000. running mean: -20.027983\n",
            "resetting env. episode 3014.000000, reward total was -21.000000. running mean: -20.037703\n",
            "resetting env. episode 3015.000000, reward total was -19.000000. running mean: -20.027326\n",
            "resetting env. episode 3016.000000, reward total was -21.000000. running mean: -20.037053\n",
            "resetting env. episode 3017.000000, reward total was -21.000000. running mean: -20.046682\n",
            "resetting env. episode 3018.000000, reward total was -18.000000. running mean: -20.026215\n",
            "resetting env. episode 3019.000000, reward total was -21.000000. running mean: -20.035953\n",
            "resetting env. episode 3020.000000, reward total was -21.000000. running mean: -20.045594\n",
            "resetting env. episode 3021.000000, reward total was -19.000000. running mean: -20.035138\n",
            "resetting env. episode 3022.000000, reward total was -21.000000. running mean: -20.044786\n",
            "resetting env. episode 3023.000000, reward total was -21.000000. running mean: -20.054338\n",
            "resetting env. episode 3024.000000, reward total was -21.000000. running mean: -20.063795\n",
            "resetting env. episode 3025.000000, reward total was -18.000000. running mean: -20.043157\n",
            "resetting env. episode 3026.000000, reward total was -21.000000. running mean: -20.052726\n",
            "resetting env. episode 3027.000000, reward total was -20.000000. running mean: -20.052198\n",
            "resetting env. episode 3028.000000, reward total was -19.000000. running mean: -20.041676\n",
            "resetting env. episode 3029.000000, reward total was -21.000000. running mean: -20.051260\n",
            "resetting env. episode 3030.000000, reward total was -20.000000. running mean: -20.050747\n",
            "resetting env. episode 3031.000000, reward total was -21.000000. running mean: -20.060239\n",
            "resetting env. episode 3032.000000, reward total was -20.000000. running mean: -20.059637\n",
            "resetting env. episode 3033.000000, reward total was -21.000000. running mean: -20.069041\n",
            "resetting env. episode 3034.000000, reward total was -20.000000. running mean: -20.068350\n",
            "resetting env. episode 3035.000000, reward total was -21.000000. running mean: -20.077667\n",
            "resetting env. episode 3036.000000, reward total was -21.000000. running mean: -20.086890\n",
            "resetting env. episode 3037.000000, reward total was -19.000000. running mean: -20.076021\n",
            "resetting env. episode 3038.000000, reward total was -20.000000. running mean: -20.075261\n",
            "resetting env. episode 3039.000000, reward total was -21.000000. running mean: -20.084508\n",
            "resetting env. episode 3040.000000, reward total was -20.000000. running mean: -20.083663\n",
            "resetting env. episode 3041.000000, reward total was -21.000000. running mean: -20.092827\n",
            "resetting env. episode 3042.000000, reward total was -21.000000. running mean: -20.101898\n",
            "resetting env. episode 3043.000000, reward total was -20.000000. running mean: -20.100879\n",
            "resetting env. episode 3044.000000, reward total was -19.000000. running mean: -20.089871\n",
            "resetting env. episode 3045.000000, reward total was -20.000000. running mean: -20.088972\n",
            "resetting env. episode 3046.000000, reward total was -18.000000. running mean: -20.068082\n",
            "resetting env. episode 3047.000000, reward total was -21.000000. running mean: -20.077401\n",
            "resetting env. episode 3048.000000, reward total was -20.000000. running mean: -20.076627\n",
            "resetting env. episode 3049.000000, reward total was -18.000000. running mean: -20.055861\n",
            "resetting env. episode 3050.000000, reward total was -21.000000. running mean: -20.065302\n",
            "resetting env. episode 3051.000000, reward total was -21.000000. running mean: -20.074649\n",
            "resetting env. episode 3052.000000, reward total was -19.000000. running mean: -20.063903\n",
            "resetting env. episode 3053.000000, reward total was -21.000000. running mean: -20.073264\n",
            "resetting env. episode 3054.000000, reward total was -21.000000. running mean: -20.082531\n",
            "resetting env. episode 3055.000000, reward total was -20.000000. running mean: -20.081706\n",
            "resetting env. episode 3056.000000, reward total was -21.000000. running mean: -20.090889\n",
            "resetting env. episode 3057.000000, reward total was -20.000000. running mean: -20.089980\n",
            "resetting env. episode 3058.000000, reward total was -21.000000. running mean: -20.099080\n",
            "resetting env. episode 3059.000000, reward total was -20.000000. running mean: -20.098089\n",
            "resetting env. episode 3060.000000, reward total was -21.000000. running mean: -20.107109\n",
            "resetting env. episode 3061.000000, reward total was -20.000000. running mean: -20.106037\n",
            "resetting env. episode 3062.000000, reward total was -19.000000. running mean: -20.094977\n",
            "resetting env. episode 3063.000000, reward total was -19.000000. running mean: -20.084027\n",
            "resetting env. episode 3064.000000, reward total was -21.000000. running mean: -20.093187\n",
            "resetting env. episode 3065.000000, reward total was -19.000000. running mean: -20.082255\n",
            "resetting env. episode 3066.000000, reward total was -20.000000. running mean: -20.081433\n",
            "resetting env. episode 3067.000000, reward total was -19.000000. running mean: -20.070618\n",
            "resetting env. episode 3068.000000, reward total was -21.000000. running mean: -20.079912\n",
            "resetting env. episode 3069.000000, reward total was -19.000000. running mean: -20.069113\n",
            "resetting env. episode 3070.000000, reward total was -20.000000. running mean: -20.068422\n",
            "resetting env. episode 3071.000000, reward total was -20.000000. running mean: -20.067738\n",
            "resetting env. episode 3072.000000, reward total was -21.000000. running mean: -20.077060\n",
            "resetting env. episode 3073.000000, reward total was -21.000000. running mean: -20.086290\n",
            "resetting env. episode 3074.000000, reward total was -18.000000. running mean: -20.065427\n",
            "resetting env. episode 3075.000000, reward total was -21.000000. running mean: -20.074772\n",
            "resetting env. episode 3076.000000, reward total was -20.000000. running mean: -20.074025\n",
            "resetting env. episode 3077.000000, reward total was -21.000000. running mean: -20.083285\n",
            "resetting env. episode 3078.000000, reward total was -21.000000. running mean: -20.092452\n",
            "resetting env. episode 3079.000000, reward total was -21.000000. running mean: -20.101527\n",
            "resetting env. episode 3080.000000, reward total was -18.000000. running mean: -20.080512\n",
            "resetting env. episode 3081.000000, reward total was -21.000000. running mean: -20.089707\n",
            "resetting env. episode 3082.000000, reward total was -21.000000. running mean: -20.098810\n",
            "resetting env. episode 3083.000000, reward total was -21.000000. running mean: -20.107822\n",
            "resetting env. episode 3084.000000, reward total was -21.000000. running mean: -20.116743\n",
            "resetting env. episode 3085.000000, reward total was -21.000000. running mean: -20.125576\n",
            "resetting env. episode 3086.000000, reward total was -21.000000. running mean: -20.134320\n",
            "resetting env. episode 3087.000000, reward total was -20.000000. running mean: -20.132977\n",
            "resetting env. episode 3088.000000, reward total was -21.000000. running mean: -20.141647\n",
            "resetting env. episode 3089.000000, reward total was -18.000000. running mean: -20.120231\n",
            "resetting env. episode 3090.000000, reward total was -19.000000. running mean: -20.109028\n",
            "resetting env. episode 3091.000000, reward total was -21.000000. running mean: -20.117938\n",
            "resetting env. episode 3092.000000, reward total was -19.000000. running mean: -20.106759\n",
            "resetting env. episode 3093.000000, reward total was -21.000000. running mean: -20.115691\n",
            "resetting env. episode 3094.000000, reward total was -21.000000. running mean: -20.124534\n",
            "resetting env. episode 3095.000000, reward total was -21.000000. running mean: -20.133289\n",
            "resetting env. episode 3096.000000, reward total was -21.000000. running mean: -20.141956\n",
            "resetting env. episode 3097.000000, reward total was -20.000000. running mean: -20.140536\n",
            "resetting env. episode 3098.000000, reward total was -21.000000. running mean: -20.149131\n",
            "resetting env. episode 3099.000000, reward total was -21.000000. running mean: -20.157640\n",
            "resetting env. episode 3100.000000, reward total was -19.000000. running mean: -20.146063\n",
            "resetting env. episode 3101.000000, reward total was -21.000000. running mean: -20.154603\n",
            "resetting env. episode 3102.000000, reward total was -20.000000. running mean: -20.153057\n",
            "resetting env. episode 3103.000000, reward total was -21.000000. running mean: -20.161526\n",
            "resetting env. episode 3104.000000, reward total was -21.000000. running mean: -20.169911\n",
            "resetting env. episode 3105.000000, reward total was -20.000000. running mean: -20.168212\n",
            "resetting env. episode 3106.000000, reward total was -20.000000. running mean: -20.166530\n",
            "resetting env. episode 3107.000000, reward total was -20.000000. running mean: -20.164864\n",
            "resetting env. episode 3108.000000, reward total was -19.000000. running mean: -20.153216\n",
            "resetting env. episode 3109.000000, reward total was -20.000000. running mean: -20.151684\n",
            "resetting env. episode 3110.000000, reward total was -21.000000. running mean: -20.160167\n",
            "resetting env. episode 3111.000000, reward total was -21.000000. running mean: -20.168565\n",
            "resetting env. episode 3112.000000, reward total was -19.000000. running mean: -20.156879\n",
            "resetting env. episode 3113.000000, reward total was -21.000000. running mean: -20.165311\n",
            "resetting env. episode 3114.000000, reward total was -21.000000. running mean: -20.173658\n",
            "resetting env. episode 3115.000000, reward total was -20.000000. running mean: -20.171921\n",
            "resetting env. episode 3116.000000, reward total was -20.000000. running mean: -20.170202\n",
            "resetting env. episode 3117.000000, reward total was -21.000000. running mean: -20.178500\n",
            "resetting env. episode 3118.000000, reward total was -20.000000. running mean: -20.176715\n",
            "resetting env. episode 3119.000000, reward total was -20.000000. running mean: -20.174948\n",
            "resetting env. episode 3120.000000, reward total was -20.000000. running mean: -20.173198\n",
            "resetting env. episode 3121.000000, reward total was -21.000000. running mean: -20.181466\n",
            "resetting env. episode 3122.000000, reward total was -20.000000. running mean: -20.179651\n",
            "resetting env. episode 3123.000000, reward total was -20.000000. running mean: -20.177855\n",
            "resetting env. episode 3124.000000, reward total was -20.000000. running mean: -20.176076\n",
            "resetting env. episode 3125.000000, reward total was -20.000000. running mean: -20.174316\n",
            "resetting env. episode 3126.000000, reward total was -21.000000. running mean: -20.182572\n",
            "resetting env. episode 3127.000000, reward total was -21.000000. running mean: -20.190747\n",
            "resetting env. episode 3128.000000, reward total was -20.000000. running mean: -20.188839\n",
            "resetting env. episode 3129.000000, reward total was -21.000000. running mean: -20.196951\n",
            "resetting env. episode 3130.000000, reward total was -20.000000. running mean: -20.194981\n",
            "resetting env. episode 3131.000000, reward total was -20.000000. running mean: -20.193032\n",
            "resetting env. episode 3132.000000, reward total was -21.000000. running mean: -20.201101\n",
            "resetting env. episode 3133.000000, reward total was -21.000000. running mean: -20.209090\n",
            "resetting env. episode 3134.000000, reward total was -20.000000. running mean: -20.206999\n",
            "resetting env. episode 3135.000000, reward total was -21.000000. running mean: -20.214929\n",
            "resetting env. episode 3136.000000, reward total was -20.000000. running mean: -20.212780\n",
            "resetting env. episode 3137.000000, reward total was -18.000000. running mean: -20.190652\n",
            "resetting env. episode 3138.000000, reward total was -21.000000. running mean: -20.198746\n",
            "resetting env. episode 3139.000000, reward total was -20.000000. running mean: -20.196758\n",
            "resetting env. episode 3140.000000, reward total was -21.000000. running mean: -20.204791\n",
            "resetting env. episode 3141.000000, reward total was -21.000000. running mean: -20.212743\n",
            "resetting env. episode 3142.000000, reward total was -21.000000. running mean: -20.220615\n",
            "resetting env. episode 3143.000000, reward total was -19.000000. running mean: -20.208409\n",
            "resetting env. episode 3144.000000, reward total was -21.000000. running mean: -20.216325\n",
            "resetting env. episode 3145.000000, reward total was -20.000000. running mean: -20.214162\n",
            "resetting env. episode 3146.000000, reward total was -21.000000. running mean: -20.222020\n",
            "resetting env. episode 3147.000000, reward total was -20.000000. running mean: -20.219800\n",
            "resetting env. episode 3148.000000, reward total was -20.000000. running mean: -20.217602\n",
            "resetting env. episode 3149.000000, reward total was -21.000000. running mean: -20.225426\n",
            "resetting env. episode 3150.000000, reward total was -21.000000. running mean: -20.233172\n",
            "resetting env. episode 3151.000000, reward total was -18.000000. running mean: -20.210840\n",
            "resetting env. episode 3152.000000, reward total was -21.000000. running mean: -20.218732\n",
            "resetting env. episode 3153.000000, reward total was -20.000000. running mean: -20.216544\n",
            "resetting env. episode 3154.000000, reward total was -19.000000. running mean: -20.204379\n",
            "resetting env. episode 3155.000000, reward total was -19.000000. running mean: -20.192335\n",
            "resetting env. episode 3156.000000, reward total was -20.000000. running mean: -20.190412\n",
            "resetting env. episode 3157.000000, reward total was -21.000000. running mean: -20.198508\n",
            "resetting env. episode 3158.000000, reward total was -20.000000. running mean: -20.196523\n",
            "resetting env. episode 3159.000000, reward total was -21.000000. running mean: -20.204557\n",
            "resetting env. episode 3160.000000, reward total was -20.000000. running mean: -20.202512\n",
            "resetting env. episode 3161.000000, reward total was -20.000000. running mean: -20.200487\n",
            "resetting env. episode 3162.000000, reward total was -19.000000. running mean: -20.188482\n",
            "resetting env. episode 3163.000000, reward total was -21.000000. running mean: -20.196597\n",
            "resetting env. episode 3164.000000, reward total was -20.000000. running mean: -20.194631\n",
            "resetting env. episode 3165.000000, reward total was -21.000000. running mean: -20.202685\n",
            "resetting env. episode 3166.000000, reward total was -21.000000. running mean: -20.210658\n",
            "resetting env. episode 3167.000000, reward total was -20.000000. running mean: -20.208551\n",
            "resetting env. episode 3168.000000, reward total was -19.000000. running mean: -20.196466\n",
            "resetting env. episode 3169.000000, reward total was -19.000000. running mean: -20.184501\n",
            "resetting env. episode 3170.000000, reward total was -21.000000. running mean: -20.192656\n",
            "resetting env. episode 3171.000000, reward total was -18.000000. running mean: -20.170730\n",
            "resetting env. episode 3172.000000, reward total was -19.000000. running mean: -20.159022\n",
            "resetting env. episode 3173.000000, reward total was -21.000000. running mean: -20.167432\n",
            "resetting env. episode 3174.000000, reward total was -20.000000. running mean: -20.165758\n",
            "resetting env. episode 3175.000000, reward total was -20.000000. running mean: -20.164100\n",
            "resetting env. episode 3176.000000, reward total was -19.000000. running mean: -20.152459\n",
            "resetting env. episode 3177.000000, reward total was -21.000000. running mean: -20.160934\n",
            "resetting env. episode 3178.000000, reward total was -20.000000. running mean: -20.159325\n",
            "resetting env. episode 3179.000000, reward total was -17.000000. running mean: -20.127732\n",
            "resetting env. episode 3180.000000, reward total was -21.000000. running mean: -20.136455\n",
            "resetting env. episode 3181.000000, reward total was -20.000000. running mean: -20.135090\n",
            "resetting env. episode 3182.000000, reward total was -18.000000. running mean: -20.113739\n",
            "resetting env. episode 3183.000000, reward total was -21.000000. running mean: -20.122602\n",
            "resetting env. episode 3184.000000, reward total was -21.000000. running mean: -20.131376\n",
            "resetting env. episode 3185.000000, reward total was -20.000000. running mean: -20.130062\n",
            "resetting env. episode 3186.000000, reward total was -20.000000. running mean: -20.128761\n",
            "resetting env. episode 3187.000000, reward total was -21.000000. running mean: -20.137474\n",
            "resetting env. episode 3188.000000, reward total was -20.000000. running mean: -20.136099\n",
            "resetting env. episode 3189.000000, reward total was -21.000000. running mean: -20.144738\n",
            "resetting env. episode 3190.000000, reward total was -21.000000. running mean: -20.153291\n",
            "resetting env. episode 3191.000000, reward total was -20.000000. running mean: -20.151758\n",
            "resetting env. episode 3192.000000, reward total was -19.000000. running mean: -20.140240\n",
            "resetting env. episode 3193.000000, reward total was -21.000000. running mean: -20.148838\n",
            "resetting env. episode 3194.000000, reward total was -17.000000. running mean: -20.117349\n",
            "resetting env. episode 3195.000000, reward total was -20.000000. running mean: -20.116176\n",
            "resetting env. episode 3196.000000, reward total was -20.000000. running mean: -20.115014\n",
            "resetting env. episode 3197.000000, reward total was -20.000000. running mean: -20.113864\n",
            "resetting env. episode 3198.000000, reward total was -20.000000. running mean: -20.112725\n",
            "resetting env. episode 3199.000000, reward total was -20.000000. running mean: -20.111598\n",
            "resetting env. episode 3200.000000, reward total was -20.000000. running mean: -20.110482\n",
            "resetting env. episode 3201.000000, reward total was -18.000000. running mean: -20.089377\n",
            "resetting env. episode 3202.000000, reward total was -19.000000. running mean: -20.078484\n",
            "resetting env. episode 3203.000000, reward total was -20.000000. running mean: -20.077699\n",
            "resetting env. episode 3204.000000, reward total was -21.000000. running mean: -20.086922\n",
            "resetting env. episode 3205.000000, reward total was -19.000000. running mean: -20.076052\n",
            "resetting env. episode 3206.000000, reward total was -20.000000. running mean: -20.075292\n",
            "resetting env. episode 3207.000000, reward total was -21.000000. running mean: -20.084539\n",
            "resetting env. episode 3208.000000, reward total was -18.000000. running mean: -20.063694\n",
            "resetting env. episode 3209.000000, reward total was -21.000000. running mean: -20.073057\n",
            "resetting env. episode 3210.000000, reward total was -20.000000. running mean: -20.072326\n",
            "resetting env. episode 3211.000000, reward total was -20.000000. running mean: -20.071603\n",
            "resetting env. episode 3212.000000, reward total was -20.000000. running mean: -20.070887\n",
            "resetting env. episode 3213.000000, reward total was -20.000000. running mean: -20.070178\n",
            "resetting env. episode 3214.000000, reward total was -20.000000. running mean: -20.069476\n",
            "resetting env. episode 3215.000000, reward total was -20.000000. running mean: -20.068781\n",
            "resetting env. episode 3216.000000, reward total was -20.000000. running mean: -20.068094\n",
            "resetting env. episode 3217.000000, reward total was -21.000000. running mean: -20.077413\n",
            "resetting env. episode 3218.000000, reward total was -19.000000. running mean: -20.066639\n",
            "resetting env. episode 3219.000000, reward total was -19.000000. running mean: -20.055972\n",
            "resetting env. episode 3220.000000, reward total was -21.000000. running mean: -20.065412\n",
            "resetting env. episode 3221.000000, reward total was -21.000000. running mean: -20.074758\n",
            "resetting env. episode 3222.000000, reward total was -21.000000. running mean: -20.084011\n",
            "resetting env. episode 3223.000000, reward total was -21.000000. running mean: -20.093171\n",
            "resetting env. episode 3224.000000, reward total was -20.000000. running mean: -20.092239\n",
            "resetting env. episode 3225.000000, reward total was -20.000000. running mean: -20.091317\n",
            "resetting env. episode 3226.000000, reward total was -19.000000. running mean: -20.080403\n",
            "resetting env. episode 3227.000000, reward total was -21.000000. running mean: -20.089599\n",
            "resetting env. episode 3228.000000, reward total was -19.000000. running mean: -20.078703\n",
            "resetting env. episode 3229.000000, reward total was -21.000000. running mean: -20.087916\n",
            "resetting env. episode 3230.000000, reward total was -21.000000. running mean: -20.097037\n",
            "resetting env. episode 3231.000000, reward total was -20.000000. running mean: -20.096067\n",
            "resetting env. episode 3232.000000, reward total was -20.000000. running mean: -20.095106\n",
            "resetting env. episode 3233.000000, reward total was -21.000000. running mean: -20.104155\n",
            "resetting env. episode 3234.000000, reward total was -20.000000. running mean: -20.103113\n",
            "resetting env. episode 3235.000000, reward total was -20.000000. running mean: -20.102082\n",
            "resetting env. episode 3236.000000, reward total was -21.000000. running mean: -20.111062\n",
            "resetting env. episode 3237.000000, reward total was -19.000000. running mean: -20.099951\n",
            "resetting env. episode 3238.000000, reward total was -20.000000. running mean: -20.098951\n",
            "resetting env. episode 3239.000000, reward total was -19.000000. running mean: -20.087962\n",
            "resetting env. episode 3240.000000, reward total was -20.000000. running mean: -20.087082\n",
            "resetting env. episode 3241.000000, reward total was -21.000000. running mean: -20.096211\n",
            "resetting env. episode 3242.000000, reward total was -21.000000. running mean: -20.105249\n",
            "resetting env. episode 3243.000000, reward total was -21.000000. running mean: -20.114197\n",
            "resetting env. episode 3244.000000, reward total was -21.000000. running mean: -20.123055\n",
            "resetting env. episode 3245.000000, reward total was -20.000000. running mean: -20.121824\n",
            "resetting env. episode 3246.000000, reward total was -19.000000. running mean: -20.110606\n",
            "resetting env. episode 3247.000000, reward total was -20.000000. running mean: -20.109500\n",
            "resetting env. episode 3248.000000, reward total was -19.000000. running mean: -20.098405\n",
            "resetting env. episode 3249.000000, reward total was -21.000000. running mean: -20.107421\n",
            "resetting env. episode 3250.000000, reward total was -20.000000. running mean: -20.106347\n",
            "resetting env. episode 3251.000000, reward total was -18.000000. running mean: -20.085283\n",
            "resetting env. episode 3252.000000, reward total was -21.000000. running mean: -20.094430\n",
            "resetting env. episode 3253.000000, reward total was -20.000000. running mean: -20.093486\n",
            "resetting env. episode 3254.000000, reward total was -20.000000. running mean: -20.092551\n",
            "resetting env. episode 3255.000000, reward total was -20.000000. running mean: -20.091626\n",
            "resetting env. episode 3256.000000, reward total was -21.000000. running mean: -20.100710\n",
            "resetting env. episode 3257.000000, reward total was -20.000000. running mean: -20.099702\n",
            "resetting env. episode 3258.000000, reward total was -18.000000. running mean: -20.078705\n",
            "resetting env. episode 3259.000000, reward total was -20.000000. running mean: -20.077918\n",
            "resetting env. episode 3260.000000, reward total was -21.000000. running mean: -20.087139\n",
            "resetting env. episode 3261.000000, reward total was -21.000000. running mean: -20.096268\n",
            "resetting env. episode 3262.000000, reward total was -19.000000. running mean: -20.085305\n",
            "resetting env. episode 3263.000000, reward total was -21.000000. running mean: -20.094452\n",
            "resetting env. episode 3264.000000, reward total was -20.000000. running mean: -20.093508\n",
            "resetting env. episode 3265.000000, reward total was -19.000000. running mean: -20.082572\n",
            "resetting env. episode 3266.000000, reward total was -20.000000. running mean: -20.081747\n",
            "resetting env. episode 3267.000000, reward total was -21.000000. running mean: -20.090929\n",
            "resetting env. episode 3268.000000, reward total was -21.000000. running mean: -20.100020\n",
            "resetting env. episode 3269.000000, reward total was -19.000000. running mean: -20.089020\n",
            "resetting env. episode 3270.000000, reward total was -21.000000. running mean: -20.098130\n",
            "resetting env. episode 3271.000000, reward total was -20.000000. running mean: -20.097148\n",
            "resetting env. episode 3272.000000, reward total was -20.000000. running mean: -20.096177\n",
            "resetting env. episode 3273.000000, reward total was -21.000000. running mean: -20.105215\n",
            "resetting env. episode 3274.000000, reward total was -19.000000. running mean: -20.094163\n",
            "resetting env. episode 3275.000000, reward total was -20.000000. running mean: -20.093221\n",
            "resetting env. episode 3276.000000, reward total was -21.000000. running mean: -20.102289\n",
            "resetting env. episode 3277.000000, reward total was -19.000000. running mean: -20.091266\n",
            "resetting env. episode 3278.000000, reward total was -21.000000. running mean: -20.100353\n",
            "resetting env. episode 3279.000000, reward total was -21.000000. running mean: -20.109350\n",
            "resetting env. episode 3280.000000, reward total was -21.000000. running mean: -20.118256\n",
            "resetting env. episode 3281.000000, reward total was -19.000000. running mean: -20.107074\n",
            "resetting env. episode 3282.000000, reward total was -20.000000. running mean: -20.106003\n",
            "resetting env. episode 3283.000000, reward total was -18.000000. running mean: -20.084943\n",
            "resetting env. episode 3284.000000, reward total was -19.000000. running mean: -20.074094\n",
            "resetting env. episode 3285.000000, reward total was -21.000000. running mean: -20.083353\n",
            "resetting env. episode 3286.000000, reward total was -20.000000. running mean: -20.082519\n",
            "resetting env. episode 3287.000000, reward total was -21.000000. running mean: -20.091694\n",
            "resetting env. episode 3288.000000, reward total was -21.000000. running mean: -20.100777\n",
            "resetting env. episode 3289.000000, reward total was -21.000000. running mean: -20.109769\n",
            "resetting env. episode 3290.000000, reward total was -21.000000. running mean: -20.118672\n",
            "resetting env. episode 3291.000000, reward total was -21.000000. running mean: -20.127485\n",
            "resetting env. episode 3292.000000, reward total was -18.000000. running mean: -20.106210\n",
            "resetting env. episode 3293.000000, reward total was -20.000000. running mean: -20.105148\n",
            "resetting env. episode 3294.000000, reward total was -20.000000. running mean: -20.104096\n",
            "resetting env. episode 3295.000000, reward total was -17.000000. running mean: -20.073056\n",
            "resetting env. episode 3296.000000, reward total was -20.000000. running mean: -20.072325\n",
            "resetting env. episode 3297.000000, reward total was -21.000000. running mean: -20.081602\n",
            "resetting env. episode 3298.000000, reward total was -20.000000. running mean: -20.080786\n",
            "resetting env. episode 3299.000000, reward total was -19.000000. running mean: -20.069978\n",
            "resetting env. episode 3300.000000, reward total was -18.000000. running mean: -20.049278\n",
            "resetting env. episode 3301.000000, reward total was -21.000000. running mean: -20.058785\n",
            "resetting env. episode 3302.000000, reward total was -20.000000. running mean: -20.058197\n",
            "resetting env. episode 3303.000000, reward total was -16.000000. running mean: -20.017615\n",
            "resetting env. episode 3304.000000, reward total was -21.000000. running mean: -20.027439\n",
            "resetting env. episode 3305.000000, reward total was -19.000000. running mean: -20.017165\n",
            "resetting env. episode 3306.000000, reward total was -21.000000. running mean: -20.026993\n",
            "resetting env. episode 3307.000000, reward total was -21.000000. running mean: -20.036723\n",
            "resetting env. episode 3308.000000, reward total was -21.000000. running mean: -20.046356\n",
            "resetting env. episode 3309.000000, reward total was -20.000000. running mean: -20.045893\n",
            "resetting env. episode 3310.000000, reward total was -21.000000. running mean: -20.055434\n",
            "resetting env. episode 3311.000000, reward total was -18.000000. running mean: -20.034879\n",
            "resetting env. episode 3312.000000, reward total was -21.000000. running mean: -20.044530\n",
            "resetting env. episode 3313.000000, reward total was -21.000000. running mean: -20.054085\n",
            "resetting env. episode 3314.000000, reward total was -19.000000. running mean: -20.043544\n",
            "resetting env. episode 3315.000000, reward total was -19.000000. running mean: -20.033109\n",
            "resetting env. episode 3316.000000, reward total was -17.000000. running mean: -20.002778\n",
            "resetting env. episode 3317.000000, reward total was -21.000000. running mean: -20.012750\n",
            "resetting env. episode 3318.000000, reward total was -21.000000. running mean: -20.022623\n",
            "resetting env. episode 3319.000000, reward total was -21.000000. running mean: -20.032396\n",
            "resetting env. episode 3320.000000, reward total was -21.000000. running mean: -20.042072\n",
            "resetting env. episode 3321.000000, reward total was -20.000000. running mean: -20.041652\n",
            "resetting env. episode 3322.000000, reward total was -19.000000. running mean: -20.031235\n",
            "resetting env. episode 3323.000000, reward total was -18.000000. running mean: -20.010923\n",
            "resetting env. episode 3324.000000, reward total was -20.000000. running mean: -20.010813\n",
            "resetting env. episode 3325.000000, reward total was -21.000000. running mean: -20.020705\n",
            "resetting env. episode 3326.000000, reward total was -21.000000. running mean: -20.030498\n",
            "resetting env. episode 3327.000000, reward total was -21.000000. running mean: -20.040193\n",
            "resetting env. episode 3328.000000, reward total was -20.000000. running mean: -20.039791\n",
            "resetting env. episode 3329.000000, reward total was -19.000000. running mean: -20.029393\n",
            "resetting env. episode 3330.000000, reward total was -20.000000. running mean: -20.029100\n",
            "resetting env. episode 3331.000000, reward total was -20.000000. running mean: -20.028809\n",
            "resetting env. episode 3332.000000, reward total was -20.000000. running mean: -20.028520\n",
            "resetting env. episode 3333.000000, reward total was -21.000000. running mean: -20.038235\n",
            "resetting env. episode 3334.000000, reward total was -21.000000. running mean: -20.047853\n",
            "resetting env. episode 3335.000000, reward total was -19.000000. running mean: -20.037374\n",
            "resetting env. episode 3336.000000, reward total was -16.000000. running mean: -19.997001\n",
            "resetting env. episode 3337.000000, reward total was -21.000000. running mean: -20.007031\n",
            "resetting env. episode 3338.000000, reward total was -20.000000. running mean: -20.006960\n",
            "resetting env. episode 3339.000000, reward total was -20.000000. running mean: -20.006891\n",
            "resetting env. episode 3340.000000, reward total was -16.000000. running mean: -19.966822\n",
            "resetting env. episode 3341.000000, reward total was -21.000000. running mean: -19.977154\n",
            "resetting env. episode 3342.000000, reward total was -19.000000. running mean: -19.967382\n",
            "resetting env. episode 3343.000000, reward total was -21.000000. running mean: -19.977708\n",
            "resetting env. episode 3344.000000, reward total was -20.000000. running mean: -19.977931\n",
            "resetting env. episode 3345.000000, reward total was -20.000000. running mean: -19.978152\n",
            "resetting env. episode 3346.000000, reward total was -21.000000. running mean: -19.988370\n",
            "resetting env. episode 3347.000000, reward total was -20.000000. running mean: -19.988487\n",
            "resetting env. episode 3348.000000, reward total was -20.000000. running mean: -19.988602\n",
            "resetting env. episode 3349.000000, reward total was -20.000000. running mean: -19.988716\n",
            "resetting env. episode 3350.000000, reward total was -21.000000. running mean: -19.998829\n",
            "resetting env. episode 3351.000000, reward total was -21.000000. running mean: -20.008840\n",
            "resetting env. episode 3352.000000, reward total was -20.000000. running mean: -20.008752\n",
            "resetting env. episode 3353.000000, reward total was -19.000000. running mean: -19.998664\n",
            "resetting env. episode 3354.000000, reward total was -21.000000. running mean: -20.008678\n",
            "resetting env. episode 3355.000000, reward total was -19.000000. running mean: -19.998591\n",
            "resetting env. episode 3356.000000, reward total was -19.000000. running mean: -19.988605\n",
            "resetting env. episode 3357.000000, reward total was -21.000000. running mean: -19.998719\n",
            "resetting env. episode 3358.000000, reward total was -20.000000. running mean: -19.998732\n",
            "resetting env. episode 3359.000000, reward total was -18.000000. running mean: -19.978744\n",
            "resetting env. episode 3360.000000, reward total was -20.000000. running mean: -19.978957\n",
            "resetting env. episode 3361.000000, reward total was -20.000000. running mean: -19.979167\n",
            "resetting env. episode 3362.000000, reward total was -19.000000. running mean: -19.969376\n",
            "resetting env. episode 3363.000000, reward total was -20.000000. running mean: -19.969682\n",
            "resetting env. episode 3364.000000, reward total was -21.000000. running mean: -19.979985\n",
            "resetting env. episode 3365.000000, reward total was -20.000000. running mean: -19.980185\n",
            "resetting env. episode 3366.000000, reward total was -18.000000. running mean: -19.960384\n",
            "resetting env. episode 3367.000000, reward total was -21.000000. running mean: -19.970780\n",
            "resetting env. episode 3368.000000, reward total was -20.000000. running mean: -19.971072\n",
            "resetting env. episode 3369.000000, reward total was -20.000000. running mean: -19.971361\n",
            "resetting env. episode 3370.000000, reward total was -20.000000. running mean: -19.971648\n",
            "resetting env. episode 3371.000000, reward total was -20.000000. running mean: -19.971931\n",
            "resetting env. episode 3372.000000, reward total was -21.000000. running mean: -19.982212\n",
            "resetting env. episode 3373.000000, reward total was -21.000000. running mean: -19.992390\n",
            "resetting env. episode 3374.000000, reward total was -20.000000. running mean: -19.992466\n",
            "resetting env. episode 3375.000000, reward total was -21.000000. running mean: -20.002541\n",
            "resetting env. episode 3376.000000, reward total was -21.000000. running mean: -20.012516\n",
            "resetting env. episode 3377.000000, reward total was -21.000000. running mean: -20.022391\n",
            "resetting env. episode 3378.000000, reward total was -21.000000. running mean: -20.032167\n",
            "resetting env. episode 3379.000000, reward total was -20.000000. running mean: -20.031845\n",
            "resetting env. episode 3380.000000, reward total was -20.000000. running mean: -20.031527\n",
            "resetting env. episode 3381.000000, reward total was -21.000000. running mean: -20.041211\n",
            "resetting env. episode 3382.000000, reward total was -19.000000. running mean: -20.030799\n",
            "resetting env. episode 3383.000000, reward total was -21.000000. running mean: -20.040491\n",
            "resetting env. episode 3384.000000, reward total was -21.000000. running mean: -20.050086\n",
            "resetting env. episode 3385.000000, reward total was -19.000000. running mean: -20.039585\n",
            "resetting env. episode 3386.000000, reward total was -20.000000. running mean: -20.039190\n",
            "resetting env. episode 3387.000000, reward total was -21.000000. running mean: -20.048798\n",
            "resetting env. episode 3388.000000, reward total was -21.000000. running mean: -20.058310\n",
            "resetting env. episode 3389.000000, reward total was -19.000000. running mean: -20.047727\n",
            "resetting env. episode 3390.000000, reward total was -19.000000. running mean: -20.037249\n",
            "resetting env. episode 3391.000000, reward total was -21.000000. running mean: -20.046877\n",
            "resetting env. episode 3392.000000, reward total was -21.000000. running mean: -20.056408\n",
            "resetting env. episode 3393.000000, reward total was -21.000000. running mean: -20.065844\n",
            "resetting env. episode 3394.000000, reward total was -19.000000. running mean: -20.055185\n",
            "resetting env. episode 3395.000000, reward total was -17.000000. running mean: -20.024634\n",
            "resetting env. episode 3396.000000, reward total was -20.000000. running mean: -20.024387\n",
            "resetting env. episode 3397.000000, reward total was -20.000000. running mean: -20.024143\n",
            "resetting env. episode 3398.000000, reward total was -20.000000. running mean: -20.023902\n",
            "resetting env. episode 3399.000000, reward total was -19.000000. running mean: -20.013663\n",
            "resetting env. episode 3400.000000, reward total was -20.000000. running mean: -20.013526\n",
            "resetting env. episode 3401.000000, reward total was -20.000000. running mean: -20.013391\n",
            "resetting env. episode 3402.000000, reward total was -21.000000. running mean: -20.023257\n",
            "resetting env. episode 3403.000000, reward total was -21.000000. running mean: -20.033025\n",
            "resetting env. episode 3404.000000, reward total was -19.000000. running mean: -20.022694\n",
            "resetting env. episode 3405.000000, reward total was -19.000000. running mean: -20.012467\n",
            "resetting env. episode 3406.000000, reward total was -18.000000. running mean: -19.992343\n",
            "resetting env. episode 3407.000000, reward total was -20.000000. running mean: -19.992419\n",
            "resetting env. episode 3408.000000, reward total was -18.000000. running mean: -19.972495\n",
            "resetting env. episode 3409.000000, reward total was -21.000000. running mean: -19.982770\n",
            "resetting env. episode 3410.000000, reward total was -20.000000. running mean: -19.982942\n",
            "resetting env. episode 3411.000000, reward total was -19.000000. running mean: -19.973113\n",
            "resetting env. episode 3412.000000, reward total was -21.000000. running mean: -19.983382\n",
            "resetting env. episode 3413.000000, reward total was -20.000000. running mean: -19.983548\n",
            "resetting env. episode 3414.000000, reward total was -21.000000. running mean: -19.993713\n",
            "resetting env. episode 3415.000000, reward total was -19.000000. running mean: -19.983775\n",
            "resetting env. episode 3416.000000, reward total was -21.000000. running mean: -19.993938\n",
            "resetting env. episode 3417.000000, reward total was -19.000000. running mean: -19.983998\n",
            "resetting env. episode 3418.000000, reward total was -21.000000. running mean: -19.994158\n",
            "resetting env. episode 3419.000000, reward total was -19.000000. running mean: -19.984217\n",
            "resetting env. episode 3420.000000, reward total was -21.000000. running mean: -19.994375\n",
            "resetting env. episode 3421.000000, reward total was -20.000000. running mean: -19.994431\n",
            "resetting env. episode 3422.000000, reward total was -20.000000. running mean: -19.994487\n",
            "resetting env. episode 3423.000000, reward total was -18.000000. running mean: -19.974542\n",
            "resetting env. episode 3424.000000, reward total was -17.000000. running mean: -19.944796\n",
            "resetting env. episode 3425.000000, reward total was -21.000000. running mean: -19.955348\n",
            "resetting env. episode 3426.000000, reward total was -21.000000. running mean: -19.965795\n",
            "resetting env. episode 3427.000000, reward total was -21.000000. running mean: -19.976137\n",
            "resetting env. episode 3428.000000, reward total was -20.000000. running mean: -19.976376\n",
            "resetting env. episode 3429.000000, reward total was -19.000000. running mean: -19.966612\n",
            "resetting env. episode 3430.000000, reward total was -19.000000. running mean: -19.956946\n",
            "resetting env. episode 3431.000000, reward total was -21.000000. running mean: -19.967376\n",
            "resetting env. episode 3432.000000, reward total was -21.000000. running mean: -19.977702\n",
            "resetting env. episode 3433.000000, reward total was -21.000000. running mean: -19.987925\n",
            "resetting env. episode 3434.000000, reward total was -21.000000. running mean: -19.998046\n",
            "resetting env. episode 3435.000000, reward total was -19.000000. running mean: -19.988066\n",
            "resetting env. episode 3436.000000, reward total was -21.000000. running mean: -19.998185\n",
            "resetting env. episode 3437.000000, reward total was -21.000000. running mean: -20.008203\n",
            "resetting env. episode 3438.000000, reward total was -18.000000. running mean: -19.988121\n",
            "resetting env. episode 3439.000000, reward total was -21.000000. running mean: -19.998240\n",
            "resetting env. episode 3440.000000, reward total was -21.000000. running mean: -20.008258\n",
            "resetting env. episode 3441.000000, reward total was -21.000000. running mean: -20.018175\n",
            "resetting env. episode 3442.000000, reward total was -21.000000. running mean: -20.027993\n",
            "resetting env. episode 3443.000000, reward total was -21.000000. running mean: -20.037713\n",
            "resetting env. episode 3444.000000, reward total was -19.000000. running mean: -20.027336\n",
            "resetting env. episode 3445.000000, reward total was -19.000000. running mean: -20.017063\n",
            "resetting env. episode 3446.000000, reward total was -17.000000. running mean: -19.986892\n",
            "resetting env. episode 3447.000000, reward total was -19.000000. running mean: -19.977023\n",
            "resetting env. episode 3448.000000, reward total was -20.000000. running mean: -19.977253\n",
            "resetting env. episode 3449.000000, reward total was -20.000000. running mean: -19.977480\n",
            "resetting env. episode 3450.000000, reward total was -20.000000. running mean: -19.977706\n",
            "resetting env. episode 3451.000000, reward total was -19.000000. running mean: -19.967929\n",
            "resetting env. episode 3452.000000, reward total was -21.000000. running mean: -19.978249\n",
            "resetting env. episode 3453.000000, reward total was -19.000000. running mean: -19.968467\n",
            "resetting env. episode 3454.000000, reward total was -19.000000. running mean: -19.958782\n",
            "resetting env. episode 3455.000000, reward total was -21.000000. running mean: -19.969194\n",
            "resetting env. episode 3456.000000, reward total was -20.000000. running mean: -19.969502\n",
            "resetting env. episode 3457.000000, reward total was -20.000000. running mean: -19.969807\n",
            "resetting env. episode 3458.000000, reward total was -20.000000. running mean: -19.970109\n",
            "resetting env. episode 3459.000000, reward total was -20.000000. running mean: -19.970408\n",
            "resetting env. episode 3460.000000, reward total was -21.000000. running mean: -19.980704\n",
            "resetting env. episode 3461.000000, reward total was -18.000000. running mean: -19.960897\n",
            "resetting env. episode 3462.000000, reward total was -19.000000. running mean: -19.951288\n",
            "resetting env. episode 3463.000000, reward total was -21.000000. running mean: -19.961775\n",
            "resetting env. episode 3464.000000, reward total was -21.000000. running mean: -19.972157\n",
            "resetting env. episode 3465.000000, reward total was -21.000000. running mean: -19.982436\n",
            "resetting env. episode 3466.000000, reward total was -20.000000. running mean: -19.982612\n",
            "resetting env. episode 3467.000000, reward total was -20.000000. running mean: -19.982785\n",
            "resetting env. episode 3468.000000, reward total was -20.000000. running mean: -19.982958\n",
            "resetting env. episode 3469.000000, reward total was -21.000000. running mean: -19.993128\n",
            "resetting env. episode 3470.000000, reward total was -20.000000. running mean: -19.993197\n",
            "resetting env. episode 3471.000000, reward total was -21.000000. running mean: -20.003265\n",
            "resetting env. episode 3472.000000, reward total was -20.000000. running mean: -20.003232\n",
            "resetting env. episode 3473.000000, reward total was -21.000000. running mean: -20.013200\n",
            "resetting env. episode 3474.000000, reward total was -21.000000. running mean: -20.023068\n",
            "resetting env. episode 3475.000000, reward total was -20.000000. running mean: -20.022837\n",
            "resetting env. episode 3476.000000, reward total was -21.000000. running mean: -20.032609\n",
            "resetting env. episode 3477.000000, reward total was -21.000000. running mean: -20.042283\n",
            "resetting env. episode 3478.000000, reward total was -21.000000. running mean: -20.051860\n",
            "resetting env. episode 3479.000000, reward total was -19.000000. running mean: -20.041341\n",
            "resetting env. episode 3480.000000, reward total was -20.000000. running mean: -20.040928\n",
            "resetting env. episode 3481.000000, reward total was -21.000000. running mean: -20.050519\n",
            "resetting env. episode 3482.000000, reward total was -17.000000. running mean: -20.020013\n",
            "resetting env. episode 3483.000000, reward total was -20.000000. running mean: -20.019813\n",
            "resetting env. episode 3484.000000, reward total was -21.000000. running mean: -20.029615\n",
            "resetting env. episode 3485.000000, reward total was -20.000000. running mean: -20.029319\n",
            "resetting env. episode 3486.000000, reward total was -19.000000. running mean: -20.019026\n",
            "resetting env. episode 3487.000000, reward total was -20.000000. running mean: -20.018835\n",
            "resetting env. episode 3488.000000, reward total was -21.000000. running mean: -20.028647\n",
            "resetting env. episode 3489.000000, reward total was -20.000000. running mean: -20.028361\n",
            "resetting env. episode 3490.000000, reward total was -20.000000. running mean: -20.028077\n",
            "resetting env. episode 3491.000000, reward total was -18.000000. running mean: -20.007796\n",
            "resetting env. episode 3492.000000, reward total was -21.000000. running mean: -20.017718\n",
            "resetting env. episode 3493.000000, reward total was -19.000000. running mean: -20.007541\n",
            "resetting env. episode 3494.000000, reward total was -20.000000. running mean: -20.007466\n",
            "resetting env. episode 3495.000000, reward total was -21.000000. running mean: -20.017391\n",
            "resetting env. episode 3496.000000, reward total was -19.000000. running mean: -20.007217\n",
            "resetting env. episode 3497.000000, reward total was -19.000000. running mean: -19.997145\n",
            "resetting env. episode 3498.000000, reward total was -21.000000. running mean: -20.007174\n",
            "resetting env. episode 3499.000000, reward total was -21.000000. running mean: -20.017102\n",
            "resetting env. episode 3500.000000, reward total was -18.000000. running mean: -19.996931\n",
            "resetting env. episode 3501.000000, reward total was -20.000000. running mean: -19.996961\n",
            "resetting env. episode 3502.000000, reward total was -17.000000. running mean: -19.966992\n",
            "resetting env. episode 3503.000000, reward total was -20.000000. running mean: -19.967322\n",
            "resetting env. episode 3504.000000, reward total was -21.000000. running mean: -19.977649\n",
            "resetting env. episode 3505.000000, reward total was -20.000000. running mean: -19.977872\n",
            "resetting env. episode 3506.000000, reward total was -21.000000. running mean: -19.988094\n",
            "resetting env. episode 3507.000000, reward total was -21.000000. running mean: -19.998213\n",
            "resetting env. episode 3508.000000, reward total was -21.000000. running mean: -20.008230\n",
            "resetting env. episode 3509.000000, reward total was -21.000000. running mean: -20.018148\n",
            "resetting env. episode 3510.000000, reward total was -19.000000. running mean: -20.007967\n",
            "resetting env. episode 3511.000000, reward total was -21.000000. running mean: -20.017887\n",
            "resetting env. episode 3512.000000, reward total was -21.000000. running mean: -20.027708\n",
            "resetting env. episode 3513.000000, reward total was -21.000000. running mean: -20.037431\n",
            "resetting env. episode 3514.000000, reward total was -21.000000. running mean: -20.047057\n",
            "resetting env. episode 3515.000000, reward total was -18.000000. running mean: -20.026586\n",
            "resetting env. episode 3516.000000, reward total was -19.000000. running mean: -20.016320\n",
            "resetting env. episode 3517.000000, reward total was -18.000000. running mean: -19.996157\n",
            "resetting env. episode 3518.000000, reward total was -20.000000. running mean: -19.996196\n",
            "resetting env. episode 3519.000000, reward total was -21.000000. running mean: -20.006234\n",
            "resetting env. episode 3520.000000, reward total was -21.000000. running mean: -20.016171\n",
            "resetting env. episode 3521.000000, reward total was -19.000000. running mean: -20.006010\n",
            "resetting env. episode 3522.000000, reward total was -21.000000. running mean: -20.015949\n",
            "resetting env. episode 3523.000000, reward total was -20.000000. running mean: -20.015790\n",
            "resetting env. episode 3524.000000, reward total was -21.000000. running mean: -20.025632\n",
            "resetting env. episode 3525.000000, reward total was -21.000000. running mean: -20.035376\n",
            "resetting env. episode 3526.000000, reward total was -21.000000. running mean: -20.045022\n",
            "resetting env. episode 3527.000000, reward total was -19.000000. running mean: -20.034572\n",
            "resetting env. episode 3528.000000, reward total was -21.000000. running mean: -20.044226\n",
            "resetting env. episode 3529.000000, reward total was -19.000000. running mean: -20.033784\n",
            "resetting env. episode 3530.000000, reward total was -19.000000. running mean: -20.023446\n",
            "resetting env. episode 3531.000000, reward total was -21.000000. running mean: -20.033211\n",
            "resetting env. episode 3532.000000, reward total was -21.000000. running mean: -20.042879\n",
            "resetting env. episode 3533.000000, reward total was -20.000000. running mean: -20.042451\n",
            "resetting env. episode 3534.000000, reward total was -19.000000. running mean: -20.032026\n",
            "resetting env. episode 3535.000000, reward total was -21.000000. running mean: -20.041706\n",
            "resetting env. episode 3536.000000, reward total was -19.000000. running mean: -20.031289\n",
            "resetting env. episode 3537.000000, reward total was -20.000000. running mean: -20.030976\n",
            "resetting env. episode 3538.000000, reward total was -20.000000. running mean: -20.030666\n",
            "resetting env. episode 3539.000000, reward total was -20.000000. running mean: -20.030359\n",
            "resetting env. episode 3540.000000, reward total was -21.000000. running mean: -20.040056\n",
            "resetting env. episode 3541.000000, reward total was -21.000000. running mean: -20.049655\n",
            "resetting env. episode 3542.000000, reward total was -20.000000. running mean: -20.049159\n",
            "resetting env. episode 3543.000000, reward total was -21.000000. running mean: -20.058667\n",
            "resetting env. episode 3544.000000, reward total was -18.000000. running mean: -20.038080\n",
            "resetting env. episode 3545.000000, reward total was -20.000000. running mean: -20.037700\n",
            "resetting env. episode 3546.000000, reward total was -19.000000. running mean: -20.027323\n",
            "resetting env. episode 3547.000000, reward total was -20.000000. running mean: -20.027049\n",
            "resetting env. episode 3548.000000, reward total was -17.000000. running mean: -19.996779\n",
            "resetting env. episode 3549.000000, reward total was -19.000000. running mean: -19.986811\n",
            "resetting env. episode 3550.000000, reward total was -20.000000. running mean: -19.986943\n",
            "resetting env. episode 3551.000000, reward total was -20.000000. running mean: -19.987074\n",
            "resetting env. episode 3552.000000, reward total was -21.000000. running mean: -19.997203\n",
            "resetting env. episode 3553.000000, reward total was -18.000000. running mean: -19.977231\n",
            "resetting env. episode 3554.000000, reward total was -21.000000. running mean: -19.987459\n",
            "resetting env. episode 3555.000000, reward total was -20.000000. running mean: -19.987584\n",
            "resetting env. episode 3556.000000, reward total was -21.000000. running mean: -19.997708\n",
            "resetting env. episode 3557.000000, reward total was -17.000000. running mean: -19.967731\n",
            "resetting env. episode 3558.000000, reward total was -20.000000. running mean: -19.968054\n",
            "resetting env. episode 3559.000000, reward total was -21.000000. running mean: -19.978373\n",
            "resetting env. episode 3560.000000, reward total was -20.000000. running mean: -19.978589\n",
            "resetting env. episode 3561.000000, reward total was -21.000000. running mean: -19.988804\n",
            "resetting env. episode 3562.000000, reward total was -21.000000. running mean: -19.998916\n",
            "resetting env. episode 3563.000000, reward total was -21.000000. running mean: -20.008926\n",
            "resetting env. episode 3564.000000, reward total was -19.000000. running mean: -19.998837\n",
            "resetting env. episode 3565.000000, reward total was -20.000000. running mean: -19.998849\n",
            "resetting env. episode 3566.000000, reward total was -21.000000. running mean: -20.008860\n",
            "resetting env. episode 3567.000000, reward total was -21.000000. running mean: -20.018772\n",
            "resetting env. episode 3568.000000, reward total was -20.000000. running mean: -20.018584\n",
            "resetting env. episode 3569.000000, reward total was -19.000000. running mean: -20.008398\n",
            "resetting env. episode 3570.000000, reward total was -21.000000. running mean: -20.018314\n",
            "resetting env. episode 3571.000000, reward total was -21.000000. running mean: -20.028131\n",
            "resetting env. episode 3572.000000, reward total was -21.000000. running mean: -20.037850\n",
            "resetting env. episode 3573.000000, reward total was -19.000000. running mean: -20.027471\n",
            "resetting env. episode 3574.000000, reward total was -21.000000. running mean: -20.037196\n",
            "resetting env. episode 3575.000000, reward total was -21.000000. running mean: -20.046824\n",
            "resetting env. episode 3576.000000, reward total was -20.000000. running mean: -20.046356\n",
            "resetting env. episode 3577.000000, reward total was -21.000000. running mean: -20.055893\n",
            "resetting env. episode 3578.000000, reward total was -21.000000. running mean: -20.065334\n",
            "resetting env. episode 3579.000000, reward total was -21.000000. running mean: -20.074680\n",
            "resetting env. episode 3580.000000, reward total was -20.000000. running mean: -20.073934\n",
            "resetting env. episode 3581.000000, reward total was -18.000000. running mean: -20.053194\n",
            "resetting env. episode 3582.000000, reward total was -20.000000. running mean: -20.052662\n",
            "resetting env. episode 3583.000000, reward total was -20.000000. running mean: -20.052136\n",
            "resetting env. episode 3584.000000, reward total was -19.000000. running mean: -20.041614\n",
            "resetting env. episode 3585.000000, reward total was -21.000000. running mean: -20.051198\n",
            "resetting env. episode 3586.000000, reward total was -19.000000. running mean: -20.040686\n",
            "resetting env. episode 3587.000000, reward total was -21.000000. running mean: -20.050279\n",
            "resetting env. episode 3588.000000, reward total was -20.000000. running mean: -20.049777\n",
            "resetting env. episode 3589.000000, reward total was -19.000000. running mean: -20.039279\n",
            "resetting env. episode 3590.000000, reward total was -21.000000. running mean: -20.048886\n",
            "resetting env. episode 3591.000000, reward total was -21.000000. running mean: -20.058397\n",
            "resetting env. episode 3592.000000, reward total was -17.000000. running mean: -20.027813\n",
            "resetting env. episode 3593.000000, reward total was -20.000000. running mean: -20.027535\n",
            "resetting env. episode 3594.000000, reward total was -21.000000. running mean: -20.037260\n",
            "resetting env. episode 3595.000000, reward total was -19.000000. running mean: -20.026887\n",
            "resetting env. episode 3596.000000, reward total was -16.000000. running mean: -19.986618\n",
            "resetting env. episode 3597.000000, reward total was -21.000000. running mean: -19.996752\n",
            "resetting env. episode 3598.000000, reward total was -20.000000. running mean: -19.996785\n",
            "resetting env. episode 3599.000000, reward total was -19.000000. running mean: -19.986817\n",
            "resetting env. episode 3600.000000, reward total was -21.000000. running mean: -19.996949\n",
            "resetting env. episode 3601.000000, reward total was -19.000000. running mean: -19.986979\n",
            "resetting env. episode 3602.000000, reward total was -21.000000. running mean: -19.997109\n",
            "resetting env. episode 3603.000000, reward total was -21.000000. running mean: -20.007138\n",
            "resetting env. episode 3604.000000, reward total was -20.000000. running mean: -20.007067\n",
            "resetting env. episode 3605.000000, reward total was -15.000000. running mean: -19.956996\n",
            "resetting env. episode 3606.000000, reward total was -20.000000. running mean: -19.957426\n",
            "resetting env. episode 3607.000000, reward total was -19.000000. running mean: -19.947852\n",
            "resetting env. episode 3608.000000, reward total was -21.000000. running mean: -19.958373\n",
            "resetting env. episode 3609.000000, reward total was -20.000000. running mean: -19.958790\n",
            "resetting env. episode 3610.000000, reward total was -21.000000. running mean: -19.969202\n",
            "resetting env. episode 3611.000000, reward total was -20.000000. running mean: -19.969510\n",
            "resetting env. episode 3612.000000, reward total was -21.000000. running mean: -19.979815\n",
            "resetting env. episode 3613.000000, reward total was -20.000000. running mean: -19.980016\n",
            "resetting env. episode 3614.000000, reward total was -18.000000. running mean: -19.960216\n",
            "resetting env. episode 3615.000000, reward total was -21.000000. running mean: -19.970614\n",
            "resetting env. episode 3616.000000, reward total was -21.000000. running mean: -19.980908\n",
            "resetting env. episode 3617.000000, reward total was -20.000000. running mean: -19.981099\n",
            "resetting env. episode 3618.000000, reward total was -18.000000. running mean: -19.961288\n",
            "resetting env. episode 3619.000000, reward total was -21.000000. running mean: -19.971675\n",
            "resetting env. episode 3620.000000, reward total was -20.000000. running mean: -19.971958\n",
            "resetting env. episode 3621.000000, reward total was -19.000000. running mean: -19.962239\n",
            "resetting env. episode 3622.000000, reward total was -20.000000. running mean: -19.962616\n",
            "resetting env. episode 3623.000000, reward total was -19.000000. running mean: -19.952990\n",
            "resetting env. episode 3624.000000, reward total was -20.000000. running mean: -19.953460\n",
            "resetting env. episode 3625.000000, reward total was -21.000000. running mean: -19.963926\n",
            "resetting env. episode 3626.000000, reward total was -19.000000. running mean: -19.954286\n",
            "resetting env. episode 3627.000000, reward total was -21.000000. running mean: -19.964744\n",
            "resetting env. episode 3628.000000, reward total was -19.000000. running mean: -19.955096\n",
            "resetting env. episode 3629.000000, reward total was -21.000000. running mean: -19.965545\n",
            "resetting env. episode 3630.000000, reward total was -18.000000. running mean: -19.945890\n",
            "resetting env. episode 3631.000000, reward total was -21.000000. running mean: -19.956431\n",
            "resetting env. episode 3632.000000, reward total was -20.000000. running mean: -19.956866\n",
            "resetting env. episode 3633.000000, reward total was -21.000000. running mean: -19.967298\n",
            "resetting env. episode 3634.000000, reward total was -19.000000. running mean: -19.957625\n",
            "resetting env. episode 3635.000000, reward total was -19.000000. running mean: -19.948049\n",
            "resetting env. episode 3636.000000, reward total was -21.000000. running mean: -19.958568\n",
            "resetting env. episode 3637.000000, reward total was -19.000000. running mean: -19.948982\n",
            "resetting env. episode 3638.000000, reward total was -15.000000. running mean: -19.899493\n",
            "resetting env. episode 3639.000000, reward total was -20.000000. running mean: -19.900498\n",
            "resetting env. episode 3640.000000, reward total was -19.000000. running mean: -19.891493\n",
            "resetting env. episode 3641.000000, reward total was -21.000000. running mean: -19.902578\n",
            "resetting env. episode 3642.000000, reward total was -18.000000. running mean: -19.883552\n",
            "resetting env. episode 3643.000000, reward total was -21.000000. running mean: -19.894716\n",
            "resetting env. episode 3644.000000, reward total was -20.000000. running mean: -19.895769\n",
            "resetting env. episode 3645.000000, reward total was -21.000000. running mean: -19.906812\n",
            "resetting env. episode 3646.000000, reward total was -18.000000. running mean: -19.887744\n",
            "resetting env. episode 3647.000000, reward total was -19.000000. running mean: -19.878866\n",
            "resetting env. episode 3648.000000, reward total was -21.000000. running mean: -19.890077\n",
            "resetting env. episode 3649.000000, reward total was -21.000000. running mean: -19.901177\n",
            "resetting env. episode 3650.000000, reward total was -18.000000. running mean: -19.882165\n",
            "resetting env. episode 3651.000000, reward total was -18.000000. running mean: -19.863343\n",
            "resetting env. episode 3652.000000, reward total was -20.000000. running mean: -19.864710\n",
            "resetting env. episode 3653.000000, reward total was -20.000000. running mean: -19.866063\n",
            "resetting env. episode 3654.000000, reward total was -19.000000. running mean: -19.857402\n",
            "resetting env. episode 3655.000000, reward total was -20.000000. running mean: -19.858828\n",
            "resetting env. episode 3656.000000, reward total was -18.000000. running mean: -19.840240\n",
            "resetting env. episode 3657.000000, reward total was -21.000000. running mean: -19.851837\n",
            "resetting env. episode 3658.000000, reward total was -20.000000. running mean: -19.853319\n",
            "resetting env. episode 3659.000000, reward total was -21.000000. running mean: -19.864786\n",
            "resetting env. episode 3660.000000, reward total was -21.000000. running mean: -19.876138\n",
            "resetting env. episode 3661.000000, reward total was -20.000000. running mean: -19.877377\n",
            "resetting env. episode 3662.000000, reward total was -20.000000. running mean: -19.878603\n",
            "resetting env. episode 3663.000000, reward total was -21.000000. running mean: -19.889817\n",
            "resetting env. episode 3664.000000, reward total was -20.000000. running mean: -19.890919\n",
            "resetting env. episode 3665.000000, reward total was -19.000000. running mean: -19.882009\n",
            "resetting env. episode 3666.000000, reward total was -21.000000. running mean: -19.893189\n",
            "resetting env. episode 3667.000000, reward total was -19.000000. running mean: -19.884257\n",
            "resetting env. episode 3668.000000, reward total was -20.000000. running mean: -19.885415\n",
            "resetting env. episode 3669.000000, reward total was -21.000000. running mean: -19.896561\n",
            "resetting env. episode 3670.000000, reward total was -19.000000. running mean: -19.887595\n",
            "resetting env. episode 3671.000000, reward total was -19.000000. running mean: -19.878719\n",
            "resetting env. episode 3672.000000, reward total was -21.000000. running mean: -19.889932\n",
            "resetting env. episode 3673.000000, reward total was -20.000000. running mean: -19.891033\n",
            "resetting env. episode 3674.000000, reward total was -21.000000. running mean: -19.902122\n",
            "resetting env. episode 3675.000000, reward total was -21.000000. running mean: -19.913101\n",
            "resetting env. episode 3676.000000, reward total was -20.000000. running mean: -19.913970\n",
            "resetting env. episode 3677.000000, reward total was -20.000000. running mean: -19.914830\n",
            "resetting env. episode 3678.000000, reward total was -19.000000. running mean: -19.905682\n",
            "resetting env. episode 3679.000000, reward total was -21.000000. running mean: -19.916625\n",
            "resetting env. episode 3680.000000, reward total was -21.000000. running mean: -19.927459\n",
            "resetting env. episode 3681.000000, reward total was -21.000000. running mean: -19.938184\n",
            "resetting env. episode 3682.000000, reward total was -19.000000. running mean: -19.928803\n",
            "resetting env. episode 3683.000000, reward total was -19.000000. running mean: -19.919515\n",
            "resetting env. episode 3684.000000, reward total was -16.000000. running mean: -19.880319\n",
            "resetting env. episode 3685.000000, reward total was -21.000000. running mean: -19.891516\n",
            "resetting env. episode 3686.000000, reward total was -19.000000. running mean: -19.882601\n",
            "resetting env. episode 3687.000000, reward total was -18.000000. running mean: -19.863775\n",
            "resetting env. episode 3688.000000, reward total was -21.000000. running mean: -19.875137\n",
            "resetting env. episode 3689.000000, reward total was -21.000000. running mean: -19.886386\n",
            "resetting env. episode 3690.000000, reward total was -20.000000. running mean: -19.887522\n",
            "resetting env. episode 3691.000000, reward total was -17.000000. running mean: -19.858647\n",
            "resetting env. episode 3692.000000, reward total was -21.000000. running mean: -19.870060\n",
            "resetting env. episode 3693.000000, reward total was -19.000000. running mean: -19.861360\n",
            "resetting env. episode 3694.000000, reward total was -21.000000. running mean: -19.872746\n",
            "resetting env. episode 3695.000000, reward total was -19.000000. running mean: -19.864019\n",
            "resetting env. episode 3696.000000, reward total was -20.000000. running mean: -19.865379\n",
            "resetting env. episode 3697.000000, reward total was -19.000000. running mean: -19.856725\n",
            "resetting env. episode 3698.000000, reward total was -21.000000. running mean: -19.868157\n",
            "resetting env. episode 3699.000000, reward total was -21.000000. running mean: -19.879476\n",
            "resetting env. episode 3700.000000, reward total was -21.000000. running mean: -19.890681\n",
            "resetting env. episode 3701.000000, reward total was -20.000000. running mean: -19.891774\n",
            "resetting env. episode 3702.000000, reward total was -21.000000. running mean: -19.902857\n",
            "resetting env. episode 3703.000000, reward total was -20.000000. running mean: -19.903828\n",
            "resetting env. episode 3704.000000, reward total was -20.000000. running mean: -19.904790\n",
            "resetting env. episode 3705.000000, reward total was -21.000000. running mean: -19.915742\n",
            "resetting env. episode 3706.000000, reward total was -21.000000. running mean: -19.926584\n",
            "resetting env. episode 3707.000000, reward total was -17.000000. running mean: -19.897319\n",
            "resetting env. episode 3708.000000, reward total was -19.000000. running mean: -19.888345\n",
            "resetting env. episode 3709.000000, reward total was -19.000000. running mean: -19.879462\n",
            "resetting env. episode 3710.000000, reward total was -18.000000. running mean: -19.860667\n",
            "resetting env. episode 3711.000000, reward total was -19.000000. running mean: -19.852061\n",
            "resetting env. episode 3712.000000, reward total was -21.000000. running mean: -19.863540\n",
            "resetting env. episode 3713.000000, reward total was -19.000000. running mean: -19.854905\n",
            "resetting env. episode 3714.000000, reward total was -21.000000. running mean: -19.866356\n",
            "resetting env. episode 3715.000000, reward total was -21.000000. running mean: -19.877692\n",
            "resetting env. episode 3716.000000, reward total was -21.000000. running mean: -19.888915\n",
            "resetting env. episode 3717.000000, reward total was -20.000000. running mean: -19.890026\n",
            "resetting env. episode 3718.000000, reward total was -18.000000. running mean: -19.871126\n",
            "resetting env. episode 3719.000000, reward total was -21.000000. running mean: -19.882414\n",
            "resetting env. episode 3720.000000, reward total was -21.000000. running mean: -19.893590\n",
            "resetting env. episode 3721.000000, reward total was -19.000000. running mean: -19.884654\n",
            "resetting env. episode 3722.000000, reward total was -20.000000. running mean: -19.885808\n",
            "resetting env. episode 3723.000000, reward total was -18.000000. running mean: -19.866950\n",
            "resetting env. episode 3724.000000, reward total was -21.000000. running mean: -19.878280\n",
            "resetting env. episode 3725.000000, reward total was -18.000000. running mean: -19.859497\n",
            "resetting env. episode 3726.000000, reward total was -20.000000. running mean: -19.860903\n",
            "resetting env. episode 3727.000000, reward total was -19.000000. running mean: -19.852293\n",
            "resetting env. episode 3728.000000, reward total was -20.000000. running mean: -19.853771\n",
            "resetting env. episode 3729.000000, reward total was -20.000000. running mean: -19.855233\n",
            "resetting env. episode 3730.000000, reward total was -20.000000. running mean: -19.856681\n",
            "resetting env. episode 3731.000000, reward total was -19.000000. running mean: -19.848114\n",
            "resetting env. episode 3732.000000, reward total was -19.000000. running mean: -19.839633\n",
            "resetting env. episode 3733.000000, reward total was -21.000000. running mean: -19.851236\n",
            "resetting env. episode 3734.000000, reward total was -20.000000. running mean: -19.852724\n",
            "resetting env. episode 3735.000000, reward total was -19.000000. running mean: -19.844197\n",
            "resetting env. episode 3736.000000, reward total was -21.000000. running mean: -19.855755\n",
            "resetting env. episode 3737.000000, reward total was -19.000000. running mean: -19.847197\n",
            "resetting env. episode 3738.000000, reward total was -20.000000. running mean: -19.848725\n",
            "resetting env. episode 3739.000000, reward total was -20.000000. running mean: -19.850238\n",
            "resetting env. episode 3740.000000, reward total was -21.000000. running mean: -19.861736\n",
            "resetting env. episode 3741.000000, reward total was -21.000000. running mean: -19.873118\n",
            "resetting env. episode 3742.000000, reward total was -19.000000. running mean: -19.864387\n",
            "resetting env. episode 3743.000000, reward total was -18.000000. running mean: -19.845743\n",
            "resetting env. episode 3744.000000, reward total was -21.000000. running mean: -19.857286\n",
            "resetting env. episode 3745.000000, reward total was -20.000000. running mean: -19.858713\n",
            "resetting env. episode 3746.000000, reward total was -20.000000. running mean: -19.860126\n",
            "resetting env. episode 3747.000000, reward total was -20.000000. running mean: -19.861524\n",
            "resetting env. episode 3748.000000, reward total was -20.000000. running mean: -19.862909\n",
            "resetting env. episode 3749.000000, reward total was -18.000000. running mean: -19.844280\n",
            "resetting env. episode 3750.000000, reward total was -21.000000. running mean: -19.855837\n",
            "resetting env. episode 3751.000000, reward total was -21.000000. running mean: -19.867279\n",
            "resetting env. episode 3752.000000, reward total was -20.000000. running mean: -19.868606\n",
            "resetting env. episode 3753.000000, reward total was -21.000000. running mean: -19.879920\n",
            "resetting env. episode 3754.000000, reward total was -20.000000. running mean: -19.881121\n",
            "resetting env. episode 3755.000000, reward total was -19.000000. running mean: -19.872310\n",
            "resetting env. episode 3756.000000, reward total was -20.000000. running mean: -19.873587\n",
            "resetting env. episode 3757.000000, reward total was -21.000000. running mean: -19.884851\n",
            "resetting env. episode 3758.000000, reward total was -21.000000. running mean: -19.896002\n",
            "resetting env. episode 3759.000000, reward total was -21.000000. running mean: -19.907042\n",
            "resetting env. episode 3760.000000, reward total was -19.000000. running mean: -19.897972\n",
            "resetting env. episode 3761.000000, reward total was -21.000000. running mean: -19.908992\n",
            "resetting env. episode 3762.000000, reward total was -20.000000. running mean: -19.909902\n",
            "resetting env. episode 3763.000000, reward total was -21.000000. running mean: -19.920803\n",
            "resetting env. episode 3764.000000, reward total was -20.000000. running mean: -19.921595\n",
            "resetting env. episode 3765.000000, reward total was -20.000000. running mean: -19.922379\n",
            "resetting env. episode 3766.000000, reward total was -20.000000. running mean: -19.923155\n",
            "resetting env. episode 3767.000000, reward total was -21.000000. running mean: -19.933924\n",
            "resetting env. episode 3768.000000, reward total was -21.000000. running mean: -19.944585\n",
            "resetting env. episode 3769.000000, reward total was -21.000000. running mean: -19.955139\n",
            "resetting env. episode 3770.000000, reward total was -21.000000. running mean: -19.965587\n",
            "resetting env. episode 3771.000000, reward total was -21.000000. running mean: -19.975931\n",
            "resetting env. episode 3772.000000, reward total was -21.000000. running mean: -19.986172\n",
            "resetting env. episode 3773.000000, reward total was -20.000000. running mean: -19.986310\n",
            "resetting env. episode 3774.000000, reward total was -20.000000. running mean: -19.986447\n",
            "resetting env. episode 3775.000000, reward total was -19.000000. running mean: -19.976583\n",
            "resetting env. episode 3776.000000, reward total was -19.000000. running mean: -19.966817\n",
            "resetting env. episode 3777.000000, reward total was -20.000000. running mean: -19.967149\n",
            "resetting env. episode 3778.000000, reward total was -21.000000. running mean: -19.977477\n",
            "resetting env. episode 3779.000000, reward total was -19.000000. running mean: -19.967703\n",
            "resetting env. episode 3780.000000, reward total was -21.000000. running mean: -19.978026\n",
            "resetting env. episode 3781.000000, reward total was -19.000000. running mean: -19.968245\n",
            "resetting env. episode 3782.000000, reward total was -20.000000. running mean: -19.968563\n",
            "resetting env. episode 3783.000000, reward total was -21.000000. running mean: -19.978877\n",
            "resetting env. episode 3784.000000, reward total was -21.000000. running mean: -19.989088\n",
            "resetting env. episode 3785.000000, reward total was -18.000000. running mean: -19.969198\n",
            "resetting env. episode 3786.000000, reward total was -19.000000. running mean: -19.959506\n",
            "resetting env. episode 3787.000000, reward total was -20.000000. running mean: -19.959911\n",
            "resetting env. episode 3788.000000, reward total was -20.000000. running mean: -19.960311\n",
            "resetting env. episode 3789.000000, reward total was -20.000000. running mean: -19.960708\n",
            "resetting env. episode 3790.000000, reward total was -20.000000. running mean: -19.961101\n",
            "resetting env. episode 3791.000000, reward total was -21.000000. running mean: -19.971490\n",
            "resetting env. episode 3792.000000, reward total was -20.000000. running mean: -19.971775\n",
            "resetting env. episode 3793.000000, reward total was -20.000000. running mean: -19.972058\n",
            "resetting env. episode 3794.000000, reward total was -20.000000. running mean: -19.972337\n",
            "resetting env. episode 3795.000000, reward total was -21.000000. running mean: -19.982614\n",
            "resetting env. episode 3796.000000, reward total was -20.000000. running mean: -19.982787\n",
            "resetting env. episode 3797.000000, reward total was -21.000000. running mean: -19.992960\n",
            "resetting env. episode 3798.000000, reward total was -19.000000. running mean: -19.983030\n",
            "resetting env. episode 3799.000000, reward total was -19.000000. running mean: -19.973200\n",
            "resetting env. episode 3800.000000, reward total was -19.000000. running mean: -19.963468\n",
            "resetting env. episode 3801.000000, reward total was -20.000000. running mean: -19.963833\n",
            "resetting env. episode 3802.000000, reward total was -19.000000. running mean: -19.954195\n",
            "resetting env. episode 3803.000000, reward total was -18.000000. running mean: -19.934653\n",
            "resetting env. episode 3804.000000, reward total was -20.000000. running mean: -19.935306\n",
            "resetting env. episode 3805.000000, reward total was -19.000000. running mean: -19.925953\n",
            "resetting env. episode 3806.000000, reward total was -21.000000. running mean: -19.936694\n",
            "resetting env. episode 3807.000000, reward total was -21.000000. running mean: -19.947327\n",
            "resetting env. episode 3808.000000, reward total was -20.000000. running mean: -19.947853\n",
            "resetting env. episode 3809.000000, reward total was -21.000000. running mean: -19.958375\n",
            "resetting env. episode 3810.000000, reward total was -21.000000. running mean: -19.968791\n",
            "resetting env. episode 3811.000000, reward total was -20.000000. running mean: -19.969103\n",
            "resetting env. episode 3812.000000, reward total was -20.000000. running mean: -19.969412\n",
            "resetting env. episode 3813.000000, reward total was -21.000000. running mean: -19.979718\n",
            "resetting env. episode 3814.000000, reward total was -20.000000. running mean: -19.979921\n",
            "resetting env. episode 3815.000000, reward total was -21.000000. running mean: -19.990122\n",
            "resetting env. episode 3816.000000, reward total was -18.000000. running mean: -19.970220\n",
            "resetting env. episode 3817.000000, reward total was -21.000000. running mean: -19.980518\n",
            "resetting env. episode 3818.000000, reward total was -20.000000. running mean: -19.980713\n",
            "resetting env. episode 3819.000000, reward total was -21.000000. running mean: -19.990906\n",
            "resetting env. episode 3820.000000, reward total was -18.000000. running mean: -19.970997\n",
            "resetting env. episode 3821.000000, reward total was -20.000000. running mean: -19.971287\n",
            "resetting env. episode 3822.000000, reward total was -21.000000. running mean: -19.981574\n",
            "resetting env. episode 3823.000000, reward total was -21.000000. running mean: -19.991758\n",
            "resetting env. episode 3824.000000, reward total was -20.000000. running mean: -19.991841\n",
            "resetting env. episode 3825.000000, reward total was -20.000000. running mean: -19.991922\n",
            "resetting env. episode 3826.000000, reward total was -21.000000. running mean: -20.002003\n",
            "resetting env. episode 3827.000000, reward total was -21.000000. running mean: -20.011983\n",
            "resetting env. episode 3828.000000, reward total was -20.000000. running mean: -20.011863\n",
            "resetting env. episode 3829.000000, reward total was -21.000000. running mean: -20.021745\n",
            "resetting env. episode 3830.000000, reward total was -19.000000. running mean: -20.011527\n",
            "resetting env. episode 3831.000000, reward total was -19.000000. running mean: -20.001412\n",
            "resetting env. episode 3832.000000, reward total was -20.000000. running mean: -20.001398\n",
            "resetting env. episode 3833.000000, reward total was -18.000000. running mean: -19.981384\n",
            "resetting env. episode 3834.000000, reward total was -18.000000. running mean: -19.961570\n",
            "resetting env. episode 3835.000000, reward total was -21.000000. running mean: -19.971954\n",
            "resetting env. episode 3836.000000, reward total was -20.000000. running mean: -19.972235\n",
            "resetting env. episode 3837.000000, reward total was -21.000000. running mean: -19.982512\n",
            "resetting env. episode 3838.000000, reward total was -18.000000. running mean: -19.962687\n",
            "resetting env. episode 3839.000000, reward total was -21.000000. running mean: -19.973060\n",
            "resetting env. episode 3840.000000, reward total was -21.000000. running mean: -19.983330\n",
            "resetting env. episode 3841.000000, reward total was -20.000000. running mean: -19.983496\n",
            "resetting env. episode 3842.000000, reward total was -21.000000. running mean: -19.993661\n",
            "resetting env. episode 3843.000000, reward total was -20.000000. running mean: -19.993725\n",
            "resetting env. episode 3844.000000, reward total was -21.000000. running mean: -20.003788\n",
            "resetting env. episode 3845.000000, reward total was -20.000000. running mean: -20.003750\n",
            "resetting env. episode 3846.000000, reward total was -17.000000. running mean: -19.973712\n",
            "resetting env. episode 3847.000000, reward total was -21.000000. running mean: -19.983975\n",
            "resetting env. episode 3848.000000, reward total was -18.000000. running mean: -19.964135\n",
            "resetting env. episode 3849.000000, reward total was -21.000000. running mean: -19.974494\n",
            "resetting env. episode 3850.000000, reward total was -21.000000. running mean: -19.984749\n",
            "resetting env. episode 3851.000000, reward total was -20.000000. running mean: -19.984902\n",
            "resetting env. episode 3852.000000, reward total was -21.000000. running mean: -19.995053\n",
            "resetting env. episode 3853.000000, reward total was -21.000000. running mean: -20.005102\n",
            "resetting env. episode 3854.000000, reward total was -20.000000. running mean: -20.005051\n",
            "resetting env. episode 3855.000000, reward total was -19.000000. running mean: -19.995001\n",
            "resetting env. episode 3856.000000, reward total was -19.000000. running mean: -19.985051\n",
            "resetting env. episode 3857.000000, reward total was -21.000000. running mean: -19.995200\n",
            "resetting env. episode 3858.000000, reward total was -19.000000. running mean: -19.985248\n",
            "resetting env. episode 3859.000000, reward total was -20.000000. running mean: -19.985396\n",
            "resetting env. episode 3860.000000, reward total was -20.000000. running mean: -19.985542\n",
            "resetting env. episode 3861.000000, reward total was -18.000000. running mean: -19.965686\n",
            "resetting env. episode 3862.000000, reward total was -21.000000. running mean: -19.976029\n",
            "resetting env. episode 3863.000000, reward total was -21.000000. running mean: -19.986269\n",
            "resetting env. episode 3864.000000, reward total was -19.000000. running mean: -19.976406\n",
            "resetting env. episode 3865.000000, reward total was -19.000000. running mean: -19.966642\n",
            "resetting env. episode 3866.000000, reward total was -20.000000. running mean: -19.966976\n",
            "resetting env. episode 3867.000000, reward total was -19.000000. running mean: -19.957306\n",
            "resetting env. episode 3868.000000, reward total was -20.000000. running mean: -19.957733\n",
            "resetting env. episode 3869.000000, reward total was -19.000000. running mean: -19.948156\n",
            "resetting env. episode 3870.000000, reward total was -19.000000. running mean: -19.938674\n",
            "resetting env. episode 3871.000000, reward total was -21.000000. running mean: -19.949287\n",
            "resetting env. episode 3872.000000, reward total was -20.000000. running mean: -19.949795\n",
            "resetting env. episode 3873.000000, reward total was -21.000000. running mean: -19.960297\n",
            "resetting env. episode 3874.000000, reward total was -21.000000. running mean: -19.970694\n",
            "resetting env. episode 3875.000000, reward total was -21.000000. running mean: -19.980987\n",
            "resetting env. episode 3876.000000, reward total was -19.000000. running mean: -19.971177\n",
            "resetting env. episode 3877.000000, reward total was -17.000000. running mean: -19.941465\n",
            "resetting env. episode 3878.000000, reward total was -21.000000. running mean: -19.952050\n",
            "resetting env. episode 3879.000000, reward total was -17.000000. running mean: -19.922530\n",
            "resetting env. episode 3880.000000, reward total was -19.000000. running mean: -19.913305\n",
            "resetting env. episode 3881.000000, reward total was -20.000000. running mean: -19.914172\n",
            "resetting env. episode 3882.000000, reward total was -21.000000. running mean: -19.925030\n",
            "resetting env. episode 3883.000000, reward total was -19.000000. running mean: -19.915780\n",
            "resetting env. episode 3884.000000, reward total was -21.000000. running mean: -19.926622\n",
            "resetting env. episode 3885.000000, reward total was -17.000000. running mean: -19.897356\n",
            "resetting env. episode 3886.000000, reward total was -19.000000. running mean: -19.888382\n",
            "resetting env. episode 3887.000000, reward total was -20.000000. running mean: -19.889498\n",
            "resetting env. episode 3888.000000, reward total was -20.000000. running mean: -19.890603\n",
            "resetting env. episode 3889.000000, reward total was -19.000000. running mean: -19.881697\n",
            "resetting env. episode 3890.000000, reward total was -20.000000. running mean: -19.882880\n",
            "resetting env. episode 3891.000000, reward total was -21.000000. running mean: -19.894051\n",
            "resetting env. episode 3892.000000, reward total was -21.000000. running mean: -19.905111\n",
            "resetting env. episode 3893.000000, reward total was -21.000000. running mean: -19.916060\n",
            "resetting env. episode 3894.000000, reward total was -21.000000. running mean: -19.926899\n",
            "resetting env. episode 3895.000000, reward total was -19.000000. running mean: -19.917630\n",
            "resetting env. episode 3896.000000, reward total was -17.000000. running mean: -19.888454\n",
            "resetting env. episode 3897.000000, reward total was -21.000000. running mean: -19.899569\n",
            "resetting env. episode 3898.000000, reward total was -20.000000. running mean: -19.900574\n",
            "resetting env. episode 3899.000000, reward total was -21.000000. running mean: -19.911568\n",
            "resetting env. episode 3900.000000, reward total was -20.000000. running mean: -19.912452\n",
            "resetting env. episode 3901.000000, reward total was -20.000000. running mean: -19.913328\n",
            "resetting env. episode 3902.000000, reward total was -21.000000. running mean: -19.924194\n",
            "resetting env. episode 3903.000000, reward total was -21.000000. running mean: -19.934952\n",
            "resetting env. episode 3904.000000, reward total was -20.000000. running mean: -19.935603\n",
            "resetting env. episode 3905.000000, reward total was -21.000000. running mean: -19.946247\n",
            "resetting env. episode 3906.000000, reward total was -19.000000. running mean: -19.936784\n",
            "resetting env. episode 3907.000000, reward total was -19.000000. running mean: -19.927417\n",
            "resetting env. episode 3908.000000, reward total was -21.000000. running mean: -19.938142\n",
            "resetting env. episode 3909.000000, reward total was -16.000000. running mean: -19.898761\n",
            "resetting env. episode 3910.000000, reward total was -19.000000. running mean: -19.889773\n",
            "resetting env. episode 3911.000000, reward total was -20.000000. running mean: -19.890876\n",
            "resetting env. episode 3912.000000, reward total was -18.000000. running mean: -19.871967\n",
            "resetting env. episode 3913.000000, reward total was -19.000000. running mean: -19.863247\n",
            "resetting env. episode 3914.000000, reward total was -20.000000. running mean: -19.864615\n",
            "resetting env. episode 3915.000000, reward total was -21.000000. running mean: -19.875969\n",
            "resetting env. episode 3916.000000, reward total was -20.000000. running mean: -19.877209\n",
            "resetting env. episode 3917.000000, reward total was -17.000000. running mean: -19.848437\n",
            "resetting env. episode 3918.000000, reward total was -18.000000. running mean: -19.829952\n",
            "resetting env. episode 3919.000000, reward total was -18.000000. running mean: -19.811653\n",
            "resetting env. episode 3920.000000, reward total was -20.000000. running mean: -19.813536\n",
            "resetting env. episode 3921.000000, reward total was -21.000000. running mean: -19.825401\n",
            "resetting env. episode 3922.000000, reward total was -21.000000. running mean: -19.837147\n",
            "resetting env. episode 3923.000000, reward total was -20.000000. running mean: -19.838776\n",
            "resetting env. episode 3924.000000, reward total was -19.000000. running mean: -19.830388\n",
            "resetting env. episode 3925.000000, reward total was -21.000000. running mean: -19.842084\n",
            "resetting env. episode 3926.000000, reward total was -21.000000. running mean: -19.853663\n",
            "resetting env. episode 3927.000000, reward total was -20.000000. running mean: -19.855126\n",
            "resetting env. episode 3928.000000, reward total was -20.000000. running mean: -19.856575\n",
            "resetting env. episode 3929.000000, reward total was -20.000000. running mean: -19.858009\n",
            "resetting env. episode 3930.000000, reward total was -18.000000. running mean: -19.839429\n",
            "resetting env. episode 3931.000000, reward total was -19.000000. running mean: -19.831035\n",
            "resetting env. episode 3932.000000, reward total was -19.000000. running mean: -19.822725\n",
            "resetting env. episode 3933.000000, reward total was -18.000000. running mean: -19.804497\n",
            "resetting env. episode 3934.000000, reward total was -20.000000. running mean: -19.806452\n",
            "resetting env. episode 3935.000000, reward total was -20.000000. running mean: -19.808388\n",
            "resetting env. episode 3936.000000, reward total was -20.000000. running mean: -19.810304\n",
            "resetting env. episode 3937.000000, reward total was -20.000000. running mean: -19.812201\n",
            "resetting env. episode 3938.000000, reward total was -21.000000. running mean: -19.824079\n",
            "resetting env. episode 3939.000000, reward total was -21.000000. running mean: -19.835838\n",
            "resetting env. episode 3940.000000, reward total was -21.000000. running mean: -19.847480\n",
            "resetting env. episode 3941.000000, reward total was -18.000000. running mean: -19.829005\n",
            "resetting env. episode 3942.000000, reward total was -20.000000. running mean: -19.830715\n",
            "resetting env. episode 3943.000000, reward total was -18.000000. running mean: -19.812408\n",
            "resetting env. episode 3944.000000, reward total was -21.000000. running mean: -19.824284\n",
            "resetting env. episode 3945.000000, reward total was -20.000000. running mean: -19.826041\n",
            "resetting env. episode 3946.000000, reward total was -21.000000. running mean: -19.837781\n",
            "resetting env. episode 3947.000000, reward total was -19.000000. running mean: -19.829403\n",
            "resetting env. episode 3948.000000, reward total was -20.000000. running mean: -19.831109\n",
            "resetting env. episode 3949.000000, reward total was -19.000000. running mean: -19.822798\n",
            "resetting env. episode 3950.000000, reward total was -19.000000. running mean: -19.814570\n",
            "resetting env. episode 3951.000000, reward total was -19.000000. running mean: -19.806424\n",
            "resetting env. episode 3952.000000, reward total was -18.000000. running mean: -19.788360\n",
            "resetting env. episode 3953.000000, reward total was -20.000000. running mean: -19.790476\n",
            "resetting env. episode 3954.000000, reward total was -20.000000. running mean: -19.792571\n",
            "resetting env. episode 3955.000000, reward total was -20.000000. running mean: -19.794646\n",
            "resetting env. episode 3956.000000, reward total was -20.000000. running mean: -19.796699\n",
            "resetting env. episode 3957.000000, reward total was -20.000000. running mean: -19.798732\n",
            "resetting env. episode 3958.000000, reward total was -21.000000. running mean: -19.810745\n",
            "resetting env. episode 3959.000000, reward total was -18.000000. running mean: -19.792637\n",
            "resetting env. episode 3960.000000, reward total was -21.000000. running mean: -19.804711\n",
            "resetting env. episode 3961.000000, reward total was -21.000000. running mean: -19.816664\n",
            "resetting env. episode 3962.000000, reward total was -19.000000. running mean: -19.808497\n",
            "resetting env. episode 3963.000000, reward total was -21.000000. running mean: -19.820412\n",
            "resetting env. episode 3964.000000, reward total was -21.000000. running mean: -19.832208\n",
            "resetting env. episode 3965.000000, reward total was -20.000000. running mean: -19.833886\n",
            "resetting env. episode 3966.000000, reward total was -20.000000. running mean: -19.835547\n",
            "resetting env. episode 3967.000000, reward total was -20.000000. running mean: -19.837192\n",
            "resetting env. episode 3968.000000, reward total was -20.000000. running mean: -19.838820\n",
            "resetting env. episode 3969.000000, reward total was -19.000000. running mean: -19.830432\n",
            "resetting env. episode 3970.000000, reward total was -15.000000. running mean: -19.782127\n",
            "resetting env. episode 3971.000000, reward total was -21.000000. running mean: -19.794306\n",
            "resetting env. episode 3972.000000, reward total was -20.000000. running mean: -19.796363\n",
            "resetting env. episode 3973.000000, reward total was -18.000000. running mean: -19.778399\n",
            "resetting env. episode 3974.000000, reward total was -19.000000. running mean: -19.770615\n",
            "resetting env. episode 3975.000000, reward total was -21.000000. running mean: -19.782909\n",
            "resetting env. episode 3976.000000, reward total was -19.000000. running mean: -19.775080\n",
            "resetting env. episode 3977.000000, reward total was -19.000000. running mean: -19.767329\n",
            "resetting env. episode 3978.000000, reward total was -21.000000. running mean: -19.779656\n",
            "resetting env. episode 3979.000000, reward total was -20.000000. running mean: -19.781859\n",
            "resetting env. episode 3980.000000, reward total was -18.000000. running mean: -19.764041\n",
            "resetting env. episode 3981.000000, reward total was -21.000000. running mean: -19.776400\n",
            "resetting env. episode 3982.000000, reward total was -20.000000. running mean: -19.778636\n",
            "resetting env. episode 3983.000000, reward total was -21.000000. running mean: -19.790850\n",
            "resetting env. episode 3984.000000, reward total was -20.000000. running mean: -19.792942\n",
            "resetting env. episode 3985.000000, reward total was -20.000000. running mean: -19.795012\n",
            "resetting env. episode 3986.000000, reward total was -18.000000. running mean: -19.777062\n",
            "resetting env. episode 3987.000000, reward total was -20.000000. running mean: -19.779291\n",
            "resetting env. episode 3988.000000, reward total was -21.000000. running mean: -19.791499\n",
            "resetting env. episode 3989.000000, reward total was -20.000000. running mean: -19.793584\n",
            "resetting env. episode 3990.000000, reward total was -21.000000. running mean: -19.805648\n",
            "resetting env. episode 3991.000000, reward total was -20.000000. running mean: -19.807591\n",
            "resetting env. episode 3992.000000, reward total was -18.000000. running mean: -19.789515\n",
            "resetting env. episode 3993.000000, reward total was -19.000000. running mean: -19.781620\n",
            "resetting env. episode 3994.000000, reward total was -19.000000. running mean: -19.773804\n",
            "resetting env. episode 3995.000000, reward total was -18.000000. running mean: -19.756066\n",
            "resetting env. episode 3996.000000, reward total was -21.000000. running mean: -19.768505\n",
            "resetting env. episode 3997.000000, reward total was -21.000000. running mean: -19.780820\n",
            "resetting env. episode 3998.000000, reward total was -17.000000. running mean: -19.753012\n",
            "resetting env. episode 3999.000000, reward total was -20.000000. running mean: -19.755482\n",
            "resetting env. episode 4000.000000, reward total was -21.000000. running mean: -19.767927\n",
            "CPU times: user 3h 54min 42s, sys: 1h 43min 54s, total: 5h 38min 36s\n",
            "Wall time: 2h 56min 20s\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "8fheN9DRlWXQ",
        "outputId": "8ad0ca8e-9838-4430-aa60-fa6ac82dc634",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "cell_type": "code",
      "source": [
        "play_game(env, model)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode finished without success, accumulated reward = -6.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 320x420 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}